**计算机书籍**

https://github.com/HeroHai/it-pdf-books

**力扣刷题笔记**

[笔记1](https://books.halfrost.com/leetcode/)

**书籍-后端**

https://tobebetterjavaer.com/xuexiluxian/os.html

https://www.javaweb.shop/article/144.html

https://www.manongbook.com/other/998.html

[很全的仓库](https://github.com/forthespada/CS-Books)

[结构很好](https://xie.infoq.cn/article/207aab244ae44b9fc5c71a059)

[github仓库1](https://github.com/7-sevens/Developer-Books)

[仓库2](https://github.com/jobbole/awesome-programming-books)

[外网私货](https://github.com/programthink/books)

https://github.com/lancetw/ebook-1

**书籍-人工智能**

[机器学习面试](https://github.com/murufeng/Awesome-AI-algorithm)

[AI项目](https://github.com/cbamls/AI_Tutorial)

[AI找工作成长路线](https://github.com/amusi/AI-Job-Notes)

[AI网安工作成长路线](https://github.com/0xMJ/AI-Security-Learning)

[AI不同领域的论文](https://github.com/BINPIPE/learning-resources/blob/master/ai.md#DL)

[AI应用领域](https://github.com/romanlutz/ResponsibleAI)

[中文资料](https://github.com/wx-chevalier/AI-Series)

[外文资料](https://github.com/ahmedbahaaeldin/From-0-to-Research-Scientist-resources-guide)

[外文资料](https://github.com/owainlewis/awesome-artificial-intelligence)

[资料](https://github.com/foochane/books)

[比较喜欢的仓库-人工智能](https://github.com/ruanyf/free-books)

[人工智能](https://github.com/fengdu78/deeplearning_ai_books)

[大数据](https://github.com/justjavac/free-programming-books-zh_CN#%E5%A4%A7%E6%95%B0%E6%8D%AE)

**面试问题**

[资料](https://github.com/huihut/interview#os)

[电子书网站](https://www.book123.info/)

# 自我介绍和实习项目相关

项目整体介绍、难点、亮点、针对某点进行提问，如果要xxx，你要怎么解决（10分钟）

## Java项目

[廖雪峰](https://www.liaoxuefeng.com/wiki/1252599548343744/1282383921807393)

## Java项目-字节跳动第三届青训营-搜索引擎设计

### Elastic Search

大咖驾到，很牛逼，涉及数据库机器学习等，讲elasticsearch很详细，为什么有了MySQL而还要用ElasticSearch(https://www.cnblogs.com/purple5252/p/14751081.html)

https://baike.baidu.com/item/elasticsearch/3411206?fr=aladdin

为什么有了ElasticSearch还要用MySQL： https://blog.csdn.net/weixin_44166705/article/details/121023662

https://zhuanlan.zhihu.com/p/373542604

https://blog.51cto.com/u_15259710/3189628

https://z.itpub.net/article/detail/0AA856CBD67F89CC0DF45928079122F9

https://blog.csdn.net/laoyang360/article/details/52227541

https://www.51cto.com/article/665240.html

ElasticSearch是一个分布式存储数据库，他和Redis，MySQL一样都是分布式存储数据库，那么这三个的区别是什么呢。MySQL是关系型数据库，Redis是基于键值对的非关系型数据库，ElasticSearch是基于倒排索引的非关系型数据库。MySQL和Redis支持事务，而ElasticSearch不支持。MySQL适合海量数据存储，但是不适合海量数据查询，有人说可以建立索引，但是有时候索引文件可能比实际的文件更大，其次，MySQL在使用索引的时候遵循最左匹配原则，那么我们的一些查询如果没有遵循就不能使用索引了，其次有些情况是没办法使用数据库的，比如like ”aaa“命令就不会使用索引而会触发全表查询，这个很耗时，也就是说MySQL全表查询性能很差；而ElasticSearch基于倒排索引（将文档的单词进行切分，然后每个单词都映射到一个文档列表保存这个单词出现的文档id），如果我们查询aaa，可以直接从倒排索引的切分的单词匹配，然后找到对应的文档，在MySQL中，这个文档可以存储MySQL的一个行数据，也就说ElasticSearch对全表查询支持友好。那么为什么不直接使用ElasticSearch存储而不用MySQL呢？因为MySQL支持事务，而ElasticSearch不支持事务，不能保证数据安全，所以生产环境中，我们使用MySQL来保证事务安全修改数据，使用ElasticSearch提供对MySQL的全表查询支持。ElasticSearch对PB（10亿级别的数据）的数据可以做到毫秒相应。而Redis数据库是内存数据库，是为了缓存加速MySQL数据库的。ElasticSearch、MySQL、Redis都可以做为分布式存储数据库，支持主从复制。ElasticSearch主要用于订单查询、日志查询等工作。

Redis是内存的key-value数据库，MySQL是结构化的关系型的数据库，ElasticSearch是倒排索引的数据库，HDFS（Hadoop，Hbase）是稀疏矩阵的数据库。

### 项目实现

https://github.com/optimjie/bytedance-youthcamp-search-engine

## Go项目-字节跳动第三届青训营-极简抖音后端开发

### 字节跳动第三届青训营-极简抖音后端开发

#### 后续问题

##### Nginx反向代理

##### docker微服务架构 kitex等

##### 消息队列RabbitMQ

#### 对象存储

https://blog.51cto.com/u_15492050/5162392

#### Go语言

http://v5blog.cn/pages/82f359/#_1-1-string

#### 一些报错的学习

**Upload file failed, nginx reset by peer**

> **docker常用命令**
>
> https://blog.csdn.net/Jjavaer/article/details/123525085
>
> > docker info:  查看docker配置信息
> >
> > docker images： 查看docker所有镜像
> >
> > docker ps -a : 查看docker创建的所有镜像进程，可以看到他们的运行状态，包括已经停止的进程
> >
> > ps aux： 查看Linux运行进程，包括docker镜像内的进程
> >
> > docker run image_id： 根据容器id启动容器
> >
> > docker run -it repository:tag /bin/bash: 在容器reapository:tag中执行命令
> >
> > docker exec -it（container id） bash:  进入容器，可以在Linux的shell中看到进入到容器内部（命令开头变成root@容器id)
> >
> > docker stop (container id) ： 停止容器运行
> >
> > docker start (container id) ： 启动已经停止的容器
> >
> > docker rm container-id： 删除指定id 的容器
>
> **connection reset by peer  出错问题总结**
>
> https://www.cnblogs.com/exmyth/p/8672076.html
>
> https://blog.csdn.net/qq_45814695/article/details/118660306
>
> https://blog.csdn.net/qq_45814695/article/details/118660306
>
> [connection reset by peer全面总结]https://dyrnq.com/docker-curl-56-recv-failure-connection-reset-by-peer/   （防火墙原因，容器退出原因，容器端口原因，容器端口映射，容器没有监听0.0.0.0）
>
> https://juejin.cn/post/7007446539190665230
>
> 上面总结了connection reset by peer的问题出现原因，其中一个是服务器没有这个端口的服务，出现这个原因上述发生的有：一种是服务监听端口不是我们需要的端口导致我们请求到一个没有服务的端口；一种是docker镜像文件失效，导致没有创建docker镜像容器；一种是dcoker创建了镜像容器但是容器发生了退出，这在nginx中可能出现，因为nginx是后台运行程序，docker根据容器Linux的1号进程状态来查看容器是否退出，因为nginx后台运行，那么一号进程执行完运行nginx的后台运行程序命令之后自己挂起，docker发现这个容器的1号进程挂起，默认这个容器已经没有工作可以做就会退出这个容器，导致这个容器的服务nginx不存在了退出了
>
> 我们使用docker ps -a发现nginx退出了，思考一下就是出现了上面的第三个原因，所以我们要让nginx持久运行，可以取消nginx后台运行
>
> https://segmentfault.com/q/1010000012210376/a-1020000012214732
>
> 我们可以使用**sudo docker start 31982c00680a && sudo docker exec -it 31982c00680a  bash**命令来让nginx启动保证运行为1号进程，但是怎么在docker-compose.yml中设置？具体设置如下，也就是要设置daemon off
>
> ```
>   nginx:
>     image: nginx:alpine
>     hostname: nginx
>     volumes:
>       - ./config/nginx.conf:/etc/nginx/nginx.conf:ro
>       - ./log/nginx:/var/log/nginx:rw
>       - ./data/cache/nginx:/usr/local/nginx/conf/cache:rw
>     command: nginx -g "daemon off;"
>     ports:
>       - "9000:9000"
>       - "9001:9001"
>     depends_on:
>       - minio1
>       - minio2
>       - minio3
>       - minio4
> ```
>
> 

**Golang一个测试文件出现函数变量未定义**

> https://blog.csdn.net/weixin_40841243/article/details/103853784
>
> 这是因为go test 命令只会使用后面接着的显示指出的go文件创建测试，如果不包含我们要测试的函数文件，那么测试文件就找不到函数文件，所以需要显示在go test命令中指出需要被测试的文件。
>
> go test -v TestUser_test.go   User.go

#### 中间件

https://aws.amazon.com/cn/what-is/middleware/#:~:text=%E4%B8%AD%E9%97%B4%E4%BB%B6%E6%98%AF%E6%8C%87%E4%B8%8D%E5%90%8C,%E5%85%B6%E7%94%A8%E6%88%B7%E6%8F%90%E4%BE%9B%E7%BB%9F%E4%B8%80%E6%9C%8D%E5%8A%A1%E3%80%82

https://baike.baidu.com/item/%E4%B8%AD%E9%97%B4%E4%BB%B6/452240

中间件是连接不同语言、不同系统、不同数据库的桥梁，是一个独立程序。可以用他来集成不同版本、不同语言、不同数据库的软件称为一个系统。中间件涉及到网络通信，传递数据一般使用JSON等。

### 项目实现

https://gjj3nncz08.feishu.cn/docx/doxcnJGyQHB30zcOkkT3CkTC6Oc

https://github.com/goldenBill/douyin-fighting

项目实现代码放到实现文件中。

**Redis开发建议**

https://blog.csdn.net/xzpdskll/article/details/81284457

> 1.冷热数据分离，不要将所有数据全部都放到Redis中
> 虽然Redis支持持久化，但是Redis的数据存储全部都是在内存中的，成本昂贵。建议根据业务只将高频热数据存储到Redis中【QPS大于5000】，对于低频冷数据可以使用MySQL/ElasticSearch/MongoDB等基于磁盘的存储方式，不仅节省内存成本，而且数据量小在操作时速度更快、效率更高！
>
> 2.不同的业务数据要分开存储
> 不要将不相关的业务数据都放到一个Redis实例中，建议新业务申请新的单独实例。因为Redis为单线程处理，独立存储会减少不同业务相互操作的影响，提高请求响应速度；同时也避免单个实例内存数据量膨胀过大，在出现异常情况时可以更快恢复服务！ 在实际的使用过程中，redis最大的瓶颈一般是CPU，由于它是单线程作业所以很容易跑满一个逻辑CPU，可以使用redis代理或者是分布式方案来提升redis的CPU使用率。
>
> 3.存储的Key一定要设置超时时间
> 如果应用将Redis定位为缓存Cache使用，对于存放的Key一定要设置超时时间！因为若不设置，这些Key会一直占用内存不释放，造成极大的浪费，而且随着时间的推移会导致内存占用越来越大，直到达到服务器内存上限！另外Key的超时长短要根据业务综合评估，而不是越长越好！
>
> 4.对于必须要存储的大文本数据一定要压缩后存储
> 对于大文本【+超过500字节】写入到Redis时，一定要压缩后存储！大文本数据存入Redis，除了带来极大的内存占用外，在访问量高时，很容易就会将网卡流量占满，进而造成整个服务器上的所有服务不可用，并引发雪崩效应，造成各个系统瘫痪！
>
> 5.线上Redis禁止使用Keys正则匹配操作
> Redis是单线程处理，在线上KEY数量较多时，操作效率极低【时间复杂度为O(N)】，该命令一旦执行会严重阻塞线上其它命令的正常请求，而且在高QPS情况下会直接造成Redis服务崩溃！如果有类似需求，请使用scan命令代替！
>
> 6.可靠的消息队列服务
> Redis List经常被用于消息队列服务。假设消费者程序在从队列中取出消息后立刻崩溃，但由于该消息已经被取出且没有被正常处理，那么可以认为该消息已经丢失，由此可能会导致业务数据丢失，或业务状态不一致等现象发生。
>
> 为了避免这种情况，Redis提供了RPOPLPUSH命令，消费者程序会原子性的从主消息队列中取出消息并将其插入到备份队列中，直到消费者程序完成正常的处理逻辑后再将该消息从备份队列中删除。同时还可以提供一个守护进程，当发现备份队列中的消息过期时，可以重新将其再放回到主消息队列中，以便其它的消费者程序继续处理。
>
> 7.谨慎全量操作Hash、Set等集合结构
> 在使用HASH结构存储对象属性时，开始只有有限的十几个field，往往使用HGETALL获取所有成员，效率也很高，但是随着业务发展，会将field扩张到上百个甚至几百个，此时还使用HGETALL会出现效率急剧下降、网卡频繁打满等问题【时间复杂度O(N)】,此时建议根据业务拆分为多个Hash结构；或者如果大部分都是获取所有属性的操作,可以将所有属性序列化为一个STRING类型存储！同样在使用SMEMBERS操作SET结构类型时也是相同的情况！
>
> 8.根据业务场景合理使用不同的数据结构类型
> 目前Redis支持的数据库结构类型较多：字符串（String），哈希（Hash），列表（List），集合（Set），有序集合（Sorted Set）, Bitmap, HyperLogLog和地理空间索引（geospatial）等,需要根据业务场景选择合适的类型。
>
> 常见的如：String可以用作普通的K-V、计数类；Hash可以用作对象如商品、经纪人等，包含较多属性的信息；List可以用作消息队列、粉丝/关注列表等；Set可以用于推荐；Sorted Set可以用于排行榜等！
>
> 9.命名规范
> 虽然说Redis支持多个数据库（默认32个，可以配置更多），但是除了默认的0号库以外，其它的都需要通过一个额外请求才能使用。所以用前缀作为命名空间可能会更明智一点。
>
> 另外，在使用前缀作为命名空间区隔不同key的时候，最好在程序中使用全局配置来实现，直接在代码里写前缀的做法要严格避免，这样可维护性实在太差了。
>
> 如：系统名:业务名:业务数据:其他
>
> 但是注意，key的名称不要过长，尽量清晰明了，容易理解，需要自己衡量
>
> 10.线上禁止使用monitor命令
> 禁止生产环境使用monitor命令，monitor命令在高并发条件下，会存在内存暴增和影响Redis性能的隐患
>
> 11.禁止大string
> 核心集群禁用1mb的string大key(虽然redis支持512MB大小的string)，如果1mb的key每秒重复写入10次，就会导致写入网络IO达10MB;
>
> 12.redis容量
> 单实例的内存大小不建议过大，建议在10~20GB以内。
>
> redis实例包含的键个数建议控制在1kw内，单实例键个数过大，可能导致过期键的回收不及时。
>
> dxdiag可以查看windows内存大小
>
> CPU所能使用内存大小受限于CPU地址总线长度，32位CPU有32个地址总线，可以寻址4G，64位CPU有64个地址总线，可以寻址16G*G=16\*10^12=16万亿内存单元=4万亿个int
>
> 13 可靠性
> 需要定时监控redis的健康情况：使用各种redis健康监控工具，实在不行可以定时返回redis 的 info信息。
>
> 客户端连接尽量使用连接池（长链接和自动重连）

**Redis非关系型数据库和关系型数据库区别**

https://blog.csdn.net/qq_47905231/article/details/125107677

https://blog.csdn.net/m0_55955242/article/details/118856728

#### 技术选型和项目架构

##### 项目架构

本项目采用 MVC 分层设计模型分离模型层、视图层和控制层，从而降低代码的耦合度，提高项目的可维护性。使用 Gin 作为 Web 框架，Redis 作为缓存框架，MySQL 作为持久层框架。

![Screenshot 2022-10-29 151836](实验\6 Web设计\图片\Screenshot 2022-10-29 151836.png)

##### 技术选型

Gin, Gorm, Redis, MySQL, Viper, ffmpeg

#### 接口和业务逻辑实现

##### 视频发布推送

###### /douyin/feed - 视频流接口

> **功能描述**
>
> 不限制登录状态，返回按投稿时间倒序的视频列表，视频数由服务端控制，单次最多30个。
>
> **接口类型**
>
> GET
>
> **接口定义**
>
> ```go
> package douyin.core;
> 
> 
> 
> message douyin_feed_request {
> 
>   optional int64 latest_time = 1; *// 可选参数，限制返回视频的最新投稿时间戳，精确到秒，不填表示当前时间*
> 
>   optional string token = 2； *// 可选参数，登录用户设置*
> 
> }
> 
> 
> 
> message douyin_feed_response {
> 
>   required int32 status_code = 1; *// 状态码，0-成功，其他值-失败*
> 
>   optional string status_msg = 2; *// 返回状态描述*
> 
>   repeated Video video_list = 3; *// 视频列表*
> 
>   optional int64 next_time = 4; *// 本次返回的视频中，发布最早的时间，作为下次请求时的latest_time*
> 
> }
> 
> 
> 
> message Video {
> 
>   required int64 id = 1; *// 视频唯一标识*
> 
>   required User author = 2; *// 视频作者信息*
> 
>   required string play_url = 3; *// 视频播放地址*
> 
>   required string cover_url = 4; *// 视频封面地址*
> 
>   required int64 favorite_count = 5; *// 视频的点赞总数*
> 
>   required int64 comment_count = 6; *// 视频的评论总数*
> 
>   required bool is_favorite = 7; *// true-已点赞，false-未点赞*
> 
>   required string title = 8; *// 视频标题*
> 
> }
> 
> 
> 
> message User {
> 
>   required int64 id = 1; *// 用户id*
> 
>   required string name = 2; *// 用户名称*
> 
>   optional int64 follow_count = 3; *// 关注总数*
> 
>   optional int64 follower_count = 4; *// 粉丝总数*
> 
>   required bool is_follow = 5; *// true-已关注，false-未关注*
> 
> }
> ```

显然，用户刷视频是短视频app中最高频的操作，也是整个后端架构最大的性能瓶颈之一。我们先从业务需求上来分析如何设计一个合理的架构以提高性能。

业务上的要求是“不限制登录状态，返回按投稿时间倒序的视频列表，视频数由服务端控制，单次最多30个”，客户端会传入两个参数“latest_time”与“token”。

对于“latest_time”参数，表示的限制返回视频的最新投稿时间戳，精确到秒，不填表示当前时间。但需要注意的是，经过测试我们发现客户端传递的参数实际上是精确到毫秒的， 所以我们对时间统一使用了UnixMilli()函数(UnixMilli函数返回从1970年1月1日以来的毫秒数作为时间内戳，这是一个10的12次方的数，需要64位8个字节进行存储，如果直接存储2022/10/11使用 ）去获取时间戳。

```go

var CurrentTimeInt = time.Now().UnixMilli()

var CurrentTime = strconv.FormatInt(CurrentTimeInt, 10)

var LatestTimeStr = c.DefaultQuery("latest_time", CurrentTime)
```

对于“token”参数，我们可以理解为是用户的登陆状态。此参数仍然是一个非必须的参数，也就是说用户没有登录的时候仍然可以完成刷视频的操作。 登录的意义在于我们给客户端返回的json中可以判断用户是否点赞了视频，是否关注了视频的作者。当用户没有登录时，我们将其设为false。

显然，实现此功能至少需要videos和users两张表。设计上的难点则在于我们的video表中是否需要去存储favorite_count与comment_count。

在不使用redis缓存的时候，我们认为在mysql中加入这两个字段是更好的。对比两者的话，加入这两个字段的好处是我们在调用feed接口的时候可以更快速的得到这两个值，无需再去favorites表与comments表中做count运算；不加入的好处则是降低数据的冗余，减少每次点赞和评论的数据库写操作。综合比较我们认为，前者更符合实际场景，因为feed是最高频的操作，用一次数据库的写操作去提高后端的响应速度我觉得是可以接受的。

但是在使用redis缓存时，我们认为可以去掉mysql中的这两个字段，将其存入redis中。这样做的唯一缺点是，当redis中的一些视频失效时，我们访问这些key的时候需要在favorites表以及comments表做count操作来统计评论数以及点赞数。但显然，短视频app的一大特点就是数据有冷热效应，每个视频的访问量分布是非常不均匀的。热门视频的key显然不会失效，用一次 redis上的写操作去代替sql上的写操作，显然是很划算的。

至此，我们的videos表已经设计完毕，接下来分析一下不同场景下的mysql与redis的读写操作。

先来看看推送视频操作，如果使用mysql的话，代码如下

```mysql
SELECT * FROM videos WHERE created_at < latest_time ORDER BY created_at DESC LIMIT 30
```

注意其中的DESC倒序是应该要输出最新的30条视频而不是最旧的30条视频。显然，上述语句几乎是我们整个短视频app中被最频繁调用的，而且其并不够高效，所以我们决定使用redis来加速数据读取。我们通过redis中的有序集合实现此功能，将key设为feed，score设为视频发布的时间戳，value就存对应的video_id，基于zrevrangebyscore去做时间戳的范围查找，实现feed功能。与此同时，我们在每次服务启动时都会从mysql中加载数据写入feed，并且不对feed设置过期时间，确保这个key是不会失效的。

当我们从redis中的feed拿到了后端要返回的全部video_id时，我们需要拿这些id去redis查找视频的全部信息。但是我们会对每个视频设置过期时间，当我们访问了在缓存中已经过期的视频，发生了cache miss时，我们不得不去从mysql中查询视频的相应信息。如技术亮点中提到，我们会采用批处理操作来处理此问题。当我们从redis中拿到了这次要返回的全部视频id时，我们逐一判断每个id是否在redis中，如果在redis中，我们直接从里面拿数据，如果不在redis中，我们将发生cache miss的video_id存入一个切片，最后批量从mysql查询。

紧接着，我们使用相似的操作从comments表以及favorites表中批量查询视频的评论数以及点赞数，最后返回全部数据，并将查询到的视频数据统一写入缓存。批量查询的思路贯穿着我们整个项目，拿到视频信息后，我们再批量查询这些视频的作者的信息，当用户处于登陆状态时，再查询当前用户是否点赞了这些视频，以及当前用户是否关注了这些视频的作者。

###### /douyin/publish - 视频投稿

> 登录用户选择视频上传。
>
> **接口类型**
>
> POST
>
> **接口定义**
>
> ```go
> syntax = "proto2";
> 
> package douyin.core;
> 
> 
> 
> message douyin_publish_action_request {
> 
>   required string token = 1; *// 用户鉴权token*
> 
>   required bytes data = 2; *// 视频数据*
> 
>   required string title = 3; *// 视频标题*
> 
> }
> 
> 
> 
> message douyin_publish_action_response {
> 
>   required int32 status_code = 1; *// 状态码，0-成功，其他值-失败*
> 
>   optional string status_msg = 2; *// 返回状态描述*
> 
> }
> ```
>
> 

投稿接口的业务需求简单明确，就是接收用户上传的视频。

如技术亮点中所述，在中间件完成安全性校验后，我们将视频存入服务器并生成封面。因为经济原因，我们并没有使用对象存储技术，只是将视频以及封面存在了本机。我们使用本地生成的唯一编号给视频以及其封面命令，分别存入public下的video以及cover目录中。其中封面的生成，我们使用了第三方软件ffmpeg，抽取了视频的第一帧。

完成了视频以及封面的存储后，我们下一步需要将视频信息写入数据库。我们先将用户上传的视频信息写入mysql中，再将相关信息写入redis中。

redis的写入主要涉及以下部分：

将视频编号加入feed中

将视频编号加入用户发表过的视频编号列表中

存入新视频的信息

标记当前用户发表过视频

在视频流接口中我们有提到feed是不会过期的，新视频则是 插入新的key，也无需判断是否失效，标记用户发表过视频的实现方法是删除一个empty标记，同样无需判断失效，所以在此接口的缓存操作中，我们只需要判断用户所发布的视频编号列表（简称keyPublish）是否失效。

当keyPublish失效时，我们查询从mysql中查询到用户发表过的全部视频id，并将其写入redis中；当缓存命中时，我们则只需要将当前视频的编号加入其中。关于keyPublish的具体储存结构会在发布列表接口中展开。我们使用redis中的哈希结构去存储视频信息，key设为video_id（简称keyVideo）, 如模型介绍中所述。

我们使用redis的事务将几条语句组合在一起，去确保其顺序执行。

```go


keyPublish := fmt.Sprintf(PublishPattern, video.AuthorID)

keyVideo := fmt.Sprintf(VideoPattern, video.VideoID)

keyEmpty := fmt.Sprintf(EmptyPattern, video.AuthorID)

videoIDStr := strconv.FormatUint(video.VideoID, 10)

pipe := global.REDIS.TxPipeline()

pipe.ZAdd(global.CONTEXT, "feed", &redis.Z{Score: float64(video.CreatedAt.UnixMilli()) / 1000, Member: videoIDStr})

pipe.ZAdd(global.CONTEXT, keyPublish, listZ...)

pipe.Expire(global.CONTEXT, keyPublish, global.PUBLISH_EXPIRE)



pipe.HSet(global.CONTEXT, keyVideo, "author_id", video.AuthorID, "play_name", video.PlayName, "cover_name", video.CoverName,

  "favorite_count", video.FavoriteCount, "comment_count", video.CommentCount, "title", video.Title, "created_at", video.CreatedAt.UnixMilli())

pipe.Expire(global.CONTEXT, keyVideo, global.VIDEO_EXPIRE)

pipe.Del(global.CONTEXT, keyEmpty)

_, err := pipe.Exec(global.CONTEXT)
```

###### /douyin/publish/list - 发布列表

> 登录用户的视频发布列表，直接列出用户所有投稿过的视频。
>
> **接口类型**
>
> GET
>
> **接口定义**
>
> ```go
> syntax = "proto2";
> 
> package douyin.core;
> 
> 
> 
> message douyin_publish_list_request {
> 
>   required int64 user_id = 1; *// 用户id*
> 
>   required string token = 2; *// 用户鉴权token*
> 
> }
> 
> 
> 
> message douyin_publish_list_response {
> 
>   required int32 status_code = 1; *// 状态码，0-成功，其他值-失败*
> 
>   optional string status_msg = 2; *// 返回状态描述*
> 
>   repeated Video video_list = 3; *// 用户发布的视频列表*
> 
> }
> 
> 
> 
> message Video {
> 
>   required int64 id = 1; *// 视频唯一标识*
> 
>   required User author = 2; *// 视频作者信息*
> 
>   required string play_url = 3; *// 视频播放地址*
> 
>   required string cover_url = 4; *// 视频封面地址*
> 
>   required int64 favorite_count = 5; *// 视频的点赞总数*
> 
>   required int64 comment_count = 6; *// 视频的评论总数*
> 
>   required bool is_favorite = 7; *// true-已点赞，false-未点赞*
> 
>   required string title = 8; *// 视频标题*
> 
> }
> 
> 
> 
> message User {
> 
>   required int64 id = 1; *// 用户id*
> 
>   required string name = 2; *// 用户名称*
> 
>   optional int64 follow_count = 3; *// 关注总数*
> 
>   optional int64 follower_count = 4; *// 粉丝总数*
> 
>   required bool is_follow = 5; *// true-已关注，false-未关注*
> 
> }
> ```

发布列表的业务需求就是列出指定用户所有投稿过的视频。可以看到，发布列表接口的返回响应与视频流接口的十分相似，两者的区别就是返回视频的逻辑不同。



在投稿接口的文档中，我们有提到发布视频时，我们会将视频编号加入用户发表过的视频编号列表中。在此，我们会对其设计进行讨论与展开。



在发生cache miss时，我们要做的是将数据从mysql中读出来，并将其写入缓存中。其中一大难点是如果确保写入缓存中的数据是最新的，因为一旦写入的是旧数据，有可能会导致之前的修改因为被覆盖而丢失。综合考虑，我们使用了redis中的有序集合去处理这样的问题，主要有以下几点原因

有序集合可以存储时间戳，实现业务上按发布时间顺序返回视频的需求

有序集合自带“去重”功能，往集合中添加相同元素是幂等的

具体来讲，假如使用list来存储用户发布的视频，如果两个线程同时发生了cache miss，都要往list中添加元素，很有可能会添加重复的元素，即使是使用lua脚本也很难保证高并发场景下的正确性。而使用有序集合可以很好的解决上述问题。

##### 用户注册登陆

###### /douyin/user/register - 用户注册

> **功能描述**
>
> 新用户注册时提供用户名，密码，昵称即可，用户名需要保证唯一。创建成功后返回用户 id 和权限token.
>
> **接口方法**
>
> POST
>
> **接口定义**
>
> ```go
> package douyin.core;
> 
> 
> 
> message douyin_user_register_request {
> 
>   required string username = 1; *// 注册用户名，最长32个字符*
> 
>   required string password = 2; *// 密码，最长32个字符*
> 
> }
> 
> 
> 
> message douyin_user_register_response {
> 
>   required int32 status_code = 1; *// 状态码，0-成功，其他值-失败*
> 
>   optional string status_msg = 2; *// 返回状态描述*
> 
>   required int64 user_id = 3; *// 用户id*
> 
>   required string token = 4; *// 用户鉴权token*
> 
> }
> ```
>
> 

基本流程：

验证用户名和密码的合法性

检查数据库中是否有相同的用户名

将用户添加到数据库中，其中使用 snoyflake 算法生成主键，并且对用户密码进行加密

生成包含用户 ID 信息且时限为一天的 token

###### /douyin/user/login - 用户登录

> 通过用户名和密码进行登录，登录成功后返回用户 id 和权限 token.
>
> **接口类型**
>
> POST
>
> **接口定义**
>
> ```go
> ProtoBuf
> 
> syntax = "proto2";
> 
> package douyin.core;
> 
> 
> 
> message douyin_user_register_request {
> 
>   required string username = 1; *// 注册用户名，最长32个字符*
> 
>   required string password = 2; *// 密码，最长32个字符*
> 
> }
> 
> 
> 
> message douyin_user_register_response {
> 
>   required int32 status_code = 1; *// 状态码，0-成功，其他值-失败*
> 
>   optional string status_msg = 2; *// 返回状态描述*  
> 
>  required int64 user_id = 3; *// 用户id*
> 
>   required string token = 4; *// 用户鉴权token*
> 
> }
> ```
>
> 

基本流程：

从数据库中查询用户信息。其中密码的的校验需要对输入的密码进行加密后，再与数据库存储的加密密码及进行对比

生成包含用户 ID 信息且时限为一天的 Token

###### /douyin/user - 用户信息

> 获取登录用户的 id、昵称，如果实现社交部分的功能，还会返回关注数和粉丝数。
>
> **接口类型**
>
> GET
>
> **接口定义**
>
> ```go
> syntax = "proto2";
> 
> package douyin.core;
> 
> 
> 
> message douyin_user_request {
> 
>   required int64 user_id = 1; *// 用户id*
> 
>   required string token = 2; *// 用户鉴权token*
> 
> }
> 
> 
> 
> message douyin_user_response {
> 
>   required int32 status_code = 1; *// 状态码，0-成功，其他值-失败*
> 
>   optional string status_msg = 2; *// 返回状态描述*
> 
>   required User user = 3; *// 用户信息*
> 
> }
> 
> 
> 
> message User {
> 
>   required int64 id = 1; *// 用户id*
> 
>   required string name = 2; *// 用户名称*
> 
>   optional int64 follow_count = 3; *// 关注总数*
> 
>   optional int64 follower_count = 4; *// 粉丝总数*
> 
>   required bool is_follow = 5; *// true-已关注，false-未关注*
> 
> }
> ```
>
> 

基本流程：

通过中间件对用户权限进行验证，并从 token 中解析出当前用户的 ID

获取指定的用户 ID，查询数据库

查询当前用户是否关注指定用户

##### 点赞功能

###### /douyin/favorite/action - 点赞操作

> 登录用户对视频的点赞和取消点赞操作。
>
> **接口类型**
>
> POST
>
> **接口定义**
>
> ```go
> syntax = "proto2";
> 
> package douyin.extra.first;
> 
> 
> 
> message douyin_favorite_action_request {
> 
>   required int64 user_id = 1; *// 用户id*
> 
>   required string token = 2; *// 用户鉴权token*
> 
>   required int64 video_id = 3; *// 视频id*
> 
>   required int32 action_type = 4; *// 1-点赞，2-取消点赞*
> 
> }
> 
> 
> 
> message douyin_favorite_action_response {
> 
>   required int32 status_code = 1; *// 状态码，0-成功，其他值-失败*
> 
>   optional string status_msg = 2; *// 返回状态描述*
> 
> }
> ```

基本流程：

通过中间件对用户权限进行验证，并从 token 中解析出当前用户的 ID

由于请求参数较多，这里使用 request 结构体对请求进行参数解析绑定

判断 action_type 是否合法

基于 action_type，进行相应的点赞或者取消点赞操作

我们考虑到可能会出现频繁的点赞和取消点赞操作，我们设计 is_favorite 来记录当前的点赞状态，减少数据库行数

###### /douyin/favorite/list - 点赞列表

> 登录用户的所有点赞视频。
>
> **接口类型**
>
> GET
>
> **接口定义**
>
> ```go
> syntax = "proto2";
> 
> package douyin.extra.first;
> 
> 
> 
> message douyin_favorite_list_request {
> 
>   required int64 user_id = 1; *// 用户id*
> 
>   required string token = 2; *// 用户鉴权token*
> 
> }
> 
> 
> 
> message douyin_favorite_list_response {
> 
>   required int32 status_code = 1; *// 状态码，0-成功，其他值-失败*
> 
>   optional string status_msg = 2; *// 返回状态描述*
> 
>   repeated Video video_list = 3; *// 用户点赞视频列表*
> 
> }
> 
> 
> 
> message Video {
> 
>   required int64 id = 1; *// 视频唯一标识*
> 
>   required User author = 2; *// 视频作者信息*
> 
>   required string play_url = 3; *// 视频播放地址*
> 
>   required string cover_url = 4; *// 视频封面地址*
> 
>   required int64 favorite_count = 5; *// 视频的点赞总数*
> 
>   required int64 comment_count = 6; *// 视频的评论总数*
> 
>   required bool is_favorite = 7; *// true-已点赞，false-未点赞*
> 
>   required string title = 8; *// 视频标题*
> 
> }
> 
> 
> 
> message User {
> 
>   required int64 id = 1; *// 用户id*
> 
>   required string name = 2; *// 用户名称*
> 
>   optional int64 follow_count = 3; *// 关注总数*
> 
>   optional int64 follower_count = 4; *// 粉丝总数*
> 
>   required bool is_follow = 5; *// true-已关注，false-未关注*
> 
> }
> ```

基本流程：

由于请求参数较多，这里使用 request 结构体对请求进行参数解析绑定

基于传入的指定用户 ID 查询用户的喜欢视频列表

由于响应体中要求判断当前用户对于视频列表是否喜欢以及作者是否关注，此处需要检查一下是否传入 token 来判断是否为登录状态。如果传入，则需要对当前用户是否点赞关注状态进行查询

这里关于点赞关注状态的查询，我们采用了批量处理操作来提高系统的响应速度

##### 评论功能

###### /douyin/comment/action - 评论操作

> 登录用户对视频进行评论。
>
> **接口类型**
>
> POST
>
> **接口定义**
>
> ```go
> syntax = "proto2";
> 
> package douyin.extra.first;
> 
> 
> 
> message douyin_comment_action_request {
> 
>   required int64 user_id = 1; *// 用户id*
> 
>   required string token = 2; *// 用户鉴权token*
> 
>   required int64 video_id = 3; *// 视频id*
> 
>   required int32 action_type = 4; *// 1-发布评论，2-删除评论*
> 
>   optional string comment_text = 5; *// 用户填写的评论内容，在action_type=1的时候使用*
> 
>   optional int64 comment_id = 6; *// 要删除的评论id，在action_type=2的时候使用*
> 
> }
> 
> 
> 
> message douyin_comment_action_response {
> 
>   required int32 status_code = 1; *// 状态码，0-成功，其他值-失败*
> 
>   optional string status_msg = 2; *// 返回状态描述*
> 
>   optional Comment comment = 3; *// 评论成功返回评论内容，不需要重新拉取整个列表*
> 
> }
> 
> 
> 
> message Comment {
> 
>   required int64 id = 1; *// 视频评论id*
> 
>   required User user =2; *// 评论用户信息*
> 
>   required string content = 3; *// 评论内容*
> 
>   required string create_date = 4; *// 评论发布日期，格式 mm-dd*
> 
> }
> ```
>
> 

此接口对应的是登陆用户对视频进行评论以及删除评论的操作，是一个写入的操作。整个接口的实现大致分为以下几个步骤

1.

根据token进行登陆校验（中间件中完成）

2.

判断action_type是否合法（过滤掉action_type不等于1或2的非法请求）

如果action_type为1，对应的添加评论操作，校验comment_text长度是否合法，写入持久层以及缓存层

如果action_type为2，对应的删除评论操作，写入持久层以及缓存层

对于添加评论以及删除评论，我们都采用了mysql的事务机制，redis中发生错误，mysql也会回滚。

```go


func DeleteComment(userID uint64, videoID uint64, commentID uint64) error {

   var comment model.Comment

   comment.CommentID = commentID

   return global.DB.Transaction(func(tx *gorm.DB) error {

​      *// user_id与video_id用来确保有权限删除（用户只能删除自己的视频）*

​      if result := tx.Where("user_id = ? and video_id = ?", userID, videoID).Delete(&comment); result.Error != nil || result.RowsAffected == 0 {

​         return errors.New("invalid delete")

​      }

​      if err := DeleteCommentInRedis(videoID, commentID); err != nil {

​         return err

​      }

​      return nil

   })

}


```

我们需要注意的是，对于评论删除操作，用户只能删除自己发布过的评论，所以我们在删除时添加了video_id以及user_id的限制条件，如果用户尝试非法删除则返回错误。 为此，我们建立了(video_id, user_id)的联合索引，同时满足了删除评论以及根据video_id查询评论列表的需求。

在缓存层中，我们使用了两个结构分别储存视频对应的评论id（keyCommentsOfVideo）以及评论信息（keyComment）。与视频相似，两者分别使用了有序集合以及哈希结构。 redis的写入主要涉及以下部分：

修改keyCommentsOfVideo

修改keyVideo中的comment_count

加入或删除comment

对于前面两个key，我们需要去判断key是否失效，失效则不进行对应的缓存写入。

###### /douyin/comment/list - 视频评论列表

> 查看视频的所有评论，按发布时间倒序。
>
> **接口类型**
>
> GET
>
> **接口定义**
>
> ```go
> syntax = "proto2";
> 
> package douyin.extra.first;
> 
> 
> 
> message douyin_comment_list_request {
> 
>   required string token = 1; *// 用户鉴权token*
> 
>   required int64 video_id = 2; *// 视频id*
> 
> }
> 
> 
> 
> message douyin_comment_list_response {
> 
>   required int32 status_code = 1; *// 状态码，0-成功，其他值-失败*
> 
>   optional string status_msg = 2; *// 返回状态描述*
> 
>   repeated Comment comment_list = 3; *// 评论列表*
> 
> }
> 
> 
> 
> message Comment {
> 
>   required int64 id = 1; *// 视频评论id*
> 
>   required User user =2; *// 评论用户信息*
> 
>   required string content = 3; *// 评论内容*
> 
>   required string create_date = 4; *// 评论发布日期，格式 mm-dd*
> 
> }
> 
> 
> 
> message User {
> 
>   required int64 id = 1; *// 用户id*
> 
>   required string name = 2; *// 用户名称*
> 
>   optional int64 follow_count = 3; *// 关注总数*
> 
>   optional int64 follower_count = 4; *// 粉丝总数*
> 
>   required bool is_follow = 5; *// true-已关注，false-未关注*
> 
> }
> ```
>
> 

此接口用于查看视频的所有评论，按发布时间倒序，功能与实现与发布列表接口非常相似，不做过多展开。

##### 关注粉丝功能

###### /douyin/follow/action - 关注操作

> 登录用户对其他用户进行关注或取消关注。
>
> **接口类型**
>
> POST
>
> **接口说明**
>
> ```go
> syntax = "proto2";
> 
> package douyin.extra.second;
> 
> 
> 
> message douyin_relation_action_request {
> 
>   required int64 user_id = 1; *// 用户id*
> 
>   required string token = 2; *// 用户鉴权token*
> 
>   required int64 to_user_id = 3; *// 对方用户id*
> 
>   required int32 action_type = 4; *// 1-关注，2-取消关注*
> 
> }
> 
> 
> 
> message douyin_relation_action_response {
> 
>   required int32 status_code = 1; *// 状态码，0-成功，其他值-失败*
> 
>   optional string status_msg = 2; *// 返回状态描述*
> 
> }
> ```
>
> 

基本流程：

通过中间件对用户权限进行验证，并从 token 中解析出当前用户的 ID

判断 action_type 是否合法

基于 action_type，进行相应的关注或者取消关注操作

我们考虑到可能会出现频繁的点赞和取消关注操作，我们设计 is_folllow 来记录当前的关注状态，减少数据库行数

###### /douyin/follow/list - 用户关注列表

> 登录用户关注的所有用户列表。
>
> **接口类型**
>
> GET
>
> **接口说明**
>
> ```go
> syntax = "proto2";
> 
> package douyin.extra.second;
> 
> 
> 
> message douyin_relation_follow_list_request {
> 
>   required int64 user_id = 1; *// 用户id*
> 
>   required string token = 2; *// 用户鉴权token*
> 
> }
> 
> 
> 
> message douyin_relation_follow_list_response {
> 
>   required int32 status_code = 1; *// 状态码，0-成功，其他值-失败*
> 
>   optional string status_msg = 2; *// 返回状态描述*
> 
>   repeated User user_list = 3; *// 用户信息列表*
> 
> }
> 
> 
> 
> message User {
> 
>   required int64 id = 1; *// 用户id*
> 
>   required string name = 2; *// 用户名称*
> 
>   optional int64 follow_count = 3; *// 关注总数*
> 
>   optional int64 follower_count = 4; *// 粉丝总数*
> 
>   required bool is_follow = 5; *// true-已关注，false-未关注*
> 
> }
> ```
>
> 

基本流程：

基于传入的指定用户 ID 查询用户的喜欢视频列表

由于响应体中要求判断当前用户对于关注粉丝列表是否关注，此处需要检查一下是否传入 token 来判断是否为登录状态。如果传入，则需要对当前用户是否关注状态进行查询

这里关于关注状态的查询，我们采用了批量处理操作来提高系统的响应速度

###### /douyin/relation/follower/list/ - 用户粉丝列表

> 所有关注登录用户的粉丝列表。
>
> **接口类型**
>
> GET
>
> **接口说明**
>
> ```go
> syntax = "proto2";
> 
> package douyin.extra.second;
> 
> 
> 
> message douyin_relation_follower_list_request {
> 
>   required int64 user_id = 1; *// 用户id*
> 
>   required string token = 2; *// 用户鉴权token*
> 
> }
> 
> 
> 
> message douyin_relation_follower_list_response {
> 
>   required int32 status_code = 1; *// 状态码，0-成功，其他值-失败*
> 
>   optional string status_msg = 2; *// 返回状态描述*
> 
>   repeated User user_list = 3; *// 用户列表*
> 
> }
> 
> 
> 
> message User {
> 
>   required int64 id = 1; *// 用户id*
> 
>   required string name = 2; *// 用户名称*
> 
>   optional int64 follow_count = 3; *// 关注总数*
> 
>   optional int64 follower_count = 4; *// 粉丝总数*
> 
>   required bool is_follow = 5; *// true-已关注，false-未关注*
> 
> }
> ```
>
> 

#### 数据模型实现

##### 视频数据模型

持久化层 MySQL 中

> 包含 video_id, author_id, title, play_name, cover_name, created_at, ext_info，其中 video_id 作为**主键**。
>
> 建立**非聚簇索引** created_at 与 author_id。

缓存层 Redis 中

> 使用有序集合 zset 记录所有发布过的视频（key:"feed"，score:视频创建的时间戳，value:video_id）。
>
> 使用哈希结构 hset 记录每一个视频的相关信息（key:"Video:"+video_id, field 包括 author_id, title, play_name, cover_name, favorite_count, comment_count, created_at）。
>
> 使用有序集合 zset 记录每个用户发布过的所有视频（key:"Publish:"+user_id, score:视频创建的时间戳， value:video_id）。

##### 用户数据模型

持久化层 MySQL 中，

> 包含 user_id, name, password, created_at, ext_info，其中 user_id 作为**主键**。

缓存层 Redis 中，

> 使用哈希结构 hset 记录用户的相关信息，（key:"user:"+user_id，field 包括 user_id, name, password, follow_count, follower_count, total_favorited, favorite_count, created_at）。  

##### 点赞数据模型

持久化层 MySQL  中，

> 包含 favorite_id, video_id, user_id, is_favorite, created_at, updated_at，其中 favorite_id 作为**主键**。
>
> 建立**非聚簇索引** (user_id, video_id) 和video_id。

缓存层 Redis 中，

> 有序集合 zset 记录用户历史点赞的所有视频（key: "favorite:"+user_id，score: 0 or 1，value: video_id），其中 score = 0 代表持久化层中已记录且取消点赞，score = 1 代表持久化层中已记录且点赞。

##### 评论数据模型

持久化层 MySQL  中

> 包含 comment_id, video_id, user_id, content, created_at, deleted_at，其中 comment_id 作为**主键**。
>
> 同时建立**非聚簇联合索引** (video_id, user_id)

缓存层 Redis 中，

> 使用有序集合 zset 来记录每个视频发布过的所有评论（key:"CommentsOfVideo:"+video_id, score:评论创建的时间戳， value:comment_id）。
>
> 使用哈希结构 hset 记录每一个评论的相关信息（key:"Comment:"+comment_id, field 包括 user_id, video_id, content, created_at）。

##### 关注数据模型

持久化层 MySQL  中，

> 包含 follow_id, celebrity_id, follower_id, is_follow, created_at, updated_at，其中 follow_id 作为**主键**。
>
> 同时建立**非聚簇索引** (follower_id, celebrity_id) 和 celebrity_id。

缓存层 Redis 中，

> 使用有序集合 zset 来记录历史粉丝（key: "celebrity:"+user_id，score: 0 or 1，value: user_id），其中 score = 0 代表持久化层中已记录且取消关注，score = 1 代表持久化层中已记录且关注。
>
> 使用有序集合 zset 来记录历史关注（key: "follower:"+user_id，score: 0 or 1，value: user_id），其中 score = 0 代表持久化层中已记录且取消关注，score = 1 代表持久化层中已记录且关注。

#### 技术亮点

> 本章节主要介绍了我们项目实现中一些关键的技术以及思想，针对具体场景的性能优化将在接口文档中展开

##### 技术亮点总结

> **技术亮点**
>
> - 鉴权
>
>   - JWT中间件保持用户连接状态
>   - 对上传的数据鉴定，比如文件大小是否接受、文件格式是否在白名单；对加入到数据库中的数据进行鉴定，比如添加评论到comment数据库要检查uid是否在user中（删除评论的时候也要鉴定这个评论是否是属于这个用户）、比如加入的评论的字段长度的检查；对操作类别函数进行鉴定，比如action_type大于等于0小于2，那么鉴定action_type是否在这个范围
>
> - 存储
>
>   - 缓存
>     - 使用Redis缓存
>     - 空表查询优化（查询用户发布列表为空，在Redis中设置一个键判断如果为空，下一次查询的时候访问Redis发现用户列表为空就不会查询视频数据库；查询粉丝列表为空，就在Redis设置空（哈希表），下一次查询粉丝列表的时候发现粉丝列表中没有这个键就查看是否为空，如果为空直接返回空而不是查数据库；此外还有关注列表和评论列表)
>
>   - MySQL
>
>     - Gorm预编译和参数查询防止SQL注入
>
>     - 使用雪花算法sonyflake随机主键作为视频模型、用户模型、点赞模型、关注模型、评论模型的主键，防止暴露数据库容量
>
>     - 用户密码加密存储，MD5加密算法对用户密码加密
>
>     - 删除评论校验登录用户
>
>     - 使用批量查询（循环查询数据库不行，因为循环查询会不断建立数据库连接造成性能变差，查询数据库应该使用批量查询，在MySQL中，批量查询例子**select * from student where id in (1,2,3,4)**，而不能是**for i in (1,2,3,4):  select * from student where id = i**。查询缓存一样可以使用批量查询，pipeline）
>
>     - 使用事务修改数据，保证一致性（MySQL事务、Redis事务）
>
>     - 加速count操作：使用并发查询favorite和comment数据表加速获得点赞数和评论数
>
>     - 使用索引加速查询，
>
>       - 视频功能
>
>         - 建立video表的create_time的列索引：无状态刷抖音。Redis缓存用有序集合保存video_id，用Hash表保存video对象信息，每次总是先从Redis中取最后30个视频id然后再到video中取视频信息。初始的时候在Redis中找不到"feed:vidlist"和“feed:vidinfo"分别代表videoid的有序集合和存储video信息的集合，那么从数据库中读取数据，从video表中读取后30条数据**select * from video order by create_time desc limit 30**读取30条数据，然后把(vid, create_time)存放到"feed:vidlist"中，把(vid, uid, create_time, ...)等其他信息存放到"feed:vidinfo"的哈希表中。"feed:vidinfo"除了存放基本video数据信息，还要存放点赞数和评论数，因为feed是一个很热的数据，所以我们要在"feed:vidinfo"中存放这两个，我们在从点赞表favorite表中统计视频的点赞数**select vid, count(uid) as num from favorite group by vid**，从评论表中获取评论数**select vid, count(content) as num from comment group by vid**.
>
>           **查询点赞数和评论数的时候可以使用并发查询来加速**
>
>         - 发布视频。发布视频会保存到对象存储中获取一个url，然后通过雪花算法计算视频的id，然后获得uid，create_time,等信息，将（vid, uid, create_time(时间戳), url）存放到video数据表中。然后把vid的信息保存到"feed:vidinfo"和"feed:vidlist"中，同时添加到用户发布列表(publish:123)中。
>
>         - 使用列索引：查询用户发布列表，对video视频数据库的用户user_id建立索引，查询一个用户发布的视频。当请求在Redis缓存的**“PublishTable"**列表项中没有发现**publish:123**这个表项key，就会查询**"HASHPublish:123"**这个哈希表项是否存在，如果存在并且为0（代表用户发布列表为空），就会直接返回发布列表为空；否则使用video数据库表的user_id的索引去查询用户发布列表**select vid from video where uid=%s**。这个查询会使用建立在uid上的列索引。
>
>       - 用户登录注册功能
>
>         - 用户注册：加密用户密码保存到数据库，同时检查数据库中是否存在这个已经注册的用户。如果成功建立用户，签发token给用户保存登录状态
>         - 用户登录：将密码加密后和数据库对比，成功后给登录用户签发token（JWT中间件）
>         - 获取用户信息：根据uid访问redis的”user"哈希表，如果不存在uid，那么访问数据库，如果数据库检查uid不存在就返回错误，否则返回用户信息并且存放到“user”哈希表中
>
>       - 点赞功能
>
>         - 点赞操作：首先检查uid和vid是否存在（检查数据库返回空的数据列表就代表不存在，也可以建立uid和vid的外键约束（uid外键约束于user，vid外键约束于video，使用索引比使用外键更好），不存在那么就返回出错（数据库一致性）。否则加入到favorite点赞数据库。
>         - 点赞列表：返回用户点赞列表，建立点赞数据表uid的列索引。从数据库中根据uid返回点赞列表**select vid from favorite where uid = 123**，然后把点赞列表加入redis数据库，"favorite:123"列表中。并且把video的点赞数增加1.这个过程要使用redis事务保证原子操作
>
>       - 评论功能
>
>         - 评论操作：和点赞操作差不多。检查uid和vid，将评论写入数据库comment。评论要设置字段长检查
>         - 评论列表：返回视频评论列表，建立comment数据库的vid索引。根据传入的vid，检查vid是否存在，然后从数据库中获得评论内容放到redis数据库的"comment:vid"中，并且增加redis数据库中video哈希表中的评论数，这锅过程要保证原子操作，使用Redis事务。
>
>       - 关注功能
>
>         - 关注操作:检查uid1和uid2是否存在，写入follow数据表，字段is_follow=true。
>         - 关注列表：建立uid1的列索引。从redis数据库中查询用户关注列表"follow:uid1"，如果不存在，就从数据库中查找，并且添加到redis中，设置过期时间
>         - 粉丝列表：建立follow表的uid2的列索引，从redis数据库中找"follower:uid2"，如果找不到，就从数据库中查找，并且添加到redis中。
>
>   - 对象存储
>     - 使用对象存储存储视频和图片数据
>   - 搜索引擎ElasticSearch全文检索
>     - 适合订单查询、日志查询
>     - 基于倒排索引的分布式存储数据库
>
> - 架构
>
>   - 微服务架构kitex
>
> - 测试
>
>   - Jmeter压力测试性能
>
>     > Jmeter安装使用
>     >
>     > https://blog.csdn.net/weixin_44909514/article/details/123871784
>     >
>     > https://blog.csdn.net/m0_37449634/article/details/126156890
>     >
>     > https://blog.csdn.net/weixin_43641920/article/details/126437338
>     >
>     > - 对feed视频流接口压测，10000并发请求TPS在570次/s；100000并发请求TPS在1200次/s；
>     >
>     >   **100000此并发请求没有延时**
>     >
>     >   ![Screenshot 2022-10-30 180925](实验\6 Web设计\图片\Screenshot 2022-10-30 180925.png)
>     >
>     >   **sleep延时feed 1s效果**
>     >
>     >   ![Screenshot 2022-10-30 181804](D:\JavaBackend\实验\6 Web设计\图片\Screenshot 2022-10-30 181804.png)
>     >
>     >   **while延时feed 1s效果**
>     >
>     >   ![Screenshot 2022-10-30 182652](D:\JavaBackend\实验\6 Web设计\图片\Screenshot 2022-10-30 182652.png)
>     >
>     >   从上面可以看到，sleep相较于没有延时，平均时延从2s到4s，而吞吐量没有太大变化，这是因为sleep只是整体将执行时间推迟，并不会改变执行时候的吞吐量，而执行时间推迟的1s在整个执行时间中很小。而while延时影响就很大了，他让吞吐量变小一半，同时平均延时增加到10s。这是应为while会占用CPU时间，他会整体推迟整个程序的执行指令。

##### 使用redis加速数据读取

本项目作为一个短视频 app，数据的冷热效应非常明显，也就是说数据的访问量不是均匀分布的，热门的数据更容易被访问，所以在高并发场景下引用 Redis 做缓存加速数据的读取是很有必要的。本项目实现了对热点数据的 Redis 全支持。

利用 Lua 脚本和 pipeline 多命令执行来保证 Redis 操作的原子性

为了防止大量缓存同一时间失效从而引起的缓存雪崩现象的发生，我们为不同的缓存 key 设置随机的过期时间，尽量让失效时间点均匀分布。

具体的结构设计将会在接口文档中展开。

##### 引入批处理操作

在数据查询操作中，需求往往是成批次的形式进行查询。如果不对这种情况进行优化，而是简单地逐一建立数据库连接后查询，这会严重影响到系统的处理性能。因此，我们对数据库所需查找的信息进行整合，来提高每次数据库连接所查询到的有效数据量。这里我们将缓存未命中的 video_id 打包为切片 notInCache，进而执行数据库的批量查询。

```go
*//缓存没有找到，数据库查询*

var uniqueVideoList []VideoFavoriteCountAPI

result := global.DB.Model(&model.Favorite{}).Select("video_id", "COUNT(video_id) as favorite_count").Where("video_id in ? and is_favorite = ?", notInCache, true).Group("video_id").Find(&uniqueVideoList)
```

因为数据库查询所返回数据与输入的查询顺序无法保证一一对应，所以需要增加额外处理，将查询到的结果映射到预期返回结果中。

```go
*// 针对查询结果建立映射关系*

mapVideoIDToFavoriteCount := make(map[uint64]int64, len(uniqueVideoList))

for _, each := range uniqueVideoList {

​    mapVideoIDToFavoriteCount[each.VideoID] = each.FavoriteCount

}

scanner := 0

for idx, each := range favoriteCountList {

​    if each == -1 {

​        favoriteCountList[idx] = mapVideoIDToFavoriteCount[notInCache[scanner]]

​        scanner++

​    }

}

return favoriteCountList, nil
```

批处理操作的思想贯穿着我们整个项目，无处不在。

##### 安全防御措施

###### 使用gorm防止sql注入

http://c.biancheng.net/view/8283.html

> sql注入主要是指程序对用户输入的字符串和sql语句拼接新城sql命令，而这个sql命令并不是程序想要用户实现的sql语句，比如**select * from db where a=$A**，其中**$A**是用户拼接的字符串，本来是想用户输入一个a的值的查询，但是如果用户输入的是**"AA and b=BB"**那么最终拼接的sql语句是**select * from db where a=AA and b=BB**，这个sql语句不是我们想要的，所以是一种sql注入。
>
> 解决SQL注入有
>
> - 检查输入字符串，可以使用正则表达式匹配我们需要的字符串
> - 参数化查询，预编译sql语句并且把传入的字符串作为参数放到sql语句，这样就算发生sql注入，他也只是被当作字符串存在用于比较，而不会被解析成sql命令
> - 其他
>   - 加密数据，避免发生sql注入攻击者可以解析
>   - 限制用户使用数据库的权限，降到最低要求
>   - 避免向用户返回数据库错误

我们全部的mysql操作全部基于 gorm 技术栈，利用 gorm 预编译有效地防止了sql注入。

###### 用户密码加密存储

由于用户密码是非常敏感的数据，采用明文保存非常容易造成密码的泄露问题。这里采用业界比较安全的 bcrypt 算法（可以有效抵御彩虹表）来对用户密码进行加密后再存储到数据库中。

当需要进行密码校验时，只需要对用户传入密码进行同样的 bcrypt 算法加密后，再与数据库存储的加密密码及进行对比即可。

##### 引用中间件检查

###### 用户权限认证

基于 Token 的无状态性质，我们采用 token 来实现权限的记录以及会话的保持。简单流程如下

- 客户端使用用户名密码请求登录

- 服务端收到请求，验证登录合法性，并签发 Token 给客户端

- 客户端接收到 Token 后储存起来，之后向服务端发起资源请求都需要携带 Token

- 服务端收到请求，验证客户端 Token 合法性（是否是自己签发、是否过期），向客户端返回请求数据

###### 文件合法性检查

对于用户上传的视频，我们在中间件中按以下流程加以校验

- 检查文件大小

- 检查文件后缀名是否在白名单内

- 通过文件字节流再次检测文件类型是否在白名单内



##### **Count 计数数据**

在本项目中，count 计数数据作为最热点的数据，理应得到合理的设计以加快系统的处理响应速度。为此本项目，基于 count 计数数据的 ”每次修改仅加减一“ 的特性，采用 “先修改数据库再更新缓存” 的策略。

其中，基于响应结构体的特征，我们将 count 计数数据直接绑定到 video 和 user 的 field 中。在缓存更新时，我们只对已经存在于缓存的 video 和 user 结构体进行更新。因此在缓存更新前我们需要对结构体是否存在于缓存进行条件判断，这里我们使用Lua脚本的方式来保证 Redis 操作的原子性。

```go


*//定义 key*

userRedis := fmt.Sprintf(UserPattern, userID)

lua := redis.NewScript(`

​         if redis.call("Exists", KEYS[1]) > 0 then

​            redis.call("HIncrBy", KEYS[1], "favorite_count", 1)

​            redis.call("Expire", KEYS[1], ARGV[1])

​            return true

​         end

​         return false

​         `)

keys := []string{userRedis}

values := []interface{}{global.USER_INFO_EXPIRE.Seconds()}

_, err := lua.Run(global.CONTEXT, global.REDIS, keys, values).Bool()
```

##### 空列表查询优化

项目中有多种列表查询操作，比如用户发布的视频列表、用户点赞过的视频列表等等。很多时候，因列表为空，redis中相应的key不存在会导致大量的缓存穿透现象。为此，我们在不同场景做了不同的优化。

###### 用户发布视频列表为空

我们使用keyEmpty去标记用户是否发表过视频，当用户查询自己的发布列表时，若发现用户并没有发表过视频时，我们将此信息写入redis中。

```go
func SetUserPublishEmpty(userID uint64) error {

​        keyEmpty := fmt.Sprintf(EmptyPattern, userID)

​        return global.REDIS.Set(global.CONTEXT, keyEmpty, "1", global.EMPTY_EXPIRE).Err()

}
```

当用户发布视频时，删除此key。这样就可以保证没有发布过视频的用户在短时间内（keyEmpty没有过期时）重复查看自己的主页时，不会重复的去查询mysql。

###### 点赞或关注列表为空

我们提出在 favorite 和 follow 的缓存集合中引入占位符来记录这种状态。

```go


*//定义 key*

*//开启pipeline*

_, err := global.REDIS.TxPipelined(global.CONTEXT, func(pipe redis.Pipeliner) error {

​    *//初始化*

​    pipe.ZAdd(global.CONTEXT, userFavoriteRedis, &redis.Z{Score: 2, Member: Header})

​    *//增加点赞关系*

​    *//设置过期时间*

​    return nil

})


```

###### 评论列表为空

当我们发现视频的评论列表在缓存中不存在时，我们会先从缓存中的视频信息中查找comment_count的值，若评论数为0则提前返回，省略可能不必要的查表操作。

##### **Sonyflake 算法**

数据库的主键策略的选择往往有很多考量，我们这里采用改进的雪花算法——snoyflake 算法来生成主键。

我们首先考虑常见的两种方案的缺陷

- 使用 自增 ID

容易被第三方通过自增 ID 爬取到业务的增长信息，对数据库隐私造成影响

Auto_increment 锁机制会造成自增锁的抢夺，有一定的性能损耗

- 使用 uuid

uuid 作为乱序序列，会严重影响到 innodb 新行的写入性能。由于写入是乱序的，innodb 不得不频繁的做页分裂操作，以便为新行分配空间，导致移动大量的数据。

Snoyflake 算法可以有效地规避这两种方案所带来的缺陷。

# 操作系统相关

**查看Linux操作系统源代码的网站，包含所有Linux内核版本**

[socket.c - net/socket.c - Linux source code (1.2.13) - Bootlin](https://elixir.bootlin.com/linux/1.2.13/source/net/socket.c)

[sparc_vfork identifier - Linux source code (v5.15.52) - Bootlin](https://elixir.bootlin.com/linux/v5.15.52/C/ident/sparc_vfork)

**书籍**

[操作系统设计与实现](C:\Users\cheng\Desktop\JavaBackend\书籍\操作系统\操作系统设计与实现(第三版上册).pdf)

[Linux内核设计与实现](C:\Users\cheng\Desktop\JavaBackend\书籍\操作系统\Linux内核设计与实现（第三版）.pdf)

**视频材料**

[哈工大李志军操作系统](https://www.bilibili.com/video/BV1d4411v7u7?p=2&spm_id_from=pageDriver)

**高级语言转汇编**

[在线高级语言转低级语言](https://godbolt.org/)

> **C/C++转汇编**
>
> gcc -E b.c -o b.i
> gcc -S b.i -o b.s

> **Python字节码**
>
> python -m dis a.py

> **Java使用hstdis和JITWatch查看字节码和汇编代码**
>
> https://blog.csdn.net/wo1901446409/article/details/98500024
>
> Java字节码javap

> **Go语言转汇编**
>
> go tool compile -N -l -S hello.go
>
> go tool objdump hello.o > hello.asm

**CPU上下文 进程上下文**

[参考](https://baike.baidu.com/item/%E4%B8%8A%E4%B8%8B%E6%96%87%E5%88%87%E6%8F%9B/4842616)

进程上下文指的是进程保存在PCB里面用于切换CPU的寄存器和程序计数器的那些数据，CPU上下文值得是保存在CPU寄存器和程序计数器的数据。CPU上下文和进程上下文实际上是一个东西。

CPU上下文切换实际上是进程切换过程中修改CPU寄存器和程序计数器的过程。

**计算机组成原理-CPU工作过程**

```
50: mov ax,[100]
51: mov bx,[101]
52: add ax,bx

执行上面程序首先设置PC为50，CPU在地址总线传50获得命令并且存放到IR寄存器，然后解释执行这个指令，他的opcode为mov，会把100放到地址总线从内存中读到数值放到ax寄存器；然后PC自增到51，取指令把101号内存数值放到bx；然后PC自增到52，将ax和bx相加并将相加结果存放到ax，在bx保存是否溢出。
```

用汇编语言编写操作系统引导程序bootsect.s的原因，因为汇编严格操纵代码段，数据段和程序变量在内存中的位置，而高级语言你不能明确指定变量的位置。

计算机硬件包括CPU（计算机和控制器）、存储器（高速缓存Cache、主存、辅存-外存）、输入输出设备

冯诺依曼体系结构：把程序载入内存，然后CPU取指令执行（PC寄存器指向内存指令地址，指令读取到IR指令寄存器，指令包括操作码，操作寄存器和操作数，执行程序把操作寄存器赋值位操作数在内存中的地址的数值。

每个CPU都有自己的指令集（CPU架构），常用的比如RISCV架构指令集，CPU指令是CPU原语，对应一个机器语言，机器语言是二进制的代码，它包括操作码和操作数两个部分，一个机器语言有位数的限制，对应CPU寄存器的长度，比如32位指令集的机器语言对应的CPU寄存器大小是32位。汇编语言和机器语言很类似，他像是把机器语言的操作码操作数分别用指令如load和变量var等替换得到的汇编指令，因此汇编语言是和机器语言相关的低级语言，可以从编译得到的汇编语言直接翻译出对应的机器语言。高级语言的指令更加面向逻辑而不是跟CPU指令集相关，比如i=i+1，在实际机器语言中包括三个指令，从主存读i到寄存器read i，将立即数1放入寄存器，然后执行加法操作add，之后把add的结果送到主存i地址。

电脑加电启动的时候，计算机各个部分初始化，CPU初始化自己的各个寄存器，CPU的PC寄存器初始化为0指向内存的第一个位置，那是一个代码区，存放各种指令；内存中存放着指令和数据，指令和数据没有任何区分，他们都是32位的数字，只是被CPU访问方式不同。CPU通过指令寄存器PC访问到内存的32位被当成指令处理，而在处理指令过程中在操作数段的访问内存的地址的访问会被当成数据处理。

CPU执行程序的时候，他的PC寄存器指向被执行的指令，并且执行完成后自动指向下一条要被执行的语句（默认自增1，如果遇到跳转指令会修改成跳转的指令的地址）。当执行到加法运算时，根据操作数的地址访问内存获取操作数（这个过程需要地址转换），然后运算将运算结果送回到对应的内存地址；如果执行的是跳转指令，会修改PC寄存器指向跳转的指令的地址（汇编语言的goto 1）

**计算机学习层次**

- 应用程序层次，通过高级编程语言（C++，C，Java，Python）等编写代码，每个代码实际会产生系统调用，去调用操作系统用机器语言实现的方法。我们编写应用程序的时候只是关注业务逻辑，而不去关心操作系统怎么实现调用裸机的指令集完成操作

  高级语言的方法（JDK的调用函数，C++的方法）都是调用操作系统系统调用方法接口实现的，应用程序调用高级语言方法，会接着调用系统调用方法，之后系统调用方法调用机器语言指令，最终编译的时候会把高级语言翻译成机器语言，放到机器内存执行。

  高级语言如C等封装操作系统提供的系统调用，并且这些接口函数可以被用户程序调用

- 操作系统层面，操作系统封装了调用裸机暴露的指令集接口的程序，完成一个完整的逻辑功能的程序，并向上封装成系统调用，供高级语言调用。操作系统层面使用的机器指令，编写的是各个部件的驱动，并将它们联合起来组成一个完成的业务程序，比如高级语言的print方法会调用操作系统的系统调用print方法，系统调用的print方法是由计算机底层机器语言指令集写成的驱动程序

  操作系统封装机器语言指令形成完整逻辑，并且向上提供系统调用

- 计算机硬件层面，计算机硬件提供了驱动计算机硬件的指令集，可以用这些指令集编写程序驱动硬件的各个部分。实际上就是嵌入式开发。操作系统实际上就是嵌入式系统，他是用计算机提供的驱动计算机硬件的指令集编写的。

  设计CPU指令集，设计CPU，设计硬件系统，硬件系统的连接和驱动开发，向上暴露调用的接口和驱动。

  计算机硬件向上提供机器语言指令

**X86计算机操作系统启动过程**

操作系统放在磁盘的0扇区

启动时，使用BIOS的bootsect.s将操作系统的setup.s加载到内存；setup.s把操作系统核心代码System加载到内存0地址并进入保护模式；System的第一个程序是head.s会跳转到c函数main.c执行设备初始化，main.c初始化的设备包括内存、中断、外部设备、CPU、时钟等，初始化内存会调用memory.c中的mem_init()函数，mem_init()函数会把内存中不是操作系统的区域初始化为0. 操作系统启动时操作系统第一步，他把操作系统从磁盘0地址读取到内存0地址。初始化好的数据结构有GDT表、IDT表、位图mem_map管理内存的数据结构。这些数据结构都时保存在内存开头的那些位置，之后的位置是应用程序可以使用的内存。

- 加电CPU初始化各个寄存器，进入16位实模式，用CS：IP两个寄存器组合指向BIOS的启动程序bootsect.s(一个汇编代码)，bootsect.s会加载操作系统的setup.s程序（操作系统保存的在启动的时候选择启动方式时会把他的内存地址送到对应的初始化时的寄存器）执行。

- settup.s功能是建立数据结构把计算机硬件信息放到内存里面（比如内存大小，光标位置），然后加载操作系统到内存0地址，然后setup.s将CPU切换到32位保护模式，CS:IP跳转到内存0地址继续执行操作系统核心模块System

- System的第一个程序是head.s，head.s进一步初始化硬件设备。head.s会调用linux的main.c（一个C函数）执行初始化，main.c对计算机每一个硬件设备执行初始化，比如初始化内存设备memory.c里面有一个mem_init()函数，main函数会调用这个设备的mem_init()方法    ，                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    从而把内存memory设备初始化，初始化内存实际上会使用setup.s时期建立的内存大小的计算机信息，用它来标记应该被初始化的内存的大小，这里的初始化内存的大小是减去了操作系统代码大小的内存大小。

  main.c初始化的设备包括内存，中断，外部设备，时钟，CPU等设备。

**应用程序调用操作系统执行过程-系统调用，操作系统接口**

1. **操作系统程序执行方式**

   - **使用命令行执行程序的过程**

     shell是一个c语言编写的程序，他一直while循环并读取命令行，当我们使用gcc 编译我们的程序，他会fork一个进程执行cmd指令（cmd就是命令行输入的指令gcc -o output output.c)

   - **使用图形界面执行程序-给无界面的Linux系统编写图形界面**

     硬件输入（点击鼠标、键盘输入）会被放入系统消息队列，操作系统会读取这个消息并且执行对应的用户程序

2.  **系统调用标准**

   POSIX是一个系统调用标准，它规定了操作系统向上层提供的系统调用接口，Potable Operating System Interface of Unix

   常用系统调用接口

   操作系统接口是系统调用，是操作系统向上提供的接口，调用系统调用会让程序进入内核态执行操作系统的系统调用程序

   | 分类     | POSIX系统调用接口 | 功能描述             |
   | -------- | ----------------- | -------------------- |
   | 任务管理 | fork              | 创建一个进程         |
   |          | execl             | 运行一个可执行程序   |
   |          | pthread_create    | 创建一个线程         |
   | 文件系统 | open              | 打开一个文件或目录   |
   |          | EACCES            | 返回值，表示没有权限 |
   |          | mode_t和st_mode   | 文件头结构和文件属性 |

3. 系统调用如何实现

- 为什么要使用系统调用而不是直接用户程序访问操作系统程序和数据

  系统调用函数和数据保存在操作系统的内存区，用户函数不能直接调用操作系统函数，也就是用户程序不能执行跳转指令直接跳转到操作系统函数位置。为什么用户程序不能直接访问操作系统函数和数据，主要是为了安全。如果用户程序能够直接访问操作系统数据，那么用户程序可能直接获得root密码，第三方用户执行操作系统时留在操作系统缓冲的数据可以被当前用户直接访问看到。

- 怎么实现用户程序不能直接访问操作系统程序和数据，怎么实现用户程序和内核程序隔离

  答案是使用硬件检查

  执行在用户态的程序的PC是CS：IP寄存器组合的，CS的最低两位是CPL，代表当前指令所在的内存段的特权级别，用户段的特权级别是3；在操作系统内核代码被setup从磁盘0地址加载到内存0地址的时候，会创建一个GDT表，这个表保存了内核段的CS的DPL是0，也就是目标段的特权级别是0，表示这个CS是内核段（操作系统保存的内存）。当一个用户程序的CS：IP要跳转到新的段的时候，他会检查目标段的DPL是否>=当前段的CPL，如果目标段的特权级别大于等于当前段的特权级别才能跳转。

  当用户段跳转到内核段的时候，会执行一个检查查看目标段的隔离级别DPL是否大于等于当前段的CPL隔离级别，如果大于才能跳转，否则是不能跳转的。因为用户段特权级别是3，而内核段的特权级别是0，所以跳转时检查不能通过，就不能从用户段跳转到内核段，也就是用户段不能直接访问内核段程序和数据。

- 不让用户程序直接调用操作系统程序和数据，那用户程序怎么想用操作系统服务

  **以printf为例解释应用程序如何执行系统调用**

  - 用户程序执行C语言库行数printf，输入参数

  - C语言库函数整理和添加部分需要的参数（对printf要添加字符大小等参数），调用系统调用

    _syscall3(int, write, int, fd, const char* buf, off_t, count) 

    实际上的系统调用是

    int write(int fd, const char* buf, off_t count)

  - 系统调用_syscall3包含嵌入汇编代码 int 0x80

    当执行int 0x80的时候，程序还处于用户态，在之后会陷入内核态。在head.s的时候调用main.c进行初始化的时候有一个sched_init()初始化函数，他会设置中断函数入口。sched_init()函数会设置GDT[0x80]的DPL=3，同时设置IDT[0x80]的高四位为8，第四位为system_call的中断函数入口地址的偏移量。这样可以通过CS：IP=8:system_call的偏移获得中断函数地址。当执行int 0x80的时候会检查到GDT[0x80].DPL>CPL，从而int 0x80可以被执行，然后int 0x80获取到IDT[0x80]的高四位和第四位组成8:system_call偏移得到中断函数地址，发生跳转。这个时候因为CS=0，造成当前CPL=0，从而当前程序会进入内核态执行。

    C语言库函数printf封装了一个包含int 0x80的嵌入汇编代码，这个嵌入汇编代码是在内核态执行的，他在执行第一个嵌入汇编代码的时候就陷入内核态了

    这个嵌入汇编代码主要内容

    ```
    int 0x80
    : %a(_res)              //执行int 0x80的返回，把eax赋值给_res，_res是C语言定义的返回变量
    : ""(_NR_NAME)          //_NR_NAME在print调用里会变成_NR_WRITE，而_NR_WRITE是系统调用号，_NR_WRITE=4，
    						//本行代码会把系统调用号送到eax寄存器
      ...                   //其他寄存器的赋值
    ```

  - 系统陷入内核后执行中断处理函数，其中系统调用号是4. system_call函数主要内容是通过系统调用号从_sys_call_table表中获取系统调用函数，从而调用这个系统调用函数执行。

    ```
    call _sys_call_table(,%eax, 4) //系统调用处理函数入口为_sys_call_table+4*%eax，调用这个处理函数,4代表函数指针								   //大小
    
    其中_sys_call_table是系统调用表，是一个全局变量，他是一个方法指针数组
    fn_ptr sys_call_table[]={
    	sys_setup, sys_exit, sys_fork, sys_read, sys_write,...
    }
    
    在我们的print函数中，他会使用系统调用表的第4项，也就是sys_write
    那么call _sys_call_table(,%eax, 4)实际上就是call sys_write
    这样就会调用系统调用函数sys_write继续执行
    ```

4. 计算机操作系统五个模块

   CPU管理（进程调度）

   内存管理

   IO管理

   磁盘管理

   文件管理

   **操作系统怎么管理不同设备各个模块**

   在操作系统初始化的时候会建立各个设备的初始化数据结构，比如管理内存的Mem_map；然后使用shell等待用户程序调用系统调用使用设备。

**操作系统实验**

- [Linux操作系统源码和实验环境配置](https://blog.csdn.net/qq_42518941/article/details/119756521)

- 缺失动态链接库的库文件查找方法

  ```
  sudo apt-file search libstdc++.so.6
  使用apt-file查找到动态链接库的库文件名称
  然后
  sudo apt-get install libstdc++6:i386
  安装，其中:i386表示是32位版本号的库文件libstdc++6
  ```

- [哈工大Linux操作系统实验详细注释](https://hoverwinter.gitbooks.io/hit-oslab-manual/content/sy1_boot.html)

- 课程大纲

  ```
  操作系统之基础
  L1 什么是操作系统
  L2 开始揭开钢琴的盖子
  L3 操作系统启动
  L4 操作系统接口
  L5 系统调用的实现
  L6 操作系统概述
  L7 操作系统历史
  L8 我们的任务
   
  操作系统之进程与线程
  L9 多进程图像
  L11 用户级线程
  L12 核心级线程
  L13 核心级线程实现实例
  L14 CPU调度策略
  L15 一个实际的schedule函数
  L16 进程同步与信号量
  L17 对信号量的临界区保护
  L18 信号量的代码实现
  L19 死锁处理
  
  操作系统之内存管理
  L20 内存使用与分段
  L21 内存分区与分页
  L22 段页结合的实际内存管理
  L23 请求调页内存换入
  L24 内存换出
  
  操作系统之外设与文件系统
  L25 IO与显示器
  L26 键盘
  L27 生磁盘的使用
  L28 用文件使用磁盘
  L29目录与文件系统
  L30 目录解析代码实现
  ```

- 资料

  [操作系统实验手册](https://hoverwinter.gitbooks.io/hit-oslab-manual/content/sy1_boot.html)

  [操作系统实验手册](https://blog.csdn.net/leoabcd12/article/details/122268321)

  [王道考研]([王道考研操作系统复习笔记_壹～的博客-CSDN博客_操作系统王道考研笔记](https://blog.csdn.net/weixin_45604295/article/details/122858800?utm_source=app&app_version=5.0.1&code=app_1562916241&uLinkId=usr1mkqgl919blen))

  [添加Linux系统调用]([【Linux内核源码分析】操作系统实验 ：向Linux内核增加一个系统调用 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/435297367))

  [Linux内核解析]([Linux0.11内核剖析–内核体系结构 - 走向全栈的MasterHan - 博客园 (cnblogs.com)](https://www.cnblogs.com/HanBlogs/p/5858895.html))

  [Linux课程]([操作系统原理与实践_Linux - 蓝桥云课 (lanqiao.cn)](https://www.lanqiao.cn/courses/115))

## 汇编实验

### 基础知识

1. 每一个微处理器CPU都有自己的机器语言，他是01字符串，汇编语言是机器语言的助记符，汇编程序编程机器语言程序要经过编译器编译和链接器链接得到机器语言程序。

2. 存储器的最小存储单元是字节，一个字节由8位二进制位，用两个十六进制数表示。存储单元从0开始编号

3. CPU管脚和总线连接，CPU总线有三种，一种是地址总线，决定CPU寻址能力，CPU寻址大小是 
   $$
   2^N B
   $$
   也就是2的N次幂那么多的字节，每个存储单元是一个字节。8086CPU的地址总线宽度是20，他可以寻址1MB内存，他的地址空间大小是1MB。

   CPU的数据总线决定了CPU与其他组件交换数据时一次传输数据量的大小，CPU总线是8的倍数，因为一次传输数据量是以一个存储单元为单位，一个存储单元的大小是一个字节，是8位。8086CPU数据总线是16位，也就是他的数据寄存器大小是一个字，是2个字节，是两个存储单元，用4个16进制数表示。

   CPU的控制总线决定了CPU对系统中其他器件的控制能力。

4. 基础知识题目

   1. 一个CPU寻址能力是8KB，也就是
      $$
      2^3*2^{10}=2^{12} B
      $$
      

      也就是他的地址总线宽度是12

   2. 1KB的存储器有1024个存储单元，编号从0到1023，有1024x8个bit，有1024个Byte

   3. 数据和指令都是以二进制数的形式存储在RAM或者ROM中，用16进制表示。

   4. 一个存储单元大小是一个字节，有8位，用两个16进制数表示。

      一个字是16位，两个字节，两个存储单元，用4个16进制表示

5. CPU通过地址总线、数据总线和控制总线和其他器件相连，CPU在控制他们的时候都把他们当成内存来控制。CPU地址空间被划分为主存RAM地址空间、BIOS ROM地址空间、显存ROM地址空间和显存RAM地址空间、万卡地址空间等。鼠标键盘等通过接口连接到CPU的地址空间，接口号也是一个地址空间。每个外部设备都占据CPU的一段地址空间，CPU通过读写这些地址空间从而控制这些期间活动。当然这些地址空间被读写之后需要被扩展插槽上的接口卡程序处理。

6. 8086CPU给出物理地址的方法

   8086CPU地址总线是20，有1MB寻址空间能力，他的寄存期宽度是16，他寻址需要两个寄存器，一个是段寄存器，一个是段内偏移寄存器CS：IP，8086CPU要寻物理地址，先将CS：IP送到地址加法器相加得到一个20位的地址，然后这个20位地址被送入地址总线寻址。CPU把CS：IP指向的物理空间的数据当成命令处理

   一个物理地址可以通过不同的CS：IP合并而成，地址加法器的运算规则是**物理地址=段基址*16+段偏移**，相当于把段基址左移四位之后加上段偏移。8086CPU物理地址有20位，用5个16进制数表示。

   内存并没有分段，分段来自CPU，段的大小不固定，最大是2的16次方，也就是8KB

7. 关于CPU分段的题目

   8086CPU给定段地址0001H，仅仅变化偏移地址寻址，则CPU寻址范围是0001Hx16+0=00010H到0001Hx16+FFFFH=00010+FFFF=1000FH

   8086CPU寻址20000H存储单元，给出的CS最小是CS*16+FFFF=20000H，也就是10001右移一位，向上取大变成1001；给出的CS最大时CS\*16+0=20000H，CS=2000H
   
8. 寄存器的高位存放的在内存高地址空间，也就是B8 22 66中数据时6622H，66在内存高地址空间。

9. CPU通过主板的扩展插槽连接其他期间，包括内存条（主存）、磁盘（外存）、网卡、鼠标键盘等。每个设备都有对应的接口卡程序来处理CPU写入的数据，或者返回数据，或者处理CPU写入的数据。

10. 进制转换

   > 十六进制转十进制
   > $$
   > 1001H=2^0*2^{12}+2^0*2^0
   > $$
   > 二进制转十六进制
   > $$
   > 0001 0000 0000 0001 = 1001H
   > $$
   > 十进制转十六进制
   > $$
   > 1024=2^{10}=2^2*2^8=400H
   > $$
   > 

11. 十六进制加减

    > $$
    > 123B9H-123B0H+1=10
    > $$
    >
    > 

12. 机器语言编程是直接面向CPU寄存器和CPU地址空间编程，直接处理计算机底层的寄存器和存储资源。汇编语言、机器语言更加高效的原因在于他们直接面对寄存器和内存编程，减少了很多高级语言的特性，比如Java和GO语言的垃圾回收机制，需要额外的复杂度取检查和清除垃圾，而这在汇编语言不存在垃圾清除，用户自己在心中构建内存结构并且读写，而不需要程序来控制内存结构的。

13. Debug的使用

    >r：查看、改变寄存器的值
    >
    >d: 查看内存内容     e: 改变内存内容
    >
    >u: 将内存机器指令翻译成汇编指令
    >
    >t: 执行一条机器指令   a: 用汇编的格式向内存写入一条机器指令
    >
    >
    >
    >r cx  查看寄存器cx
    >
    >d 1000:0001 000f 查看10001到1000f的存储单元，如果缺失000f就显示从10001开始的128个存储单元
    >
    >e 1000:0001 修改10001号存储单元数值，如果时ROM修改不成功
    >
    >t 执行一条指令，首先要r cs和r ip修改cs:ip指向的地址
    >
    >a 1000:1 从10001开始写汇编指令
    >
    >
    >
    >8086CPU 分配给ROM存放ROM生产日期的内存地址在fff0:00f5到fff0:00fc，这个日期使用e无法修改
    >
    >

​		debug的d指令显示内存数据，只能显示ASCII字符，如果不是ASCII字		符，那么就会显示一个点	

  	  8086CPU 主存地址空间分配00000到9FFFF的640K，显存地址空间从		A0000到BFFFF的128K地址空间

​        内存存放数据，搞位在低地址单元，低位在低地址单元

14. 使用汇编语言编写和执行程序的过程

    > 找一块地址空间输入数据（例如 e 0：0），并且记住每个数据的地址
    >
    > 找一块地址空间输入指令（例如 a 0：0），注意指令空间和数据空间不要重合，注意地址空间应该是主存空间，而不是显存空间或者ROM空间。注意要在指令中使用mov ds, ax来修改数据段的地址，以此来指定数据段
    >
    > 修改指令寄存器（rcs和rip）指向指令空间的第一个地址
    >
    > 使用t一条指令执行

15. 8086CPU将程序划分3个段，这三个段时代码段、数据段和栈段，每个段使用响应的寄存器进行标记。

    > CS:IP指向代码段，debug可以通过rcs和rip更改CS和IP，汇编程序可以通过jmp 1000:0更改CS:IP或者jmp ax更改IP而不改变CS
    >
    > DS:[立即数] 指向数据段，可以通过mov、add、sub操作内存数据
    >
    > SS:SP 指向栈段，是栈的栈顶地址，可以通过pop和push操作SP

16. 操作的数据的长度
    - 有寄存器的指令，寄存器长度确定数据长度，如add ax,10
    - 没有寄存器的指令需要用word ptr或者byte ptr给定数据的长度，比如mov word ptr [bx],10
17. 8086CPU数据长度只有两种，字节db或者字dw，有一个编译器使用的伪指令双字dd

### 寄存器

8086CPU地址总线宽度20，可以寻址1MB内存，地址空间大小1MB；数据总线16位，决定了他的寄存器宽度是16位，也就是一个字，也就是2个字节，也就是一次传输1个字，2个字节，用4位16进制数表示。8086CPU有14个寄存器，其中，

**通用寄存器**是AX、BX、CX、DX，用来存储一般数据，每个通用寄存器都可以分为两个8位小的寄存器，分为高八位和低八位寄存器，AH/AL，BH/BL，CH/CL，DH/DL

**段寄存器**包括CS、DS、SS、ES。其中CS是指令段，他结合IP寄存器得到指令的地址；DS是数据段，他结合偏移[0]获得数据地址；SS是栈段地址，他结合SP指向栈的栈顶地址；ES是空闲的段地址

#### 赋值指令(修改寄存器的值)

- 通用寄存器赋值

  ```
  mov ax,8   //立即数赋值给ax寄存器
  mov ax,bx  //寄存器bx的数值赋值给ax寄存器
  ```

- 段寄存器赋值

  ```
  //8086CPU读取数据和读取指令使用的不同寄存器
  
  //指令段寄存器CS，结合偏移IP给出指令的内存地址
  jmp 2AE3:3 //执行之后CS=2AE3, IP=0003
  jmp ax, //只会修改IP寄存器数据为ax的值，而CS不变化
  
  //数据段寄存器DS，结合偏移[0]给出数据的内存地址
  mov bx,0000
  mov ds,bx
  mov ax,[0] //读取0:0号字
  mov [0],ax //将ax数据存入0:0号字
  
  //栈段寄存器SS，结合SP给除栈顶地址
  mov ax,1000
  mov ss,ax
  ```
  

#### mov add sub 指令

```
mov/add/sub 寄存器，数据
mov/add/sub 寄存器，寄存器
mov/add/sub 寄存器，内存单元
mov/add/sub 内存单元，寄存器
mov 段寄存器，寄存器
```

#### 栈操作pop和push

```
push/pop 通用寄存器/段寄存器/内存单元
```

8086CPU没有检查是否栈溢出的机制，需要用户程序自己检查是否栈溢出。栈溢出包括空栈使用pop或者满栈使用push。

```
push操作过程
1. sp=sp-2
2. 写入数据
push操作数据向低地址空间增长

pop操作过程
1. sp=sp+2
2. 写入数据
pop操作数据向高地址空间增长

8086CPU没有栈溢出检测机制，需要用户自己检查是否栈溢出，这显示出操作系统的作用，省去了用户程序自己检查是否栈溢出的内存管理

使用10000到1000F这16个字节8个字作为栈，初始化SS=1000，初始化栈顶SP=10，因为没有元素的栈顶是10，而有一个元素的栈顶是E。满栈的时候SP=0.每次出栈和入栈的时候操作的是一个字。

任何时刻，SS:SP指向栈顶元素

8086CPU只能改变栈顶指针SP，所以栈的大小最多是64KB
```

**使用栈交换寄存器值的程序**

```
//使用1000:0到1000:F作为栈空间，则空栈SP=10，满栈SP=0
mov ax,1000
mov ss, ax 
mov sp, 10  //构造栈顶指针用三句话
mov ax,10
mov bx,20
push ax
push bx
pop ax
pop bx
```

**使用栈逆序将内存中的数据保存到另外一个内存块**

```
//数据段在1000:0 01 00 02 00 03 00
//栈段在2000:0到2000:F，设置SP=10
//代码段在3000:0开始的地方

mov ax,1000
mov ds,ax //构造数据段
mov ax,2000
mov ss,ax
mov sp,10 //构造栈段和栈顶地址，在执行mov ss,ax的时候mov sp,10跟				着被执行
push [0]
push [2]
push [4]
pop [0]
pop [2]
pop [4]
//从上面程序我们看出，汇编语言没有类型的概念，那么也就没有数据类型不同位的概念，汇编里面只有字节和字的概念，所有数据都是一样的字节或者字，那么对于不同类型的数据的支持，就需要我们使用高级语言如C上面构造类型，然后不同类型使用不同的指令完成类型操作，比如要入栈一个long类型，他是在16位寄存器是4个字节数据，也就是两个字，那么要存储一个int数据，就需要push或者pop两次，或者在内存中mov两次
```

### 汇编程序编写和执行过程

1. 编写成源程序

   源程序伪指令，用于编译器编译的一些代码

   - code segment 和code ends，标记一个代码段开始和结束，code这个段后面编译连接成为一个地址，标记段的开始
   - end，标记整个汇编程序结束
   - assume，将段和CPU段寄存器关联

2. 编译和连接成exe可执行程序，里面包括数据和代码，以及程序描述信息

3. 操作系统（DOS的shell程序）将exe程序加载到内存并且设置cs:ip执行程序（这时shell程序失去CPU）

   使用debug temp.exe可以让debug加载temp程序到内存

   ![屏幕截图 2022-05-10 194207](C:\Users\cheng\Desktop\JavaBackend\屏幕截图 2022-05-10 194207.png)

   其中，cx保存代码长度，自动分配代码段在076A:0000，自动分配数据段在075A，自动分配栈段在0769:0000

   debug装载程序，从SA开始加载256K的PSP程序，然后在SA*16+0+256=SA+10H:0开始的地方加载用户程序

   注意在debug中要用p指令执行int 21，而不是t指令

   在debug的汇编程序中，mov ax,[0]中0会被单程ds的偏移地址ds:0

   而在masm中，mov ax,[0]的0会被当成数字，也就是ax=0

   如果要在masm中实现[0]被当成地址，只有使用寄存器bx=0,mov ax,[bx]

#### Loop指令（循环）

loop指令使用cx寄存器保存循环的次数。

**执行2*3**

```
// 执行2*3
assume cs:codeseg
codeseg segment
	mov ax,0H

	mov cx,3H
s:     add ax,2H
	loop s
	
	mov ax,4c00H
	int 21H
codeseg ends
end
```

**执行在2000:0开始的64个字节写入0到64**

```
//执行在2000:0开始的64个字节写入0到64
assume cs:codeseg
codeseg segment
	mov ax,2000H
	mov ds,ax

	mov cx,64
	mov bx,0
s:  	mov ds:[bx],bl
	inc bx
	loop s	

	mov ax,4c00H
	int 21H
codeseg ends
end
```

使用g cs:e 可以直接执行到指定的行，而不用t单步执行

#### 具有数据段、栈段、代码段的完整程序

**反转数组**

```
assume ds:dataseg,ss:stackseg,cs:codeseg

dataseg segment
	dw 1234H,4567H,6789H
dataseg ends

stackseg segment
	dw 0,0,0
stackseg ends

codeseg segment
start:	mov ax,dataseg		;start标记主程序地址入口
	mov ds,ax			;构造数据段地址

	mov ax,stackseg
	mov ss,ax
	mov sp,10H			;构造栈段地址

	mov cx,3
	mov bx,0
s0:	push [bx]
	add bx,2
	loop s0			;入栈
	
	mov cx,3
	mov bx,0
s1:	pop [bx]
	add bx,2
	loop s1			;弹栈

	mov ax,4c00H
	int 21H
codeseg ends

end start				;end start可以标记主程序入口地址
```

#### 多维数组的寻址方式

bx、si、di和立即数都可以用来多维数组寻址，他们可以相互组合[bx+si+立即数]

当处理多维数组需要嵌套循环的时候，因为循环只有cx可以当作计数器，所以我们要保存外部循环的cx，保存外部循环的cx一种方式是在内存中自己找一块空间，另外一种是使用栈来保存cx，推荐用栈，因为这样减少出错可能。

> 8086CPU只有四种寄存器bx、bp、si、di可以放到方括号里面进行内存寻址
>
> 其中组合方式也是固定的，只有下面的几种方式
>
> 1. 立即数寻址，数据段地址ds给出
>
>    [立即数]
>
> 2. 寄存器间接寻址，数据段地址ds给出
>
>    [bx]
>
>    [bp]
>
>    [si]
>
>    [di]
>
> 3. 寄存器相对寻址
>
>    - 用于结构体[bx].idata，一维数组idata[bx]，二维数组\[bx][idata]，数据段地址ds给出
>
>      [bx+立即数]
>
>      [si+立即数]
>
>      [di+立即数]
>
>    - 段地址ss给出
>
>      [bp+立即数]
>
> 4. 基址变址寻址
>
>    - 用于二维数组\[bx][si]，数据段地址ds给出
>
>      [bx+si]
>
>      [bx+di]
>
>    - 短地址栈段地址给出ss
>
>      [bp+si]
>
>      [bp+di]
>
> 5. 相对基址变址寻址
>
>    - 用于包含结构体的二维数组[bx].idata[si]，短地址ds给出
>
>      [bx+si+立即数]
>
>      [bx+di+立即数]
>
>      [bp+si+立即数]
>
>    - 短地址ss给出
>
>      [bp+di+立即数]

**将二维数组的字符串改成大写**

```
assume cs:codeseg,ds:dataseg,ss:stackseg

dataseg segment
	db 'abcd'
	db 'efgh'
	db 'igkl'
dataseg ends

stackseg segment
stackseg ends

codeseg segment
start:mov ax,dataseg
	mov ds,ax

	mov ax,stackseg
	mov ss,ax
	mov sp,16

	mov cx,3
	mov bx,0  		; for(bx=0;bx<3;...)
s0:	push cx
	mov cx,4		; for(si=0;si<3;...)
	mov si,0
	
s1:	mov al,[bx+si]
	and al,11011111B	;将小写转成大写用这个命令，将大写转成小写用
				;or al,00100000B
	mov [bx+si],al
	add si,1		; si+1，这里就是加一
	loop s1

	pop cx		;外层循环的cx保存在栈里面
	add bx,4		; bx+1,加一实际加的是数组的长度
	loop s0

	mov ax,4c00H
	int 21H
	
codeseg ends

end start
```

#### 使用结构体

```
assume cs:codeseg,ds:dataseg

dataseg segment
	db 3 dup(0,'abc',0)
dataseg ends

codeseg segment
start:mov ax,dataseg
	mov ds,ax
	
	mov cx,3
	mov bx,0

s0:	mov si,1
	mov al,[bx+si+1]
	and al,11011111B
	mov [bx+si+1], al ;修改结构体的第二项的第二个字符

	add bx,5
	loop s0

	mov ax,4c00H
	int 21H
codeseg ends

end start
```

### 转移程序

8086CPU转移指令有五类

- 无条件转移指令（jmp）
- 条件转移指令
- 循环指令（loop）
- 过程（函数调用）
- 中断

#### 转移指令原理

**转移行为有两种**

- 只修改IP，成为段内转移
  - 段内段转移，IP修改范围-128到127，也就是8位数据
  - 段内近转移，IP修改范围-32768到32767，也就是16位数据
- 同时修改CS和IP，称为段间转移

**段内转移原理**

- 段内短转移jmp short 标号

  程序执行到jmp short 标号过程

  1. IP指向jmp short 标号指令，传入指令寄存器IR
  2. IP加上IR指令长度，从而指向下一条指令
  3. CPU执行IR内指令，跳转到标号的位置，执行标号位置的指令

  上述的过程jmp short 标号指令被编译器编译的时候没有给出标号的目的地址，而是给出了标号到**jmp short 标号**这条指令的下一条指令地址的偏移量，这个偏移量范围是8位数据，计算这个偏移量的过程是编译器完成的。比如编译器编译得到EB03，03表示的就是偏移量。

- 段内近转移jmp near ptr 标号

  同上述一样，段内近转移的区别在于偏移量范围是16位数据

**段间转移原理**

段间转移的转移指令会直接给出目的地址

- jmp dword ptr ds:[0]

  ds:[0]字单元给出转移偏移地址IP

  ds:[2]字单元给出转移段地址CS

- jmp far ptr 标号

  转移的段地址和偏移地址是标号所在的段地址和偏移地址

**段间转移题目**

- 使用loop实现循环

  loop时段内短转移

```
assume cs:codeseg

codeseg segment
start:mov cx,3
	mov ax,0
s0:	add ax,1
	loop s0

	mov ax,4c00H
	int 21H
codeseg ends

end start
```

- 使用jmp far ptr 标号实现循环

  ```
  assume cs:codeseg
  
  codeseg segment
  start:mov ax,0
  s0:	add ax,1
  	jmp far ptr s0
  
  	mov ax,4c00H
  	int 21H
  codeseg ends
  
  end start
  ```

- 使用jmp dword ptr ds:[0]实现循环

  ```
  assume cs:codeseg, ds:dataseg
  
  dataseg segment
  	dd	0
  dataseg ends
  
  codeseg segment
  start:
  	mov ax, dataseg
  	mov ds, ax		;构造数据段
  	mov ax, offset s0	;伪指令offset获得标号在代码段的偏移
  	mov ds:[0], ax  	;偏移
  	mov ds:[2], cs	;代码段段地址
  	
  	mov cx,3
  	mov ax,0
  s0:	add ax,1
  	
  	jcxz ok		; jcxz是段内段转移，他表示cx=0时跳转到标号位置
  	jmp dword ptr ds:[0]
  
  ok:	mov ax,4c00H
  	int 21H
  codeseg ends
  
  end start
  
  ```

**注意事项**

编译器会对转移偏移越界报错，如果loop，jcxz，jmp short发生标号超过范围，将会报编译器错误。

### 8086CPU显示器的地址空间

8086CPU显示器地址空间在B8000H到BFFFFFH这32KB的空间。

一共时25行，每行80个字符，每个字符包含ASCII码和字符属性，25x80x2=4000B。一共有8页，显示器可以显示任意一页，一般显示低0页，也就是地址在B8000H到B8F9FH这个地址空间。

**向显示器缓冲区输入的程序**

```
assume cs:codeseg, ds:dataseg

dataseg segment
	db 160 dup(41H,11001010B)	;41H是字符A，caH是字符属性，红底								 绿字闪烁
dataseg ends

codeseg segment
start:
	mov ax,0B800H	;要加0才能识别16进制，显示器缓冲区的段地址
	mov es,ax
	mov ax,dataseg
	mov ds,ax

	mov cx,160
	mov bx,0
s:	mov ax,ds:[bx+0]
	mov es:[bx+0],ax
	add bx,2
	loop s

	mov ax,4c00H
	int 21H
codeseg ends

end start
```

###  汇编调用子程序设计（模块化程序设计）

#### call指令

**call 标号**

push ip

jmp near ptr 标号

**call far ptr 标号**

push cs

push ip

jmp far ptr 标号

**call 16位reg**

push ip

jmp 16位reg

**call word ptr 内存单元**

push ip

jmp word ptr 内存单元

**call dword ptr 内存单元**

push cs 

push ip

jmp dword ptr 内存单元

#### ret指令

**ret指令相当于执行了**

pop ip

**retf指令相当于执行了**

pop ip

pop cs

**使用栈实现call和ret指令**

```
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
assume cs:codeseg, ds:dataseg, ss:stackseg

dataseg segment
	db 160 dup(41H,11001010B)
dataseg ends

stackseg segment
	db 16 dup(0)
stackseg ends

; 实现2x3
codeseg segment

main:	mov ax,dataseg
	mov ds,ax
	mov ax,stackseg
	mov ss,ax
	mov sp,16

	mov ax,2
	mov cx,3
	call s

	mov ax,4c00H
	int 21H

s:	add ax,2
	loop s
	ret				;子程序结果保存在ax寄存器

codeseg ends

end main


;;;;;;;;;;;;;;;;;;;使用栈实现

assume cs:codeseg, ds:dataseg, ss:stackseg

dataseg segment
	db 160 dup(41H,11001010B)
dataseg ends

stackseg segment
	db 16 dup(0)
stackseg ends

; 实现2x3
codeseg segment

main:	mov ax,dataseg
	mov ds,ax
	mov ax,stackseg
	mov ss,ax
	mov sp,16

	mov ax,2
	mov cx,3
	
	;使用栈实现call
	push cs
	mov bx,offset ip	;ip为call执行的下一条指令入栈
	push bx
	jmp far ptr s

ip:	mov ax,4c00H
	int 21H

s:	add ax,2
	loop s

	mov dx,ss
	mov ds,dx
	mov bx,sp
	jmp dword ptr ds:[bx]  ;按双字跳转

codeseg ends

end main
```

#### 参数传递

1. 寄存器传递
2. 内存传递（使用ds段指向传递的内存地址）
3. 栈传递（使用ss指向传递的参数的栈），此外，栈还用于保存调用子程序的主程序的参数。

**二维字符串转大写**

- 使用cx和jcxz遍历字符串
- 保存主程序寄存器cx到栈

```
assume cs:codeseg, ds:dataseg, ss:stackseg

dataseg segment
	db	'abcd',0
	db	'cdef',0
dataseg ends

stackseg segment
	db 16 dup(0)
stackseg ends

codeseg segment
main:	mov ax,dataseg
	mov ds, ax
	mov ax, stackseg
	mov ss, ax
	mov sp, 16
	
	mov cx,2
	mov bx,0

loops:	
	call change
	add bx,5
	loop loops
	
	mov ax,4c00h
	int 21h

change:
	push cx		;保存主程序变量cx

	mov si,0
changeLoop:
	mov ch,0
	mov cl,ds:[bx+si]
	jcxz changeReturn
	mov al, ds:[bx+si]
	and al,11011111B
	mov ds:[bx+si],al
	add si,1
	jmp changeLoop

changeReturn:
	pop cx
	ret
	
	
codeseg ends

end main
```

#### 调用子程序输出到显示缓冲区

```
assume cs:codeseg, ds:dataseg

dataseg segment
	db 'Welcom to China',0	;
dataseg ends

codeseg segment
start:
	mov ax,0B800H	;要加0才能识别16进制，显示器缓冲区的段地址
	mov es,ax		;显示缓冲区地址
	mov ax,dataseg
	mov ds,ax
	call show

	mov ax,4c00h
	int 21h

show:	
	mov bx,0
	
	mov si,0
showLoop:
	mov ch,0
	mov cl,ds:[si]
	add si,1
	jcxz showReturn
	mov es:[bx+1124],cl
	mov byte ptr es:[bx+1+1124],11001010B
	add bx,2
	loop showLoop	

showReturn:
	ret
codeseg ends

end start
```

#### 将12306输出到屏幕

```
assume cs:codeseg,ss:stackseg,ds:dataseg

dataseg segment
	db 10 dup(0)
dataseg ends

stackseg segment
	db 16 dup(0)
stackseg ends

;将12306输出到屏幕
;首先获取12306的十进制数数字的编码，再加上30H得到十进制数的字符的编码
;然后把十进制数字的字符输出到屏幕
codeseg segment
start:	
	mov ax, stackseg
	mov ss, ax
	mov sp, 16

	mov ax, dataseg
	mov ds, ax

	mov word ptr ds:[0], 10

	mov bx,0
	call divtrans	;调用获取12306的每位字符保存到栈，
				;寄存器传递参数，
				;包括数字bx=12306，栈ss:sp，记录字符个数bx
				;返回数据
				;包括bx表示记录字符个数，栈指针ss:sp
	mov ax,4c00H
	int 21H

divtrans:
	mov ax,12306
	mov dx,0

divtransLoop:
	div word ptr ds:[0]
	
	add dx,30H  ;加上30H是把十进制数字符变成数字字符
	push dx
	add bx,1
	mov cx,ax
	jcxz divtransReturn
	mov dx,0

	jmp divtransLoop

divtransReturn:

;show显示，传递参数栈，计数bx
show:	
	mov ax,0B800H	;要加0才能识别16进制，显示器缓冲区的段地址
	mov es,ax		;显示缓冲区地址

	mov cx,bx
	mov bx,0
showLoop:
	pop ax
	mov es:[bx+1124],al
	mov byte ptr es:[bx+1+1124],11001010B
	add bx,2
	loop showLoop


	ret
	

codeseg ends

end start
```

#### 标志寄存器

- ZF，零标志位，判断算术指令或者逻辑指令结果是否为0，如果为0，则ZF=1，否则，ZF=0.算术指令和逻辑指令包括sub\add\mul\div\inc\or\and等，传送指令mov\push\pop不影响ZF
- PF，奇偶标志位，判断运算结果中1的个数是否为奇数
- SF，符号标志位，表示数字的正负
- CF，进位标志位
- OF，溢出标志位

**标志寄存器的作用-用于条件转移指令**

比如cmp 8,3; 则ZF=0，CF=0等，条件操作影响标志位

**cmp配合指令完成条件转移**

| 指令 | 含义                     | 检测标志位 |
| ---- | ------------------------ | ---------- |
| je   | 等于就跳转               | zf=1       |
| jne  | 不等于就跳转             | zf=0       |
| jb   | 小于就跳转               | cf=1       |
| jnb  | 不小于就跳转（大于等于） | cf=0       |
| ja   | 大于就跳转               | cf=0且zf=0 |
| jna  | 不大于就跳转（小于等于） | cf=1或zf=1 |

- DF，方向标志位，串传送指令控制si和di增长的方向，配合rep movsb或者rep movsw使用

  - 当DF=0，正向增长，如果是rep movsb，那么si+1,di+1,如果rep movsw，那么si+2,di+2
  - 当DF=1，福祥增长，如果是rep movsb，那么si-1,di-1, 如果是rep movsw，那么si-2,di-2

  **使用方向标标志位复制字符串**

  ```
  assume cs:codeseg, ds:dataseg
  
  dataseg segment
  	db 'Welcom to China'
  	db 15 dup(0)
  dataseg ends
  
  ; cld 设置df=0
  ; std设置df=1
  codeseg segment
  start:	
  	mov ax, dataseg
  	mov ds, ax
  	mov si,0
  	mov es, ax
  	mov di,15		;将ds:si处的字符复制到es:di处，DF控制增长方向
  	mov cx,15		;复制字符个数
  	cld
  	rep movsb
  
  	mov ax,4c00H
  	int 21h
  codeseg ends
  
  end start
  ```

- pushf和popf，将标志寄存器压栈和弹栈

### 内中断

中断时CPU执行过程中因为系统发生了某些时间而不得不暂停当前程序转而执行其他程序的过程。

中断类型码标识中断来源，中断处理程序是发生中断时执行的处理程序，中断类型码和中断处理程序通过中断向量表进行映射。中断向量表按双字保存了中断处理程序的段地址和偏移地址CS:IP，中断类型码是字节型数据，有256种来源，每个有4个字节两个字标识一个中断处理程序起始地址，那么中断向量表大小
$$
2^8*2^2=2^{10}=1KB
$$
8086CPU中断向量表大小1KB

**中断过程**

- 取得中断类型码N

- pushf标志寄存器入栈

- TF=0，IF=0，设置标志寄存器的TF和IF位

- push cs

- push ip

- mov ip, 0:[4*N], 

  mov cs, 0:[4*N+2]

**Debug单步中断**

Debug使用了8086CPU的单步中断，8086CPU当TF=1时会发生单步中断，单步中断中断类型码是1。使用t触发单步中断，但是进入的时候要设置TF=0，否则中断处理程序执行完成之后返回主程序发现TF=1就会又触发中断

**不响应中断的情况**

一些情况需要原子操作，比如mov ss,ax, mov sp,16，这两个指令要一起操作指向栈顶，不能分开，这样在执行这两个指令的时候不会响应中断。

**编写一个中断**

编写函数使用call ret两个指令，编写中断使用int iret执行

int过程：

- pushf
- TF=0,IF=0
- push cs
- push ip
- 重新设置cs和ip

iret过程

- pop ip
- pop cs
- popf

编写一个中断主要包括三个方面的内容

- 将中断处理程序加载到内存模块
- 设置中断向量表模块（8086CPU中断向量表时0起始1KB的内存空间）
- 编写中断处理程序（一个普通程序）

使用中断int iret可以从栈中获得陷入中断的主程序入口地址

**编写一个中断8c，中断处理程序保存在0:200H开始的位置**

- 使用了串传送指令

```

;编写一个中断8c，中断处理程序保存在0:200H开始的位置。
;
assume cs:codeseg	

codeseg segment

;装载中断处理程序到内存
;设置中断向量表
main:
	mov ax,0
	mov es,ax
	mov di,200H
	
	mov ax,cs
	mov ds,ax
	mov si,offset int0

	mov cx,offset int0End-offset int0
	rep movsb		;上面的程序用来装载中断处理程序到0:200开始的位置

	mov bx,0230H
	mov ax,0
	mov es,ax
	mov word ptr es:[bx+2],0H
	mov word ptr es:[bx+0],0200H	;设置中断向量表，中断号为0230H/4=140=8cH,中断入口程序地址0:0200H

	mov ax,4c00H
	int 21H


int0:	jmp int0Start	;中断处理程序

data:	
	db 'W',11001010B
	db 'e',11001010B
	db 'l',11001010B
	db 'c',11001010B
	db 'o',11001010B
	db 'm',11001010B
	db 'e',11001010B

int0Start:
	mov ax,0B800H
	mov es,ax
	mov di,1124		;设置es:di

	mov ax,cs		;这个cs将会在设置中断向量表和装载中断处理程序中给出，都是cs
	mov ds,ax
	mov si,200H+offset data-offset int0		;设置ds:si,计算si就是数据段的偏移，200H是整个中断处理程序偏移，
											;offset data-offset int0是数据段相对200H偏移
	
	mov cx,7
	rep movsw

	iret
int0End:
	nop

codeseg ends

end main
```

### BIOS启动过程

- 计算机加电时CS:IP自动指向FFFF:0，执行BIOS的系统监测和初始化程序
- BIOS的系统检测和初始化程序会将BIOS的中断例程登记到内存中断向量表中（8086中断向量表在内存0地址处1KB的内存）。BIOS的中断例程不用被加载到内存，因为ROM本身就是内存一部分，但是操作系统在磁盘上，不是内存一部分，需要被加载到内存。
- BIOS系统检测和初始化程序执行完之后，会调用int 19hBIOS中断进行操作系统引导（操作系统存放在磁盘的0地址处，是一个image文件，操作系统引导会提醒选择操作系统的引导项）。
- 启动DOS后，DOS会将操作系统中断例程DOS中断例程加载到内存，并且登记到中断向量表。

#### BIOS中断例程的应用   

BIOS的中断例程包含多个子程序，int 10h时BIOS设置光标的中断

**使用BIOS中断例程设置光标并且在光标处显示字符的程序**

```
assume cs:codeseg	

codeseg segment
main:
	mov ah,2	;ah用来标记10h号中断例程使用的子程序，这里是第二号，第二号子程序设置光标位置
	mov bh,0	;bh用来标记显示的是哪一页，8086CPU显存分为8页，每页是25*80的字符=2000个字符=4000个字节
	mov dh,5	;dh存放行号
	mov dl,12	;dl设置光标列号
	int 10h

	mov ah,9	;9号中断例程子程序是在光标处显示字符的子程序
	mov al,'a'	;显示的字符
	mov bl,11001010b ;设置显示字符的属性
	mov bh,0	;存放页号
	mov cx,3	;字符重复个数
	int 10h		;调用中断处理程序需要使用寄存器或者内存传递参数

	mov ax,4c00h
	int 21h
codeseg ends

end main
```

#### DOS中断例程的应用

**使用DOS中断例程在光标处显示字符串，实现printf**

```
assume cs:codeseg	


dataseg segment
	db 'Welcome to China', '$'	;$在DOS的21h号中断例程的第9个子程序中标记字符串结束
dataseg ends

codeseg segment
main:
	mov ah,2	;BIOS的10号中断例程的2号子程序
	mov bh,0	;传递0页
	mov dh,24	;行号
	mov dl,0	;列号
	int 10h

	mov ax,dataseg
	mov ds,ax
	mov dx,0	;ds:dx指向字符串首地址
	mov ah,9	;DOS的21号中断例程的第9个子程序
	int 21h	;DOS的21号中断例程

	mov ax,4c00h
	int 21h
	
codeseg ends

end main
```

### 端口

8086CPU通过总线（地址总线、控制总线、数据总线）连接存储器，存储器占用CPU内存地址空间，存储器包括主存RAM、ROM、cache、各种器件的RAM和ROM

8086CPU通过总线还连接外部器件的寄存器，这些外部器件寄存器被称为**端口**，CPU也对这些端口进行编址，形成端口地址空间。端口地址空间大小是64KB

读写存储器的命令是mov, push, pop，而读写端口的命令是in, out；读写端口的结果保存到al或者ax寄存器（只有这两个，如果读取8位端口，使用al；如果读取16位端口，使用ax）

**in al, 60h执行过程**

这是一条读取60h号端口的命令，读取的数据存放到al寄存器。

- CPU向地址总线发出60h
- CPU向控制总线发出**端口读**指令，选中60h端口所在寄存器通知他读数据
- 端口所在芯片把数据通过数据总线送入CPU

**mov al, [60h]执行过程**

- CPU像地址总线发出60h
- CPU向控制总线发出**内存读**指令，选中60h所在的存储器并通知他读数据
- 存储器把数据通过数据总线送入CPU

**读取CMOS系统信息端口**

CMOS芯片是主板上芯片，存放系统信息，包括时钟信息，他包含一个128B的存储单元RAM。70h传递访问的RAM地址，71h传递数据，注意不要修改RAM信息，这样会产生系统错误。

**读取月份**

```
assume cs:codeseg	

codeseg segment
main:
	mov al,8	;8号CMOS地址单元存放月份，al的前四个位是月份十位BCD码，后四位是月份个位BCD码
	out 70h,al	;al传递读写端口的数据
	in al,71h	;CPU写入CMOS的70h端口之后CMOS芯片会在71h端口写入数据

	mov ah,al
	mov cl,4
	shr ah,cl	;取al的前四位保存到ah
	and al,00001111b	;取al的后四位保存到al

	add ah,30h
	add al,30h	;十进制BCD码转字符ASCII码是加上30h

	mov bx,0b800h
	mov es,bx
	mov byte ptr es:[24*80*2+0],ah
	mov byte ptr es:[24*80*2+2],al

	mov ax,4c00h
	int 21h

codeseg ends

end main
```

**读取年月日 时分秒**

```
;使用栈传递参数注意事项
;主程序压入传递参数，调用call函数，会把主函数ip或者cs:ip压入栈（根据jmp near或者jmp far确定）
;函数内先把cs:ip或者ip弹出保存到内存，然后按照参数压栈的反向顺序弹出栈，同时保存主程序的一些今存其参数，这些参数在ret之前弹出ip或者cs:ip之前需要恢复。

;这个过程（函数调用过程）的切换实际上很接近进程切换了，函数切换只需要改变cs:ip指向，不改变ds和ss等寄存器指向，也就是函数调用不切换数据段和栈段，一定切换cs:ip，可能改变其他寄存器的数值，因为新程序要用到现在的寄存器，那么就会改变主程序的寄存器数值。用户线程切换只是切换了栈，需要保存栈ss:ip到内存地址


assume cs:codeseg,ds:dataseg,ss:stackseg

stackseg segment
	dw 8 dup(0)
stackseg ends

dataseg segment
	a db 9,8,7,4,2,0
	b dw 2 dup(0)
dataseg ends

codeseg segment

main:
	mov ax,stackseg
	mov ss,ax
	mov sp,16
	
	mov ax,dataseg
	mov ds,ax

	mov cx,6
	mov si,0
s:	mov al,a[si]
	mov ah,0
	push ax
	push si			;使用栈传递参数si和a[si]

	call disp
	add si,1
	loop s

	mov ax,4c00h
	int 21h	

disp:	
	pop word ptr b[0]	;保存程序返回地址，程序ret前重新压栈

	pop si				;传递的参数
	pop ax			

	push cx				;保留主程序寄存器参数，在程序ret压入ip之前要恢复cx

	out 70h,al	;al传递读写端口的数据
	in al,71h	;CPU写入CMOS的70h端口之后CMOS芯片会在71h端口写入数据

	mov ah,al
	mov cl,4
	shr ah,cl	;取al的前四位保存到ah
	and al,00001111b	;取al的后四位保存到al

	add ah,30h
	add al,30h	;十进制BCD码转字符ASCII码是加上30h

	mov bx,0b800h
	mov es,bx

	mov bx,0
	add bx,si
	add bx,si
	add bx,si
	add bx,si

	mov byte ptr es:[24*80*2+bx+0],ah
	mov byte ptr es:[24*80*2+bx+2],al

	pop cx

	push b[0]
	ret

codeseg ends

end main
```

### 外中断

输入输出设备的接口芯片控制输入输出设备的工作，CPU的端口是CPU用来标识输入输出设备接口芯片的寄存器的地址（端口地址空间），CPU和输入输出设备通过端口进行联系。CPU和输入输出设备通过总线（地址总线、控制总线、数据总线）进行连接。

内中断时CPU执行程序引发的，比如int 21h，中断类型码从CPU执行程序内部给出；外中断时外部器件产生的，中断类型码通过数据总线传给CPU。CPU在执行指令之前会检查是否发生中断，如果发生中断，就会跳转到中断处理程序执行。跳转的过程

- 内中断

  从中断源获取中断类型码N

  pushf

  TF=0,IF=0 ，其中TF=0标识CPU处于连续工作状态，而不是单步工作状态，单步工作状态执行一条指令之后会显示寄存器信息并且等待给出下一条地址；IF表示中断处理程序是否可以被中断，sti设置if=1，cli设置if=0.

  push cs， push ip

  设置ip=(N\*4) cs=(N\*4+2)

- 外中断

  外中断分为可屏蔽中断和不可屏蔽中断，根据中断类型码来区分，不可屏蔽中断类型码固定位2

  - 可屏蔽外中断

    可屏蔽中断时CPU可以不响应的中断，几乎所有的外设中断都是可屏蔽中断

    可屏蔽中断执行过程和内中断差不多，只是他的中断类型吗是外设通过数据总线传递的，而不是从程序执行过程获得的

    其次，如果要设置一个中断可以被中断，也就是执行完一条指令之后就跳转到其他中断，那么这个中断处理程序需要设置sti令if=1，那么这个中断处理程序就可以被中断。

  - 不可屏蔽中断

    不可屏蔽中断类型码固定位2，它不需要获取中断类型码。一般时系统紧急时间才会使用不可屏蔽中断，当中断看到一个不可屏蔽中断，那么他必须跳转。而不用关是否if=0

**外中断引发过程，以键盘输入为例**

- 外设输入送入端口。按下键盘，产生扫描码送入端口
- 外设向CPU传递中断信息，引发中断，包括中断类型码。键盘向CPU传递int 9h中断。int 9h中断是BIOS提供的用于处理键盘输入的中断
- CPU在执行一条指令之前检查是否有中断，如果发生中断并且IF=1，那么CPU跳转到中断处理程序执行。设置IF=0实际就是关中断，除非中断处理程序执行完成，否则不会响应中断，除非遇到不可屏蔽中断2h。设置IF使用sti和cli指令

**编写int 9h中断处理键盘输入，引发int 9h中断是由硬件产生的，我们能做的是中断处理程序实现，下面的程序根据输入的F1键更改窗口显示的背景色**

```
;
assume cs:code

stack segment
	db 128 dup(0)
stack ends

code segment
start:
	mov ax, stack
	mov ss,ax
	mov sp,128
	
	push cs
	pop ds

	mov ax,0
	mov es,ax

	mov si,offset int9
	mov di,204h
	mov cx,offset int9end-offset int9
	cld		;设置movsb的增长方向
	rep movsb

;保存int 9h的原来的中断程序的入口地址
	push es:[4*9]
	pop es:[200h]
	push es:[4*9+2]
	pop es:[202h]
	
;原子操作实现修改新的int 9h中断程序入口地址
	cli
	mov word ptr es:[4*9],204h
	mov word ptr es:[4*9+2],0
	sti					;使用cli和sti实现原子操作，通过关中断实现原子操作

	mov ax,4c00h
	int 21h

int9:
	push ax
	push bx
	push cx
	push es

	in al,60h
	
	pushf
	call dword ptr cs:[200h]

	cmp al,3bh
	jne int9ret

	mov ax,0b800h
	mov es,ax
	mov bx,1
	mov cx,2000
s:
	inc byte ptr es:[bx]
	add bx,2
	loop s

int9ret:
	pop es
	pop cx
	pop bx
	pop ax
	iret

int9end:
	nop

code ends
end start
```



**使用栈模拟int 和iret 指令，同理可以模拟call和ret指令**

### 8086CPU指令

#### 数据传送指令

mov,push,pop,pushf,popf

#### 算术运算指令

add,sub,adc,sbb,inc,dec,cmp,imul,idiv,aaa，实现寄存器和内存算术运算，结果影响标志寄存器sf,zf,of,cf,pf,af

#### 逻辑指令

and,or,not,xor,test,shl,shr,sal,sar,rol,ror,rcl,rcr，影响标志位

#### 转移指令

- 无条件转移，jmp
- 条件转移，jcxz，je，jb，ja，jnb，jna
- 循环指令，loop
- 过程，call，ret，retf
- 中断，int，iret

#### 处理机控制指令

设置标志寄存器或者其他CPU状态的指令，cld，std，cli，sti，nop，clc，cmc，stc，hlt，wait，esc，lock

#### 串处理指令

批量处理内存数据，movsh，movsw，cmps，scas，lods，stos，需要结合rep，repe，repne等指令执行串处理



### int 9h和int 16h处理键盘输入

BIOS处理键盘输入指令有两个，一个是int 9h负责把数据存放到键盘缓冲区，键盘缓冲区是BIOS的9h号中断处理程序使用的内存，有16个字单元，可以存放15个按键扫描码和对应的ASCII码。当按下一个键，int 9h中断获取扫描码，检查状态字节，把扫描码转换成相应的ACSII码，然后把扫描码存放到高位，ASCII码存放到低位。

int 16h负责从键盘缓冲区中读取数据，如果键盘缓冲区有数据，那么就读取到ax，其中ah存放扫描码，al存放ASCII码，然后从键盘缓冲区删除这个数据。

int 9h和int 16h配合使用实现键盘输入和处理

**int 16h处理键盘输入**

```
;根据输入r g b来改变背景颜色
;int 16h如果键盘缓冲区为空会忙等待循环直到有数据输出到ax寄存器，然后返回
assume cs:code

code segment
start:
	mov ah,0
	int 16h

	mov ah,1
	cmp al,'r'
	je red
	cmp al,'g'
	je green
	cmp al,'b'
	je blue
	jmp short sret

red:
	shl ah,1
green:
	shl ah,1
blue:
	mov bx,0b800h
	mov es,bx
	mov bx,1
	mov cx,2000
s:
	and byte ptr es:[bx],11111000b
	or es:[bx],ah
	add bx,2
	loop s

sret:
	mov ax,4c00h
	int 21h

code ends
end start
```



**int 16h处理键盘输入**

```
assume cs:codeseg


codeseg segment

charstack: 
	jmp short charstart

table	dw charpush,charpop,charshow	;子程序地址表，保存子程序CS:IP
top	dw 0								;栈顶指针，使用默认ds和si定义空栈栈顶，top表示添加元素之后偏移，加上ds:												;[si+top]之后得到真正内存栈顶指针。用内存top实现一个栈。这个栈要和ss:sp栈区别
										;这个内存栈空间无限大，但是ss:sp栈大小只有16位个字节

charstart:								;根据功能号ah从子程序地址表找到功能程序入口地址执行
	push bx
	push dx
	push di
	push es

	cmp ah,2
	ja sret
	mov bl,ah
	mov bh,0
	add bx,bx
	jmp word ptr table[bx]

charpush:								;压入数据到内存栈
	mov bx,top
	mov [si][bx],al
	inc top
	jmp sret

charpop:								;从内存站弹出
	cmp top,0
	je sret
	dec top
	mov bx,top
	mov al,[si][bx]
	jmp sret

charshow:								;显示内存站数据
	mov bx,0b800h
	mov es,bx
	mov al,160
	mov ah,0
	mul dh
	mov di,ax
	add dl,dl
	mov dh,0
	add di,dx

	mov bx,0

charshows:
	cmp bx,top
	jne noempty
	mov byte ptr es:[di],' '
	jmp sret
noempty:
	mov al,[si][bx]
	mov es:[di],al
	mov byte ptr es:[di+2],' '
	inc bx
	add di,2
	jmp charshows

sret:
	pop es
	pop di
	pop dx
	pop bx
	ret

getstr:
	push ax

getstrs:							;使用int 16h读取键盘缓冲区数据，根据读入char执行对应功能号程序
	mov ah,0
	int 16h
	cmp al,20h
	jb nochar
	mov ah,0
	call charstack
	mov ah,2
	call charstack
	jmp getstrs

nochar:
	cmp ah,0eh
	je backspace
	cmp ah,1ch
	je enter
	jmp getstrs
backspace :
	mov ah,1
	call charstack	
	mov ah,2
	call charstack	
	jmp getstrs

enter:
	mov al,0
	mov ah,0
	call charstack
	mov ah,2
	call charstack
	pop ax
	ret


main:
	call getstr
	
	mov ax,4c00h
	int 21h
codeseg ends
end main
```

### int 13h指令对磁盘读写

3.5英寸磁盘分为上下两面，每面有80个磁道，么个磁道有18个扇区，每个扇区有512B，则3.5英寸磁盘总字节数是
$$
2*80*18*512
$$
BIOS提供int 13h中断例程对磁盘进行读写，要向磁盘控制器传入寄存器参数，包括磁面号、磁道号、扇区号、扇区数、驱动器号等，磁面号、磁道号、驱动器号从0开始编址，扇区号从1开始编址。

**读写磁盘**

```
assume cs:codeseg


codeseg segment
;把内存es:bx处1个扇区写入到磁盘0面0道1扇区开始的地方
main:
	mov ax,0b800h
	mov es,ax
	mov bx,0
	
	mov al,1
	mov ch,0
	mov cl,1
	mov dl,0
	mov dh,0
	mov ah,3	;功能号，写磁盘
	int 13h

;从磁盘读1个扇区到内存es:bx处
	mov ax,0
	mov es,ax
	mov bx,200h	;es:bx指向接收从磁盘写入到内存的内存地址

	mov al,1	;al向磁盘控制器程序传递扇区数
	mov ch,0	;磁道号
	mov cl,1	;扇区号
	mov dl,0	;驱动器号
	mov dh,0	;磁头号（磁面号）
	mov ah,2	;功能号，读磁盘
	int 13h

	mov ax,4c00h
	int 21h

codeseg ends
end main
```

**实现磁盘逻辑地址空间**

使用int 13读写磁盘需要传递面号、磁道号、扇区号、驱动器号、扇区数等，考虑实现磁盘逻辑地址空间，使得传递的不是面号、磁道号、扇区号，而是逻辑地址
$$
逻辑地址=(磁面号*80+磁道号)*18+扇区号-1
$$

### 编写系统引导程序

BIOS启动过程

- 计算机加电后CS:IP指向FFFF:0，执行一条跳转指令，转移到BIOS硬件系统检测和初始化程序，这个过程会将BIOS的中断登记到中断向量表（内存0开始的1KB内存）
- 系统检测和初始化程序执行结束后调用int 19h进行操作系统引导，int 19h使用0号软驱，将磁盘0面0道1扇区的512B复制到0:7c00开始的地方，设置CS:IP=0:7c00，从此执行操作系统引导程序。（这个过程中直到设置0:7c00，都不是我们能够控制的范围，我们可以控制的是将我们的系统引导程序写入到0:7c00开始的地方，然后设置cs:7c00重新执行系统引导程序。

**从0:7c00h开始启动系统引导程序**

```
assume cs:codeseg

;Boot
;装载程序将Boot放到0:7c00
;设置cs:ip到0:7c00，模拟引导操作系统

codeseg segment

main:
	mov ax,0
	mov es,ax
	mov di,7c00H
	
	mov ax,cs
	mov ds,ax
	mov si, offset Boot
	
	mov cx,offset Boot0 - offset Boot
	rep movsb						;Boot程序装载到0:7c00

	mov bx, 0
	push bx
	mov bx, 7c00h
	push bx
	retf

	mov ax,4c00h
	int 21h

Boot:
	jmp BootStart

scr0	dw 2000 dup(0)
str	db 'W',11001010B
	db 'e',11001010B
	db 'l',11001010B
	db 'c',11001010B
	db 'o',11001010B
	db 'm',11001010B
	db 'e',11001010B

BootStart:
	;初始化界面
	;显示需要的字符串
	call initScreen
	call showStr

	mov ax,4c00h
	int 21h

initScreen:
	mov ax,0B800h
	mov es,ax
	mov di,0						;屏幕0地址

	mov ax,cs
	mov ds,ax
	mov si, 7c00h +offset scr0-offset Boot				
								;scr0起始地址偏移
								;7c00h是程序装载的位置
	
	mov cx, offset str- offset scr0
	rep movsb
	
	ret

showStr:
	mov ax,0B800h
	mov es,ax
	mov di,12*80*2+40*2				;屏幕0地址

	mov ax,cs
	mov ds,ax
	mov si, 7c00h +offset str-offset Boot				
								;str起始地址偏移
								;7c00h是程序装载的位置
	
	mov cx, offset BootStart- offset str
	rep movsb
	
	ret

Boot0:
	nop

codeseg ends

end main
```

**将上面的系统引导程序写入软盘0面0道1扇区，从FFFF:0开始BIOS引导**

```
assume cs:codeseg

;Boot
;装载程序将Boot放到0:7c00
;设置cs:ip到0:7c00，模拟引导操作系统

codeseg segment

main:
	mov ax,cx
	mov es,ax
	mov bx,offset Boot
	
	mov al,1	;扇区数
	mov ch,0	;磁道
	mov cl,1	;扇区
	mov dl,0	;驱动器
	mov dh,0	;磁面
	mov ah,3	;功能号，写磁盘
	int 13h						;将系统引导程序写入磁盘0面0道1扇区

	mov bx, 0FFFFH
	push bx
	mov bx, 0h
	push bx
	retf

	mov ax,4c00h
	int 21h

Boot:
	jmp BootStart

scr0	dw 2000 dup(0)
str	db 'W',11001010B
	db 'e',11001010B
	db 'l',11001010B
	db 'c',11001010B
	db 'o',11001010B
	db 'm',11001010B
	db 'e',11001010B

BootStart:
	;初始化界面
	;显示需要的字符串
	call initScreen
	call showStr

	mov ax,4c00h
	int 21h

initScreen:
	mov ax,0B800h
	mov es,ax
	mov di,0						;屏幕0地址

	mov ax,cs
	mov ds,ax
	mov si, 7c00h +offset scr0-offset Boot				
								;scr0起始地址偏移
								;7c00h是程序装载的位置
	
	mov cx, offset str- offset scr0
	rep movsb
	
	ret

showStr:
	mov ax,0B800h
	mov es,ax
	mov di,12*80*2+40*2				;屏幕0地址

	mov ax,cs
	mov ds,ax
	mov si, 7c00h +offset str-offset Boot				
								;str起始地址偏移
								;7c00h是程序装载的位置
	
	mov cx, offset BootStart- offset str
	rep movsb
	
	ret

Boot0:
	nop

codeseg ends

end main
```

### 基于汇编开发高级语言

**怀疑的方向，怀疑三问**

- 都在用就非得用吗
- 规定了就只能遵守吗
- 司空见惯我们就不怀疑了吗

高级语言特性就是编译器的东西，是编译原理的东西，高级语言的程序会被编译连接成汇编语言可执行程序。C语言规定，使用变量（内存空间）、使用main函数、参数传递方式等规定都是可以通过编译器改变，比如使用内存存储变量，可以使用寄存器存储变量，内存变量mov ds:[0],1 实际上在编译的时候就已经分配了内存，这个内存不是实际的物理内存，只是逻辑内存，对应的使用的是编译器编译得到的一个变量的偏移，在实际运行时，可以使用DOS默认分配的或者自己手动填写的物理地址基址ds:0开始实际将数据写入或者初始化道物理内存。

**使用Turbo将.c程序转成8086CPU汇编程序命令**

- 启动DOS

  ```
  mount c d:\asm
  c:
  tcc -S -ml b.c
  ```

[masm link tcc安装包](C:\Users\cheng\Desktop\JavaBackend\书籍\操作系统\masm,link,tcc安装包)

#### C语言转汇编语言-变量和参数传递

- C程序

```
#include "include/stdarg.h"

void add(int a, int b, int c){
	c=a+b ;
	printf("in add %d",c);
}
int main(){
	int a=1;
	int b=2;
	int c=0;

	add(a,b,c);
	c++ ;
	printf("in main %d", c);
}
```



- 对应的8086CPU汇编程序

```
_add	proc	far
	push	bp
	mov	bp,sp
;	?debug	L 4				
	mov	ax,word ptr [bp+6]			;变量a所在位置bp+6，前面包含bp,ip,cs
									;从而bp时加上6
	add	ax,word ptr [bp+8]			;变量b所在位置bp+8
	mov	word ptr [bp+10],ax			;变量c所在位置bp+10


;	?debug	L 5
	push	word ptr [bp+10]		;用栈传递参数，保存调用的内存地址
	push	ds
	mov	ax,offset DGROUP:s@
	push	ax
	call	far ptr _printf			;printf函数
	mov	sp,bp						;因为sp会被改变，所以用bp暂存sp恢复
@1:
;	?debug	L 6
	pop	bp
	ret	
_add	endp
;	?debug	L 7
_main	proc	far
	push	bp
	mov	bp,sp
	sub	sp,2
	push	si
	push	di
;	?debug	L 8
	mov	di,1
;	?debug	L 9
	mov	word ptr [bp-2],2
;	?debug	L 10
	xor	si,si
;	?debug	L 12
	push	si						; c=0，寄存器实现变量
	push	word ptr [bp-2]			; b=2，内存实现变量
	push	di						; a=1，寄存器实现变量
	push	cs
	call	near ptr _add
	add	sp,6
;	?debug	L 13
	inc	si			; c++

;	?debug	L 14
	push	si
	push	ds
	mov	ax,offset DGROUP:s@+10
	push	ax
	call	far ptr _printf	; printf函数
	add	sp,6
@2:
;	?debug	L 15
	pop	di
	pop	si
	mov	sp,bp
	pop	bp							;恢复调用main程序的程序的寄存器
	ret	
_main	endp

```

- C语言转汇编栈的作用
  - 用来传递参数，这个参数是值传递，先申请的变量保存在sp的低地址，后压栈
  - 用来保存函数调用的返回地址，也就是call指令的下一条指令的CS:IP地址，用于调用程序返回ret使用
  - 用来保存被调用函数的寄存器，调用函数使用的寄存器都要保存，返回的时候恢复被调用函数的寄存器数据
- C语言转汇编变量在哪里
  - 变量保存在内存
  - 变量保存在寄存器

#### 循环

**C代码**

```
#include "include/stdarg.h"

int main(){
	int i;
	for(i=0;i<10;i++){
		printf("%d\n",i);
	}
}
```



**汇编代码**

```
_main	proc	far
	push	si
;	?debug	L 5
	xor	si,si						;变量i用寄存器保存
	jmp	short @5
@4:									;printf函数调用
;	?debug	L 6
	push	si
	push	ds
	mov	ax,offset DGROUP:s@
	push	ax
	call	far ptr _printf
	add	sp,6						;丢弃调用printf压入的三个参数si,ds,ax
@3:
	inc	si							;i++
@5:									;判断i<10
	cmp	si,10
	jl	@4
@2:
@1:
;	?debug	L 8
	pop	si
	ret	
_main	endp

```

#### 全局变量和局部变量

全局变量在内存中保存，局部变量用寄存器di/si或者内存保存，优先使用si/di/内存保存变量

**C代码**

```
#include "include/stdarg.h"


int a=1;
int b=2;

int main(){
	int c=a+b;
	printf("%d\n",c);

}
```



**汇编代码**

```
_DATA	segment word public 'DATA'
_a	label	word					; int a=1,变量声明给出变量类型int，变量内存地址，变量初始化赋值三个数据可以确定变量
	dw	1
_b	label	word					; int b=2
	dw	2
_DATA	ends
B_TEXT	segment	byte public 'CODE'
;	?debug	L 7
_main	proc	far
	push	si						
;	?debug	L 8
	mov	si,word ptr DGROUP:_a		; int c=a
	add	si,word ptr DGROUP:_b		; c+ b
	
;	?debug	L 9
	push	si
	push	ds
	mov	ax,offset DGROUP:s@
	push	ax
	call	far ptr _printf
	add	sp,6						;prinf
@1:
;	?debug	L 11
	pop	si
	ret	
_main	endp

```

#### 数组和栈

**C语言**

```
#include "include/stdarg.h"


int stack[16]={0};
int tmp ;

void push(int val){
	if( stack[0] <= 1){
		printf("stack is full\n");
		return ;
	}
	stack[0]-- ;
	stack[ stack[0] ] = val ;
}

int pop(){
	if( stack[0]>=16 ){
		printf("stack is empty");
		return -1;
	}

	tmp = stack[ stack[0] ] ;
	stack[0]++ ;
	return tmp ;
}

int main(){
	stack[0]=16 ;

	push(1);
	push(2);
	push(3);

	printf("%d\n",pop());
	printf("%d\n",pop());
	printf("%d\n",pop()) ;

	printf("%d\n",pop()) ;
}
```

**汇编**

```
_DATA	segment word public 'DATA'
_stack	label	word					;数组和栈位全局变量，在内存分配
	dw	0
	db	30 dup (0)
_DATA	ends
B_TEXT	segment	byte public 'CODE'
;	?debug	L 7
_push	proc	far
	push	bp
	mov	bp,sp
;	?debug	L 8
	cmp	word ptr DGROUP:_stack,1
	jg	@2
;	?debug	L 9
	push	ds
	mov	ax,offset DGROUP:s@
	push	ax
	call	far ptr _printf
	mov	sp,bp
	jmp	short @1
@2:
;	?debug	L 12
	dec	word ptr DGROUP:_stack
;	?debug	L 13
	mov	ax,word ptr [bp+6]
	mov	bx,word ptr DGROUP:_stack
	shl	bx,1
	mov	word ptr DGROUP:_stack[bx],ax
@1:
;	?debug	L 14
	pop	bp
	ret	
_push	endp
;	?debug	L 16
_pop	proc	far
;	?debug	L 17
	cmp	word ptr DGROUP:_stack,16
	jl	@4
;	?debug	L 18
	push	ds
	mov	ax,offset DGROUP:s@+15
	push	ax
	call	far ptr _printf
	pop	cx
	pop	cx
;	?debug	L 19
	mov	ax,-1
	jmp	short @3
@4:
;	?debug	L 22
	mov	bx,word ptr DGROUP:_stack
	shl	bx,1
	mov	ax,word ptr DGROUP:_stack[bx]
	mov	word ptr DGROUP:_tmp,ax
;	?debug	L 23
	inc	word ptr DGROUP:_stack
;	?debug	L 24
	mov	ax,word ptr DGROUP:_tmp
	jmp	short @3
@3:
;	?debug	L 25
	ret	
_pop	endp
;	?debug	L 27
_main	proc	far
;	?debug	L 28
	mov	word ptr DGROUP:_stack,16
;	?debug	L 30
	mov	ax,1
	push	ax
	push	cs
	call	near ptr _push
	pop	cx
;	?debug	L 31
	mov	ax,2
	push	ax
	push	cs
	call	near ptr _push
	pop	cx
;	?debug	L 32
	mov	ax,3
	push	ax
	push	cs
	call	near ptr _push
	pop	cx
;	?debug	L 34
	push	cs
	call	near ptr _pop
	push	ax
	push	ds
	mov	ax,offset DGROUP:s@+30
	push	ax
	call	far ptr _printf
	add	sp,6
;	?debug	L 35
	push	cs
	call	near ptr _pop
	push	ax
	push	ds
	mov	ax,offset DGROUP:s@+34
	push	ax
	call	far ptr _printf
	add	sp,6
;	?debug	L 36
	push	cs
	call	near ptr _pop
	push	ax
	push	ds
	mov	ax,offset DGROUP:s@+38
	push	ax
	call	far ptr _printf
	add	sp,6
;	?debug	L 38
	push	cs
	call	near ptr _pop
	push	ax
	push	ds
	mov	ax,offset DGROUP:s@+42
	push	ax
	call	far ptr _printf
	add	sp,6
@5:
;	?debug	L 39
	ret	
_main	endp
B_TEXT	ends
_BSS	segment word public 'BSS'
_tmp	label	word				;tmp变量在内存分配
	db	2 dup (?)
_BSS	ends

```

## 操作系统实验

[socket.c - net/socket.c - Linux source code (1.2.13) - Bootlin](https://elixir.bootlin.com/linux/1.2.13/source/net/socket.c)

[一个很全的Linux内核学习资料，包含论文、项目、书籍、视频，多看看](https://github.com/0voice/linux_kernel_wiki)

[Linux最新feature的github](https://github.com/0voice/kernel_new_features)

[Github上上千本计算机书籍](https://blog.csdn.net/skelking/article/details/41279657)

[阿秀学习笔记](https://gitee.com/ForthEspada/CS-Books)

> **git查看提交命令**
>
> > git reflog |  awk '{ print $1 }' | xargs gitk
> >
> > git log --pretty=format:"%h - %an, %ar : %s"
>
> **学习日记：**
>
> > 7-11;14-18;19-22/11
> >
> > 220923/9-14;16-18;19-22/10h: sys_fork
> >
> > 220925/19-26/7h: schedule;sys_waitpid/sys_pause/sleep_on/interruptible_sleep_on;wake_up;sys_exit
> >
> > 220926/8-12/4h: sleep库函数
> >
> > 220927/12-16;18-20/6h: sleep函数是glibc库函数实现的，内核实现的定时是nanosleep，这两个sleep实现方式不一样;
> >
> > 220929/9-12;16-10/6h: 基于内核栈的内核线程切换
> >
> > 220930/14-18/4h: 基于内核栈的内核线程切换；信号量
> >
> > 221001/9-11/2h: 信号量
> >
> > 221002/9-15/6h: 信号量，c语言数据类型的实现，后端优化方向

### 实验1-修改系统启动

计算机启动的时候，CPU首先初始化CS:IP=FFFF:0h，执行一个跳转指令，执行BIOS系统检测和初始化程序，这个程序会将BIOS中断例程注册道中断向量表（0地址处），执行完成之后执行int 19h的BIOS例程引导操作系统，将操作系统从软盘0面0道1扇区读到内存0:7c00h处，然后设置CS:IP指向0:7c00h,这样开始执行操作系统程序

Linux 0.11 是在80x86CPU上运行的，8086CPU是早期CPU，只能在16位实模式下运行，一个时刻只能执行一个任务，而80x86包括80386、80486等，是8086的增强型，提供了32位保护模式，32位保护模式支持多任务、支持4G物理内存和64TB虚拟内存、支持虚拟内存、支持段页式内存管理、支持特权级。Linux 0.11是80836CPU上运行的

**VMware适合应用程序开发，Bochs适合底层如操作系统或编译器开发**

Bochs仿真了80x86CPU的所有内部环境和外围设备，而VMware只仿真了IO流，其他的部分直接交给实际80x86CPU直接执行

**80386的32位保护模式**

80386默认工作在实模式下，实模式只支持单任务，类似8086CPU的实模式，8086CPU实模式支持1M内存空间寻址

- 内存管理寄存器，使用4个寄存器用于分段内存管理

  - GDTR寄存器，指向全局描述符表
  - LDTR寄存器，指向局部描述符表，和上面一样都是段描述符表，保护模式下的段地址ds给出的是全局描述符表或者局部描述符表的表项的偏移，而不是实模式下的直接的段地址，为什么要这么做，因为32位保护模式下段有多重属性，比如段的特权级、段所处在局部描述符表还是全局描述符表，段的真实段地址。
  - IDTR寄存器，指向中断向量表，中断向量表存放所有中断处理程序的入口地址
  - TR寄存器，指向进程控制块，当前进程的描述信息

- 控制寄存器

  有四个32位控制寄存器CR0,CR1,CR2,CR3

  - CR0控制和指示CPU工作的整个系统的运行状态和条件
    - PE，保护模式开启位，第0位比特，PE=1表示运行在保护模式
    - MP，协处理器存在标志，第1位比特，控制WAIT指令的功能能，以配合协处理器运行
    - EM，仿真控制，比特位2，只是是否需要仿真协处理器的功能
    - TS，任务切换，比特位3，每当任务切换处理器时设置整个位
    - ET，扩展类型，比特位4，指出是那种协处理器，80287或者80387
    - PG，分页操作，比特位31，使用页表将虚拟地址转换成物理地址
  - CR2，在PG=1时使用，保存缺页中断时的地址
  - CR3，在PG=1时使用，保存页表基地址

**C语言数据类型**

https://www.runoob.com/cprogramming/c-data-types.html

- 整型
  - char 1B
  - short 2B
  - int 4B
  - long 4B
  - long long 8B
- 浮点型
  - float 4B
  - double 8B
  - long double 16B
- 构造类型
  - 数组
  - 结构体
- void类型
- 指针类型

**段式存储器和寻址过程**

> 80386以上CPU支持段页式存储器，物理内存4G。80386CPU和8086CPU寻址方式不一样，8086CPU给出的段基址不是实际的物理地址，这个段基址左移4位加上偏移值16位组合得到20位物理地址。而80386寻址需要使用段寄存器、描述符表和偏移值，段寄存器给出的数值是描述符表的表项的偏移，描述符表寄存器会给出描述符表的实际的物理地址，这个实际物理地址加上段寄存器的索引值*8得到真正的段物理地址，也就是说段描述保存了真正的物理地址32位，而不是像8086CPU一样要用段基址\*16才能得到实际的段的物理地址
>
> **段寄存器**(CS,DS,SS,ES等)，包括显示部分16位和隐藏部分8个字节64位，隐藏部分是缓存显示部分的段描述符，以减少访问内存获得段描述符的操作。段寄存器内容RPL（2位，表示特权级别，0表示内核态，3表示用户态）、TI（1位，表示使用的描述符表，0表示GDT表，1表示LDT表）、索引值（13位，用于查找描述符表中的段描述符，索引值13位左移3位得到16位+描述符寄存器中基地址得到描述符表中的一个表项段描述符，描述符寄存器GDTR或者LDTR中的基地址就是一个内存线性地址，是物理地址，代表物理内存大小4G，索引值13位代表描述符表表项最多2的13次方，左移3位是因为一个表项段描述符是8个字节）
>
> **描述符表寄存器**GDTR和LDTR，段寄存器中TI位指定使用哪一个描述符表寄存器，TI=0使用GDTR，TI=1使用LDTR。描述符表寄存器有六个字节48位，前两个字节十六位指定表限长，其中只有低13位用于表限长，这个位数和段寄存器的索引值一样，表示最多有2的13次方个索引值；描述符表寄存器的后四个字节32位指示描述符表的线性地址，这是一个实际的物理地址，这个基地址+索引值*8得到段描述符地址
>
> **段描述符**一个有8个字节64位，其中**基地址**三个部分组合成一个32位的基地址；**段限长**三个部分组合成一个20位的段限长（这个段限长和偏移地址一样都是20位；**颗粒度**G位定义了段限长的单位，如果G=1表示4K，那么段限长左移12位变成32位，如果G=0那么代表字节；**类型Type**4位用于区分描述符类型；**段存在位P**位为1表示这个描述符项无效，那么在访问这个描述符项并且加载到段寄存器的隐藏位时将发生CPU异常信号；**描述符特权级DPL**定义段描述符的特权级别，0表示内核态，3表示用户态；**访问位A=1**代表CPU访问过这个描述符项。描述符项是由编译器、连接器、加载器、操作系统创建的，操作系统给用户程序或者内核模块分配内存时建立描述符项
>
> **偏移值**用来和段基地址相加得到实际的代码或者数据的物理地址
>
> **段存储器**寻址方式，段寄存器给出13位索引值，描述符寄存器的基地址32位给出描述符表基地址，32位基地址+13位索引*8 得到段描述符表中的段描述符物理地址，从段描述符获得实际的段物理地址；这个物理地址加上20为或者32位偏移值得到实际的代码或者数据物理地址；这个物理地址就是一个线性地址，如果没有开启32位保护模式CRO的p位位1，那么这个线性地址就是实际的物理地址32位，如果时32位保护模式，那么这个线性地址只是一个虚地址，还需要经过页变换获得实际的物理地址。

**页式存储器和寻址过程**

> 开启了CPU控制寄存器CR0的PG位32位保护模式后，段式存储器得到的线性地址就不是实际的物理地址，还需要叶变换获得实际的物理地址。
>
> 80386地址总线32位，数据总线32位，物理内存4GB，一次传输数据4个字节，寄存器是32位
>
> 80386CPU支持两级页表，页目录表、页表和页框，段式存储器给出的虚拟地址被划分位三个部分，前10位是页目录表偏移（页目录号）、中间十位是页表偏移（页号）、后十二位是页框偏移（页框号）。80386CPU把分页存储器把4G内存划分为每4KB为一个单元，数据和程序被放到磁盘中，以512B单元存储，给出磁面（磁头号）、磁道、扇面定位一个磁盘单元。80386CPU总是以4K读取磁盘，每次读取8个磁盘单元。一个页框大小被CPU固定分配位4KB大小。
>
> CPU的CR3控制寄存器保存页目录表实际物理地址，页表的一个页表项前20位保存下一级页表的物理地址的前20位，因为一个页表项的后12位总是为0（因为一个页表项单位是4KB，所以在32为寻址中，前二十位就可以定位下一级页表的物理地址）。页表项的后十二位因为全为0，就被用来保存页表项的属性，比如p位属性表示这个页表项是否可用，这在虚拟内存分配的时候很有用，在shell加载程序的时候会创建页表，这个时候不需要填充页表，让所有的页表项的p位位0，我们只需要用操作系统设置好程序在磁盘的起始地址，设置好程序使用的段地址，然后转到段地址处执行，段寄存器通过GDT表获得段基址，加上偏移值得到虚拟地址，这个虚拟地址页号指向的页表项的p位位0，那么就是这个页框号不在内存中，发生缺页中断，缺页被CPU放到CR2控制寄存器，CPU转到缺页中断执行，将缺失页页号减去初始分配的页号得到实际偏移的页号，这样就可以获取一个页放到内存中，然后设置页表指向内存中的这个页地址，设置p=1，重新跳转到寻址执行执行，就能获得要求的指令。
>
> **使用TLB加快访问页表**
>
> TLB使用CPU高速缓存Cache来保存一个页表
>
> **两级页表一次指令执行需要访问内存3次**
>
> 

**任务切换**

80386CPU提供了TSS（任务状态段）来实现进程PCB保存的进程信息，TR寄存器（任务寄存器）是一个选择符，TSS是一个链表结构，他最后一个部分是下一个任务的TSS描述符，TSS的描述符只能保存在GDT表中，被TR寄存器指向GDT表中TSS描述符。

Linux不适用TSS机制实现任务切换，而是使用进程PCB实现进程切换

**中断和异常**

中断寄存器IDTR是一个指向IDT表的寄存器，是6字节寄存器，前两个字节是段限长、后四个字节是物理地址

中断描述符表IDT保存的中断描述符记录了中断的起始地址，其中段选择符会返回到GDT表中获得段基地址，其中20位偏移值会作位偏移值加到段基地址中

Linux没有使用80386的任务门切换机制TSS

**Linux操作系统启动**

- 80386CPU启动，CPU指向FFFF:0执行跳转，跳转到BIOS自检和初始化程序，这个程序会把BIOS中断注册到内存0地址处中断向量表1K大小，然后执行int 19h把磁盘0面0道1扇区的512B字节加载到内存0:7c00处，然后跳转到0:7c00执行操作系统启动项bootsect.s
- bootsect.s
  - 将自己移动到0x90000处，
  - 加载setup.s到0x92000处，
  - 将system模块加载到0x10000处，
  - 然后交给setup.s执行
- setup.s
  - 利用ROM BIOS中断读取计算机参数存放到0x90000处，覆盖bootsect.s代码
  - 把system模块移动到0x00000处，head.s处于0x00000处
  - 加载描述符表到描述符表寄存器
  - 重新设置中断控制硬件
  - 通过控制寄存器CR0跳转到system模块的head.s处执行
- head.s
  - 初始化中断描述符表INT各个表项位哑中断
  - 检查A20地址线是否开启
  - 测试系统是否含有数学协处理器
  - 初始化内存页目录表
  - 跳转到system模块的init/main.c执行

**GCC编译C语言库文件查找路径**

[参考文献](https://blog.csdn.net/yang_chen_shi_wo/article/details/46416093)

> gcc -I mylocal/include -L mylocal/lib a.c -lworld -static

其中，-I指定用户自己编译a.c使用的头文件，-L是用户使用的链接库文件，-lworld表示在mylocal/lib查找动态链接库库.so，-static表示在mylocal/lib查找静态链接库.a。虽然用户指定了inlude，但是编译器还是用了标准路径下面的include，在linux环境这个标准路径是user/local/include和user/include两个，而使用的lib的标准路径包括两个user/lib和user/local/lib

**C语言使用#include<stdio.h>和#include"stdio.h"的区别**

使用尖括号会直接在标准路径下面的include文件夹查找stdio.h，不会关本地的include文件，而使用冒号会优先在本地include查找，如果找不到才到标准路径下面查找

**编写C语言库函数并且调用-实现printf函数**

参考文献

http://c.biancheng.net/view/8030.html

https://zhuanlan.zhihu.com/p/438805348

https://wenku.baidu.com/view/d50a5fb1de88d0d233d4b14e852458fb760b3857.html

https://blog.csdn.net/wtl1992/article/details/122654203

https://blog.csdn.net/liuxiao723846/article/details/97617681

- 开始编写文件结构

  > main.c
  >
  > include
  >
  > ​		----mystdio.h
  >
  > lib 
  >
  > ​		----mystdio.c

- 文件内容

  - main.c

    > #include "mystdio.h"
    >
    > int main(){
    > 	int a = my_printf("%d\n", 1);
    > }

  - mystdio.h

    > #ifndef _MYSTDIO_H
    > #define _MYSTDIO_H 
    >
    > extern int my_printf(char* str, ...);  //声明外部函数，使用extern声明外部变量
    >
    > #endif

  -  mystdio.c

    > #include <stdio.h>
    > #include<stdarg.h>
    >
    > int my_printf(char* str, ...){
    > 	int n ;
    > 	va_list list;								// va_list va_start va_end 是宏，vprintf是c库函数
    > 	va_start(list,str);
    > 	n = vprintf(str,list);
    > 	va_end(list);
    > 	return n ;
    > }

- 编译成库

  cd 到lib文件夹，编译动态链接库

  > gcc -o mystdio.o -c mystdio.c -fPIC
  >
  > gcc -shared -o libmystdio.so mystdio.o     //可以添加多个.o文件

- 将动态链接库添加到gcc查找路径

  > export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/cheng/Desktop/gcc/lib

- 编译执行main函数

  > gcc -o main main.c -Iinclude -Llib -lmystdio
  >
  > ./main

- 添加库头文件到Linux默认gcc查找路径

  把.h文件添加到usr/include或者usr/local/include

  把.so添加到usr/lib或者usr/local/include

  这样使用编译main的时候旧可以直接用-lmystdio而不用-Iinclude和-Llib编译的时候指出编译使用的头文件和库文件

**64位计算机指的是寄存器位数64位，64位操作系统是指令长度64位**

**如何使用操作系统调用**

Linux上使用操作系统系统调用的方式主要是三种。总之最后实际上汇集到第三种，本质上是使用内联汇编把系统调用号传递给寄存器eax，再使用int 0x80中断进行处理。GCC内联汇编实现C语言变量和汇编寄存器内存之间相互传递。

[参考文献](https://www.cnblogs.com/hazir/p/three_methods_of_syscall.html)

- 使用C语言库函数

  ```c
  #include <sys/types.h>
  #include <sys/stat.h>
  #include <errno.h>
  #include <stdio.h>
  
  int main()
  {
          int rc;
  
          rc = chmod("/etc/passwd", 0444);
          if (rc == -1)
                  fprintf(stderr, "chmod failed, errno = %d\n", errno);
          else
                  printf("chmod success!\n");
          return 0;
  }
  ```

- 直到系统调用号后使用c库函数syscall，适合新加入的系统调用而c库函数没有对应的函数，下面的例程SYS_chmod是系统调用号，他在sys/syscall.h定义

  ```c
  #include <stdio.h>
  #include <unistd.h>
  #include <sys/syscall.h>
  #include <errno.h>
  
  int main()
  {
          int rc;
          rc = syscall(SYS_chmod, "/etc/passwd", 0444);
  
          if (rc == -1)
                  fprintf(stderr, "chmod failed, errno = %d\n", errno);
          else
                  printf("chmod succeess!\n");
          return 0;
  }
  ```

- 直到系统调用号直接使用内联汇编进行中断处理，这个函数使用eax寄存器传递系统调用号

  ```c
  #include <stdio.h>
  #include <sys/types.h>
  #include <sys/syscall.h>
  #include <errno.h>
  
  int main()
  {
          long rc;
          char *file_name = "/etc/passwd";
          unsigned short mode = 0444;
  
          asm(
                  "int $0x80"
                  : "=a" (rc)
                  : "0" (SYS_chmod), "b" ((long)file_name), "c" ((long)mode)
          );
  
          if ((unsigned long)rc >= (unsigned long)-132) {
                  errno = -rc;
                  rc = -1;
          }
  
          if (rc == -1)
                  fprintf(stderr, "chmode failed, errno = %d\n", errno);
          else
                  printf("success!\n");
  
          return 0;
  }
  
  ```

**内联汇编实例**

https://www.jianshu.com/p/1782e14a0766

[内联汇编书籍](https://bbs.pku.edu.cn/attach/ca/dd/cadde373e533b3ea/chapter2.pdf)

- 实现变量赋值

  ``` c
  #include <stdio.h>
  
  int main()
  {
  	long  a=1;
  	long  b=0;
  	printf("%p\n",&a);
  	asm volatile(
  		"movl %%eax, %%ebx ;"	//asm function
  	
  		:"=b"(b) 	//return value to c variable b
  		:"a"(a)		//push parameter to asm function
  	); 
  	printf("%ld\n",a);
  	printf("%ld\n", b) ;
  }
  ```

**C语言使用  open/read/write/用户缓冲空间buffer  复制文件**

https://blog.csdn.net/ly52352148/article/details/52873819

```c
//copy file in.txt to out.txt


#include<stdio.h>
#include<unistd.h>
#include<fcntl.h>
#include<sys/types.h>
#include<sys/stat.h>


const char *pathName = "out.txt" ;

int main(){
	int in, out, num;
	char buffer[1024] ;

	in = open("in.txt", O_RDONLY, S_IRUSR) ; //open file in.txt, in is file describer
	printf("in file describer:%d\n", in) ;
	if( in == -1 ){
		return -1 ;
	}

	out = open(pathName, O_WRONLY|O_CREAT);
	printf("out file describer:%d\n", out) ;
	if( out == -1){
		return -1;
	}
	
	while((num=read(in, buffer, 1024))>0){
		write( out, buffer, num) ;
	}
	close(in);
	close(out);

	return 0;
}
```

**sizeof 获取字节数**

```cassandra
#include<stdio.h>

int main(){
	//get number of bytes of a type
	printf("bytes of char: %lu\n", sizeof(char) ) ;   //lu for unsigned_int
	printf("bytes of int: %lu\n", sizeof(int) )	;
	printf("bytes of short: %lu\n", sizeof(short) )	;
	printf("bytes of long: %lu\n", sizeof(long) )	;
	printf("bytes of long long: %lu\n", sizeof(long long) )	;

	printf("bytes of float: %lu\n", sizeof(float) ) ;
	printf("bytes of double: %lu\n", sizeof(double) ) ;


	//get number of elements of an array
	int a[] = {1,2,3} ;
	printf("number of elements of array: %lu\n", sizeof(a)/sizeof(a[0]) ) ;
	return 0;
}
```

**文件描述符**

https://xzchsia.github.io/2020/03/03/file-descriptor/

https://www.ruanyifeng.com/blog/2011/12/inode.html

文件句柄是File*，也就是一个File结构体指针，包括缓冲区（各种类型的数组）和一个文件描述符。文件描述符是进程文件描述符表的偏移，进程PCB中有一个文件描述符表，文件描述符表就是他的偏移；操作系统维护了一个打开文件表，文件描述符和一个打开文件表的表项相关联，打开文件表描述了进程打开文件的属性，比如open使用的flag或者打开模式，除此以外，操作系统维护了一个i-node表，维护了文件的固有属性，比如文件读写权限、创建用户等，还包括一个inode号码，这个号码唯一标记一个i-node表项。

**修改操作系统启动 实验结果**

实验文件保存在(\实验\操作系统实验\实验一 操作系统启动\)

![屏幕截图 2022-05-20 233607](C:\Users\cheng\Desktop\JavaBackend\实验\操作系统实验\实验一 操作系统启动\实验截图\屏幕截图 2022-05-20 233607.png)



### 实验2-系统调用

**外部变量声明，头文件的作用**

https://blog.csdn.net/zqixiao_09/article/details/49913523

使用extern实现外部变量声明，主要用于模块化程序设计，一般声明变量定义在头文件中，在使用的文件中使用extern来声明这个变量就可以使用这个变量了。

头文件保存变量数组函数的声明，作用是保存变量方便开发、提供外部接口、使函数作用域从函数声明的位置开始而不是定义的位置开始（这需要使用extern声明变量从而使得作用域从extern声明的位置开始）

**使用gcc编译c文件位汇编文件s**

```c
//将b.c编译成.s文件汇编文件
gcc -E b.c -o b.i
gcc -S b.i -o b.s
    
//使用gcc编译.o .s .c 文件为可执行程序，c语言函数调用参数传递使用栈来传递的，
//而参数类型将决定传递参数所占用的字节数量，因此从sp开始把参数从右往左压栈，
gcc -o a a.c b.s
```

**函数指针的地址指向函数开始的地址**

```c
//打印函数指针地址

#include<stdio.h>

extern int add(int, int) ;

int main(){
	printf("asdfb\n") ;
	printf("%d\n",add(1,2) );

	printf("%p\n", &add ) ;
	printf("%p\n", &main) ;
}
```

**C语言的main.c文件使用另外一个文件A.c的函数**

需要再main.c函数中使用export来关联到A里面的函数，这样main.c才能使用这个函数

**GCC的C语言库函数和Linux内核库函数区别**

GCC编译器可以同时使用C语言库函数和Linux内核库函数编译成汇编语言，进而形成可执行文件。C语言库函数大都是运行再用户空间的程序，当他们想要使用内核服务比如申请内存或者读写外部设备，那么他就要调用Linux内核库函数，这个提供给C语言库函数调用的Linux库函数是一个系统调用。因此，C语言库函数可以是封装了底层系统调用的函数，也可以是独立的处理用户空间的函数，两者没有完全的依赖关系。实际上，可以不适用C语言库函数而自己独立写一个库函数实现替代C语言库函数，当要使用Linux内核服务区分配内存或者读写外部设备的时候我们自己使用系统调用_sys_call 加上系统调用号和参数实现调用系统调用。系统调用就是Linux内核提供的一个函数而已。

在编写内核函数的时候可以调用的是内核函数，内核函数的最基本的实现是用汇编语言编写的，比如Linux内核函数strcpy就是用汇编语言编写的复制字符串，他在linux/include/string.h定义和实现。不过这个函数不是系统调用，不能直接在我们编写的用户程序上直接调用，我们调用的strcpy是在C语言库函数gcc/include/string.h中定义和在gcc/string/strcpy.c实现的，这里strcpy完全是C语言编写的

**添加系统调用实现用户程序使用系统调用向内核空间写入字符串和从内核空间读取字符串**

- 定义系统调用号，在linux-0.11/include/unistd.h添加两行

  ```
  #define __NR_whoami 	72
  #define __NR_iam 		73
  ```

- 定义系统调用函数，在linux-0.11/include/linux/sys.h添加

  ```
  extern int sys_whoami() ;
  extern int sys_iam() ;
  ```

  

  ![屏幕截图 2022-05-22 023610](C:\Users\cheng\Desktop\JavaBackend\实验\操作系统实验\实验二 系统调用\实验截图\屏幕截图 2022-05-22 023610.png)

  在系统调用表中添加

  ```
  sys_whoami, sys_iam
  ```

  ![屏幕截图 2022-05-22 023804](C:\Users\cheng\Desktop\JavaBackend\实验\操作系统实验\实验二 系统调用\实验截图\屏幕截图 2022-05-22 023804.png)

  注释，在用户程序使用系统调用号调用syscall宏函数的时候，系统调用号实际上是系统调用表sys_call_table中的表项，他从系统调用表中获取到系统调用函数的地址，转而去执行对应的系统调用函数

- 实现系统调用函数，在linux-0.11/kernel下建立C文件who.c，其中内容是

  ```c
  #include<asm/segment.h>
  #include<errno.h>
  #include<string.h>
  
  
  char _myname[24] ;
  
  int sys_iam(const char* name){
  	char str[25] ;
  	int i =0;
  
  	do{
  		str[i] = get_fs_byte(name+i) ; 
  	}while(i<=25 && str[i++] != '\0' ) ;
  
  	if( i>24){
  		errno = EINVAL ;
  		i=-1 ;
  	}
  	else{
  		strcpy(_myname, str) ;
  	}
  	return i ;
  }
  
  int sys_whoami(char* name, unsigned int size){
  	int length = strlen(_myname) ;
  	printk("%s\n",_myname) ;
  
  	if( size < length){
  		errno = EINVAL ;
  		length = -1;	
  	}
  	else{
  		int i=0;
  		for( i=0;i<length;i++){
  			put_fs_byte(_myname[i], name+i) ;
  		}
  	}
  	return length ;
  }
  ```

- 修改linux-0.11/kernel/system_call.s 将nr_system_calls = 72 改成nr_system_calls = 74，也就是总的系统调用数量

- 修改linux-0.11/kernel/Makefile编译

  - OBJ添加who.o

    ![屏幕截图 2022-05-22 024543](C:\Users\cheng\Desktop\JavaBackend\实验\操作系统实验\实验二 系统调用\实验截图\屏幕截图 2022-05-22 024543.png)

  - Dependencies添加

    ```
    whos.s who.o :who.c ../include/linux/kernel.h ../include/unistd.h
    ```

    ![屏幕截图 2022-05-22 024739](C:\Users\cheng\Desktop\JavaBackend\实验\操作系统实验\实验二 系统调用\实验截图\屏幕截图 2022-05-22 024739.png)

  - 之后编译make all执行操作系统

- 编写用户程序调用系统调用

  ![屏幕截图 2022-05-22 025011](C:\Users\cheng\Desktop\JavaBackend\实验\操作系统实验\实验二 系统调用\实验截图\屏幕截图 2022-05-22 025011.png)

  - whoami.c

    ```c
    #define __LIBRARY__
    
    #include <unistd.h>
    #include<errno.h>
    #include<asm/segment.h>
    #include<linux/kernel.h>
    #include<stdio.h>
    
    _syscall2(int, whoami, char*, name, unsigned int, size) ;
    
    int main(int argc, char* argv[]){
    	char username[64] = {0} ;
    	whoami(username, 24) ;
    	printf("%s\n", username) ;
    	return 0 ;
    }
    ```

  - iam.c

    ```c
    #define __LIBRARY__
    
    
    #include<unistd.h>
    #include<errno.h>
    #include<asm/segment.h>
    #include<linux/kernel.h>
    
    
    _syscall1(int, iam, const char*, name) ;
    
    int main(int argc, char* argv[]){
    	iam(argv[1]) ;
    	return 0 ;
    }
    ```

- 将用户程序文件挂载到Linux-0.11的/usr/root目录，之后执行./run运行操作系统可以在usr/root看到两个.c文件

  ![屏幕截图 2022-05-22 025647](实验\操作系统实验\实验二 系统调用\实验截图\屏幕截图 2022-05-22 025647.png)

- 编译运行用户程序

  ![屏幕截图 2022-05-22 025847](实验\操作系统实验\实验二 系统调用\实验截图\屏幕截图 2022-05-22 025847.png)

  这个过程可能gcc编译的时候没有系统调用错误，需要在usr/include/unistd.h添加系统调用号

  ```
  #define __NR_whoami 	72
  #define __NR_iam 		73
  ```

**==========================================================总结**================================================

**系统调用**

系统调用是一个中断处理函数，中断号是0x80，函数名是system_call。系统调用这个中断实在init/main.c的sched_init函数中设置的，这个函数将系统中断函数system_call的地址注册到中断向量表IDT表0x80的位置。system_call中断函数判断使用的中断处理子函数的语句是call sys_call_table(,%eax,4)，这句话实际跳转到sys_call_table+4*%eax的位置。sys_call_table是系统调用表，他是一个存放了系统调用子程序的一个数组。

**系统调用API**

系统调用这个中断处理函数有许多子函数，用系统调用号标记，__NR_XXX这个宏定义了系统调用号。用户程序可以直接使用中断处理程序，因为可以直接用内联汇编调用int 0x80中断处理函数就行，在这个过程中，我们要为EAX寄存器存入系统调用号，这样就能调用我们需要的中断处理函数的子程序了。另外一种调用中断处理函数的方式是使用系统调用API，这个系统调用API实际是内联汇编的一个宏，sys_call1等来声明的一个函数，本质再用户程序展开之后也就是对应前面所说的在用户程序中嵌入汇编调用中断处理函数的方法，这种方式的好处是节省了写内联汇编的代码，提取到公共的一个宏sys_call1。

**编写系统调用**

首先编写一个系统调用处理函数，命名为sys_xxx，把这个sys_xxx，添加到include/unistd中注册一个系统调用号__NR_XXX。在include/linux/sys.h中的sys_call_table中添加系统调用sys_xxx。在kernel/system_call.s中修改系统调用总数。

**include尖括号和双引号的区别**

尖括号会优先从系统目录usr/include中寻找声明文件.h，而双引号会优先从本地目录寻找.h文件。

**头文件的作用**

[头文件的作用 - 百度文库 (baidu.com)](https://wenku.baidu.com/view/e6b62e5c312b3169a451a466.html?fr=aladdin664466&ind=1)

- 方便提供给用户使用。因为保密性不方便提供源程序，提供给用户的总是头文件和链接库，这样用户可以通过头文件了解程序功能，通过链接库提取需要的函数。
- 编译器类型检查。在遇到一个函数的时候需要了解函数的声明来检查用户程序是否按照声明的方法来使用的，而在每个文件中都声明是冗余的，那么使用头文件可以方便把函数声明都集中起来。
- 提高程序的可读性。

**头文件的书写**

- 如果程序需要内敛函数，需要在头文件中定义一个内联函数的宏，因为内联函数总是被在用户程序中展开，而不是函数调用。
- 头文件结构
  - 头文件注释（功能描述，版本声明）
  - #ifndef/#define
  - #include其他头文件
  - 外部变量和全局变量声明
  - 常量和红底应
  - 类型定义和声明
  - 全局变量原型和内联函数定义
  - endif
  - 文件版本修订说明

### 实验3-进程运行轨迹的跟踪与统计

进程从创建（Linux下调用fork()）到结束的整个过程就是进程的生命期，进程在其生命期中的运行轨迹实际上就表现为进程状态的多次切换，如进程创建以后会成为就绪态；当该进程被调度以后会切换到运行态；在运行的过程中如果启动了一个文件读写操作，操作系统会将该进程切换到阻塞态（等待态）从而让出CPU；当文件读写完毕以后，操作系统会在将其切换成就绪态，等待进程调度算法来调度该进程执行

**Linux参数**

https://blog.csdn.net/gatieme/article/details/51058797

https://cloud.tencent.com/developer/article/1122484

```
//查看进程状态
top //实时显示进程状态
px aux | grep   //显示当前时刻的进程状态
```

进程从创建（Linux 下调用 fork()）到结束的整个过程就是进程的生命期，进程在其生命期中的运行轨迹实际上就表现为进程状态的多次切换，如进程创建以后会成为就绪态；当该进程被调度以后会切换到运行态；在运行的过程中如果启动了一个文件读写操作，操作系统会将该进程切换到阻塞态（等待态）从而让出 CPU；当文件读写完毕以后，操作系统会在将其切换成就绪态，等待进程调度算法来调度该进程执行……

内核空间：操作系统内核态使用的空间，保存操作系统程序和操作系统内核函数执行使用的空间。操作系统内核程序执行使用的空间在内核空间，这是用户程序不能使用的空间，用户程序使用的空间是用户空间。

**调度算法的评价指标**

https://blog.csdn.net/weixin_45990326/article/details/119861173

CPU利用率：CPU执行时间占总时间比例，总时间包括CPU执行时间和IO时间

系统吞吐量：总共完成作业的数量除以总共花费的时间

周转时间：作业被提交给系统开始到作业完成为止的时间，等于作业完成时间-作业提交时间，包括作业在外存后备队列的等待时间和、就绪队列的等待时间、CPU执行时间、IO时间，后面三项组成进程周转时间。

- 平均周转时间：所有作业的周转时间/作业数
- 带权周转时间：作业周转时间/CPU时间
- 平均带权周转时间：所有带权周转时间/作业数

等待时间：作业在外存后备队列的等待时间+就绪队列的等待时间。IO时间也是被服务的状态，不计入等待时间

响应时间：作业从提交到首次被执行的时间。

![在这里插入图片描述](https://img-blog.csdnimg.cn/e9f2852d49ed41e78d7000d52bf0cc43.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTk5MDMyNg==,size_16,color_FFFFFF,t_70)

**进程调度算法**

https://cloud.tencent.com/developer/article/1882760

先来先服务：

短作业优先：

时间片轮转：

优先级调度（静态优先级和动态优先级）

多级反馈队列：

**fork系统调用**

fork系统创建一个子进程，将父进程的数据段和堆栈段复制，将父进程的代码段从fork后面的一句开始复制（因为前面的代码已经执行过了，他的数据已经被反映到数据段和堆栈段上了，就不用再执行他们了，也就不用复制他们了）。在父进程的pid_t pid中返回子进程pid，也就是pid=子进程pid；在子进程的pid_t pid中返回0，也就是pid=0；如果fork出错，那么返回一个负数。fork出错有两个原因，一个是内存不足，一个是创建进程数量超过限制。可以通过pid返回值确定执行的进程是父进程或者子进程，并且通过分支判断来执行父进程和子进程的任务。

**文件描述符0、1、2**

https://blog.csdn.net/qq_45831156/article/details/107469716

https://blog.51cto.com/u_15315240/5096978

https://blog.csdn.net/silent123go/article/details/71108501

Linux所有设备被当成文件处理，当打开或者创建一个文件的时候将返回一个文件描述符。一个文件描述符关联一个文件设备，使用tty可以查看本console使用的文件描述符对应的设备的地址。dev/tty是系统终端，dev/tty0是当前使用的终端，dev/tty1是虚拟终端，他是系统终端tty衍生的。

- **Linux读写文件过程**

​	open系统调用打开一个文件设备并返回文件描述符，之后使用read系统调用根据这个文件描述符读取数据到内核空间，再拷贝到用户空间（拷贝到用户程序定义的数组或	变量，也就是=的复制操作会在内核态把内核数据拷贝到用户变量）。write系统调用会把用户空间的数据拷贝到内核空间，然后写入到标准输出设备1或者标准错误输出设	备2里面。0、1、2分别对应标准输入、标准输出、标准错误输出设备。这种内核空间	和用户空间的数据会让在用户空间对数据的修改和原打开的在外存中的文件内容不一	致。为什么不直接进行外存设备的修改？主要是外存设备是块设备，每次只能读写一个内存块512B，并且不能支持随机存取，而内存可以支持随机访问，他的粒度可以是字节。对文件write完成之后，需要使用close系统调用关闭文件，这样才会把用户空间的修改的文件数据覆盖到外存文件设备中。

- **dup作用**

  创建一个新的文件描述符（文件描述符号是当前进程文件描述符最大的+1），并且这个文件描述符指向前一个文件描述符打开的文件

**实验三log文件要在main.c进程move_to_user后接着打开**

main.c进程是Linux初始化进程0进程，在move_to_user之后从内核态进入用户态，创建一个子进程init进程1进程，init进程打开了三个文件描述符，标准输入输出和错误输出。这三个文件描述符通过创建子进程被init这个1进程的子进程全部继承，因此所有的其他的进程因为是init进程的子进程或者孙进程就都包含了标准输入和输出和错误输出文件。这三个文件描述符变成了全局的所有1和1以上的进程都包含的文件描述符，并且都关联到相同的标准输入输出和错误输出。

log文件是记录所有进程调度轨迹的文件，它可以在init这个1进程中打开（但是要在创建子进程之前），也可以在main.c这个0进程的move_to_user之后打开，不能比move_to_user更前了，因为那样就是内核空间打开log文件了，不能在后面创建的子进程中访问到内核空间的文件描述符。

**inode和vnode**

https://www.ruanyifeng.com/blog/2011/12/inode.html

Unix标准vnode和inode 保存文件元信息，vnode包含inode。在Linux中只用了inode。inode包含文件字节数，文件数据块位置，文件创建者，文件读写权限，文件修改创建打开时间等信息。

每个硬盘分区被划分为两个部分，inode区和数据区。inode大小是128B或者256B，每间隔1kB或者2kB有一个inode。

每个inode都被inode号码标识，Linux通过inode号码来标识一个文件

```
查看文件inode信息：stat a.txt
查看硬盘所有分区inode总数和已经使用的数量：df -i
查看硬盘某个分区inode占用空间大小：sudo dumpe2fs -h /dev/hda | grep "Inode size"
查看文件inode号码：ls -i debug.txt
```

- Linux读取文件过程

  这里值得重复一遍，Unix/Linux系统内部不使用文件名，而使用inode号码来识别文件。对于系统来说，文件名只是inode号码便于识别的别称或者绰号。

  表面上，用户通过文件名，打开文件。实际上，系统内部这个过程分成三步：首先，系统找到这个文件名对应的inode号码；其次，通过inode号码，获取inode信息；最后，根据inode信息，找到文件数据所在的block，读出数据。

**内核库函数只能访问内核库函数，不能访问C语言库函数printf或者用户函数**

**include/linux/sched.h  文件描述符 打开文件表 inode表**

https://blog.csdn.net/qq_36553387/article/details/118703354

这个文件定义了NR_TASKS 64也就是最大进程数量是64；定义了HZ 100也就是时钟滴答数是100个/每秒；声明了NR_OPEN 20代表最多20个打开文件

inode信息保存了文件元信息，而inode结构体是inode表的数据类型

定义了进程PCB结构task_struct

```c
struct i387_struct {
	long	cwd;
	long	swd;
	long	twd;
	long	fip;
	long	fcs;
	long	foo;
	long	fos;
	long	st_space[20];	/* 8*10 bytes for each FP-reg = 80 bytes */
};

struct tss_struct {
	long	back_link;	/* 16 high bits zero */
	long	esp0;
	long	ss0;		/* 16 high bits zero */
	long	esp1;
	long	ss1;		/* 16 high bits zero */
	long	esp2;
	long	ss2;		/* 16 high bits zero */
	long	cr3;
	long	eip;
	long	eflags;
	long	eax,ecx,edx,ebx;
	long	esp;
	long	ebp;
	long	esi;
	long	edi;
	long	es;		/* 16 high bits zero */
	long	cs;		/* 16 high bits zero */
	long	ss;		/* 16 high bits zero */
	long	ds;		/* 16 high bits zero */
	long	fs;		/* 16 high bits zero */
	long	gs;		/* 16 high bits zero */
	long	ldt;		/* 16 high bits zero */
	long	trace_bitmap;	/* bits: trace 0, bitmap 16-31 */
	struct i387_struct i387;
};

struct task_struct {
/* these are hardcoded - don't touch */
    //状态相关的变量
	long state;	/* -1 unrunnable, 0 runnable, >0 stopped */
	long counter;
	long priority;
    //信号相关的变量
	long signal;
	struct sigaction sigaction[32];
	long blocked;	/* bitmap of masked signals */
/* various fields */
    //创建进程的用户属性uid等变量
	int exit_code;
	unsigned long start_code,end_code,end_data,brk,start_stack;
	long pid,father,pgrp,session,leader;
	unsigned short uid,euid,suid;
	unsigned short gid,egid,sgid;
	long alarm;
	long utime,stime,cutime,cstime,start_time;
	unsigned short used_math;
/* file system info */
    //进程打开文件信息
	int tty;		/* -1 if no tty, so it must be signed */
	unsigned short umask;
	struct m_inode * pwd;
	struct m_inode * root;
	struct m_inode * executable;
	unsigned long close_on_exec;
    //文件描述符表
	struct file * filp[NR_OPEN];
/* ldt for this task 0 - zero 1 - cs 2 - ds&ss */
    //进程ldt表
	struct desc_struct ldt[3];
/* tss for this task */
    //进程CPU寄存器信息
	struct tss_struct tss;
};



其中文件描述符表filp结构体在include/linux/fs.h定义，文件描述符表和打开文件表都是file 结构数组，其中file结构体的数据在两个数据结构中含义不同
struct file {
	unsigned short f_mode;    //在打开文件表中代表访问模式，只读只写等
	unsigned short f_flags;   //在打开文件表中代表open调用的flag参数
                     //在文件描述符表中代表控制文件描述符的标志。
	unsigned short f_count;   //在打开文件表中与驱动和IO相关的设置
	struct m_inode * f_inode; //在打开文件表中代表文件inode对象的引用
	off_t f_pos;     //在文件描述符表中代表文件句柄，也就是打开文件表中的偏移
    				          //在打开文件表中代表文件文件偏移量
};

在include/linux/fs.h还定义了打开文件表和inode表
struct m_inode {
	unsigned short i_mode;	//访问权限
	unsigned short i_uid;	//文件所有人
	unsigned long i_size;	//文件大小
	unsigned long i_mtime;
	unsigned char i_gid;
	unsigned char i_nlinks;	//文件链接数量
	unsigned short i_zone[9];
/* these are in memory also */
	struct task_struct * i_wait; //打开文件的进程列表
	unsigned long i_atime;
	unsigned long i_ctime;
	unsigned short i_dev;
	unsigned short i_num;
	unsigned short i_count;
	unsigned char i_lock;	//文件锁
	unsigned char i_dirt;
	unsigned char i_pipe;
	unsigned char i_mount;
	unsigned char i_seek;
	unsigned char i_update;
};
struct file {
	unsigned short f_mode;
	unsigned short f_flags;
	unsigned short f_count;
	struct m_inode * f_inode;
	off_t f_pos;
};
extern struct m_inode inode_table[NR_INODE];	//inode表
extern struct file file_table[NR_FILE];			//打开文件表





Linux的proc/pid/fd目录记录了对应pid的文件描述符表。
```

定义0进程INIT_TASK的进程PCB

```c
#define INIT_TASK \
/* state etc */	{ 0,15,15, \
/* signals */	0,{{},},0, \
/* ec,brk... */	0,0,0,0,0,0, \
/* pid etc.. */	0,-1,0,0,0, \
/* uid etc */	0,0,0,0,0,0, \
/* alarm */	0,0,0,0,0,0, \
/* math */	0, \
/* fs info */	-1,0022,NULL,NULL,NULL,0, \
/* filp */	{NULL,}, \
	{ \
		{0,0}, \
/* ldt */	{0x9f,0xc0fa00}, \
		{0x9f,0xc0f200}, \
	}, \
/*tss*/	{0,PAGE_SIZE+(long)&init_task,0x10,0,0,0,0,(long)&pg_dir,\
	 0,0,0,0,0,0,0,0, \
	 0,0,0x17,0x17,0x17,0x17,0x17,0x17, \
	 _LDT(0),0x80000000, \
		{} \
	}, \
}
```

定义就绪队列和当前执行进程的PCB

```c
extern struct task_struct *task[NR_TASKS];
extern struct task_struct *last_task_used_math;
extern struct task_struct *current;
```

定义进程状态

```c
#define TASK_RUNNING		0
#define TASK_INTERRUPTIBLE	1
#define TASK_UNINTERRUPTIBLE	2
#define TASK_ZOMBIE		3
#define TASK_STOPPED		4
```

![在这里插入图片描述](https://img-blog.csdnimg.cn/20210713162217231.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2NTUzMzg3,size_16,color_FFFFFF,t_70)

- 文件系统为所有文件建立inode表，创建一个文件会将文件inode信息保存到inode表，inode表是操作系统自动创建的。

- 使用open系统调用会在打开文件表创建一个表项并且他的inode指针指向对应的inode表中的一个表项的地址，并且在进程pcb的task_struct的文件描述符表filp中添加一个文件描述符，文件句柄指向打开文件表创建的新表项的偏移下标
- 不同进程的文件描述符有相同的文件句柄，可能是使用了fork或者一个进程给另一个进程传递了文件描述符
- 同一进程有相同的文件句柄可能是使用dup,dup2或fcnt1

**Linux时钟中断**

在kernel/sched.c中定义了jiffies，它记录了从开机到现在的时钟中断次数

```c
long volatile jiffies=0;
```

在kernel/sched.c中还设置了发生时钟中断的中断处理函数timer_interrupt

```c
set_intr_gate(0x20,&timer_interrupt);
```

在kernel/system_call.s中实现了timer_interrupt，在这个时钟中断中每次时钟中断都会增加jiffies

```c
.align 2
timer_interrupt:
	push %ds		# save ds,es and put kernel data space
	push %es		# into them. %fs is used by _system_call
	push %fs
	pushl %edx		# we save %eax,%ecx,%edx as gcc doesn't
	pushl %ecx		# save those across function calls. %ebx
	pushl %ebx		# is saved as we use that in ret_sys_call
	pushl %eax
	movl $0x10,%eax
	mov %ax,%ds
	mov %ax,%es
	movl $0x17,%eax
	mov %ax,%fs
	incl jiffies
	movb $0x20,%al		# EOI to interrupt controller #1
	outb %al,$0x20
	movl CS(%esp),%eax
	andl $3,%eax		# %eax is CPL (0 or 3, 0=supervisor)
	pushl %eax
	call do_timer		# 'do_timer(long CPL)' does everything from
	addl $4,%esp		# task switching to accounting ...
	jmp ret_from_sys_call

```

在kernel/sched.c的sched_init函数中设置了时钟中断发生的时间间隔，他设置定时芯片的工作模式是8253模式，8253定时芯片的时钟频率是1193180Hz每秒，LATCH定义了一次时钟中断发生的时钟芯片跳数，那么一秒发生时钟中断的数目是HZ个，也就是每间隔1/HZ秒发生一次时钟终端，那么jiffies/HZ就代表系统开机的总的时间。

```c
// 设置8253模式
outb_p(0x36, 0x43);
outb_p(LATCH&0xff, 0x40);
outb_p(LATCH>>8, 0x40);

// 在 kernel/sched.c 中
#define LATCH  (1193180/HZ)

// 在 include/linux/sched.h 中
#define HZ 100
```

**fork函数**

7-11;14-18;19-22/11

220923/9-14;16-18;19-22/10h

https://blog.csdn.net/honey_qin/article/details/121003012

[(103条消息) linux0.11 fork源码详解_VirtualR_的博客-CSDN博客_linux0.11源码](https://blog.csdn.net/honey_qin/article/details/121003012)

fork系统调用使用的系统调用中断程序system_call（在kernel/system_call.s）的一个子程序sys_fork。system_call对fork系统调用进行一些检查之后跳转到sys_fork函数（call sys_fork)来完成fork系统调用。

include/linux/sched.h中，task[NR_TASKS]规定了任务数组大小64个任务

ss0:esp0指向用户程序工作在内核态使用的堆栈段，ss:esp指向用户程序工作在用户态使用的堆栈

fork函数的声明在include/unistd.h中，他的定义在init/main.c中，他的系统调用号在include/unistd.h中，他的功能函数是sys_fork在include/linux/sys.h中声明，在kernel/system_call.s中定义（因为sys_fork涉及到内存操作，所以需要使用汇编来具体操作内存单元）。

kernel/system_call.s定义了sys_fork系统调用函数实现

```
.align 2
sys_fork:
	call find_empty_process
	testl %eax,%eax
	js 1f
	push %gs
	pushl %esi
	pushl %edi
	pushl %ebp
	pushl %eax
	;copy_process使用内核栈ss0:esp0来传递数据，其中eax是任务数组项号nr
	call copy_process
	addl $20,%esp
1:	ret
```

kernel/fork.c定义了find_empty_process和copy_process。其中find_empty_process没有传递参数，返回参数保存在eax寄存器里，find_empty_process作用是分配last_pid和task[i]，也就是进程pid和进程任务号，其中last_pid是一个全局变量，不需要返回，task[i]中的任务数组项号保存在eax寄存器里面。

[关于get_limit的注解](https://www.cnblogs.com/chenglei/archive/2009/08/12/1544258.html)

[Linux内核完全注释–get_base()、get_limit() | 码农家园 (codenong.com)](https://www.codenong.com/cs106694665/)

```c
/*
 *  linux/kernel/fork.c
 *
 *  (C) 1991  Linus Torvalds
 */

/*
 *  'fork.c' contains the help-routines for the 'fork' system call
 * (see also system_call.s), and some misc functions ('verify_area').
 * Fork is rather simple, once you get the hang of it, but the memory
 * management can be a bitch. See 'mm/mm.c': 'copy_page_tables()'
 */
#include <errno.h>

#include <linux/sched.h>
#include <linux/kernel.h>
#include <asm/segment.h>
#include <asm/system.h>

extern void write_verify(unsigned long address);

long last_pid=0;

void verify_area(void * addr,int size)
{
	unsigned long start;

	start = (unsigned long) addr;
	size += start & 0xfff;
	start &= 0xfffff000;
	start += get_base(current->ldt[2]);
	while (size>0) {
		size -= 4096;
		write_verify(start);
		start += 4096;
	}
}

int copy_mem(int nr,struct task_struct * p)
{
	unsigned long old_data_base,new_data_base,data_limit;
	unsigned long old_code_base,new_code_base,code_limit;

    
    /*
    get_limit, get_base, set_limit, set_base在 include/linux/sched.h定义，都是宏
    
    #define _set_base(addr,base)  \
    __asm__ ("push %%edx\n\t" \
        "movw %%dx,%0\n\t" \
        "rorl $16,%%edx\n\t" \
        "movb %%dl,%1\n\t" \
        "movb %%dh,%2\n\t" \
        "pop %%edx" \
        ::"m" (*((addr)+2)), \
         "m" (*((addr)+4)), \
         "m" (*((addr)+7)), \
         "d" (base) \
        )
    #define _set_limit(addr,limit) \
    __asm__ ("push %%edx\n\t" \
        "movw %%dx,%0\n\t" \
        "rorl $16,%%edx\n\t" \
        "movb %1,%%dh\n\t" \
        "andb $0xf0,%%dh\n\t" \
        "orb %%dh,%%dl\n\t" \
        "movb %%dl,%1\n\t" \
        "pop %%edx" \
        ::"m" (*(addr)), \
         "m" (*((addr)+6)), \
         "d" (limit) \
        )
    #define set_base(ldt,base) _set_base( ((char *)&(ldt)) , (base) )
    #define set_limit(ldt,limit) _set_limit( ((char *)&(ldt)) , (limit-1)>>12 )
    
    static inline unsigned long _get_base(char * addr)
    {
             unsigned long __base;
             __asm__("movb %3,%%dh\n\t"
                     "movb %2,%%dl\n\t"
                     "shll $16,%%edx\n\t"
                     "movw %1,%%dx"
                     :"=&d" (__base)
                     :"m" (*((addr)+2)),
                      "m" (*((addr)+4)),
                      "m" (*((addr)+7)));
             return __base;
    }

	//ldt表保存在内存中，包含两个段代码段和数据段，ldt表的段保存在GDT表的ldt段，GDT表中保存一个进程的tss段和ldt段。
	//ldt定义在task_struct里面 desc_struct ldt[3]，是一个两个struct{ long a,b}
	//把这两个a,b组合成8个字节的一个段描述符项，在这个段描述符项里面保存有三个部分的基地址，get_base就是组合这三个部分的基地址为一个32位的段基址
    #define get_base(ldt) _get_base( ((char *)&(ldt)) )

    #define get_limit(segment) ({ \
    unsigned long __limit; \
    __asm__("lsll %1,%0\n\tincl %0":"=r" (__limit):"r" (segment)); \
    __limit;})
    */
	code_limit=get_limit(0x0f); //ldtr是当前进程的ldt表在gdt表中的段选择符，ldtr+gdt表可以获得ldt表所在的基地址。
	data_limit=get_limit(0x17); //0x0f使用说明使用ldt表，也就是使用ldtr在gdt表中先找到ldt的基地址，然后用oxof的index选择ldt表的选择符
                                //0x0f代表代码段，0x17代表数据&堆栈段，都会从current->ldt中获取段限长
	old_code_base = get_base(current->ldt[1]); //ldt表保存在进程pcb的ldt中，ldt表的段保存在GDT表中
	old_data_base = get_base(current->ldt[2]); //get_base从ldt表中获得代码段或者数据段的基地址
	if (old_data_base != old_code_base)
		panic("We don't support separate I&D");
	if (data_limit < code_limit)
		panic("Bad data_limit");
	new_data_base = new_code_base = nr * 0x4000000;
	p->start_code = new_code_base; //代码起始位置
	set_base(p->ldt[1],new_code_base); //设置新进程的ldt表中的基地址
	set_base(p->ldt[2],new_data_base);
    
    /*
    copy_page_tables和free_page_tables在mm/memory.c中定义
    
    void free_page(unsigned long addr) //计算addr的内存页号并让mem_map-1
    {
        if (addr < LOW_MEM) return;   //内核地址空间不能free
        if (addr >= HIGH_MEMORY)	//超过最大内存，内存不存在
            panic("trying to free nonexistent page");
        addr -= LOW_MEM;
        addr >>= 12;
        if (mem_map[addr]--) return; //找到addr所在页面，页面计数-1，内存映射字节图实际是一个内存引用计数
        mem_map[addr]=0;
        panic("trying to free free page");
    }
    int free_page_tables(unsigned long from,unsigned long size) //free空间，源地址from，大小size
    {
        unsigned long *pg_table;
        unsigned long * dir, nr;

        if (from & 0x3fffff)   //源地址必须是4M的倍数，因为申请和释放总是一个页目录项的大小，为了简单，总是由64个任务，每个人物分配内存64M
            panic("free_page_tables called with wrong alignment");
        if (!from)
            panic("Trying to free up swapper memory space");
        size = (size + 0x3fffff) >> 22;   //页目录项数
        dir = (unsigned long *) ((from>>20) & 0xffc); //页目录项起始位置，页表从0x1000开始，紧接着页目录表 
        for ( ; size-->0 ; dir++) {
            if (!(1 & *dir))	//页目录表的最后一位p位检查这个页目录项是否被使用，如果没有被使用就跳过
                continue;
            pg_table = (unsigned long *) (0xfffff000 & *dir); //取页目录项对应的页表线性地址，前二十位
            for (nr=0 ; nr<1024 ; nr++) {//每个页表由1k个页表项，每个页表项对赢一个页框，也就是一个页面
                if (1 & *pg_table)//检查页表项（一个页）是否被使用，之后使用的才会被free，free内核函数，将mem_map引用计数的内存映射图减-1
                    free_page(0xfffff000 & *pg_table);
                *pg_table = 0; //释放页表项对应的页框内容之后清空页表项
                pg_table++;
            }
            free_page(0xfffff000 & *dir); //清空页表，因为页表在内核代码空间low_mem，所以是不能被清空的，所以个这个函数没作用。
            *dir = 0;
        }
        invalidate();//更新cr3
        return 0;
    }
    int copy_page_tables(unsigned long from,unsigned long to,long size)
    // from 和to是进程虚拟地址空间其实地址，他是nr*64M，也就是说他是64M的倍数
    {
        unsigned long * from_page_table;
        unsigned long * to_page_table;
        unsigned long this_page;
        unsigned long * from_dir, * to_dir;
        unsigned long nr;

        if ((from&0x3fffff) || (to&0x3fffff)) //from ,to 必须是4M的倍数
            panic("copy_page_tables called with wrong alignment");
        from_dir = (unsigned long *) ((from>>20) & 0xffc);    //父进程内存起始地址，进程在虚拟内存中是连续分配的。size就是取得的连续分配大小
        to_dir = (unsigned long *) ((to>>20) & 0xffc);
        size = ((unsigned) (size+0x3fffff)) >> 22;		//父进程分配内存的页目录数
        for( ; size-->0 ; from_dir++,to_dir++) {  
            if (1 & *to_dir) //子进程起始页目录项的p位，如果为1就代表这个页目录项已经被使用了。分配内存的时候总是找空mem_map并变成1，并没用说明使								用
                panic("copy_page_tables: already exist");
            if (!(1 & *from_dir)) //父进程的页目录项没有使用，跳过复制
                continue;
            //父进程的页目录项被使用了
            from_page_table = (unsigned long *) (0xfffff000 & *from_dir);//页目录项对应的页表地址
            if (!(to_page_table = (unsigned long *) get_free_page())) //获取一个空页来保存父进程页表
                return -1;	 
            *to_dir = ((unsigned long) to_page_table) | 7; //设置子进程的页目录项的u/s，R/W位
            nr = (from==0)?0xA0:1024;  //如果0号页目录项，他是内核页目录项，这个内核页目录项的页表的页表项大小是160个页，也就是头部640K是内核空间
            							 其他的页目录项对应的页表数量是1024个页，也就是4M大小的内存
            for ( ; nr-- > 0 ; from_page_table++,to_page_table++) {
                this_page = *from_page_table; //复制页表项
                if (!(1 & this_page))
                    continue;
                this_page &= ~2;   //设置父进程的页表位共享只读，子进程对父进程的页表项只能只读，设置子进程对该页只读
                *to_page_table = this_page; //拷贝父进程的页表项到子进程的页表项
                if (this_page > LOW_MEM) { //子进程使用了父进程的那个页，那么这个页的mem_map+1，引用计数+1
                    *from_page_table = this_page;
                    this_page -= LOW_MEM;
                    this_page >>= 12;
                    mem_map[this_page]++;
                }
            }
        }
        invalidate();
        return 0;
    }
    
    */
	if (copy_page_tables(old_data_base,new_data_base,data_limit)) {
        //复制父进程的页表到子进程的页表
		printk("free_page_tables: from copy_mem\n");
		free_page_tables(new_data_base,data_limit);
		return -ENOMEM;
	}
	return 0;
}

/*
 *  Ok, this is the main fork-routine. It copies the system process
 * information (task[nr]) and sets up the necessary registers. It
 * also copies the data segment in it's entirety.
 */
int copy_process(int nr,long ebp,long edi,long esi,long gs,long none,
		long ebx,long ecx,long edx,
		long fs,long es,long ds,
		long eip,long cs,long eflags,long esp,long ss)
{
	struct task_struct *p;
	int i;
	struct file *f;

    /*
    get_free_page从mem_map内存字节图（char mem_map[paging_pages）找到一个空页（从后往前找一个空页），将这个字节位置1，将这个页置0之后返回
    这个页的起始位置（32位）
    get_free_page和mem_map在mm/memory.c中定义
    
    static unsigned char mem_map [ PAGING_PAGES ] = {0,};
    unsigned long get_free_page(void)
    {
    register unsigned long __res asm("ax");

    __asm__("std ; repne ; scasb\n\t"
        "jne 1f\n\t"
        "movb $1,1(%%edi)\n\t"
        "sall $12,%%ecx\n\t"
        "addl %2,%%ecx\n\t"
        "movl %%ecx,%%edx\n\t"
        "movl $1024,%%ecx\n\t"
        "leal 4092(%%edx),%%edi\n\t"
        "rep ; stosl\n\t"
        "movl %%edx,%%eax\n"
        "1:"
        :"=a" (__res)
        :"0" (0),"i" (LOW_MEM),"c" (PAGING_PAGES),
        "D" (mem_map+PAGING_PAGES-1)
        );
    return __res;
    }
    
    ############################## 分割
    
    Linux0.11内存管理
    Linux0.11管理的内存是16M，可以扩充内存大小。其中LOW_MEM大小是内核代码位置，之后的的15M内存是内存管理的空间，也就是mem_map管理的内存空间
   	这个空间大小是15M，这个空间被划分为4K大小的页，页面数是paging_pages=paging_memory>>12
   	因此给出内存addr计算他的内存页号的时候是(addr-low_mem)>>12
   	
    #define LOW_MEM 0x100000
    #define PAGING_MEMORY (15*1024*1024)
    #define PAGING_PAGES (PAGING_MEMORY>>12)
    #define MAP_NR(addr) (((addr)-LOW_MEM)>>12)
    #define USED 100
    */
    
    //给新进程申请一页新内存，将当前进程的进程PCB（父进程任务结构体）复制到新内存的新任务结构体中，这个复制不会复制堆栈等的内容
	p = (struct task_struct *) get_free_page(); //申请新任务 任务结构体 一页内存
	if (!p)
		return -EAGAIN;		//如果申请不到内存返回
	task[nr] = p;	//nr是新任务任务号（和进程PID不同，进程PID是long last_pid，而任务号只有64个）
	*p = *current;	/* NOTE! this doesn't copy the supervisor stack */
    				//复制父进程的任务结构体的数据到新任务结构体
	p->state = TASK_UNINTERRUPTIBLE;
	p->pid = last_pid;			//当前进程pid
	p->father = current->pid;	//父进程pid
	p->counter = p->priority;	//时间片大小
	p->signal = 0;
	p->alarm = 0;
	p->leader = 0;		/* process leadership doesn't inherit */
	p->utime = p->stime = 0;
	p->cutime = p->cstime = 0; 	//进程用户态和内核态消耗时间（iO时间和CPU时间）
	p->start_time = jiffies;	//进程新建时间p->start_time=jiffies
    
    
    //任务状态段tss设置
	p->tss.back_link = 0;
    
    //设置新进程内核态使用的堆栈是ss0:esp0，为分配内存页的顶端
	p->tss.esp0 = PAGE_SIZE + (long) p;	
	p->tss.ss0 = 0x10;
    
   	//子进程使用父进程的段选择符和数据寄存器，蠢了eax寄存器返回0
	p->tss.eip = eip;		//子进程执行位置和父进程相同
	p->tss.eflags = eflags;
	p->tss.eax = 0;		//eax是函数返回，子进程返回eax=0
	p->tss.ecx = ecx;
	p->tss.edx = edx;
	p->tss.ebx = ebx;
	p->tss.esp = esp;	
	p->tss.ebp = ebp;
	p->tss.esi = esi;
	p->tss.edi = edi;
   	
	p->tss.es = es & 0xffff;
	p->tss.cs = cs & 0xffff;
	p->tss.ss = ss & 0xffff;
	p->tss.ds = ds & 0xffff;
	p->tss.fs = fs & 0xffff;
	p->tss.gs = gs & 0xffff;
    
    //新任务的ldt表的段选择符，_LDT宏
	p->tss.ldt = _LDT(nr);
	p->tss.trace_bitmap = 0x80000000;
	if (last_task_used_math == current)
		__asm__("clts ; fnsave %0"::"m" (p->tss.i387));
    
    //copy_mem设置新进程pcb的start_code位置位nr*64M，使用set_base，设置新进程pcb的ldt表的代码段和数据段基地址
    //使用get_base获取父进程pcb的ldt表中代码段和数据段的起始地址，使用get_limit获取代码段和数据段的段限长
    //使用copy_page_tables把父进程数据段的页表复制到子进程的页表中（利用了写时复制），设置子进程的页为只读，并让mem_map内存映射表+1
	if (copy_mem(nr,p)) {
		task[nr] = NULL;
		free_page((long) p);
		return -EAGAIN;
	}
    //打开文件表打开数量+1
	for (i=0; i<NR_OPEN;i++)
		if ((f=p->filp[i]))
			f->f_count++;
	if (current->pwd)
		current->pwd->i_count++;
	if (current->root)
		current->root->i_count++;
	if (current->executable)
		current->executable->i_count++;
    
    //在gdt表中设置tss和ldt段描述符的起始地址，实际内容保存在进程pcb的那一页里面
	set_tss_desc(gdt+(nr<<1)+FIRST_TSS_ENTRY,&(p->tss));
	set_ldt_desc(gdt+(nr<<1)+FIRST_LDT_ENTRY,&(p->ldt));
	p->state = TASK_RUNNING;	/* do this last, just in case */
	return last_pid;
}

int find_empty_process(void)
    //分配任务号和进程pid
{
	int i;

	repeat:
		if ((++last_pid)<0) last_pid=1;
		for(i=0 ; i<NR_TASKS ; i++)
			if (task[i] && task[i]->pid == last_pid) goto repeat;
	for(i=1 ; i<NR_TASKS ; i++)
		if (!task[i])
			return i;
	return -EAGAIN;
}


```

- fork 系统调用总结

  使用find_empty_process分配任务号（保存在eax中）和进程pid（保存为last_pid的全局变量）

  使用copy_process先调用get_free_page分配新的一个页面，将父进程的pcb复制到这个新页面，设置进程运行状态p->state为uninteruptable。然后修改子进程pcb的参数，主要是eax=0（fork子进程返回0的原因），设置tss（ss0:esp0指向子进程pcb页的顶端），设置pcb的打开文件表+1。然后调用copy_mem函数获取父进程pcb的数据段和代码段基地址和段限长(get_base, get_limit)，获取子进程的数据段和代码段的起始地址(nr*64M)并设置到子进程pcb的ldt表中，然后调用copy_page_tables把父进程的数据段的页表复制到子进程的数据段的页表，并且设置子进程的页表项为只读，并且增加mem_map内存映射图+1。然后将子进程pcb的tss和ldt的起始位置写入到gdt表中。

  总之fork只拷贝了进程pcb并修改了部分属性，并且将父进程的页表复制到子进程中，整个过程并没有复制页（也复制需要写时复制）。linux0.11的内核空间大小是16M，他的页表在内核中有4页来管理内核空间。fork系统调用涉及到新进程的新建态(task_uninteruptable)和就绪态（tast_running)，只有current指向的进程才是正在运行的进程。在task_table里面是就绪队列的进程。

**内存使用**

- 内存划分情况

![Screenshot 2022-09-23 184750](D:\JavaBackend\实验\操作系统实验\实验三 进程轨迹跟踪\截图\Screenshot 2022-09-23 184750.png)

全局描述符表GDT表2K字节，每个描述符项8字节，一共256项。其中前四项分别是null,系统代码段，系统数据段，系统段。之后每两个描述符想标明一个任务，分别是任务状态段tss和局部描述符表ldt的段，状态段开始的项是4，局部描述符表段开始的项是4+1=5，那么之后要获取第NR个任务号的状态段是4\*8+NR\*16。

- GDT表结构

  ![Screenshot 2022-09-23 184955](D:\JavaBackend\实验\操作系统实验\实验三 进程轨迹跟踪\截图\Screenshot 2022-09-23 184955.png)

**schedule函数**

schedule函数是进程调度函数，这个函数在include/linux/sched.h声明，在kernel/sched.c定义。

```c
void schedule(void)
{
	int i,next,c;
	struct task_struct ** p;

/* check alarm, wake up any interruptible tasks that have got a signal */

    /*
    #define TASK_RUNNING		0
    #define TASK_INTERRUPTIBLE	1
    #define TASK_UNINTERRUPTIBLE	2
    #define TASK_ZOMBIE		3
    #define TASK_STOPPED		4
    
    */
    
	for(p = &LAST_TASK ; p > &FIRST_TASK ; --p) 
		if (*p) {
            /*
            如果任务alarm不为0并且alarm时间失效了（alarm<jiffies，jiffies是系统时间-滴答数），就给任务发送SIGALRM信号
            也就是信号为土signal的SIGALRM位变成1，这个信号的处理函数一般是终止进程
                */
			if ((*p)->alarm && (*p)->alarm < jiffies) {
					(*p)->signal |= (1<<(SIGALRM-1));
					(*p)->alarm = 0;
				}
            /*
            处于interruptable状态的进程收到一个可中断信号，就将进程设置成运行状态
            */
			if (((*p)->signal & ~(_BLOCKABLE & (*p)->blocked)) &&
			(*p)->state==TASK_INTERRUPTIBLE)
				(*p)->state=TASK_RUNNING;
		}

/* this is the scheduler proper: */
	/*
	调度算法：
	在任务数组中选择时间片最大的那个任务运行(switch_to)，如果所有时间片都是0，也就是时间片用完，那么重新给进程分配时间片再选最大的时间片的任务运行。
	*/
	while (1) {
		c = -1;
		next = 0;
		i = NR_TASKS;
		p = &task[NR_TASKS];
		while (--i) {
			if (!*--p)
				continue;
			if ((*p)->state == TASK_RUNNING && (*p)->counter > c)
				c = (*p)->counter, next = i;
		}
		if (c) break;
		for(p = &LAST_TASK ; p > &FIRST_TASK ; --p)
			if (*p)
				(*p)->counter = ((*p)->counter >> 1) +
						(*p)->priority;
	}
    //任务切换
    /*
    switch_to在include/linux/sched.h定义为一个宏
    
    #define switch_to(n) {\
    struct {long a,b;} __tmp; \
    __asm__("cmpl %%ecx,current\n\t" \
        "je 1f\n\t" \
        "movw %%dx,%1\n\t" \
        "xchgl %%ecx,current\n\t" \
        "ljmp *%0\n\t" \
        "cmpl %%ecx,last_task_used_math\n\t" \
        "jne 1f\n\t" \
        "clts\n" \
        "1:" \
        ::"m" (*&__tmp.a),"m" (*&__tmp.b), \
        "d" (_TSS(n)),"c" ((long) task[n])); \
    }
    */
	switch_to(next);
}

```

**运行到睡眠函数 sleep_on interuptable_sleep_on sys_pause  sys_waitpid**

```c
//任务睡眠只需要设置task_state=TASK_INTERRUPTABLE或者 TASK_UNINTERUPTABLE
//任务苏醒有两种方式，一种是直接调用wake_up将task_state设置位TASK_RUNNING，或者可中断状态的任务收到一个可中断信号之后被schedule检测到修改task_state为TSAK_RUNNING，还有一种方式就是sleep_on和interruptible_sleep_on唤醒同意等待队列上的其他进程。

int sys_pause(void)
{
	current->state = TASK_INTERRUPTIBLE;
	schedule();
    //调用schedule函数之后sys_pause所在的进程已经被放弃CPU，切换到另外一个进程执行了。sys_pause想要被唤醒需要使用wake_up或者接收到信号之后被schedule的信号检查部分唤醒。
	return 0;
}

void sleep_on(struct task_struct **p)
{
	struct task_struct *tmp;

	if (!p)
		return;
	if (current == &(init_task.task))
		panic("task[0] trying to sleep");
	tmp = *p;
	*p = current;
	current->state = TASK_UNINTERRUPTIBLE;
	schedule();
    //前面的两句话就完成了将sleep_on所在的进程睡眠到等待队列中（每个被等待的资源都可以形成一个等待队列），并且调用schedule函数进行任务切换。后面的代码是这个进程被唤醒后执行的，唤醒这个进程的方式因为为uninterruptible所以必须是wake_up唤醒，唤醒之后这个后面的代码会唤醒p等待队列上的其他进程
	if (tmp)
		tmp->state=0;
}

void interruptible_sleep_on(struct task_struct **p)
{
	struct task_struct *tmp;

	if (!p)
		return;
	if (current == &(init_task.task))
		panic("task[0] trying to sleep");
	tmp=*p;
	*p=current;
repeat:	current->state = TASK_INTERRUPTIBLE;
	schedule();
    //前面两句话已经完成了睡眠和任务切换，后面的话是在interruptible_sleep_on所在的任务被唤醒重新执行后执行的，他会唤醒p队列上的下一个等待这个资源的其他进程。
	if (*p && *p != current) {
		(**p).state=0;
		goto repeat;
	}
	*p=NULL;
	if (tmp)
		tmp->state=0;
}
```

**睡眠到就绪**

```c
/*睡眠到就绪TASK_INTERRUPTIBLE TASK_UNINTERRUPTIBLE 到TASK_RUNNING，由三种方式，一种是wake_up，一种是可中断任务收获到一个可中断信号之后被schedule的信号检查部分唤醒，一种是同一等待队列上的一个被唤醒之后会唤醒同一等待队列上的任务。

wake_up 在kernel/sched.c定义

*/

void wake_up(struct task_struct **p)
{
	if (p && *p) {
		(**p).state=0;
		*p=NULL;
	}
}
```

**运行到退出**

```c
/*
kernel/exit.c包含了三个系统调用sys_kill sys_waitpid sys_exit
sys_kill(int pid,int sig)是向pid的进程发送sig信号
sys_waitpid(pid_t pid,unsigned long * stat_addr, int options)是父进程等待子进程退出，他的参数pid和sys_kill的参数pid一样
sys_exit(int error_code) 程序退出码
*/

//释放进程pcb的页内存
void release(struct task_struct * p)
{
	int i;

	if (!p)
		return;
	for (i=1 ; i<NR_TASKS ; i++)
		if (task[i]==p) {
			task[i]=NULL;
			free_page((long)p);
			schedule();
			return;
		}
	panic("trying to release non-existent task");
}

//向进程pcb  p发送信号sig，这个和tell_father一样，就是修改pcb中的signal信号位图
static inline int send_sig(long sig,struct task_struct * p,int priv)
{
	if (!p || sig<1 || sig>32)
		return -EINVAL;
	if (priv || (current->euid==p->euid) || suser())
		p->signal |= (1<<(sig-1));
	else
		return -EPERM;
	return 0;
}

//关闭会话所有进程，相当于是send_sig修改信号位图signal的某些位
static void kill_session(void)
{
	struct task_struct **p = NR_TASKS + task;
	
	while (--p > &FIRST_TASK) {
		if (*p && (*p)->session == current->session)
			(*p)->signal |= 1<<(SIGHUP-1);
	}
}

/*
 * XXX need to check permissions needed to send signals to process
 * groups, etc. etc.  kill() permissions semantics are tricky!
 */
int sys_kill(int pid,int sig)
{
	struct task_struct **p = NR_TASKS + task;
	int err, retval = 0;

	if (!pid) while (--p > &FIRST_TASK) {  					//pid=0，sig信号发送给进程组内所有进程
		if (*p && (*p)->pgrp == current->pid) 
			if ((err=send_sig(sig,*p,1)))
				retval = err;
	} else if (pid>0) while (--p > &FIRST_TASK) {			//pid>0，sig发送给pid的那个进程
		if (*p && (*p)->pid == pid) 
			if ((err=send_sig(sig,*p,0)))
				retval = err;
	} else if (pid == -1) while (--p > &FIRST_TASK) {		//pid=-1，sig发送给第一个进程外的所有进程
		if ((err = send_sig(sig,*p,0)))
			retval = err;
	} else while (--p > &FIRST_TASK)
		if (*p && (*p)->pgrp == -pid)						//pid<-1，sig发送给进程组-pid的所有进程
			if ((err = send_sig(sig,*p,0)))
				retval = err;
	return retval;
}

static void tell_father(int pid)							//向父进程发送子进程终止信号
{
	int i;

	if (pid)
		for (i=0;i<NR_TASKS;i++) {
			if (!task[i])
				continue;
			if (task[i]->pid != pid)
				continue;
			task[i]->signal |= (1<<(SIGCHLD-1));
			return;
		}
/* if we don't find any fathers, we just release ourselves */
/* This is not really OK. Must change it to make father 1 */
	printk("BAD BAD - no father found\n\r");
	release(current);
}

int do_exit(long code)
{
	int i;
    //释放进程数据段和代码段内存
	free_page_tables(get_base(current->ldt[1]),get_limit(0x0f));
	free_page_tables(get_base(current->ldt[2]),get_limit(0x17));
    //释放进程子进程，让子进程的父进程指向1进程，如果子进程僵尸态，就给1进程发送子进程终止信号
	for (i=0 ; i<NR_TASKS ; i++)
		if (task[i] && task[i]->father == current->pid) {
			task[i]->father = 1;
			if (task[i]->state == TASK_ZOMBIE)
				/* assumption task[1] is always init */
				(void) send_sig(SIGCHLD, task[1], 1);
		}
    //释放进程占有的文件，包括文件描述符表，pwd，root，i文件
	for (i=0 ; i<NR_OPEN ; i++)
		if (current->filp[i])
            /*
            (fs/open.c定义)
            int sys_close(unsigned int fd)
            {	
                struct file * filp;

                if (fd >= NR_OPEN)
                    return -EINVAL;
                current->close_on_exec &= ~(1<<fd);
                //文件描述符不存在出错
                if (!(filp = current->filp[fd]))
                    return -EINVAL;
                current->filp[fd] = NULL;	//文件描述符变空
                if (filp->f_count == 0)	//文件引用为0出错
                    panic("Close: file count is 0");
                if (--filp->f_count)	//如果文件引用计数-1之后不为0，则返回成功关闭，否则代表文件没被占用，那么释放inode节点
                    return (0);
                iput(filp->f_inode);
                return (0);
            }
            */
			sys_close(i);
	iput(current->pwd);
	current->pwd=NULL;
	iput(current->root);
	current->root=NULL;
	iput(current->executable);
	current->executable=NULL;
    //如果是会话首领并拥有控制终端，释放控制终端
	if (current->leader && current->tty >= 0)
		tty_table[current->tty].pgrp = 0;
    //如果占用了协处理器，释放协处理器
	if (last_task_used_math == current)
		last_task_used_math = NULL;
    //如果是会话首领，关闭会话所有进程
	if (current->leader)
		kill_session();
    
    //设置进程状态，退出码，通知父进程子进程终止信号，重新调度。
	current->state = TASK_ZOMBIE;
	current->exit_code = code;
	tell_father(current->father);
	schedule();
	return (-1);	/* just to suppress warnings */
}

int sys_exit(int error_code)
{
	return do_exit((error_code&0xff)<<8);
}

int sys_waitpid(pid_t pid,unsigned long * stat_addr, int options)
{
	int flag, code;
	struct task_struct ** p;
	
    //内存写验证函数。因为linux内存页写时复制（共享）机制，导致写内存的时候需要分配空间复制原来的页，这个修改不影响addr给出的线性地址，只需要在分配内存页完成之后修改页表和页表就行了。
    /*
    （kernel/fork.c定义)
    void verify_area(void * addr,int size)	//逻辑地址addr
    {
        unsigned long start;

        start = (unsigned long) addr;
        size += start & 0xfff;
        start &= 0xfffff000;
        start += get_base(current->ldt[2]);	//物理地址start
        while (size>0) {
            size -= 4096;
            write_verify(start);			//start所在的页写验证
            start += 4096;
        }
    }
    
    （mm/memory.c定义)
    void write_verify(unsigned long address)
    {
        unsigned long page;

        if (!( (page = *((unsigned long *) ((address>>20) & 0xffc)) )&1))	//如果页目录项p=0，则这个页可写
            return;
        page &= 0xfffff000;
        page += ((address>>10) & 0xffc);
        if ((3 & *(unsigned long *) page) == 1)                             //如果页不可写，对页进行复制
            un_wp_page((unsigned long *) page);
        return;
    }
    
    （mm/memory.c定义)
    void un_wp_page(unsigned long * table_entry)
    {
        unsigned long old_page,new_page;

		//如果页面只被引用一次，那么这个页面是可写的
        old_page = 0xfffff000 & *table_entry;
        if (old_page >= LOW_MEM && mem_map[MAP_NR(old_page)]==1) {
            *table_entry |= 2;
            invalidate();
            return;
        }
        
        //如果页面被引用多次，那么复制页面到新页面，让旧页面内存映射图-1
        if (!(new_page=get_free_page()))
            oom();
        if (old_page >= LOW_MEM)
            mem_map[MAP_NR(old_page)]--;
        *table_entry = new_page | 7;
        invalidate();
        copy_page(old_page,new_page);
    }	
    */
	verify_area(stat_addr,4);
repeat:
	flag=0;
	for(p = &LAST_TASK ; p > &FIRST_TASK ; --p) {
        //跳过本进程
		if (!*p || *p == current)
			continue;
        //不是当前进程的子进程，跳过
		if ((*p)->father != current->pid)
			continue;
		if (pid>0) {
			if ((*p)->pid != pid)
				continue;
		} else if (!pid) {
			if ((*p)->pgrp != current->pgrp)
				continue;
		} else if (pid != -1) {
			if ((*p)->pgrp != -pid)
				continue;
		}
        //根据子进程状态确定
		switch ((*p)->state) {
			case TASK_STOPPED:				//子进程位stopped，返回pid
				if (!(options & WUNTRACED))
					continue;
				put_fs_long(0x7f,stat_addr);
				return (*p)->pid;
			case TASK_ZOMBIE:				//子进程位zombie，将子进程用户时间和内核时间加到父进程，之后释放进程pcb并返回pid
				current->cutime += (*p)->utime;
				current->cstime += (*p)->stime;
				flag = (*p)->pid;
				code = (*p)->exit_code;
				release(*p);
				put_fs_long(code,stat_addr);
				return flag;
			default:
				flag=1;
				continue;
		}
	}
	if (flag) {					//子进程为运行态或者阻塞态，设置父进程为阻塞态并调度。在本进程被唤醒是如果由除子进程终止信号之外的信号就报错
		if (options & WNOHANG)
			return 0;
		current->state=TASK_INTERRUPTIBLE;
		schedule();
		if (!(current->signal &= ~(1<<(SIGCHLD-1))))
			goto repeat;
		else
			return -EINTR;
	}
	return -ECHILD;
}


```



**进程轨迹跟踪**

进程有五种状态，新建到就绪，就绪到运行，运行到就绪，运行到睡眠，睡眠到就绪，运行到终止

- 新建到就绪

  新建并就绪由sys_fork系统调用完成。在find_empty_process中分配任务号和pid，在copy_process中申请一页新内存复制父进程pcb到新内存中（get_free_page)，修改子进程的pcb（eax=0, ss0:esp0指向新页的顶端, 打开文件+1），使用copy_mm获取父进程代码段和数据段起始地址和限址，获取子进程起始地址，将父进程的页表复制到子进程的页表，设置子进程页表项为只读，再mem_map+1，之后把ldt段和tss段写入gdt表。

  fork系统调用的copy_process涉及到新建太和就绪态。

- 就绪到运行和运行到就绪

  就绪到运行和运行到就绪通过schedule调度函数完成。schedule函数有三个部分，第一部分处理信号（任务数组的任务如果alarm<jiffies，设置任务信号为土signal SIGALRM位=1；如果signal含有不可阻塞信号SIGKILL/SIGSTOP并且任务处于interruptable，则设置位RUNNING）；第二部分进程调度，选择时间片最大的那个进程，如果时间篇都是0，就重新分配时间片再调度；第三部分调用switch_to进行任务切换（保存当前任务的tss结构到PCB中，加载新任务的tss结构到CPU）
  
- 运行到睡眠

  运行到睡眠由sleep_on 和interruptable_sleep_on，还有主动睡眠的系统调用sys_pause和sys_waitpid

- 运行到退出(TASK_ZOMBIE TASK_STOPPED)

  sys_exit

**内存管理**

- 早期没有内存管理直接操作内存的问题

  [(103条消息) 内存管理之分段与分页_Coding~Farmer的博客-CSDN博客_内存分页分段](https://blog.csdn.net/weixin_44151739/article/details/108416656)

  [(103条消息) 内存管理＜原理篇＞（一、内存认识和无存储器抽象）_酱油师兄的博客-CSDN博客_无存储器抽象](https://blog.csdn.net/C1033177205/article/details/124529063)

  - 地址空间不隔离。一个程序可以访问到另外一个程序的位置
  - 程序地址不确定。程序被装入内存的时候位置不确定，那么如果在程序中有一个固定访问的内存单元，这个内存单元需要被重定位
  - 内存利用率低。总是把一个程序完整的放入到内存中，如果内存大小400M，而有三个进程100M 、200M、300M，那么装入一个100M和200M的进程就剩下100M的内存没用。

- 程序地址绑定方式&程序装入内存方式

  [(103条消息) 内存管理＜原理篇＞（二、地址空间和链接和装入）_酱油师兄的博客-CSDN博客_界限寄存器](https://blog.csdn.net/C1033177205/article/details/124559014)

  - 绝对装入。事先知道程序在内存中的位置，在编译链接的时候就固定程序的地址为那个位置（编译器处理），那么装入的位置就是绝对位置。适合单道程序系统
  - 静态重定位。编译器编译链接的程序是逻辑0地址开始的程序，在装入的时候操作系统修改代码将代码中的地址修改为被装入位置相加之后的地址，这样爱被装入位置代码中的地址也是一个绝对地址。和上一种方式一样。
  - 动态重定位。编译器编译链接得到的是逻辑0地址开始的程序，再装入的时候操作系统分配内存装入并不改变代码的地址。在是级CPU执行过程中，遇到一个逻辑地址，就通过一些转换比如基址寻址（基址<逻辑地址+基址<基址+限址 ），分区、分段、分页存储器都是动态重定位。

- 内存分配方式&实现多进程并发方式

  [(103条消息) 内存管理＜原理篇＞（三、交换和分区）_酱油师兄的博客-CSDN博客_下次适配算法](https://blog.csdn.net/C1033177205/article/details/124767212)

  [(103条消息) 内存管理＜原理篇＞（四、分段和分页）_酱油师兄的博客-CSDN博客_内存管理 分段 分页](https://blog.csdn.net/C1033177205/article/details/124833422)

  - 交换

    单道程序中内存一次运行一个进程，可以把进程交换到磁盘实现并发。交换的缺点是内存和磁盘交换的性能瓶颈。交换用的不多，不到不得已不用。Linux使用交换分区来实现交换的磁盘存储。交换技术会在内存不够的时候强行终止现在的进程交换到外存并开启新的进程。

  - 分区

    一个进程占用一个连续的分区，将多个进程放入内存。基址寻址就是一种分区内存分配的实现方式。

    - 固定分区和动态分区

      固定分区就是内存区大小固定，动态分区就是内存区大小不固定（进程PCB保存基址和限址）

    - 分区内存分配和管理

      使用空闲分区表或者空闲分区链来管理分区，一般使用空闲分区链。分配内存的时候可以使用首次适配（第一个满足要求的空闲分区）、最佳适配、最差适配等。

    - 分区的回收

      回收的时候和相邻的空闲分区合并

    - 分区的缺点

      分区的时候会遇到外部碎片问题，也就是总的空闲分区足够，但是没有一个单独的空闲分区满足要求导致不能分配内存。此时可以使用的技术是内存紧缩，也就是把所有分配的内存放到内存首位置同时重定位（静态重定位要修改代码中所有地址，动态重定位要修改PCB的基址等）。其他的解决方法是分段和分页。

  - 分段

    分段是一种非连续内存分配技术，用户程序被按照逻辑单元分为不同的段，比如一个函数、一个数组、一个结构体、堆、栈等都被分为不同的段。和动态分区类似，动态分区把一个进程当成一个段，而分段将一个进程按照不同的逻辑单元划分为不同的段，在寻址的时候，动态分区使用保存在PCB的基址寄存器的地址加上偏移得到实际的物理地址，而分段因为有多个段，需要用一个段表来保存段号和段基址的映射。段表的结构如下

    | 段号 | 段基址 | 保护 |
    | ---- | ------ | ---- |
    |      |        |      |

    分段时段寄存器给出的是段选择符（段号，这个段在段表的编号，CS、DS等给出段号），根据CS或DS给出的段号在段表中找到段基址，加上偏移得到诗集的物理地址。

    分段的好处是以段为单位分配内存单元，相比分区内存分配粒度更小

  - 分页

    分页是一种非连续内存分配技术，内存被分配为固定大小的页，Linux是4K为单位（磁盘块是512B为单位）。内存没4K被分为一个快，称为页框，4G大小的内存有1M页框；用户程序也被分为4K大小的一块，称为页面。页面和页框的映射通过页表来标记。页表结构

    | 页号 | 页框号 | 保护 |
    | ---- | ------ | ---- |
    |      |        |      |

    分页相比于分段来说减少了外部碎片。分段和分页实际是分区的升级版本，一个使用段为单位，一个使用固定大小的页单位进行内存分配。分段和分页都需要空闲列表或者空闲链表来管理空闲分区，分段会有外部碎片问题，而分页有内部碎片问题。

    分页给出的是虚拟地址，这个地址除以4K得到页号，取余4K得到页内偏移，页号在页表中查找得到页框号，页框号*4K得到页框基址，最后实际地址是页框基址+页内偏移得到实际地址。

- 分段和分页的区别和联系

  [分页和分段有什么区别（内存管理）？ - holmes_now - 博客园 (cnblogs.com)](https://www.cnblogs.com/holmes7521/p/15118070.html)

  [(103条消息) 分页与分段的主要联系和区别_Octoberone的博客-CSDN博客_分段和分页的区别和联系](https://blog.csdn.net/qq_38855717/article/details/80552459)

  - 联系

    两者都是非连续内存分配，都需要经过地址映射机构MMU进行地址转换

  - 区别

    - 目的不同。分段是满足用户需要，段是信息逻辑单位，存储完整的信息；分页是操作系统内存管理的需要
    - 信息共享。段是信息的逻辑单位，方便共享和存储。
    - 大小不同。段的大小不固定，页的大小固定
    - 地址空间不同。段式存储器需要用户程序给出二维地址，需要段号和段内偏移；而页式存储器需要用户给出的是一维线性地址，地址变换机构通过除以页框大小得到页号，区域页框大小得到页内偏移。
    - 内存碎片不同。两者都减少了内存碎片，分页存在内部碎片问题，分段存在外部碎片问题。

- 段页式存储器

  [GDT,LDT,GDTR,LDTR 详解,包你理解透彻 | 技术部落 (techbulo.com)](https://www.techbulo.com/708.html)

  [(103条消息) 分页和分段的联系和区别_FishBear_move_on的博客-CSDN博客](https://blog.csdn.net/haluoluo211/article/details/42263281)

  [(103条消息) 操作系统——内存管理——分段和分页_zhaohong_bo的博客-CSDN博客](https://blog.csdn.net/zhaohong_bo/article/details/90166135)

  [(103条消息) GDT和LDT详解_关关纠纠的博客-CSDN博客_gdt ldt](https://blog.csdn.net/qq_42762094/article/details/120423812)

  Linux的段页式存储器一个CPU只有一个GDT表，GDT表中给出系统所有段的段描述符项，同时也包含每个进程的LDT表，每个进程的LDT表也包含在GDT表中。GDTR有48位，高32位给出GDT表的物理地址，低16位是GDT表的表限长；LDTR是16位，LDTR实际上是GDT表的段选择子，高13位给出LDT表在GDT表中的编号。GDT表或者LDT表段选择子13位index，规定最多8K个段。

  Linux寻址有两个指令的差别，一种是访问内核空间的数据和程序只是用GDT表，一种是访问用户空间的程序需要使用GDT表和LDT表。

  访问内核空间的时候，CPU给出的逻辑地址是一个二维地址（段选择子：段内偏移），段选择子（CS,DS,ES,FS,SS,GS)的T1=0位代表这个段是系统段使用GDT表，他有两位的RPL请求特权级，他的高13位index是GDT表中的编号，index*8+GDTR的32位基地址=指令在GDT表中的段描述符项的物理地址，GDT表中一个段描述符项有8个字节64位，包括32位段地址，20位段限长，DPL段描述符特权级2位。从段描述符项中取出段基地址+段内偏移得到指令的物理地址。

  访问用户空间的时候，CPU给出的逻辑地址是一个二维地址（段选择子：段内偏移），段选择子的T1=1代表使用LDT表，此时会使用LDTR的高13位作为段号在GDT表中获得LDT表的段描述符项（LDT表存放在内存中被当成一个段处理），这个段描述符项的段基地址是LDT表的物理地址，这个32位的物理地址+index*8得到指令的段描述符项地址，然后从LDT表的段描述符项中获得段基地址+偏移地址得到指令的物理地址。

  从上面段式存储器获得的线性地址是一个一维地址，他的高10位是页目录号，中间10位是页号，最低12位是页内偏移。从CR3寄存器获得页目录表的物理地址32位，CR3+页框号*4=指令所在页目录项（页表项大小4字节），页目录项的高20位是页表地址的高20位，页表地址高20位\*4K+页号\*4=页表项，页表项高20位\*4K+页内偏移=指令物理地址。页内偏移12位满足页大小4K

- 请求特权级

  [(103条消息) Linux从头学12：读完这篇【特权级】文章，你就比别人更“精通”操作系统！_IOT物联网小镇的博客-CSDN博客_linux特权级](https://blog.csdn.net/jchen1218/article/details/120321176)

**glibc/系统调用/c库函数**

[(103条消息) glibc的头文件 linux_Glibc、系统调用和C库函数_勃勃大师兄的博客-CSDN博客](https://blog.csdn.net/weixin_36015213/article/details/112843302?ops_request_misc=&request_id=&biz_id=102&utm_term=glibc的头文件 linux&utm_medium=distribute.pc_search_result.none-task-blog-2~blog~sobaiduweb~default-1-112843302.nonecase)

[glibc_百度百科 (baidu.com)](https://baike.baidu.com/item/glibc/10058561?fr=aladdin)

[(103条消息) linux 如何查找命令的路径（which,whereis命令）_IT新人一枚的博客-CSDN博客_linux 查询命令路径where](https://blog.csdn.net/itbaoku1352/article/details/120220326)

c库函数的头文件保存在/usr/include里面，包括系统调用API和glibc头文件，应用程序使用的函数一方面是系统调用API，另一方面也可以是glibc头文件，区别在于系统调用API是内核提供的头文件，而glibc是一个独立的c语言运行时库函数提供的头文件

系统调用API的头文件保存在/usr/include里面，他是一个宏，他把系统调用号放到eax寄存器，调用0x80中断进行处理。也就是说系统调用API的实现是一个0x80的中断处理程序，他的实现是内核实现的。

glibc是一个c语言库函数，他的头文件放到/usr/include里，他的链接库在/usr/local/lib里面（下面的.so文件和.a文件是链接库文件libc.so）。glibc的函数可以不使用系统调用，而系统调用的函数基本上都是内核函数。stdio是glibc库文件的头文件。

linux指令使用which指令查找指令的执行程序位置。whereis查看文件的位置，which查看指令的位置。which在PATH包含usr/bin;usr/local/bin等位置。gcc编译器程序保存在usr/local/bin下面，gcc编译器使用glibc库函数保存在/usr/local/lib下面的.so和.a库文件中。编译器将源代码编译成中间文件.o文件，之后链接器从库文件提取库函数，和其他.o文件一起链接成可执行程序。

ubuntu 查看glibc版本使用lld --version命令

头文件并不是必须的，只要制定了库文件，而库文件包含这个函数，那么编译就不会报错。glibc的头文件是不用显示的在c文件中给出的，因为gcc会从库文件中获得这个程序进行链接。头文件作用主要有两个，一个是通知用户库文件中的函数和调用方法，另外一个是编译器类型检查，如果没有头文件，那么就算库文件存在这个函数，程序会成功链接这个函数，但是如果传入参数类型和数量错误是不会被发现的，这样的坏处是运行的时候会出问题。

**Linux版本**

https://blog.csdn.net/debug_cpp/article/details/2687067

https://blog.csdn.net/m0_46278037/article/details/115195273

[https://zh.wikipedia.org/wiki/Linux%E5%86%85%E6%A0%B8](https://zh.wikipedia.org/wiki/Linux内核)

```
查看Ubuntu版本
cat /etc/issue
查看内核版本
uname -r
查看glibc版本
lld --version

内核代码文件保存在
/usr/src
```

Linux内核有三个不同的命名方案。

早期版本：第一个版本的内核是0.01，其次是0.02,0.03,0.10,0.11,0.12（第一[GPL](https://zh.wikipedia.org/wiki/GPL)版本),0.95,0.96,0.97,0.98,0.99及1.0。[[77\]](https://zh.wikipedia.org/wiki/Linux内核#cite_note-77)，从0.95版有许多的补丁发布于主要版本版本之间。

旧计划（1.0和2.6版之间)，版本的格式为A.B.C，其中A,B,C代表：**A**大幅度转变的内核，这是很少发生变化，只有当发生重大变化的代码和内核发生才会发生，在历史上曾改变两次的内核：1994年的1.0及1996年的2.0； **B**是指一些重大修改的内核，内核使用了传统的奇数次要版本号码的软件号码系统（用偶数的次要版本号码来表示稳定版本）；**C**是指轻微修订的内核，这个数字当有安全补丁，bug修复，新的功能或驱动程序，内核便会有变化。自2.6.0（2003年12月）发布后，人们认识到，更短的发布周期将是有益的。自那时起，版本的格式为A.B.C.D，其中A,B,C,D代表：**A**和**B**是无关紧要的，**C**是内核的版本，**D**是安全补丁。

自3.0（2011年7月）发布后，版本的格式为3.A.B，其中A,B代表：**A**是内核的版本，**B**是安全补丁。而4.0（2015年4月）发布后，则延续3.A.B的命名格式，只是将主版号变更为4。

**系统调用追踪**

https://stackoverflow.com/questions/175882/whats-the-algorithm-behind-sleep

sleep让进程睡眠，同时设置定时器，在每次调度过程中检查

**glibc源代码网站**

[https://www.j10.monster/Glibc-source-browser/glibc_src_2.23/glibc_src_2.23/stdio-common](https://www.j10.monster/Glibc-source-browser/glibc_src_2.23/glibc_src_2.23/stdio-common/)

### 实验4-内核级线程的切换

[(104条消息) 操作系统学习笔记——用户级线程和核心级线程_qq_42518941的博客-CSDN博客_用户级线程举例](https://blog.csdn.net/qq_42518941/article/details/119145575)

**内存映射表MMU**

[一文读懂Linux内核内存映射与页表 (qq.com)](https://view.inews.qq.com/k/20220818A03GM000?web_channel=wap&openApp=false)

MMU是将虚拟地址映射到物理地址的内存映射机构，就是管理页表的一个芯片

**CPU TSS段，LDT表等都是全局变量，CPU执行的时候会load这些全局变量从而切换CPU的数值**

**用户级线程和内核级线程**

[(104条消息) 操作系统学习笔记——用户级线程和核心级线程_qq_42518941的博客-CSDN博客_用户级线程举例](https://blog.csdn.net/qq_42518941/article/details/119145575)

用户级线程是跑在用户空间里面的程序，他的线程跳转需要用户自己手动设置，需要用户自己编写yield程序去设置跳转到线程的操作。yeild程序的主要功能有两个，一个是切换用户栈，一个是切换cs:ip。用户及线程的缺点是如果一个用户级线程发生阻塞（读取文件），那么整个程序都将被阻塞。

现代操作系统是基于多核系统的。多核系统和多处理器系统的区别是多处理器系统每个CPU占有一个MMU和cache，而多核系统共用一个cache和MMU（他们内存和外存都是共享的）。Linux是基于多核系统的多线程操作系统，他是多线程而不是多进程的操作系统，主要区别就在于这些线程公用cache和MMU。

![在这里插入图片描述](https://img-blog.csdnimg.cn/c4f55a9055004d55801554517a1fd59c.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQyNTE4OTQx,size_16,color_FFFFFF,t_70#pic_center)

**Linux多线程的实现，用户级线程到内核级线程的映射**

内核级线程切换分为4个步骤：

- 系统调用（启动磁盘等触发阻塞的系统调用）或者时钟中断触发schedule函数执行调度程序

  - 磁盘系统调用触发系统调度

    int80会将用户程序ss:sp,EFLAGS，CS:IP如内核栈（程序TCB所在页的高地址空间），然后执行system_call中断处理程序。system_call中断处理程序如下

    ```
    .align 2
    bad_sys_call:
    	movl $-1,%eax
    	iret
    .align 2
    reschedule:
    	pushl $ret_from_sys_call
    	jmp schedule
    .align 2
    system_call:
    	cmpl $nr_system_calls-1,%eax
    	ja bad_sys_call
    	push %ds
    	push %es
    	push %fs
    	pushl %edx
    	pushl %ecx		# push %ebx,%ecx,%edx as parameters
    	pushl %ebx		# to the system call
    	movl $0x10,%edx		# set up ds,es to kernel space
    	mov %dx,%ds
    	mov %dx,%es
    	movl $0x17,%edx		# fs points to local data space
    	mov %dx,%fs
    	call sys_call_table(,%eax,4)
    	pushl %eax
    	movl current,%eax
    	cmpl $0,state(%eax)		# state
    	jne reschedule
    	cmpl $0,counter(%eax)		# counter
    	je reschedule
    ret_from_sys_call:
    	movl current,%eax		# task[0] cannot have signals
    	cmpl task,%eax
    	je 3f
    	cmpw $0x0f,CS(%esp)		# was old code segment supervisor ?
    	jne 3f
    	cmpw $0x17,OLDSS(%esp)		# was stack segment = 0x17 ?
    	jne 3f
    	movl signal(%eax),%ebx
    	movl blocked(%eax),%ecx
    	notl %ecx
    	andl %ebx,%ecx
    	bsfl %ecx,%ecx
    	je 3f
    	btrl %ecx,%ebx
    	movl %ebx,signal(%eax)
    	incl %ecx
    	pushl %ecx
    	call do_signal
    	popl %eax
    3:	popl %eax
    	popl %ebx
    	popl %ecx
    	popl %edx
    	pop %fs
    	pop %es
    	pop %ds
    	iret
    
    ```


  ​		system_call执行完成之后内核栈的内容变化为。其中ds,es,fs,edx,ecx,ebx,eax等压栈操作是system_call的内容，前面是int80的操作。

  ![img](https://img-blog.csdnimg.cn/ea58d55547a7471eb3dd48340c7ac672.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQyNTE4OTQx,size_16,color_FFFFFF,t_70#pic_center)

  ​		在system_call的后面部分的代码会检测当前线程如果不是运行状态或者时间片用完机会触发调度（如果时间片没有用完就不会出发调度，而是继续执行系		统调用）

  ```
  	cmpl $0,state(%eax)		# state
  	jne reschedule
  	cmpl $0,counter(%eax)		# counter
  	je reschedule
  	
  ```

  ​		ret_from_sys_call会让内核线程从内核态返回到用户态，他的弹栈是system_call压入的内容，最后使用iret指令从内核态返回到用户态（类似int80传入的		那些参数的弹栈处理

  - 时钟中断触发系统调度

    ```c
    .align 2
    timer_interrupt:
    	push %ds		# save ds,es and put kernel data space
    	push %es		# into them. %fs is used by _system_call
    	push %fs
    	pushl %edx		# we save %eax,%ecx,%edx as gcc doesn't
    	pushl %ecx		# save those across function calls. %ebx
    	pushl %ebx		# is saved as we use that in ret_sys_call
    	pushl %eax
    	movl $0x10,%eax
    	mov %ax,%ds
    	mov %ax,%es
    	movl $0x17,%eax
    	mov %ax,%fs
    	incl jiffies
    	movb $0x20,%al		# EOI to interrupt controller #1
    	outb %al,$0x20
    	movl CS(%esp),%eax
    	andl $3,%eax		# %eax is CPL (0 or 3, 0=supervisor)
    	pushl %eax
    	call do_timer		# 'do_timer(long CPL)' does everything from
    	addl $4,%esp		# task switching to accounting ...
    	jmp ret_from_sys_call
    	
    	
    	
    	
    void do_timer(long cpl)
    {
    	extern int beepcount;
    	extern void sysbeepstop(void);
    
    	if (beepcount)
    		if (!--beepcount)
    			sysbeepstop();
    
    	if (cpl)
    		current->utime++;
    	else
    		current->stime++;
    
    	if (next_timer) {
    		next_timer->jiffies--;
    		while (next_timer && next_timer->jiffies <= 0) {
    			void (*fn)(void);
    			
    			fn = next_timer->fn;
    			next_timer->fn = NULL;
    			next_timer = next_timer->next;
    			(fn)();
    		}
    	}
    	if (current_DOR & 0xf0)
    		do_floppy_timer();
    	if ((--current->counter)>0) return;
    	current->counter=0;
    	if (!cpl) return;
    	schedule();
    }
    ```

- schedule函数执行系统调度，选择一个就绪的线程

- schedule后面的switch_to函数将执行线程的切换

- 如果是进程切换，还需要切换内存映射表（多处理器系统切换MMU，Linux是多核系统不用切换MMU）

**sys_fork执行过程以及调度过程**

（cpu栈寄存器只有ss:esp，ss0:esp0是保存在pcb里面的内核栈地址，他在执行int0x80的时候加载到ss:esp里面指向内核栈）

（c语言函数调用A(int b) 会被编译成push b, call A, add 4, %esp；也就是call的返回地址是add 4,%esp，将A函数的参数弹出栈）

int0x80先设置ss:esp栈指针指向内核栈，然后保存调用int0x80中断的下一条指令，一般是一个赋值到pcb指针的指令，int0x80会在内核栈压入ss:esp,eflags,cs:ip，都是用户程序的栈和返回指令地址。然后进入system_call系统调用处理程序，他先压入一些寄存器，然后根据eax传入的的NR_fork中断调用号call sys_call_table+NR_fork*6(cs2字节，eip4字节)找到sys_fork中断处理程序执行。

sys_fork中断处理程序首先find_empty_process分配任务号和进程pid，然后使用copy_process，分配一页内存把父进程pcb复制到内存中去，然后修改子进程pcb的father，counter等参数；最后根据父进程的数据size分配页目录项和页表项，将页表项的数据赋值为父进程页表项，同时设置这些页表指向的页面的mem_map引用计数加1，设置子进程的页表项为只读。（在进行写变量的时候，会首先对这个变量所在的页进行写验证，如果这个页面是只读的，那么就会重新分配一个页面赋值父进程的页面，然后在分配的页面修改这个变量，同时把这个页面的地址赋值给页表项，同时修改mem_map减1)

sys_fork修改子进程的pcb的时候，父进程和子进程的内核栈的数据分别是

![fork调用内核栈情况](D:/JavaBackend/实验/操作系统实验/实验4 基于内核栈的进程切换/截图/fork调用内核栈情况.PNG)

在system_call后面调用sys_fork之后，是一个reschedule函数，这个函数压入ret_from_sys_call地址，跳转到schedule函数执行，schedule函数先进行系统调度找到下一个执行的目标进程，然后调用switch_to函数，参数为pnext, LDT(next)，以及addl 8,%esp的返回地址，然后执行switch_to切换进程，switch_to 切换进程函数如下

```
.align 2
switch_to:
    //因为该汇编函数要在c语言中调用，所以要先在汇编中处理栈帧
	pushl %ebp
	movl %esp,%ebp
	pushl %ecx
	pushl %ebx
	pushl %eax

    //先得到目标进程的pcb，然后进行判断
    //如果目标进程的pcb(存放在ebp寄存器中) 等于   当前进程的pcb => 不需要进行切换，直接退出函数调用
    //如果目标进程的pcb(存放在ebp寄存器中) 不等于 当前进程的pcb => 需要进行切换，直接跳到下面去执行
	movl 8(%ebp),%ebx
	cmpl %ebx,current
	je 1f

    /** 执行到此处，就要进行真正的基于堆栈的进程切换了 */
	
        // PCB的切换
	movl %ebx,%eax                   	;%ebx 保存目标进程pcb地址
	xchgl %eax,current					;eax指向当前进程pcb地址，current/ebx指向目标pcb
	
	// TSS中内核栈指针的重写
	movl tss,%ecx						;cpu按照tss切换内核栈，这种特性要被维护，所以使用tss0来保存目标pcb内核栈
	addl $4096,%ebx
	movl %ebx,ESP0(%ecx)

	//切换内核栈
	movl %esp,KERNEL_STACK(%eax)		;保存当前esp到当前进程的pcb中，读取目标进程pcb的内核栈到esp中
	movl 8(%ebp),%ebx
	movl KERNEL_STACK(%ebx),%esp

	//LDT的切换
	movl 12(%ebp),%ecx					;切换LDT表
	lldt %cx
	movl $0x17,%ecx
	mov %cx,%fs
	
	cmpl %eax,last_task_used_math
	jne 1f
	clts
	
	//在到子进程的内核栈开始工作了，接下来做的四次弹栈以及ret处理使用的都是子进程内核栈中的东西

1:	popl %eax							;切换内核栈之后执行的程序已经是目标进程的程序了，这段话是返回到目标进程的用户空间。
	popl %ebx
	popl %ecx
	popl %ebp
	ret
```

switch_to函数在父进程中首先pop一些参数之后会ret回到reschedule函数的下一条语句add 8,%esp，然后ret跳转到ret_from_sys_call函数，这句话进一步回复一些寄存器之后使用iret指令回到父进程的用户程序中；在子进程中，switch_to函数pop一些参数之后ret跳转到first_return_kernel函数，这个函数进一步弹出一些寄存器之后iret回到子进程的用户程序。

### 实验5-信号量的实现

[操作系统实验05-信号量实现和应用 - mirage_mc - 博客园 (cnblogs.com)](https://www.cnblogs.com/mirage-mc/p/12913993.html)

**关中断和开中断**

[(104条消息) 汇编指令CLI/STI_小蚂蚁_CrkRes的博客-CSDN博客_cli指令](https://blog.csdn.net/zang141588761/article/details/52325106)

c语言cli()和sti()是关中断和开中断，使用cli + sti可以实现原子操作，内核中修改ss:esp的时候需要使用cli+sti变成原子操作

系统调用是一个中断处理函数，系统调用函数是原子操作的，原因就在于进入int0x80的时候，也就是执行中断处理函数的时候会使用cli+sti关中断，那么中断处理函数就变成了原子操作。

中断处理程序分为可屏蔽中断和不可屏蔽中断，不可屏蔽中断会使用cli和sti操作标志寄存器eflags的IF位，从而让IF=0实现程序在执行这个中断的时候不会相应其他的中断，也就是关中断。（内核线程分为可中断线程和不可中断线程，可中断线程可以用信号唤醒（信号或者wake_up主动唤醒），而不可中断线程必须使用wake_up主动唤醒。

中断分为内中断和外中断，内中断是程序指令引发的，比如int0x80系统调用/除0等等；外中断分为可屏蔽外中断和不可屏蔽外中断，是有外部设备引发的中断，可屏蔽外中断cpu可以拒绝执行，不可屏蔽外中断CPU必须执行而不用理会IF状态标志。时钟中断

**结构体struct/c语言基本数据类型/指针的底层实现**

[(104条消息) 汇编中movl,movw,movb的作用_Lawrence_121的博客-CSDN博客_movw](https://blog.csdn.net/m0_37806112/article/details/80549927)

[(104条消息) AT&T汇编——MOV指令_z974656361的博客-CSDN博客_movl和movq](https://blog.csdn.net/z974656361/article/details/107133955)

[汇编指令：lea - YangARTuan - 博客园 (cnblogs.com)](https://www.cnblogs.com/YangARTuan/p/11628591.html)

[(104条消息) C语言 数组定义和使用 - C语言零基础入门教程_猿说编程的博客-CSDN博客_c语言数组声明](https://blog.csdn.net/ZhaDeNianQu/article/details/119725736)

[c语言详解sizeof - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/74066384)

[(104条消息) C语言 -- 字符串的使用及内存分配_FebSummer的博客-CSDN博客_字符串内存分配](https://blog.csdn.net/u012834152/article/details/108358996)

sizeof是一个操作符，而不是函数，类似++一样，他是取内存字节数的操作

movq 8字节；movl 操作4字节；movw 2字节；movb 1字节

leaq	-40(%rbp), %rax; 把-40(%rbp)的内存地址放到rax寄存器，mov是把内存的内容放到寄存器。计算地址方-40+%rbp

基本数据类型/结构体/指针/数组等数据类型的实现是由编译器实现的。

- 在编译的时候，把printf和string等字符串数组/全局变量放到数据区，把函数的局部变量/函数传递的参数放到栈上申请内存；

- 在编译的时候，基本数据类型变量的定义会在x(%ebp)上开辟一个基本数据类型大小的栈空间（ebp指向用户栈的底端，%esp指向用户栈的顶端，x是局部变量/参数申请栈上的内存区域），基本数据类型变量的赋值会使用mov $y, x(%ebp)将字面值使用mov传送指令传送到对应变量申请的栈空间；

- 在编译的时候，结构体的数据类型分配的栈空间总是以4字节为单位分配的，分配的内存空间总是结构体所定义的基本数据类型的所有字节数的最小的4的倍数的字节，也就是sizeof= (基本数据类型和+4)/4\*4，多出的分配的字节作为填充字节，没有被使用。比如struct T{char a; int b}，基本数据类型的字节数的和是1+4=5个字节，但是编译器在分配内存的时候会分配sizeof(struct T)=(5+4)/4\*4=8个字节，其他的字节被作为填充字节没有被使用，一种底层实现是***movb 0,-4(%ebp) ;  movl 0, -8(%ebp) **  ，也就是给char放入了三个填充字节而没有使用  

- 在编译的时候，局部变量的基本数据类型的数组的定义是在栈空间上分配内存的，c语言基本数据类型数组的定义和初始化为char ctmp[]={0,0,0}，这里ctmp并不是一个独立的变量，他是一个数组，他只会被分配在栈上3个字节，ctmp会被编译成这3个字节开头的栈地址-3(%ebp)，那么在printf("%p", ctmp)中，传送给printf参数数据地址是lea -3(%ebp), eax；ctmp数组的栈空间的内存的初始化由mov完成，而不是像printf或者字符串数组char* p="abcdefg"一样被放到数据区，也就是使用大括号{0,0,0}初始化的基本数据类型数组的初始化是在栈上分配内存和初始化的，是在代码汇编代码中使用mov指令一个一个数组的字节进行初始化的，对于char ctmp[]={0,0,0}的一种初始化方案是**movw -3(%ebp); movb -1(%ebp)**；基本数据类型数组分配的栈空间大小是**基本数据类型字节数\*基本数据类型个数**

- 在编译的时候，字符串局部变量的定义是在数据区分配内存的，也就是char *p="abcdefg"是和printf中的字符数组一样被放到数据区分配内存保存字符串“abcdefg”的，但是在栈区依旧会分配一个内存4字节变量保存数据区的内容的地址，也就是p是栈上的一个4字节的变量，他保存了“abcdefg”字符串在数据区的地址，这个过程在编译到的汇编代码是**data: "abcdefg"          code:  leal data, -4(%ebp) **，也就是字符串数组保存到数据区，然后使用lea把数据区的地址赋值给栈局部变量的位置p；当使用p[1]获取字符串数组中的一个元素的时候，会先加载啊栈上的变量到eax，然后eax增加[  1\*sizeof(基本数据类型)  ]个字节的数字（增加的数字由编译器计算得到），然后使用mov指令从eax指向的内存单元读取数字到eax寄存器，这个过程用汇编指令完成为**mov -4(%ebp), %eax;  add 1, %eax; mov (%eax), %eax**,  寄存器eax的数值被传递给printf函数或者其他操作

- 在编译的时候，结构体数组并不是按照结构体来分配内存的，而是按照结构体的基本数据类型来分配内存的，也就是struct T p[2] 并不会分配(sizeof(T)+4)/4*2，而是把基本数据类型打散之后分配内存的，如果struct T{char a,b,c} ，那么分配的内存是sizeof(char)\*3=6个字节char，分配的内存在栈上，而对于p的初始化依旧使用mov指令将字面值赋值给栈上的内存；当我们使用p[1].a获取p中的元素的变量的时候，实际汇编将p[1].a解释称栈上的一个内存-4(%ebp)放到eax寄存器，汇编代码为mov -4(%ebp), %eax。局部变量结构体数组分配内存和使用方式实际上转换成局部变量基本类型数组分配内存和使用方式，只是局部变量字符串数组分配内存和使用方式不同于上面两种。

- 全局变量都是按照基本类型分配内存的。全局基本类型，全局结构体，全局基本类型数组，全局结构体数组，全局字符串数组都是按照基本数据类型分配内存，但是内存分配需要是4的倍数，所以会有编译器进行数据对齐，但是使用sizeof并不会显示这些对齐数据(.align)。字符串数组分配的内存要+1，因为会有一个'\0'字符，字符串数组无法通过sizeof来获取字符串数组分配的内存大小，因为字符串数组是一个指针类型，sizeof总是获取的指针的字节数4，这样就不能获取字符串数组的内存大小。全局基本数据类型数组int a[10]={0}和全局字符串数组char* a="abc"中前一个a和后一个a是不同的，前一个a直接指向的是分配的int数组的首地址，而后一个a直接指向的是一个4位的指针，他保存了字符串"abc"被分配的内存的首地址。

  ```c
  #include<stdio.h>
  
  struct T{
  	char a;
  	short b;
  	int c;
  };
  
  struct S{
  	long long a;
  	long b ;
  };
  
  struct E{
  	char a,b,c;
  };
  
  
  //global variable
  //global basic type
  char ga =4;
  short gb = 1;
  int gc = 2 ;
  
  //global struct type
  struct E gpEE = {0,1,2} ;
  
  //global basic type list
  char gpchar[] = {1,2,3} ;
  
  //global character list
  char * gcl = "abcefghigkl" ;
  
  //global struct list
  struct E gpE[] = {
  	[0]{
  		.a=1,.b=2,.c=3
  	},
  	[1]{
  		.a=4,.b=5,.c=6
  	}
  } ;
  
  
  int main(){
  	printf("==============local basic type\n");
  	
  	char a=0;
  	short b=0;
  	int c=0;
  	long d=0;
  	long long e=0;
  	float f=0;
  	double g=0;
  	printf("char:  		%lu\n",sizeof(a)) ;
  	printf("short: 		%lu\n",sizeof(b)) ;
  	printf("int: 			%lu\n",sizeof(c)) ;
  	printf("long:			%lu\n",sizeof(d)) ;
  	printf("long long:		%lu\n",sizeof(e)) ;
  	printf("float:			%lu\n",sizeof(f)) ;
  	printf("double:		%lu\n",sizeof(g)) ;
  	
  	printf("================local struct\n") ;
  	printf("================\n");
  	struct T tmp={0,0,0};
  	printf("st:			%lu\n",sizeof(tmp));
  	
  	printf("================\n");
  	struct S stmp={0,0} ;
  	printf("ss:			%lu\n",sizeof(stmp));
  	
  	printf("================local basic type list\n");
  	struct T *ptmp = &tmp ;
  	printf("*ptmp:			%p\n",ptmp) ;
  	
  	char ctmp[]={0,0,0} ;
  	printf("sizeof(ctmp):		%lu\n",sizeof(ctmp));
  	printf("length(ctmp):		%lu\n",sizeof(ctmp)/sizeof(ctmp[0]));
  	printf("sizeof(ctmp[0]):	%lu\n",sizeof(ctmp[0]) );
  	printf("ctmp address:		%p\n",ctmp) ;
  	short shtmp[]={0,0,0} ;
  	printf("sizeof(shtmp):		%lu\n",sizeof(shtmp));
  	printf("length(shtmp):		%lu\n",sizeof(shtmp)/sizeof(shtmp[0]));
  	printf("sizeof(shtmp[0]):	%lu\n",sizeof(shtmp[0]) );
  	printf("shtmp address:		%p\n",shtmp) ;
  	int itmp[]={0,0,0};
  	printf("sizeof(itmp):		%lu\n",sizeof(itmp));
  	printf("length(itmp):		%lu\n",sizeof(itmp)/sizeof(itmp[0]));
  	printf("sizeof(itmp[0]):	%lu\n",sizeof(itmp[0]) );
  	printf("itmp address:		%p\n",itmp) ;
  	
  	printf("================local character list\n");
  	
  	char *pchar = "abcdefg";
  	printf("pchar:			%s\n",pchar);
  	printf("pchar[0]:		%c\n",pchar[1]);
  	printf("sizeof(pchar):		%lu\n",sizeof(pchar)) ;
  	printf("length(pchar):		%lu\n",sizeof(pchar)/sizeof(pchar[0])) ;
  	printf("address(pchar):	%p\n",pchar) ;
  	
  	
  	
  	printf("================local struct list \n");
  	struct E pE[2]={
  		[0]{
  			.a = 0,
  			.b = 1,
  			.c = 2
  		},
  		[1]{
  			.a=3,
  			.b=4,
  			.c=5
  		}
  	} ;
  	printf("pE[1].a:		%d\n", pE[1].a) ;	
  	printf("sizeof(pE):		%lu\n", sizeof(pE) ) ;
  	
  	
  	
  	printf("\n\n\n\n\n") ;
  	printf("================global basic type\n") ;
  	printf("sizeof(ga):			%lu\n", sizeof(ga) ) ;
  	printf("sizeof(gb):			%lu\n", sizeof(gb) ) ;
  	printf("sizeof(gc):			%lu\n", sizeof(gc) );
  	printf("address(ga):			%p\n", &ga ) ;
  	printf("address(gb):			%p\n", &gb ) ;
  	printf("address(gc):			%p\n", &gc );
  	
  	printf("================global struct\n") ;
  	printf("sizeof(gpEE):		%lu\n", sizeof(gpEE) ) ;
  	printf("address(gpEE):			%p\n", &gpEE );
  	
  	printf("================global basic type list\n") ;
  	printf("sizeof(gpchar):	%lu\n", sizeof(gpchar)) ;
  	printf("address(gpchar):	%p\n", gpchar );
  	printf("gpchar[1]:		%d\n", gpchar[1]);
  	printf("sizeof(gpchar[1]):	%lu\n", sizeof(gpchar[1]) );
  	
  	printf("================global character list\n") ;
  	printf("sizeof(gcl):		%lu\n", sizeof( gcl) ) ;
  	printf("address(gcl):			%p\n", gcl);
  	printf("gcl[1]:		%d\n", gcl[1]);
  	printf("sizeof(gcl[1]):	%lu\n", sizeof(gcl[1]) );
  	
  	printf("================global struct list\n") ;
  	printf("sizeof(gpE):		%lu\n", sizeof( gpE) ) ;
  	printf("address(gpE):			%p\n", gpE );
  	printf("gpE[1].a:		%d\n", gpE[1].a);
  	
  	
  
  }
  	
  ```

  ```
  	.file	"ab.c"
  	.text
  	.globl	ga
  	.data
  	.type	ga, @object
  	.size	ga, 1
  ga:
  	.byte	4
  	.globl	gb
  	.align 2
  	.type	gb, @object
  	.size	gb, 2
  gb:
  	.value	1
  	.globl	gc
  	.align 4
  	.type	gc, @object
  	.size	gc, 4
  gc:
  	.long	2
  	.globl	gpEE
  	.type	gpEE, @object
  	.size	gpEE, 3
  gpEE:
  	.byte	0
  	.byte	1
  	.byte	2
  	.globl	gpchar
  	.type	gpchar, @object
  	.size	gpchar, 3
  gpchar:
  	.ascii	"\001\002\003"
  	.globl	gcl
  	.section	.rodata
  .LC0:
  	.string	"abcefghigkl"
  	.section	.data.rel.local,"aw"
  	.align 8
  	.type	gcl, @object
  	.size	gcl, 8
  gcl:
  	.quad	.LC0
  	.globl	gpE
  	.data
  	.type	gpE, @object
  	.size	gpE, 6
  gpE:
  	.byte	1
  	.byte	2
  	.byte	3
  	.byte	4
  	.byte	5
  	.byte	6
  	.section	.rodata
  	.align 8
  .LC1:
  	.string	"==============local basic type"
  .LC4:
  	.string	"char:  \t\t%lu\n"
  .LC5:
  	.string	"short: \t\t%lu\n"
  .LC6:
  	.string	"int: \t\t\t%lu\n"
  .LC7:
  	.string	"long:\t\t\t%lu\n"
  .LC8:
  	.string	"long long:\t\t%lu\n"
  .LC9:
  	.string	"float:\t\t\t%lu\n"
  .LC10:
  	.string	"double:\t\t%lu\n"
  .LC11:
  	.string	"================local struct"
  .LC12:
  	.string	"================"
  .LC13:
  	.string	"st:\t\t\t%lu\n"
  .LC14:
  	.string	"ss:\t\t\t%lu\n"
  	.align 8
  .LC15:
  	.string	"================local basic type list"
  .LC16:
  	.string	"*ptmp:\t\t\t%p\n"
  .LC17:
  	.string	"sizeof(ctmp):\t\t%lu\n"
  .LC18:
  	.string	"length(ctmp):\t\t%lu\n"
  .LC19:
  	.string	"sizeof(ctmp[0]):\t%lu\n"
  .LC20:
  	.string	"ctmp address:\t\t%p\n"
  .LC21:
  	.string	"sizeof(shtmp):\t\t%lu\n"
  .LC22:
  	.string	"length(shtmp):\t\t%lu\n"
  .LC23:
  	.string	"sizeof(shtmp[0]):\t%lu\n"
  .LC24:
  	.string	"shtmp address:\t\t%p\n"
  .LC25:
  	.string	"sizeof(itmp):\t\t%lu\n"
  .LC26:
  	.string	"length(itmp):\t\t%lu\n"
  .LC27:
  	.string	"sizeof(itmp[0]):\t%lu\n"
  .LC28:
  	.string	"itmp address:\t\t%p\n"
  	.align 8
  .LC29:
  	.string	"================local character list"
  .LC30:
  	.string	"abcdefg"
  .LC31:
  	.string	"pchar:\t\t\t%s\n"
  .LC32:
  	.string	"pchar[0]:\t\t%c\n"
  .LC33:
  	.string	"sizeof(pchar):\t\t%lu\n"
  .LC34:
  	.string	"length(pchar):\t\t%lu\n"
  .LC35:
  	.string	"address(pchar):\t%p\n"
  	.align 8
  .LC36:
  	.string	"================local struct list "
  .LC37:
  	.string	"pE[1].a:\t\t%d\n"
  .LC38:
  	.string	"sizeof(pE):\t\t%lu\n"
  .LC39:
  	.string	"\n\n\n\n"
  	.align 8
  .LC40:
  	.string	"================global basic type"
  .LC41:
  	.string	"sizeof(ga):\t\t\t%lu\n"
  .LC42:
  	.string	"sizeof(gb):\t\t\t%lu\n"
  .LC43:
  	.string	"sizeof(gc):\t\t\t%lu\n"
  .LC44:
  	.string	"address(ga):\t\t\t%p\n"
  .LC45:
  	.string	"address(gb):\t\t\t%p\n"
  .LC46:
  	.string	"address(gc):\t\t\t%p\n"
  .LC47:
  	.string	"================global struct"
  .LC48:
  	.string	"sizeof(gpEE):\t\t%lu\n"
  .LC49:
  	.string	"address(gpEE):\t\t\t%p\n"
  	.align 8
  .LC50:
  	.string	"================global basic type list"
  .LC51:
  	.string	"sizeof(gpchar):\t%lu\n"
  .LC52:
  	.string	"address(gpchar):\t%p\n"
  .LC53:
  	.string	"gpchar[1]:\t\t%d\n"
  .LC54:
  	.string	"sizeof(gpchar[1]):\t%lu\n"
  	.align 8
  .LC55:
  	.string	"================global character list"
  .LC56:
  	.string	"sizeof(gcl):\t\t%lu\n"
  .LC57:
  	.string	"address(gcl):\t\t\t%p\n"
  .LC58:
  	.string	"gcl[1]:\t\t%d\n"
  .LC59:
  	.string	"sizeof(gcl[1]):\t%lu\n"
  	.align 8
  .LC60:
  	.string	"================global struct list"
  .LC61:
  	.string	"sizeof(gpE):\t\t%lu\n"
  .LC62:
  	.string	"address(gpE):\t\t\t%p\n"
  .LC63:
  	.string	"gpE[1].a:\t\t%d\n"
  	.text
  	.globl	main
  	.type	main, @function
  main:
  .LFB0:
  	.cfi_startproc
  	endbr64
  	pushq	%rbp
  	.cfi_def_cfa_offset 16
  	.cfi_offset 6, -16
  	movq	%rsp, %rbp
  	.cfi_def_cfa_register 6
  	addq	$-128, %rsp
  	movq	%fs:40, %rax
  	movq	%rax, -8(%rbp)
  	xorl	%eax, %eax
  	leaq	.LC1(%rip), %rdi
  	call	puts@PLT
  	movb	$0, -123(%rbp)
  	movw	$0, -122(%rbp)
  	movl	$0, -120(%rbp)
  	movq	$0, -112(%rbp)
  	movq	$0, -104(%rbp)
  	pxor	%xmm0, %xmm0
  	movss	%xmm0, -116(%rbp)
  	pxor	%xmm0, %xmm0
  	movsd	%xmm0, -96(%rbp)
  	movl	$1, %esi
  	leaq	.LC4(%rip), %rdi
  	movl	$0, %eax
  	call	printf@PLT
  	movl	$2, %esi
  	leaq	.LC5(%rip), %rdi
  	movl	$0, %eax
  	call	printf@PLT
  	movl	$4, %esi
  	leaq	.LC6(%rip), %rdi
  	movl	$0, %eax
  	call	printf@PLT
  	movl	$8, %esi
  	leaq	.LC7(%rip), %rdi
  	movl	$0, %eax
  	call	printf@PLT
  	movl	$8, %esi
  	leaq	.LC8(%rip), %rdi
  	movl	$0, %eax
  	call	printf@PLT
  	movl	$4, %esi
  	leaq	.LC9(%rip), %rdi
  	movl	$0, %eax
  	call	printf@PLT
  	movl	$8, %esi
  	leaq	.LC10(%rip), %rdi
  	movl	$0, %eax
  	call	printf@PLT
  	leaq	.LC11(%rip), %rdi
  	call	puts@PLT
  	leaq	.LC12(%rip), %rdi
  	call	puts@PLT
  	movb	$0, -72(%rbp)
  	movw	$0, -70(%rbp)
  	movl	$0, -68(%rbp)
  	movl	$8, %esi
  	leaq	.LC13(%rip), %rdi
  	movl	$0, %eax
  	call	printf@PLT
  	leaq	.LC12(%rip), %rdi
  	call	puts@PLT
  	movq	$0, -64(%rbp)
  	movq	$0, -56(%rbp)
  	movl	$16, %esi
  	leaq	.LC14(%rip), %rdi
  	movl	$0, %eax
  	call	printf@PLT
  	leaq	.LC15(%rip), %rdi
  	call	puts@PLT
  	leaq	-72(%rbp), %rax
  	movq	%rax, -88(%rbp)
  	movq	-88(%rbp), %rax
  	movq	%rax, %rsi
  	leaq	.LC16(%rip), %rdi
  	movl	$0, %eax
  	call	printf@PLT
  	movw	$0, -11(%rbp)
  	movb	$0, -9(%rbp)
  	movl	$3, %esi
  	leaq	.LC17(%rip), %rdi
  	movl	$0, %eax
  	call	printf@PLT
  	movl	$3, %esi
  	leaq	.LC18(%rip), %rdi
  	movl	$0, %eax
  	call	printf@PLT
  	movl	$1, %esi
  	leaq	.LC19(%rip), %rdi
  	movl	$0, %eax
  	call	printf@PLT
  	leaq	-11(%rbp), %rax
  	movq	%rax, %rsi
  	leaq	.LC20(%rip), %rdi
  	movl	$0, %eax
  	call	printf@PLT
  	movw	$0, -36(%rbp)
  	movw	$0, -34(%rbp)
  	movw	$0, -32(%rbp)
  	movl	$6, %esi
  	leaq	.LC21(%rip), %rdi
  	movl	$0, %eax
  	call	printf@PLT
  	movl	$3, %esi
  	leaq	.LC22(%rip), %rdi
  	movl	$0, %eax
  	call	printf@PLT
  	movl	$2, %esi
  	leaq	.LC23(%rip), %rdi
  	movl	$0, %eax
  	call	printf@PLT
  	leaq	-36(%rbp), %rax
  	movq	%rax, %rsi
  	leaq	.LC24(%rip), %rdi
  	movl	$0, %eax
  	call	printf@PLT
  	movl	$0, -24(%rbp)
  	movl	$0, -20(%rbp)
  	movl	$0, -16(%rbp)
  	movl	$12, %esi
  	leaq	.LC25(%rip), %rdi
  	movl	$0, %eax
  	call	printf@PLT
  	movl	$3, %esi
  	leaq	.LC26(%rip), %rdi
  	movl	$0, %eax
  	call	printf@PLT
  	movl	$4, %esi
  	leaq	.LC27(%rip), %rdi
  	movl	$0, %eax
  	call	printf@PLT
  	leaq	-24(%rbp), %rax
  	movq	%rax, %rsi
  	leaq	.LC28(%rip), %rdi
  	movl	$0, %eax
  	call	printf@PLT
  	leaq	.LC29(%rip), %rdi
  	call	puts@PLT
  	leaq	.LC30(%rip), %rax
  	movq	%rax, -80(%rbp)
  	movq	-80(%rbp), %rax
  	movq	%rax, %rsi
  	leaq	.LC31(%rip), %rdi
  	movl	$0, %eax
  	call	printf@PLT
  	movq	-80(%rbp), %rax
  	addq	$1, %rax
  	movzbl	(%rax), %eax
  	movsbl	%al, %eax
  	movl	%eax, %esi
  	leaq	.LC32(%rip), %rdi
  	movl	$0, %eax
  	call	printf@PLT
  	movl	$8, %esi
  	leaq	.LC33(%rip), %rdi
  	movl	$0, %eax
  	call	printf@PLT
  	movl	$8, %esi
  	leaq	.LC34(%rip), %rdi
  	movl	$0, %eax
  	call	printf@PLT
  	movq	-80(%rbp), %rax
  	movq	%rax, %rsi
  	leaq	.LC35(%rip), %rdi
  	movl	$0, %eax
  	call	printf@PLT
  	leaq	.LC36(%rip), %rdi
  	call	puts@PLT
  	movb	$0, -30(%rbp)
  	movb	$1, -29(%rbp)
  	movb	$2, -28(%rbp)
  	movb	$3, -27(%rbp)
  	movb	$4, -26(%rbp)
  	movb	$5, -25(%rbp)
  	movzbl	-27(%rbp), %eax
  	movsbl	%al, %eax
  	movl	%eax, %esi
  	leaq	.LC37(%rip), %rdi
  	movl	$0, %eax
  	call	printf@PLT
  	movl	$6, %esi
  	leaq	.LC38(%rip), %rdi
  	movl	$0, %eax
  	call	printf@PLT
  	leaq	.LC39(%rip), %rdi
  	call	puts@PLT
  	leaq	.LC40(%rip), %rdi
  	call	puts@PLT
  	movl	$1, %esi
  	leaq	.LC41(%rip), %rdi
  	movl	$0, %eax
  	call	printf@PLT
  	movl	$2, %esi
  	leaq	.LC42(%rip), %rdi
  	movl	$0, %eax
  	call	printf@PLT
  	movl	$4, %esi
  	leaq	.LC43(%rip), %rdi
  	movl	$0, %eax
  	call	printf@PLT
  	leaq	ga(%rip), %rsi
  	leaq	.LC44(%rip), %rdi
  	movl	$0, %eax
  	call	printf@PLT
  	leaq	gb(%rip), %rsi
  	leaq	.LC45(%rip), %rdi
  	movl	$0, %eax
  	call	printf@PLT
  	leaq	gc(%rip), %rsi
  	leaq	.LC46(%rip), %rdi
  	movl	$0, %eax
  	call	printf@PLT
  	leaq	.LC47(%rip), %rdi
  	call	puts@PLT
  	movl	$3, %esi
  	leaq	.LC48(%rip), %rdi
  	movl	$0, %eax
  	call	printf@PLT
  	leaq	gpEE(%rip), %rsi
  	leaq	.LC49(%rip), %rdi
  	movl	$0, %eax
  	call	printf@PLT
  	leaq	.LC50(%rip), %rdi
  	call	puts@PLT
  	movl	$3, %esi
  	leaq	.LC51(%rip), %rdi
  	movl	$0, %eax
  	call	printf@PLT
  	leaq	gpchar(%rip), %rsi
  	leaq	.LC52(%rip), %rdi
  	movl	$0, %eax
  	call	printf@PLT
  	movzbl	1+gpchar(%rip), %eax
  	movsbl	%al, %eax
  	movl	%eax, %esi
  	leaq	.LC53(%rip), %rdi
  	movl	$0, %eax
  	call	printf@PLT
  	movl	$1, %esi
  	leaq	.LC54(%rip), %rdi
  	movl	$0, %eax
  	call	printf@PLT
  	leaq	.LC55(%rip), %rdi
  	call	puts@PLT
  	movl	$8, %esi
  	leaq	.LC56(%rip), %rdi
  	movl	$0, %eax
  	call	printf@PLT
  	movq	gcl(%rip), %rax
  	movq	%rax, %rsi
  	leaq	.LC57(%rip), %rdi
  	movl	$0, %eax
  	call	printf@PLT
  	movq	gcl(%rip), %rax
  	addq	$1, %rax
  	movzbl	(%rax), %eax
  	movsbl	%al, %eax
  	movl	%eax, %esi
  	leaq	.LC58(%rip), %rdi
  	movl	$0, %eax
  	call	printf@PLT
  	movl	$1, %esi
  	leaq	.LC59(%rip), %rdi
  	movl	$0, %eax
  	call	printf@PLT
  	leaq	.LC60(%rip), %rdi
  	call	puts@PLT
  	movl	$6, %esi
  	leaq	.LC61(%rip), %rdi
  	movl	$0, %eax
  	call	printf@PLT
  	leaq	gpE(%rip), %rsi
  	leaq	.LC62(%rip), %rdi
  	movl	$0, %eax
  	call	printf@PLT
  	movzbl	3+gpE(%rip), %eax
  	movsbl	%al, %eax
  	movl	%eax, %esi
  	leaq	.LC63(%rip), %rdi
  	movl	$0, %eax
  	call	printf@PLT
  	movl	$0, %eax
  	movq	-8(%rbp), %rdx
  	xorq	%fs:40, %rdx
  	je	.L3
  	call	__stack_chk_fail@PLT
  .L3:
  	leave
  	.cfi_def_cfa 7, 8
  	ret
  	.cfi_endproc
  .LFE0:
  	.size	main, .-main
  	.ident	"GCC: (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0"
  	.section	.note.GNU-stack,"",@progbits
  	.section	.note.gnu.property,"a"
  	.align 8
  	.long	 1f - 0f
  	.long	 4f - 1f
  	.long	 5
  0:
  	.string	 "GNU"
  1:
  	.align 8
  	.long	 0xc0000002
  	.long	 3f - 2f
  2:
  	.long	 0x3
  3:
  	.align 8
  4:
  ```

- **C语言内存分配**

  [(104条消息) 深入理解C语言数组与内存分配_未羊_z的博客-CSDN博客_c语言中定义数组内存分配](https://blog.csdn.net/weixin_44793395/article/details/106292650)

  C语言内存分为3个段，数据段.data段、堆段、栈段

  数据段保存全局变量，字符串数组，printf的字符串，静态变量等，他是在加载的时候被加载器分配内存和初始化的

  堆段是动态内存分配使用的，也就是malloc分配内存使用的

  栈段保存局部变量和传递参数

  局部变量的数组的定义可以使用int n=3; int a[n]， 而全局变量或者静态变量的数组的定义不能这样，只能int a[3]，因为全局变量和静态变量是在程序加载的时候被加载器分配内存和初始化的，他必须知道分配的内存的大小，所以需要显示给出；而局部变量数组分配内存和初始化是在执行过程中得到的，局部变量数组在栈上分配内存，他在分配内存的时候先定义了int n的大小，那么在分配的时候知道了内存大小，并且局部变量分配内存只需要移动sp就行，也就是sp-n\*sizeof(int)就可以分配内存了，那么要寻找数组的元素只需要sp-n\*sizeof(int)+idx*sizeof(int)就能查找到a[idx]元素的位置。这样就能在运行过程中初始化对应的元素了。

  全局变量和静态变量的定义和初始化必须使用int a[3]={1,2,3}这样的方式，也就是在main函数上定义的全局变量和在main函数内部定义的数组必须这样来定义和初始化，在main函数上面不能使用a[1]=1这样的方式来赋值全局变量，因为这个语句实际上是一个代码**lea 3\*4(%esp), %eax; add 1\*4,%eax; mov 1,(%eax)**,这个代码的是在运行时赋值的，而全局变量和静态变量的初始化是在加载器加载的时候分配内存和初始化的，并不是运行时

  局部变量的内存分配并不是使用malloc来分配内存的，他的内存分配实际上在编译的时候就完成了，只需要修改sp指针就能指定数组的元素位置，所以局部变量的定义和初始化使用int n=3;int a[3]是可以的，因为局部变量数组分配内存只需要修改sp指针，局部变量数组初始化也只是是用mov指令在运行时赋值。编译器在处理a[3]在全局变量和局部变量时不同的，全局变量会时a:  .byte1 .byte 2 .byte 3，这个语句块会在加载的时候被加载器使用分配内存和初始化，而在局部变量里面，int a[3]并不会特意的处理，只是编译器会根据3\*sizeof(int)让sp减少(也就是sp-3*sizeof(int))。而对于int a[3]={1,2,3}的处理时lea -12(%ebp), %eax; movl $1, -12(%ebp); movl $2,-8(%ebp); movl $3 -4(%ebp)

- 变量/子程序调用&递归/循环的底层实现

  变量/子程序调用/循环的底层实现以来编译器以及CPU（机器指令）不同而不同，一种将c语言编译成汇编语言的底层实现可以如下

  ```c
  //C源代码
  
  char a=1;
  short b=2;
  struct T{
  	char a,b,c;
  };
  struct T st0={1,2,3};
  char la[]={1,2,3} ;
  struct T ls[]={
  	[0]{1,2,3},
  	[1]{4,5,6}
  };
  char * lc = "abc" ;
  
  
  void func(short n){
  	char a[n];
  	for(char i=0;i<n;i++){
  		a[i]=i+1;
  	}
  }
  
  int main(){
  	char lcva=1;
  	short lcvb=1;
  	struct T lcvst={1,2,3} ;
  	char lcvc[]={1,2,3} ;
  	struct T ls[]={
  		[0]{1,2,3},
  		[1]{4,5,6}
  	};
  	char * lcvchar = "abcd" ;
  
  	lcva++
  	lcvst.b ++
  	lcvc[1] ++
  	lcvlst[1].b ++
  	lcvchar[1] ++
  
  	func(3) ;
  }
  ```

  ```
  //8086 intel汇编指令
  assume cs:codeseg, ss:stackseg, ds:dataseg
  
  
  ; 数据段，保存常量，全局变量，静态变量，malloc动态内存分配空间
  ; 常量池段（常量），数据段（全局变量和字符串数组），栈段，堆段都是数据段/堆栈段，在编译的时候需要编译器指定
  ; 内存变量由编译器设置，并由Linux内存管理模块管理。
  ; 汇编语言的加载器需要手动分配栈段的内存
  ; 在操作系统运行的程序加载器由操作系统分配内存的单位自动分配栈段的内存位数据区的高地址空间
  ; 也就是在高级语言的汇编代码中不用显示分配栈段的内存，同样的道理，数据段（.data段/常量池段）和堆段在操作系统中都是
  ; 	自动分配的，不用显式分配，但是在汇编代码中需要显示分配，因为汇编代码的加载器不会自动分配内存
  ;常量池段/.data段，保存常量，全局变量，printf中的和代码中定义的字符串数组，常量
  dataseg segment
  					;常量池
  ca	dw	1			;静态变量或者常量 const short ca=1/ static short ca=1,由编译器约束
  lcc	db	'abc\0'			;全局字符串变量的内容
  lcvchar	db	'abcd\0'		;局部字符串变量内容	
  
  					
  					;全局变量
  a	db	1,0			;全局基本类型变量 char a=1, 0是对齐使用的
  b	dw	2			;全局基本类型变量 short b=2
  st0	db	1,2,3			;全局结构体类型变量 struct T st0 = {1,2,3}, 其中struct T{char a,b,c} ;
  la	db	1,2,3			;全局基本类型数组变量 char la[] = {1,2,3}
  ls	db	1,2,3
  	db	4,5,6			;全局结构体数组变量 struct T ls[] = {
  					;			[0]{
  					;				.a=1,.b=2,.c=3
  					;			},
  					;			[1]{
  					;				.a=4,.b=5,.c=6
  					;			}
  					;		   }	
  lc	dw	0,0			;全局字符串变量 char* lc = "abc"
  
  heap	db 100 dup(0)
  dataseg ends
  
  
  
  ;栈段，保存局部变量和传递参数，局部变量指针
  stackseg segment
  	db 100 dup(0)
  stackseg ends
  
  
  
  
  ; 代码段
  codeseg segment
  
  func:
  	push bp				; bp指向局部变量的栈顶，这里保存调用子程序的父程序的局部变量的栈顶
  	mov bp, sp			; bp+2+2指向的是子程序传递的参数
  					; 在子程序结束ret前要释放局部变量, add sp,n （n是局部变量申请的内存字节数）
  					; 之后是pop bp恢复父程序的局部变量栈顶
  					; 之后是ret返回父程序
  					; 在父程序中需要 add sp, m (m是分配的参数的内存数），来释放参数内存
  	mov ax, ss:[bp+4]			; bp+4 越过了 旧bp/sp，得到的是参数的地址
  	add ax, 1			; ax是char a[3]分配内存大小n，加1是分配内存给char i和其他局部变量
  	sub sp, ax			; char a[3]; char i; 分配内存
  	
  
  					; 循环结构底层实现
  					; for(i=0;i<n;i++){
  					; 	a[i] = i+1;
  					; }
  	mov byte ptr ss:-4[bp], 0		; i=0
  	mov al, byte ptr ss:-4[bp]
  	mov cl, ss:[bp+4]
  func_1C:
  	cmp al, cl
  	jb func_1			; if ax<bx, 循环体执行，否则跳出循环结构
  					; 跳出循环结构的后续代码
  					; 结束子程序，也就是子程序} 的内容，释放局部变量并且ret
  	mov sp, bp			; 释放局部变量，bp指向局部变量栈顶
  	pop bp
  	ret
  
  func_1:
  	mov dl, al
  	add dl, 1			; i+1
  	
  	lea bx, ss:-3[bp]		; a[]基地址
  	mov di, ax			; a[] 偏移idx
  	mov ss:[bx+di], dl		; a[i] = i+1
  
  	add ax, 1			; i++
  	jmp func_1C
  
  main:
  
  	;设置栈段的地址
  	;在Linux操作系统中这个操作不需要
  	;加载器会自动分配内存并指定ss:esp
  	mov ax,stackseg
  	mov ss, ax
  	mov sp, 100		
  
  	;设置数据段地址，这个过程在Linux加载器中同样被隐式初始化
  	mov ax, dataseg
  	mov ds, ax        
  
  	;设置全局字符串变量的指针，这个过程在Linux上由加载器完成，不需要显示设置
  	;在8086汇编lea把lcc偏移地址放到bx，可以用mov bx,offset lcc代替得到同样结果
  	;x86CPU汇编lea会加载虚拟地址32位
  	lea bx, ds:lcc
  	mov ds:lc, bx
  
  	
  	;main函数实际代码
  	;局部基本类型变量
  	;char lcva=1						1b
  	;short lcvb=1						2b
  	;struct T lcvst={1,2,3}					4b
  	;char lcvc[]={1,2,3}					3b
  	;struct T lcvlst[] = {[0]{1,2,3},[1]{4,5,6}}		6b
  	;char *lcvchar = "abcd"					2b
  	;局部变量在栈上分配内存和初始化
  	mov bp, sp						;bp指向栈顶，栈顶的再上面存放的是函数返回地址cs:ip
  	sub sp, 18						;sp指向栈底，也就是再栈上分配空间
  								; 局部基本类型变量
  	mov byte ptr ss:-1[bp],1				; lcva=1
  	mov word ptr ss:-3[bp],1				; lcvb = 1
  								; 局部结构体变量
  								; struct T lcvst = {1,2,3}
  	mov byte ptr ss:-7[bp],1				; lcvst.a=1
  	mov byte ptr ss:-6[bp],2				; lcvst.b=2
  	mov byte ptr ss:-5[bp],3				; lcvst.c=3
  								; 局部基本类型数组
  								; char lcvc[]= {1,2,3}
  	mov byte ptr ss:-10[bp],1				; lcvc[0] = 1
  	mov byte ptr ss:-9[bp],2				; lcvc[1]=2
  	mov byte ptr ss:-8[bp],3				; lcvc[3]=3
  								; 局部结构体数组
  								; struct T lcvlst[] = {[0]{1,2,3},[1]{4,5,6}}
  	mov byte ptr ss:-16[bp],1				; lcvlst[0].a=1
  	mov byte ptr ss:-15[bp],2				; lcvlst[0].b=2
  	mov byte ptr ss:-14[bp],3				; lcvlst[0].c=3
  	mov byte ptr ss:-13[bp],4				; lcvlst[1].a=4
  	mov byte ptr ss:-12[bp],5				; lcvlst[1].b=5
  	mov byte ptr ss:-11[bp],6				; lcvlst[1].c=6
  								; 局部字符串指针
  								; char * lcvchar="abcd"
  	lea bx, ds:lcvchar
  	mov ss:-18[bp], bx					; -10[bp]保存常量池中"abcd"字符串地址
  
  	;局部变量的使用
  	; lcva++
  	; lcvst.b ++
  	; lcvc[1] ++
  	; lcvlst[1].b ++
  	; lcvchar[1] ++
  	mov al, ss:-1[bp]
  	add al, 1
  	mov ss:-1[bp], al					; lcva++
  
  	lea bx, ss:-7[bp]
  	mov al, ss:1[bx]
  	add al, 1
  	mov ss:1[bx], al						; lcvst.b ++
  
  	lea bx, ss:-10[bp]
  	mov al, ss:1[bx]					; 1=1*sizeof(char)
  	add al, 1
  	mov ss:1[bx], al					; lcvc[1]++
  
  	lea bx, ss:-16[bp]
  	mov al, ss:4[bx]					
  	add al, 1
  	mov ss:4[bx], al					; lcvlst[1].b ++ 
  	
  	mov bx, ss:-18[bp]
  	mov al, ds:1[bx]					; 1=1*sizeof(char)
  	add al, 1
  	mov ds:1[bx], al					; lcvchar[1] ++ 
  
  	
  
  	;子程序调用,用栈传递参数
  	mov ax, 3
  	push ax
  	call func
  	add sp,2
  
  	mov ax,4c00H
  	int 21H
  codeseg ends
  
  end main
  ```

  - x86_32 intel汇编

    [(105条消息) MASM 32位汇编 32与16汇编区别_不会写代码的丝丽的博客-CSDN博客_32位汇编](https://blog.csdn.net/qfanmingyiq/article/details/120824722)

    [(105条消息) x86汇编入门_kikajack的博客-CSDN博客](https://blog.csdn.net/kikajack/article/details/110247241)

    [(105条消息) x86-64 intel64 AMD64 IA-32e x64汇编语言_wufeng_asia的博客-CSDN博客](https://blog.csdn.net/icandoit_2014/article/details/87385583)

    [(105条消息) x86_64汇编之五：System V AMD64调用约定下的函数调用_ponnylv的博客-CSDN博客_amd64汇编](https://blog.csdn.net/qq_29328443/article/details/107235138)

    [(105条消息) x86_64汇编之四：函数调用、调用约定_ponnylv的博客-CSDN博客_汇编函数调用](https://blog.csdn.net/qq_29328443/article/details/107232025)

    [(105条消息) x86_64汇编之一：AT&T汇编语法_ponnylv的博客-CSDN博客_x86汇编at&t](https://blog.csdn.net/qq_29328443/article/details/107242121)

    调用约定，子程序设计的时候参数传递和返回参数是使用寄存器还是使用栈来操作，这些不同诞生了不同的子程序调用约定

    c语言内存结构，代码段，data数据段（只读数据&常量&字面值&字符串，被初始化了的全局变量&静态变量，可读写的数据），bss数据段（未被初始化的全局变量和局部变量），堆段（动态内存分配区域，malloc），栈段（局部变量和参数）

    ![在这里插入图片描述](https://img-blog.csdnimg.cn/20200710084539928.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzI5MzI4NDQz,size_16,color_FFFFFF,t_70)

    子程序的调用设计规则，和上面8086所设计的规则一样

    [(105条消息) x86的32位汇编快速入门_luckyone906的博客-CSDN博客_32位汇编](https://blog.csdn.net/u011555996/article/details/80265537)


**后端优化方向**

![后端优化方向](实验\操作系统实验\实验5 信号量的实现和应用\后端优化方向.PNG)

**没有信号量进程无法协作的原因**

- 缓冲区满，生产者进程继续运行覆盖缓冲区
- 缓冲区空，消费者进程继续运行读取错误数据
- 消费这进程同时竞争文件出错 

**信号量的实现**

````c
//信号量街头提sem.h

#ifndef _SEM_H
#define _SEM_H

#include <linux/sched.h>

struct sem_t{
	char * name ;
	unsigned int value;
	struct task_t* queue ;
} ;

#endif



//信号量的实现sem.c

#include <linux/sem.h>
#include <linux/sched.h>
#include <unistd.h>
#include <asm/segment.h>
#include <linux/tty.h>
#include <linux/kernel.h>
#include <linux/fdreg.h>
#include <asm/system.h>
#include <asm/io.h>


struct sem_t Buffer[20] ;
int cnt=0;

sem_t* sys_sem_open(const char * name, unsigned int value){
	struct sem_t* tmp ;
	cli() ;
	
	Buffer[cnt].value= value ;
	tmp = Buffer[cnt] ;
	cnt ++ ;
	
	sti() ;
	
	return tmp ;
}

void sys_sem_wait(sem_t* sem){
	cli() ;
	while( sem.value<=0 )
		sleep_on(sem.queue) ;
	sem.value-- ;
	sti() ;
}

void sys_sem_post(sem_t* sem){
	cli() ;
	sem.value++ ;
	wake_up(sem.queue) ;
	sti() ;
}

void sys_sem_unlink(const char * name){
	
}



//测试函数test.c


#define __LIBRARY__
#include <unistd.h>
#include <linux/sem.h>
#include <stdio.h>
#include <sys/types.h>
#include <sys/stat.h>
#include <fcntl.h>
#include <linux/sched.h>

_syscall2(sem_t *,sem_open,const char *,name,unsigned int,value)
_syscall1(int, sem_wait, sem_t *, sem)
_syscall1(int, sem_post, sem_t *, sem)
_syscall1(int, sem_unlink, const char *, name)

const char *FileName="/usr/root/buffer";
const int consumers=5;
const int items = 20 ;
const int bufferSize=5 ;

unsigned int used ;

unsigned int i1,i2 ;

sem_t *mutex, *full, *empty ;
int fi, fo;

int main(int argc, char *argv[]){
	int pid;

	fi = open(FileName, O_CREAT| O_TRUNC| O_WRONLY, 0222);
	fo = open(FileName, O_TRUNC| O_RDONLY, 0444);       
	
	printf("aaaaaaa\n") ;
	
	mutex = sem_open("Mutex", 1) ;
	printf("======\n") ;
	full = sem_open("Full", 0) ;
	printf("======1\n") ;
	empty = sem_open("Empty", bufferSize) ;
	printf("======2\n") ;
	
	if( pid = fork() ){
		for(i1=0;i1<items;i1++){
			sem_wait(empty) ;
			sem_wait(mutex) ;
			
			if( !(i1%bufferSize) )
				lseek(fi,0,0) ;
				
			write(fi, (char*)&i1, sizeof(i1) ) ;

			sem_post(full) ;
			sem_post(mutex) ;
		}
	}else{
		for(i2=0;i2<consumers;i2++){
			if( !(pid=fork() ) ) {
				pid = getpid() ;
				while(1){
					sem_wait(full) ;
					sem_wait(mutex) ;
					if(!read(fo, (char*)&used, sizeof(used)) ){
						lseek(fo,0,0) ;
						read(fo, (char*)&used, sizeof(used)) ;
					}
					printf("%d: %d\n", pid, used);
        				fflush(stdout);
					
					sem_post(empty) ;
					sem_post(mutex) ;
					
					if(used== items)
						goto OK;
						
					
				}
			}
		}
	}
OK:
	close(fi);
	close(fo) ;
	return 0;
}
````

**使用信号量实现阻塞队列**

我想用信号量实现阻塞队列，代码如下，但是这个是错误的，因为在没有实现共享内存下使用malloc分配的堆内存在fork的时候会重新分配内存给子进程，这样父进程和子进程操作的队列并不是同一个队列。在这个过程中我怀疑过不是同一个队列，但是我用&符号来取地址发现地址相同，我怀疑&号取的不是物理地址而是逻辑地址，查阅材料可知&取得的就是逻辑地址，这个逻辑地址和数据段结合组成虚拟地址，虚拟地址通过MMU映射得到实际的物理地址。

```c
#define __LIBRARY__
#include <unistd.h>
#include <linux/sem.h>
#include <stdio.h>
#include <sys/types.h>
#include <sys/stat.h>
#include <fcntl.h>
#include <linux/sched.h>

_syscall2(sem_t *,sem_open,const char *,name,unsigned int,value)
_syscall1(int,sem_wait,sem_t *,sem)
_syscall1(int,sem_post,sem_t *,sem)
_syscall1(int,sem_unlink,const char *,name)


#define queLength 5

typedef struct Queue{
	int que[queLength] ;
	int start, end ;
	
	sem_t * mutex, *full, *empty ;
} Queue_t;

int push(struct Queue* que, int value){
	int start, end;
	
	sem_wait(que->empty) ;
	sem_wait(que->mutex) ;
	
	
	start = que->start ;
	end = que->end ;

	que->que[end] = value ;
	/*printf("push: start %d, end %d: %d\n", start, end, que->que[end]) ; */
	printf("push: %p %d %d %d %d %p\n", &que->que[0], que->que[1], que->que[2], que->que[3], que->que[4] ,que) ;
	que->end = (que->end+1)%queLength ;
	
	sem_post(que->full) ;
	sem_post(que->mutex) ;
	return 0;
}

int pop(struct Queue* que){
	int start, end, res;

	sem_wait(que->full) ;
	sem_wait(que->mutex) ;

	
	start = que->start ;
	end = que->end;
	
	res = que->que[start] ;
	printf("pop: %p %d %d %d %d %p\n", &que->que[0], que->que[1], que->que[2], que->que[3], que->que[4] ,que) ;
	/*printf("pop: start %d, end %d: %d\n", start, end, que->que[start]) ;*/
	que->start = (que->start+1)%queLength ;
	sem_post(que->empty) ;
	sem_post(que->mutex) ;
	return res;
	
}


const char *FileName="/usr/root/buffer";
const int consumers=5;
const int items = 20 ;
const int bufferSize=queLength ;

int used ;

unsigned int i1,i2 ;

struct Queue* que ;

int main(){
	int pid ;
	que= (Queue_t*)malloc(sizeof(Queue_t)) ;
	
	que->start = 0;
	que->end=0;
	que->mutex=sem_open("Mutex",1) ;
	que->empty=sem_open("Empty",bufferSize) ;
	que->full =sem_open("Full", 0) ;



	if( pid = fork() ){
		for(i1=0;i1<items;i1++){
			push(que, i1) ;
		}
	}else{
		for(i2=0;i2<consumers;i2++){
			if( !(pid=fork() ) ) {
				pid = getpid() ;
				while(1){

					used = pop(que) ;
					
					printf("%d: %d\n", pid, used);
        				fflush(stdout);
				}
			}
		}
	}
	return 0;
}

```

![Screenshot 2022-10-12 180431](实验\操作系统实验\实验5 信号量的实现和应用\Screenshot 2022-10-12 180431.png)

**&取得的是逻辑地址而不是物理地址**

https://www.cnblogs.com/fengxing999/p/10209835.html

要想获得实际的物理地址只有操作系统才能获得，需要写一个系统调用来获取实际的物理地址。获取GDTR和LDTR，LDTR32位是一个段选择子，GDTR是GDT表的物理地址，GDTR+LDTR20位*16得到进程LDT表段描述符，从其中取得LDT表的基地址，从ds段选择符获取段选择子，从LDT表中基地址+ds段选择子20位\*8得到变量所处数据段段选择符，从段选择符获取变量所处数据段基地址，基地址+逻辑地址得到实际物理地址。

### 实验6-地址映射和共享内存实现

这个章节的实验就是我在第五实验想到的基于共享内存和信号量实现阻塞队列和生产者消费者模型的方法的解决。这个章节重点是实现共享内存

**CPU原语**

[CPU 原语，汇编语言，机器语言 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/380524095)

[cpu 硬件同步原语(compare and swap) - langke93 - 博客园 (cnblogs.com)](https://www.cnblogs.com/langke93/archive/2011/11/15/2249812.html)

CPU原语就是需要连续完成的一段程序，CPU原语的实现通过关中断实现。和数据库事务的差别在于事务是一段连续完成的程序，如果不能连续完成可以回滚，通过回滚相关文件实现回滚，而CPU原语时保证能够连续完成的一段程序，没有回滚。

CPU原语通过cli sti关中断实现或者本身就是一个原子指令，而数据库事务通过回滚操作实现

CPU硬件同步原语CAS，在Intel处理器上有一条指令cmpxchg来执行CAS操作

**JVM的CAS相关**

[(107条消息) cas cpu 硬件同步原语(compare and swap)_not_in_mountain的博客-CSDN博客](https://blog.csdn.net/not_in_mountain/article/details/78070447)

[(107条消息) JVM之CAS(Compare and swap缩写)_墨xiao渊的博客-CSDN博客_cas jvm](https://blog.csdn.net/qq_28772075/article/details/119282482)

[(107条消息) cas cpu 硬件同步原语(compare and swap)_zdy0_2004的博客-CSDN博客](https://blog.csdn.net/zdy0_2004/article/details/40875761)

[(107条消息) synchronized的CPU原语原理解析_草根玉堂的博客-CSDN博客_cpu原语](https://blog.csdn.net/byt420/article/details/105988133)

**POSIX标准：操作系统功能和系统调用相关的定义**

[POSIX标准理解 - 1130136248 - 博客园 (cnblogs.com)](https://www.cnblogs.com/1130136248wlxk/articles/5308863.html)

POSIX标准定义了操作系统的功能和系统调用相关的内容。

**Linux内核常见的系统调用**

[Linux系统调用实例和功能速查 (baidu.com)](https://baijiahao.baidu.com/s?id=1604601045858159778&wfr=spider&for=pc)

[Linux文档](https://cn.bing.com/search?q=man+pages&aqs=edge..69i57&FORM=ANCMS9&PC=WSEDDB)

[linux系统调用列表 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/344311940)

Linux系统调用和功能函数并不完全遵循POSIX标准，比如共享内存相关的系统调用POSIX标准和Linux实现的标准是不一样的。

**一些疑惑的解答**

[(107条消息) 操作系统实验一到实验九合集(哈工大李治军)_Casten-Wang的博客-CSDN博客_哈工大操作系统实验](https://blog.csdn.net/leoabcd12/article/details/122268321)

上述链接的实验7部分给出了ds:[eax]的逻辑地址到物理地址映射的全过程，其中的堆GDT表、段描述符各个位的功能、特权级、页目录表、页表等描述很详细。有关逻辑地址映射到物理地址的方面非常详细

虚拟地址=线性地址=段基址+逻辑地址

C语言程序内存段划分：代码段（.text)，已初始化的数据段（.data)，未初始化的数据段(.bss)，堆段(brk指针指向，brk保存在PCB中，他是堆段的逻辑地址，brk+数据段基地址得到堆段基地址)，栈段（esp寄存器指向）

**使用共享内存的线程必须通过共享内存变量的key来获得变量的实际物理地址**

下面的代码使用共享内存的方式是错误的

```c
#define __LIBRARY__
#include <unistd.h>
#include <linux/sem.h>
#include <stdio.h>
#include <sys/types.h>
#include <sys/stat.h>
#include <fcntl.h>
#include <linux/sched.h>
#include <linux/shm.h>

_syscall2(sem_t *,sem_open,const char *,name,unsigned int,value)
_syscall1(int,sem_wait,sem_t *,sem)
_syscall1(int,sem_post,sem_t *,sem)
_syscall1(int,sem_unlink,const char *,name)


_syscall2(int,shmget,unsigned int,key,size_t,size)
_syscall1(void *,shmat,int,shmid)

int * tmp;
int shmid ;

int main(){

	shmid = shmget(1234, sizeof(int) );

	if(shmid == -1){
		return -1;
	}

	tmp = (int *) shmat(shmid);
	(*tmp) = 1;

	if( fork() ){
		while(1){
			printf("f: %d\n", *tmp) ;
			sleep(1) ;
		}

	}else{
		while(1){
			(*tmp) = 2;
			printf("s: %d\n", *tmp) ;
			sleep(1) ;
		}
	}
	return 0;
}



```

上面代码得到的结果截图是

![Screenshot 2022-10-13 223913](D:\JavaBackend\实验\操作系统实验\实验5 信号量的实现和应用\Screenshot 2022-10-13 223913.png)

从上面我们可以看到f父进程和s子进程实际上使用的是两个变量，也就是tmp在父进程和子进程中物理地址是不同的。实际上上面的问题出在我们在fork之前申请了共享内存，设置了全局变量int *tmp的内存分配为共享内存，设置了(\*tmp)这个堆内存虚拟地址的实际物理地址是一个共享内存，也即是ds:(\*tmp)这个虚拟地址所映射的页表项为page|7，其中7代表设置申请的实际物理页page到虚拟地址的映射为可写。在这个过程中我们设置了一个共享内存变量（\*tmp)，实现他的方式实际上是设置虚拟地址ds:(\*tmp)所映射到的物理地址page的属性是（U/S, R/W, P)=(1,1,1)=7，也就是可写。但是在我们使用fork系统调用的时候，fork会赋值父进程的页表到子进程并且设置父进程和子进程的页表为只读，也就是(U/S,R/W,P)=(0,0,1)=1，那么我们的(\*tmp)这个变量分配的内存就失去了共享内存的效果，这个时候已经没有共享内存了，所以在子进程中我们获得（\*tmp)变量实际上在(\*tmp)=2写(\*tmp)内存的时候会进行write_verify写检查，发现ds:(\*tmp)所对应的虚拟地址的页表项的属性已经不是7了，而是1，所以他会重新分配内存进行写时复制，这样我们在父进程和子进程中的逻辑变量(\*tmp)在父进程和子进程中指向的不是同一块内存了。要实现共享内存，必须使用key关键字来标记，也就是在每个进程中我们都需要使用key关键字来获取共享内存的变量，下面的程序才是合法的。

```c
#define __LIBRARY__
#include <unistd.h>
#include <linux/sem.h>
#include <stdio.h>
#include <sys/types.h>
#include <sys/stat.h>
#include <fcntl.h>
#include <linux/sched.h>
#include <linux/shm.h>

_syscall2(sem_t *,sem_open,const char *,name,unsigned int,value)
_syscall1(int,sem_wait,sem_t *,sem)
_syscall1(int,sem_post,sem_t *,sem)
_syscall1(int,sem_unlink,const char *,name)


_syscall2(int,shmget,unsigned int,key,size_t,size)
_syscall1(void *,shmat,int,shmid)

int * tmp;
int shmid ;

int main(){

	if( fork() ){
	
		shmid = shmget(1234, sizeof(int) );
		if(shmid == -1){
			return -1;
		}

		tmp = (int *) shmat(shmid);
		(*tmp) = 1;
		
		
		while(1){
			printf("f: %d\n", *tmp) ;
			sleep(1);
		}

	}else{
	
		shmid = shmget(1234, sizeof(int) );

		if(shmid == -1){
			return -1;
		}

		tmp = (int *) shmat(shmid);
		(*tmp) = 2;
		
		while(1){
			printf("s: %d\n", *tmp) ;
			sleep(1) ;
		}
	}
	return 0;
}



```

mov [eax], 2写内存的时候会先进行写验证write_verify，就像除0发生除0中断一样。是一种软中断

上面的程序可以看到在每个进程中我们都必须通过共享内存关键字key=1234来实际获得共享内存的物理地址。上面程序的结果如下图

![Capture](实验\操作系统实验\实验5 信号量的实现和应用\Capture.PNG)

从上面我们可以看到共享内存对了。

共享内存变量要在每个进程中通过key来获得实际物理地址

**使用共享内存和信号量实现阻塞队列，进而使用阻塞队列实现生产者消费者进程**

```c
#define __LIBRARY__
#include <unistd.h>
#include <linux/sem.h>
#include <stdio.h>
#include <sys/types.h>
#include <sys/stat.h>
#include <fcntl.h>
#include <linux/sched.h>
#include <linux/shm.h>

_syscall2(sem_t *,sem_open,const char *,name,unsigned int,value)
_syscall1(void,sem_wait,sem_t *,sem)
_syscall1(void,sem_post,sem_t *,sem)
_syscall1(void,sem_unlink,const char *,name)


_syscall2(int,shmget,unsigned int,key,size_t,size)
_syscall1(void *,shmat,int,shmid)


#define queLength 5

typedef struct Queue{
	int que[queLength] ;
	int start, end ;
	
	sem_t * mutex, *full, *empty ;
} Queue_t;

const char *FileName="/usr/root/buffer";
const int consumers=5;
const int items = 20 ;
const int bufferSize=queLength ;

int used ;

unsigned int i1,i2 ;

struct Queue* que ;

int pid, shmid;

int *tmpque;


int push(struct Queue* que, int value){
	int start, end;
	
	/*
	printf("===============push %d\n", value) ;
	fflush(stdout); */
	
	sem_wait(que->empty) ;
	sem_wait(que->mutex) ;
	
	
	start = que->start ;
	end = que->end ;

	que->que[end] = value ;
	/*printf("push: start %d, end %d: %d\n", start, end, que->que[end]) ; */
	
	/*
	printf("push: %d %d\n", que->que[0], que->que[1]) ;
	fflush(stdout); 
	*/
	que->end = (que->end+1)%queLength ;
	
	sem_post(que->full) ;
	sem_post(que->mutex) ;
	return 0;
}

int pop(struct Queue* que){	
	int start, end, res;
	
	/*
	printf("===============pop \n") ;
	fflush(stdout);*/

	sem_wait(que->full) ;
	sem_wait(que->mutex) ;

	
	start = que->start ;
	end = que->end;
	
	res = que->que[start] ;
	
	/*
	printf("pop: %d %d \n", que->que[0], que->que[1]) ;
	fflush(stdout);
	*/
	/*printf("pop: start %d, end %d: %d\n", start, end, que->que[start]) ;*/
	que->start = (que->start+1)%queLength ;
	sem_post(que->empty) ;
	sem_post(que->mutex) ;
	return res;
	
}

int main(){

	
	shmid = shmget(1234, sizeof(Queue_t) );
	if(shmid == -1){
		return -1;
	}
	que = (Queue_t*) shmat(shmid);

	que->start = 0;
	que->end=0;
	que->mutex=sem_open('M',1) ;
	que->empty=sem_open('E',bufferSize) ;
	que->full =sem_open('F', 0) ;


	if( pid = fork() ){
		shmid = shmget(1234, sizeof(Queue_t) );
		if(shmid == -1){
			return -1;
		}
		que = (Queue_t*) shmat(shmid);
		
		for(i1=0;i1<items;i1++){
			push(que, i1+100) ;
		}
	}else{
		for(i2=0;i2<consumers;i2++){
			if( !(pid=fork() ) ) {
			
				shmid = shmget(1234, sizeof(Queue_t) );
				if(shmid == -1){
					return -1;
				}
				que = (Queue_t*) shmat(shmid);
				
				pid = getpid() ;
				while(1){

					used = pop(que) ;
					
					printf("%d: %d\n", pid, used);
					fflush(stdout);
				}
			}
		}
	}
	return 0;
}



```

上面实验的结果

![Screenshot 2022-10-13 234825](实验\操作系统实验\实验5 信号量的实现和应用\Screenshot 2022-10-13 234825.png)

从上面可以看到顺序输出结果

**编写系统调用方法**

- 编写头文件定义相关数据结构体和系统调用函数原型，编写源文件实现系统调用函数，修改Makefile编译文件包含系统调用的编译
- 在include/unistd.h中添加系统调用号__NR\_XXX，在include/linux/sys.h中添加系统调用函数到系统调用表sys_call_table，在kernel/system_call.s中修改系统调用总数nr_system_calls
- 在应用文件或者测试文件中使用\_\_systemcall1,\_\_systemcall2等宏定义系统调用API

### 实验7-终端设备的控制

**IO管理，网络管理都是设备管理**

IO管理涉及到的设备有鼠标和键盘，网络管理涉及到的设备有网卡。鼠标键盘网卡都是设备，都是设备管理的部分。

鼠标键盘都是字符设备，网卡是串行设备，但是都是按照字符来操作的。

**设备驱动程序**

管理设备的驱动程序是内核函数或者中断处理函数，管理键盘的驱动程序是键盘中断（在keyboard.S中实现），管理显示器的驱动程序是一个内核函数con_write(在console.c中实现)

**键盘中断过程/scanf和printf实现**

scanf传入字符串地址和变量地址，调用read系统调用，read系统调用会把进程阻塞到键盘设备结构体的等待队列上。

此时，scanf等待读取键盘输入的进程被阻塞，操作系统调度到其他程序运行。当按下键盘的时候，引发键盘中断，键盘中断获取键盘传递的扫描符在一个寄存器里面，键盘中断会将这个扫描符按照字符映射表映射到ascii字符（字符映射表是按照使用的输入法来设置的，比如英语键盘对应ascii字符映射表，韩语键盘对应韩语字符映射表），然后使用put_char()将这个字符放到键盘读缓冲队列中去（读缓冲队列可以设计成循环队列，清空读缓冲队列可以让head=tail，检验满可以使用head==tail，添加元素tail+1，从缓冲区读元素queue[head]）。然后键盘中断使用行规范函数copy_to_cooked（）将键盘读缓冲区的原始字符通过转义等规范转换成实际需要的字符放到辅助队列（比如backspace删除键会被处理，他会删除前面的字符，而本字符backspace不会放到辅助队列中。）在copy_to_cooked函数里，如果设置了回显到控制台Echo标志，那么copy_to_cooked函数会将字符写入控制台设备结构体的写缓冲队列并且调用写控制台（显示器）函数con_write()。当键盘都缓冲区满的时候，wake_up唤醒等待这个设备队列的阻塞进程（设置进程PCB结构体的state为task_running，也就是运行态放入就绪队列）。

当键盘中断满或者遇到回车符时，键盘中断wake_up唤醒scanf的被阻塞进程，当进程被唤醒之后，使用它tty_read函数（在ttyio.c定义，同时还有tty_write，copy_to_cooked)把键盘缓冲区的数据拷贝到用户程序变量中，如果输入不够，会继续阻塞到键盘设备结构体的阻塞队列上，如果输入够了，就返回read系统调用iret回到调用scanf的用户程序中继续执行。

printf调用write系统调用，write系统调用会使用tty_write函数将用户空间的字符串拷贝到内核的显示设备结构体tty_table[n]的写缓冲队列中，然后调用写控制台函数con_write将显示设备结构体的写缓冲区的字符串拷贝到显示器内存中（显示器内存是一块固定位置和大小的内存，被内核管理，是内核空间），拷贝到显示器内存就能在显示器上看到字符。

写控制台函数con_write的属性保存在控制台设备结构体的termios结构体中，这个结构体规定了一些参数，比如写到控制台（显示器）的速率颜色等等。修改控制台termios的参数是一个系统调用，在tty_ioctn.c中定义，这个系统调用可以修改控制台设备结构体的termios变量的参数，从而控制向控制台输出字符串的参数。

上面的过程涉及4个文件，keyboard.S提供键盘中断，put_char函数，将键盘扫描码转换成ascii码放到键盘设备结构体的读缓冲区中，之后调用copy_to_cooked将读缓冲队列的数据转义之后放到辅助队列，如果设置回显还会调用con_write将读缓冲队列数据写道控制台显示；tty_io.c提供用户程序系统调用read/write时的地层函数和copy_to_cooked，read系统调用调用了tty_read，tty_read将键盘设备结构体的读缓冲队列的数据从内核态拷贝到用户程序空间的变量，write系统调用调用了tty_write函数，tty_write函数将用户空间变量拷贝到控制台设备结构体的写缓冲队列，然后调用con_write将控制台结构体写缓冲队列的数据写到屏幕上；consol.c提供了con_write，他按照控制台结构体的termios参数将控制台设备结构体写缓冲区的数据写到控制台内存中；tty_ioctl.c提供了系统调用修改控制台设备结构体的termios参数，从而控制con_write写控制台结构体写缓冲队列的数据到控制台内存的过程。

下面的图是从《Linux内核剖析》截取的

![Screenshot 2022-10-14 165649](实验\操作系统实验\实验5 信号量的实现和应用\Screenshot 2022-10-14 165649.png)

read系统调用判断设备结构体的读缓冲区为空就阻塞，否则调用tty_read从设备结构体的读缓冲区读取一个字符然后put_fs_byte从内核空间拷贝到用户变量。

**串行设备中断/网络中断过程/socket系统调用**

![Screenshot 2022-10-14 170739](实验\操作系统实验\实验5 信号量的实现和应用\Screenshot 2022-10-14 170739.png)

![Screenshot 2022-10-14 170832](实验\操作系统实验\实验5 信号量的实现和应用\Screenshot 2022-10-14 170832.png)

当网络或电路发生变化，或者接收到字符或者要发送字符，会触发串行中断。串行设备通过端口连接到系统，网卡通过端口连接到系统。当使用socket进程等待网卡数据输入的时候会阻塞socket进程，当网卡端口接收到字符的时候会触发网卡中断，中断调用rs_read函数将端口的字符写入到网卡设备结构体的读缓冲队列，当写读缓冲队列函数遇到输入结束字符的时候会唤醒阻塞在网卡读缓冲队列的进程。被唤醒的进程通过tty_read从网卡读缓冲队列将内核数据拷贝到用户空间，之后从socket读系统调用返回。当进程需要写网卡的时候，会调用socket某系统调用，该系统调用使用tty_write将用户程序数据拷贝到网卡写缓冲队列，然后调用rs_write函数把写缓冲队列的数据发送到网卡设备的内存中，网卡设备自己又将内存中的数据发送出去。

网络中断和设备中断的不同点主要在于从设备中获取字符并转换和写入到设备结构体的读缓冲队列的函数rs_read/put_char，以及将设备写缓冲队列写到设备内存的函数rs_write/con_write等的差异，其他基本一样。

**实验要求**

按下F12，那么向控制台输出的字母和数字都用*代替，再次按下F12，那么显示正常。

实现思路：按下F12引发键盘中断，键盘中断根据F12扫描码从key_table中找到处理F12扫描码的程序，然后跳转到那个程序执行，在F12处理程序中添加一个全局变量，按下一次F12设置F12STATE=1，在字符回显到控制台的时候修改con_write函数，这个函数根据F12STATE=1，将从控制台缓冲区读取的字符转换为*后写到显存。这个实现只能实现控制台变换，因为他只修改了con_write函数。对于write系统调用写入到控制台有用，对于写入文件没有用，因为文件设备写函数是file_write函数，要实现在文件中的过程需要修改file_write函数。

**tty_read/tty_write/con_write/rs_write**

- tty_read

  tty_read定义在tty_io.c中，原型int tty_read(unsigned channel, char * buf, int nr)， 其中channel是被读取的设备，是tty_table中的下标；buf是用户空间字符串指针，nr是需要从tty_table[channel]设备的辅助队列读取的字符个数，返回值代表实际读取的字符数目（因为有信号和超时等设置，造成实际读取的数目没有那么多）。tty_read的含义是从tty_table[channel]的辅助队列中读取nr个字符返回给用户空间。

  tty_read在nr--循环while(nr--)，遇到有信号就返回，遇到tty_table[channel]的辅助队列为空就阻塞在辅助队列的阻塞队列上，否则将一个字符(nr--) put_fs_byte从内核空间的辅助队列拷贝到用户空间的字符串数组buf中（b= buff, b++)，直到nr>0或者辅助队列为空。最后返回实际读取的字符个数b-buff

  ```c
  int tty_read(unsigned channel, char * buf, int nr)
  {
  	struct tty_struct * tty;
  	char c, * b=buf;
  	int minimum,time,flag=0;
  	long oldalarm;
  
  	if (channel>2 || nr<0) return -1;
  	tty = &tty_table[channel];
  	oldalarm = current->alarm;
  	time = 10L*tty->termios.c_cc[VTIME];
  	minimum = tty->termios.c_cc[VMIN];
  	if (time && !minimum) {
  		minimum=1;
  		if ((flag=(!oldalarm || time+jiffies<oldalarm)))
  			current->alarm = time+jiffies;
  	}
  	if (minimum>nr)
  		minimum=nr;
  	while (nr>0) {
  		if (flag && (current->signal & ALRMMASK)) {
  			current->signal &= ~ALRMMASK;
  			break;
  		}
  		if (current->signal)
  			break;
  		if (EMPTY(tty->secondary) || (L_CANON(tty) &&
  		!tty->secondary.data && LEFT(tty->secondary)>20)) {
  			sleep_if_empty(&tty->secondary);
  			continue;
  		}
  		do {
  			GETCH(tty->secondary,c);
  			if (c==EOF_CHAR(tty) || c==10)
  				tty->secondary.data--;
  			if (c==EOF_CHAR(tty) && L_CANON(tty))
  				return (b-buf);
  			else {
  				put_fs_byte(c,b++);
  				if (!--nr)
  					break;
  			}
  		} while (nr>0 && !EMPTY(tty->secondary));
  		if (time && !L_CANON(tty)) {
  			if ((flag=(!oldalarm || time+jiffies<oldalarm)))
  				current->alarm = time+jiffies;
  			else
  				current->alarm = oldalarm;
  		}
  		if (L_CANON(tty)) {
  			if (b-buf)
  				break;
  		} else if (b-buf >= minimum)
  			break;
  	}
  	current->alarm = oldalarm;
  	if (current->signal && !(b-buf))
  		return -EINTR;
  	return (b-buf);
  }
  ```

- tty_write

  tty_write原型int tty_write(unsigned channel, char * buf, int nr)， 含义是将用户空间的字符串buf的nr个字符输出到设备数组tty_table[channel]中，并且返回输出的字符个数。

  tty_write在while(nr--)里面，如果遇到信号就break，如果遇到tty_table[channel]的写缓冲队列为满就可中断阻塞，然后while(nr>0 && 写缓冲队列不满)就不断从用户空间buf中拷贝到内核写缓冲队列中（get_fs_byte)，在这个while结束拷贝了所有字符到写缓冲队列或者写缓冲队列为满的时候，掉要昂tty->write函数（对控制台设备是con_write，对键盘设备时rs_write)将写缓冲队列的数据写入到对应的控制终端（rs_write没有实现任何功能，因为键盘不用写入数据，但是rs_write可以用在网卡设备中），接下来的schedul是为了保证其他进程使用写缓冲队列响应时间而设计的。

  ```c
  int tty_write(unsigned channel, char * buf, int nr)
  {
  	static int cr_flag=0;
  	struct tty_struct * tty;
  	char c, *b=buf;
  
  	if (channel>2 || nr<0) return -1;
  	tty = channel + tty_table;
  	while (nr>0) {
  		sleep_if_full(&tty->write_q);
  		if (current->signal)
  			break;
  		while (nr>0 && !FULL(tty->write_q)) {
  			c=get_fs_byte(b);
  			if (O_POST(tty)) {
  				if (c=='\r' && O_CRNL(tty))
  					c='\n';
  				else if (c=='\n' && O_NLRET(tty))
  					c='\r';
  				if (c=='\n' && !cr_flag && O_NLCR(tty)) {
  					cr_flag = 1;
  					PUTCH(13,tty->write_q);
  					continue;
  				}
  				if (O_LCUC(tty))
  					c=toupper(c);
  			}
  			b++; nr--;
  			cr_flag = 0;
  			PUTCH(c,tty->write_q);
  		}
  		tty->write(tty);
  		if (nr>0)
  			schedule();
  	}
  	return (b-buf);
  
  ```

- con_write

  con_write 原型 void con_write(struct tty_struct *tty)，他的含义是将tty写缓冲队列的数据全部写入到控制台中。他在控制台键盘中断的tty_write被调用用来写到控制台。

  ```c
  void con_write(struct tty_struct * tty)
  {
  	int nr;
  	char c;
  
  	nr = CHARS(tty->write_q);
  	while (nr--) {
  		GETCH(tty->write_q,c);
  		switch(state) {
  			case 0:
  				if (c>31 && c<127) {
  					if (x>=video_num_columns) {
  						x -= video_num_columns;
  						pos -= video_size_row;
  						lf();
  					}
  					__asm__("movb attr,%%ah\n\t"
  						"movw %%ax,%1\n\t"
  						::"a" (c),"m" (*(short *)pos)
  						);
  					pos += 2;
  					x++;
  				} else if (c==27)
  					state=1;
  				else if (c==10 || c==11 || c==12)
  					lf();
  				else if (c==13)
  					cr();
  				else if (c==ERASE_CHAR(tty))
  					del();
  				else if (c==8) {
  					if (x) {
  						x--;
  						pos -= 2;
  					}
  				} else if (c==9) {
  					c=8-(x&7);
  					x += c;
  					pos += c<<1;
  					if (x>video_num_columns) {
  						x -= video_num_columns;
  						pos -= video_size_row;
  						lf();
  					}
  					c=9;
  				} else if (c==7)
  					sysbeep();
  				break;
  			case 1:
  				state=0;
  				if (c=='[')
  					state=2;
  				else if (c=='E')
  					gotoxy(0,y+1);
  				else if (c=='M')
  					ri();
  				else if (c=='D')
  					lf();
  				else if (c=='Z')
  					respond(tty);
  				else if (x=='7')
  					save_cur();
  				else if (x=='8')
  					restore_cur();
  				break;
  			case 2:
  				for(npar=0;npar<NPAR;npar++)
  					par[npar]=0;
  				npar=0;
  				state=3;
  				if ((ques=(c=='?')))
  					break;
  			case 3:
  				if (c==';' && npar<NPAR-1) {
  					npar++;
  					break;
  				} else if (c>='0' && c<='9') {
  					par[npar]=10*par[npar]+c-'0';
  					break;
  				} else state=4;
  			case 4:
  				state=0;
  				switch(c) {
  					case 'G': case '`':
  						if (par[0]) par[0]--;
  						gotoxy(par[0],y);
  						break;
  					case 'A':
  						if (!par[0]) par[0]++;
  						gotoxy(x,y-par[0]);
  						break;
  					case 'B': case 'e':
  						if (!par[0]) par[0]++;
  						gotoxy(x,y+par[0]);
  						break;
  					case 'C': case 'a':
  						if (!par[0]) par[0]++;
  						gotoxy(x+par[0],y);
  						break;
  					case 'D':
  						if (!par[0]) par[0]++;
  						gotoxy(x-par[0],y);
  						break;
  					case 'E':
  						if (!par[0]) par[0]++;
  						gotoxy(0,y+par[0]);
  						break;
  					case 'F':
  						if (!par[0]) par[0]++;
  						gotoxy(0,y-par[0]);
  						break;
  					case 'd':
  						if (par[0]) par[0]--;
  						gotoxy(x,par[0]);
  						break;
  					case 'H': case 'f':
  						if (par[0]) par[0]--;
  						if (par[1]) par[1]--;
  						gotoxy(par[1],par[0]);
  						break;
  					case 'J':
  						csi_J(par[0]);
  						break;
  					case 'K':
  						csi_K(par[0]);
  						break;
  					case 'L':
  						csi_L(par[0]);
  						break;
  					case 'M':
  						csi_M(par[0]);
  						break;
  					case 'P':
  						csi_P(par[0]);
  						break;
  					case '@':
  						csi_at(par[0]);
  						break;
  					case 'm':
  						csi_m();
  						break;
  					case 'r':
  						if (par[0]) par[0]--;
  						if (!par[1]) par[1] = video_num_lines;
  						if (par[0] < par[1] &&
  						    par[1] <= video_num_lines) {
  							top=par[0];
  							bottom=par[1];
  						}
  						break;
  					case 's':
  						save_cur();
  						break;
  					case 'u':
  						restore_cur();
  						break;
  				}
  		}
  	}
  	set_cursor();
  }
  ```

- rs_write

  ```c
  void rs_write(struct tty_struct * tty)
  {
  	cli();
  	if (!EMPTY(tty->write_q))
  		outb(inb_p(tty->write_q.data+1)|0x02,tty->write_q.data+1);
  	sti();
  }
  ```

### 实验8-虚拟文件系统的实现

**C语言关键字**

https://worktile.com/blog/know-1394/

  	 **关键字的实质是约束编译器编译的行为**

* 数据类型关键字(12个)

  数据类型关键字约束编译器声明变量分配内存数据量（字节数）

  - char, short, int, long, siagned，unsigned
  - float，double
  - enum， struct，union，union

* 控制语句关键字（12个）

  **控制语句关键字约束编译器生成一段代码**

  - 循环语句：for，do，while，break，continue
  - 条件语句：if，else，goto，switch/case/default
  - 返回语句：return（返回参数保存到eax寄存器或者栈上的指针）

- 存储类型关键字（4个）

  - auto: 声明自动变量

  - extern： 声明的变量在其他文件声明

  - register：声明寄存器变量

  - static：

    https://blog.csdn.net/iuices/article/details/115385660

    https://www.cnblogs.com/jacklong-yin/p/9613037.html

    https://blog.csdn.net/mm_hh/article/details/77126878#:~:text=%E8%BF%99%E4%B8%A4%E8%80%85%E5%9C%A8%E5%AD%98%E5%82%A8,%E6%96%87%E4%BB%B6%E4%B8%AD%E4%B8%8D%E8%83%BD%E4%BD%BF%E7%94%A8%E5%AE%83%E3%80%82

    声明静态变量，静态变量放到数据段。C语言内存分为代码段，数据段（已初始化数据区.data和未初始化数据区.bss，前者由加载器初始哈，后者通过代码赋值和初始化，字面值，常量池处在已初始化数据区（包括字面值和字符串），静态变量放到数据段。

    static发展了三层语义：1. 一个存储在数据区但是作用域在定义的函数域中的变量，函数退出之后不会消失的变量，只被初始化一次的变量；2. 一个全局变量只能作用在定义的文件中而不能使用extern被外部文件引用；3.在C++中扩展的，一个只属于一个类的而不属于任何对象的全局变量，Java有同样的语义

    C语言变量类型有：全局变量，静态全局变量，局部变量，静态局部变量。

    - 全局变量在数据区分配内存，如果没有初始化将会初始化为0，如果有初始化会初始化为字面值，全局变量作用域在定义的文件和外部文件（可以使用extern引用全局变量到外部文件），全局变量和静态全局变量区别在于静态全局变量作用在定义的文件，他们都是在数据区分配内存，保存在程序整个生命周期；
    - 静态局部变量只被初始化一次（在main函数中初始化一次，随后定义他的函数中的初始化语句**static int a=1**的初始化操作**mov a, 1**不会再出现再定义的函数位置。静态局部变量再定义的函数退出之后不会消失，在再次进入定义的函数时会继续引用内存中的静态全局变量。静态局部变量和局部变量的区别在于局部变量在栈上分配内存，程序进入时分配内存并初始化(sub sp, xxx)，程序退出时被销毁（add sp, xxx)。

    C++和Java中扩展了static的语义，static变量被认为是类变量，可以通过**类名.静态变量**的方式直接访问。

    C语言静态函数规定了函数只能在本文件中作用，不能使用extern被其他文件访问，可以减少函数耦合。

  其他关键字（4个）

  - const：声明只读变量（只读变量的实现由编译器保证，编译器检查变量发生写行为就会报错编译错误），变量只读，但是变量的指针可以变的。

  - sizeof：计算数据类型长度（sizeof是一个操作符，计算数据类型的长度，由编译器根据数据类型计算长度，如果struct在数据区，那么计算的长度是每个基本类型长度和，如果在栈区，计算长度是基本长度和/4*4，也就是4倍对齐。

  - typdef： 给数据类型别名

  - volatile：

    https://blog.csdn.net/u010134355/article/details/125058164

    https://blog.csdn.net/weixin_38815998/article/details/102883098

    https://blog.csdn.net/weixin_38815998/article/details/102857437

    保证使用变量的时候总是从内存中重新读取变量。volatile作用在于多进程编译器优化方面，非多进程编译器优化不受影响，在非多进程程序中，改变用户程序的指令总是在当前进程中，而这个改变是会反映到使用该变量的指令中的；而对于多进程编译器优化，应为编译器优化的时候总是针对一个进程内部的指令的优化，不能反映时钟中断和调度的效果，造成被优化的变量读取到一个寄存器，然后这个寄存器一直被使用，而实际上在这个过程中可能发生时钟中断子进程修改了共享变量的数值，所以父进程在使用这个共享变量的时候寄存器的值不是实际变量的值，这个时候应该重新读取共享变量到寄存器使用。而volatile的作用就在于这样，他在共享变量被使用的时候总是从变量内存重新读取变量新值。

    volatile变量的实现是，在使用volatile变量的地方先关中断，然后重新读取volatile共享变量的值到寄存器，然后操作完成之后再开中断。比如**volatile a=0; int c=a;**代码的实现是**cli; mov eax, ss:-8[ebp]; mov ss:-4[ebp],eax; sti**

    gcc编译器默认不适用优化，但是工业界为了获得更高效的代码，会开启编译器优化，开启编译器优化就会产生上述的多进程编译器优化共享变量不一致的问题，所以产生了volatile变量来解决这个问题。

    gcc编译器有会员又3个级别，高级别优化会更厉害。

    编译器优化方法：

    - 编译器优化会对未使用的变量根本不会申请内存（比如上int a=0，如果a没有被使用那么main函数就不会分配栈内存给a变量，同时main里面也不是又mov ss:-4[ebp],0这样初始化a变量的代码）
    - 编译器优化会对赋值操作直接使用寄存器上的值而不会重新读取栈上变量的值到寄存器然后赋值（比如栈上**int a=0; int b=a; int c=a;** 编译器优化会让实现变成**mov ss:-12[ebp], 0; mov eax, ss:-12[ebp]; mov ss:-8[ebp], eax; mov ss:-4[ebp], eax; **而不是**mov ss:-12[ebp], 0; mov eax, ss:-12[ebp]; mov ss:-8[ebp], eax; mov eax, ss:-12[ebp]; mov ss:-4[ebp], eax; ** 
    - 编译器优化会对非volatile修饰while(value--)延时操作直接无视掉，根本不会申请value变量内存和做这个循环，把延时操作删除。而延时操作时触发时钟中断进行调度的一种方式，所以在多进程中是不能忽略的。那么设置**volatile int value=1000000**也就是设置value为volatile可以强制产生**cli; mov eax, ss:X[ebp]; sti**的指令，那么也就不会忽略while(value--)延时操作

    **下面的程序时编译器优化导致的效果比较**

    ```c
    //源程序
    #include <stdio.h>
    #include <stdlib.h>
    #include <unistd.h>
    #include <pthread.h>
     
    int main(){
    	int a=1;
    	printf("%d\n",a) ;
    	return 0;
    }
    
    
    //没有编译器优化gcc编译
    //gcc -o test0 test1.c
    	.file	"test1.c"
    	.text
    	.section	.rodata
    .LC0:
    	.string	"%d\n"
    	.text
    	.globl	main
    	.type	main, @function
    main:
    .LFB6:
    	.cfi_startproc
    	endbr64
    	pushq	%rbp
    	.cfi_def_cfa_offset 16
    	.cfi_offset 6, -16
    	movq	%rsp, %rbp
    	.cfi_def_cfa_register 6
    	subq	$16, %rsp
    	movl	$1, -4(%rbp)
    	movl	-4(%rbp), %eax
    	movl	%eax, %esi
    	leaq	.LC0(%rip), %rdi
    	movl	$0, %eax
    	call	printf@PLT
    	movl	$0, %eax
    	leave
    	.cfi_def_cfa 7, 8
    	ret
    	.cfi_endproc
    .LFE6:
    	.size	main, .-main
    	.ident	"GCC: (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0"
    	.section	.note.GNU-stack,"",@progbits
    	.section	.note.gnu.property,"a"
    	.align 8
    	.long	 1f - 0f
    	.long	 4f - 1f
    	.long	 5
    0:
    	.string	 "GNU"
    1:
    	.align 8
    	.long	 0xc0000002
    	.long	 3f - 2f
    2:
    	.long	 0x3
    3:
    	.align 8
    4:
    
    
    
    //编译器优化1级
    //gcc -O1 -o test1 test1.c
    	.file	"test1.c"
    	.text
    	.section	.rodata.str1.1,"aMS",@progbits,1
    .LC0:
    	.string	"%d\n"
    	.text
    	.globl	main
    	.type	main, @function
    main:
    .LFB51:
    	.cfi_startproc
    	endbr64
    	subq	$8, %rsp
    	.cfi_def_cfa_offset 16
    	movl	$1, %edx
    	leaq	.LC0(%rip), %rsi
    	movl	$1, %edi
    	movl	$0, %eax
    	call	__printf_chk@PLT
    	movl	$0, %eax
    	addq	$8, %rsp
    	.cfi_def_cfa_offset 8
    	ret
    	.cfi_endproc
    .LFE51:
    	.size	main, .-main
    	.ident	"GCC: (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0"
    	.section	.note.GNU-stack,"",@progbits
    	.section	.note.gnu.property,"a"
    	.align 8
    	.long	 1f - 0f
    	.long	 4f - 1f
    	.long	 5
    0:
    	.string	 "GNU"
    1:
    	.align 8
    	.long	 0xc0000002
    	.long	 3f - 2f
    2:
    	.long	 0x3
    3:
    	.align 8
    4:
    
    
    
    //编译器优化2级
    //gcc -O2 -o test2 test1.c
    	.file	"test1.c"
    	.text
    	.section	.rodata.str1.1,"aMS",@progbits,1
    .LC0:
    	.string	"%d\n"
    	.section	.text.startup,"ax",@progbits
    	.p2align 4
    	.globl	main
    	.type	main, @function
    main:
    .LFB51:
    	.cfi_startproc
    	endbr64
    	subq	$8, %rsp
    	.cfi_def_cfa_offset 16
    	movl	$1, %edx
    	movl	$1, %edi
    	xorl	%eax, %eax
    	leaq	.LC0(%rip), %rsi
    	call	__printf_chk@PLT
    	xorl	%eax, %eax
    	addq	$8, %rsp
    	.cfi_def_cfa_offset 8
    	ret
    	.cfi_endproc
    .LFE51:
    	.size	main, .-main
    	.ident	"GCC: (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0"
    	.section	.note.GNU-stack,"",@progbits
    	.section	.note.gnu.property,"a"
    	.align 8
    	.long	 1f - 0f
    	.long	 4f - 1f
    	.long	 5
    0:
    	.string	 "GNU"
    1:
    	.align 8
    	.long	 0xc0000002
    	.long	 3f - 2f
    2:
    	.long	 0x3
    3:
    	.align 8
    4:
    
    
    
    //编译器优化3级
    //gcc -O3 -o test3 test1.c
    	.file	"test1.c"
    	.text
    	.section	.rodata.str1.1,"aMS",@progbits,1
    .LC0:
    	.string	"%d\n"
    	.section	.text.startup,"ax",@progbits
    	.p2align 4
    	.globl	main
    	.type	main, @function
    main:
    .LFB51:
    	.cfi_startproc
    	endbr64
    	subq	$8, %rsp
    	.cfi_def_cfa_offset 16
    	movl	$1, %edx
    	movl	$1, %edi
    	xorl	%eax, %eax
    	leaq	.LC0(%rip), %rsi
    	call	__printf_chk@PLT
    	xorl	%eax, %eax
    	addq	$8, %rsp
    	.cfi_def_cfa_offset 8
    	ret
    	.cfi_endproc
    .LFE51:
    	.size	main, .-main
    	.ident	"GCC: (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0"
    	.section	.note.GNU-stack,"",@progbits
    	.section	.note.gnu.property,"a"
    	.align 8
    	.long	 1f - 0f
    	.long	 4f - 1f
    	.long	 5
    0:
    	.string	 "GNU"
    1:
    	.align 8
    	.long	 0xc0000002
    	.long	 3f - 2f
    2:
    	.long	 0x3
    3:
    	.align 8
    4:
    
    ```

    volatile主要应用在多进程编译器优化程序中，并且必须设置volatile变量为共享全局变量，并且必须使用vfork（使用fork的话为了使用共享全局变量必须使用共享内存，而共享内存返回的时一个指针，而堆指针进行volatile设置没有任何效果）。vfork天然为多进程共享数据设计。

    **下面是多进程编译器优化使用volatile和不使用的结果**

    ​		从下面的实验可以看到volatile变量会阻止编译器优化删除while延时函数，同时保证每次使用变量的时候会重新读取内存中的volatile变量值。

    - 非volatile非编译器优化

      ```
      //不使用volatile源程序
      
      #include <stdio.h>
      #include <stdlib.h>
      #include <unistd.h>
      #include <pthread.h>
       
      int a = 1;
       
      void *child_pth_fun(void *arg);
       
      int main(){
       
      	int b, c;
      	int val = 10000000;
      	
      	//创建子线程
      	pthread_t child_pth_id;
      	/*
      	pthread_create使用的vfork来实现子进程。fork系统调用创造子进程过程，先find_empty_process获取空pid和任务id，
      		然后申请一页内存，将父进程的PCB复制到新页中作为子进程的PCB，修改子进程PCB的参数，修改子进程的父进程节点，
      		修改子进程的状态为可运行态TASK_RUNNING，（打开文件表，TSS寄存器结构，信号相关），修改brk堆指针，修改用户程序和内核程序执行时间等，
      		同时对基于栈切换进程的进程切换，会构造栈切换数据结构，将当前寄存器的数据压入子进程PCB页的顶部形成子进程内核栈，
      		也就是构造子进程内核栈在子进程PCB的页顶端；然后申请数据段&堆栈段页目录项（在0地址空间开始），为页表申请内存，
      		将父进程的页表项赋值给新的页表，将新页表地址赋值给页目录项，将子进程的页目录表的地址赋值给CR3寄存器（current指向内存），
      		然后修改父进程和子进程页表为只读，增加mem_map内存映射图中对应页的共享数目；之后调用schedule进行进程调度，
      		schedule首先从任务数组task_table中找到一个就绪态的进程，然后返回任务号，之后使用switch_to执行进程切换，
      		保存PCB，重写tss栈指针（保存intel结构），切换current指针指向切换到的进程，切换ss:esp为切换到的进程的内核栈，然后执行fork的返回，
      		fork返回会恢复寄存器数值，最后使用iret指令恢复进程用户空间程序的cs:eip, ss:esp, eflags，重新回到用户程序执行。
      		
      		vfork的却别在于在复制父进程页表的时候，本来需要修改页表项为只读并且增加mem_map内存映射图的占用数，但是vfork对数据区（数据区分
      		初始化数据区.data和未初始化数据区.bss）的页表项并不设置只读，导致数据区的数据是共享数据，子进程在写共享数据的时候会进行写检查write_verify，
      		发现这个地方为可读，就不会重新分配空间复制这个变量，那么子进程修改的变量和父进程占用的是同一个变量，达到共享内存的全局变量的效果。
      	*/
      	pthread_create(&child_pth_id, NULL, child_pth_fun, NULL);
      	
      		
      	b = a;
      	
      
      	//延时操作
      	//消耗时间片延时
      	/*
      	消耗时间片方法延迟会占用CPU，这个过程主要发生时钟中断，在while消耗CPU时间的时候，会发生时钟中断，时钟中断发生调度，执行其他程序。
      	发生时钟中断的时候进程的运行状态依然是TASK_RUNNING，当while所处进程被重新调度唤醒，会冲洗运行while循环。
      	*/
      	while(val--) ;
      	//通过阻塞延时
      	/*
      	sleep延时方法会使用设置信号系统调用设置进程的ALARM信号，根据延时时间1s和Linux时间片1个10ms，那么会有1s/10ms=100个时钟中断，也就是ALARM=jiffies+100，
      	设置ALARM信号之后，设置进程状态为阻塞状态，然后调用schedule调度程序进行京城调度。当每次时钟中断发生时，会让进程运行时间counter-1,同时会检查每个进程的信号，如果当前jiffies>=ALARM，
      	就会设置那个进程的状态为TASK_RUNNING,然后时钟中断启动schedule系统调度，从TASK_RUNNING的进程中找到一个执行switch_to进程切换。switch_to保存PCB，重置TSS栈，
      	切换current指针，切换内核栈，然后执行从内核空间返回到用户空间操作。如果是sleep所在的进程，就是返回sleep的用户程序执行。
      
      	消耗CPU延时和阻塞延时的却别在于，CPU延时会占用CPU，这个过程可能发生时钟中断让进程放弃CPU，当时状态是TASK_RUNNING，在就绪队列中；
      	阻塞延时会设置进程为TASK_INTERRUPTIBLE并且立即放弃CPU进行进程调度，同时修改ALARM信号，阻塞延时依靠时钟中断检查是否超过ALARM信号设置的时间，等到超过的时候才会设置进程TASK_RUNNING进入就绪队列
      	*/
      	//sleep(1);
       
      	c = a;
      	printf("In main pthread: a=%d, b=%d, c=%d\n", a, b, c);
      	
       	/*
      	pthread_join调用wait调用。wait系统调用等待子进程完成退出之后菜才能退出。当子进程执行自己的程序到右括号}的时候，会调用exit内核函数来杀死进程。
      		exit会清空任务数组中子进程所在位置设置为null，同时释放子进程占用的内存（清除页目录表，清除页表的mem_map位置-1），释放占用文件等等。
      		修改子进程的运行状态为TASK_END。当发生时钟中断的时候，时钟中断会检查所有进程，如果是TASK_END，就会循环任务队列，将子进程对应的父进程
      		等待的子进程数目-1，如果子进程数据变成0，那么父进程将被设置成TASK_RUNNING，然后调用schedule函数进行进程调度。如果调度到父进程，
      		父进程从pthread_join的wait系统调用返回到用户空间
      	
      		如果不适用wait系统调用，那么在父进程右括号}exit退出之后，exit内核退出函数会扫描所有任务队列，对父进程的子进程，因为父进程退出了，会设置
      		子进程的父进程为0进程。0进程执行的程序时while(1）{pause}，也就是0进程他不断触发调度。
      	*/
      	pthread_join(child_pth_id, NULL);
      	return 0;
       
      }
       
      void *child_pth_fun(void *arg){
       
          //子线程修改共享的全局变量
          	a = 4;		
          	printf("In child pthread: a=%d\n", a);
      }
      
      
      
      
      //不适用volatile源程序编译结果
      	.file	"testUnV.c"
      	.text
      	.globl	a
      	.data
      	.align 4
      	.type	a, @object
      	.size	a, 4
      a:
      	.long	1
      	.section	.rodata
      	.align 8
      .LC0:
      	.string	"In main pthread: a=%d, b=%d, c=%d\n"
      	.text
      	.globl	main
      	.type	main, @function
      main:
      .LFB6:
      	.cfi_startproc
      	endbr64
      	pushq	%rbp
      	.cfi_def_cfa_offset 16
      	.cfi_offset 6, -16
      	movq	%rsp, %rbp
      	.cfi_def_cfa_register 6
      	subq	$32, %rsp
      	movq	%fs:40, %rax
      	movq	%rax, -8(%rbp)
      	xorl	%eax, %eax
      	movl	$10000000, -28(%rbp)
      	leaq	-16(%rbp), %rax
      	movl	$0, %ecx
      	leaq	child_pth_fun(%rip), %rdx
      	movl	$0, %esi
      	movq	%rax, %rdi
      	call	pthread_create@PLT
      	movl	a(%rip), %eax
      	movl	%eax, -24(%rbp)
      	nop
      .L2:
      	movl	-28(%rbp), %eax
      	leal	-1(%rax), %edx
      	movl	%edx, -28(%rbp)
      	testl	%eax, %eax
      	jne	.L2
      	movl	a(%rip), %eax
      	movl	%eax, -20(%rbp)
      	movl	a(%rip), %eax
      	movl	-20(%rbp), %ecx
      	movl	-24(%rbp), %edx
      	movl	%eax, %esi
      	leaq	.LC0(%rip), %rdi
      	movl	$0, %eax
      	call	printf@PLT
      	movq	-16(%rbp), %rax
      	movl	$0, %esi
      	movq	%rax, %rdi
      	call	pthread_join@PLT
      	movl	$0, %eax
      	movq	-8(%rbp), %rsi
      	xorq	%fs:40, %rsi
      	je	.L4
      	call	__stack_chk_fail@PLT
      .L4:
      	leave
      	.cfi_def_cfa 7, 8
      	ret
      	.cfi_endproc
      .LFE6:
      	.size	main, .-main
      	.section	.rodata
      .LC1:
      	.string	"In child pthread: a=%d\n"
      	.text
      	.globl	child_pth_fun
      	.type	child_pth_fun, @function
      child_pth_fun:
      .LFB7:
      	.cfi_startproc
      	endbr64
      	pushq	%rbp
      	.cfi_def_cfa_offset 16
      	.cfi_offset 6, -16
      	movq	%rsp, %rbp
      	.cfi_def_cfa_register 6
      	subq	$16, %rsp
      	movq	%rdi, -8(%rbp)
      	movl	$4, a(%rip)
      	movl	a(%rip), %eax
      	movl	%eax, %esi
      	leaq	.LC1(%rip), %rdi
      	movl	$0, %eax
      	call	printf@PLT
      	nop
      	leave
      	.cfi_def_cfa 7, 8
      	ret
      	.cfi_endproc
      .LFE7:
      	.size	child_pth_fun, .-child_pth_fun
      	.ident	"GCC: (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0"
      	.section	.note.GNU-stack,"",@progbits
      	.section	.note.gnu.property,"a"
      	.align 8
      	.long	 1f - 0f
      	.long	 4f - 1f
      	.long	 5
      0:
      	.string	 "GNU"
      1:
      	.align 8
      	.long	 0xc0000002
      	.long	 3f - 2f
      2:
      	.long	 0x3
      3:
      	.align 8
      4:
      ```

      ![Screenshot 2022-10-15 182556](实验\操作系统实验\实验5 信号量的实现和应用\Screenshot 2022-10-15 182556.png)

    - 非volatile编译器优化

      ```c
      //源程序见上面一个讨论，这里给出非volatile编译器优化 汇编代码
      
      	.file	"testUnV.c"
      	.text
      	.section	.rodata.str1.1,"aMS",@progbits,1
      .LC0:
      	.string	"In child pthread: a=%d\n"
      	.text
      	.p2align 4
      	.globl	child_pth_fun
      	.type	child_pth_fun, @function
      child_pth_fun:
      .LFB52:
      	.cfi_startproc
      	endbr64
      	subq	$8, %rsp
      	.cfi_def_cfa_offset 16
      	movl	$4, %edx
      	movl	$1, %edi
      	xorl	%eax, %eax
      	leaq	.LC0(%rip), %rsi
      	movl	$4, a(%rip)
      	call	__printf_chk@PLT
      	addq	$8, %rsp
      	.cfi_def_cfa_offset 8
      	ret
      	.cfi_endproc
      .LFE52:
      	.size	child_pth_fun, .-child_pth_fun
      	.section	.rodata.str1.8,"aMS",@progbits,1
      	.align 8
      .LC1:
      	.string	"In main pthread: a=%d, b=%d, c=%d\n"
      	.section	.text.startup,"ax",@progbits
      	.p2align 4
      	.globl	main
      	.type	main, @function
      main:
      .LFB51:
      	.cfi_startproc
      	endbr64
      	subq	$24, %rsp
      	.cfi_def_cfa_offset 32
      	xorl	%ecx, %ecx
      	leaq	child_pth_fun(%rip), %rdx
      	xorl	%esi, %esi
      	movq	%fs:40, %rax
      	movq	%rax, 8(%rsp)
      	xorl	%eax, %eax
      	movq	%rsp, %rdi
      	call	pthread_create@PLT
      	movl	a(%rip), %edx
      	leaq	.LC1(%rip), %rsi
      	xorl	%eax, %eax
      	movl	$1, %edi
      	movl	%edx, %r8d
      	movl	%edx, %ecx
      	call	__printf_chk@PLT
      	movq	(%rsp), %rdi
      	xorl	%esi, %esi
      	call	pthread_join@PLT
      	movq	8(%rsp), %rax
      	xorq	%fs:40, %rax
      	jne	.L7
      	xorl	%eax, %eax
      	addq	$24, %rsp
      	.cfi_remember_state
      	.cfi_def_cfa_offset 8
      	ret
      .L7:
      	.cfi_restore_state
      	call	__stack_chk_fail@PLT
      	.cfi_endproc
      .LFE51:
      	.size	main, .-main
      	.globl	a
      	.data
      	.align 4
      	.type	a, @object
      	.size	a, 4
      a:
      	.long	1
      	.ident	"GCC: (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0"
      	.section	.note.GNU-stack,"",@progbits
      	.section	.note.gnu.property,"a"
      	.align 8
      	.long	 1f - 0f
      	.long	 4f - 1f
      	.long	 5
      0:
      	.string	 "GNU"
      1:
      	.align 8
      	.long	 0xc0000002
      	.long	 3f - 2f
      2:
      	.long	 0x3
      3:
      	.align 8
      4:
      ```

      ![Screenshot 2022-10-15 183718](实验\操作系统实验\实验5 信号量的实现和应用\Screenshot 2022-10-15 183718.png)

      - volatile非编译器优化

        ```
        #include <stdio.h>
        #include <stdlib.h>
        #include <unistd.h>
        #include <pthread.h>
         
        int a = 1;
         
        void *child_pth_fun(void *arg);
         
        int main(){
         
        	int b, c;
        	volatile int val = 10000000;
        	
        	//创建子线程
        	pthread_t child_pth_id;
        	/*
        	pthread_create使用的vfork来实现子进程。fork系统调用创造子进程过程，先find_empty_process获取空pid和任务id，
        		然后申请一页内存，将父进程的PCB复制到新页中作为子进程的PCB，修改子进程PCB的参数，修改子进程的父进程节点，
        		修改子进程的状态为可运行态TASK_RUNNING，（打开文件表，TSS寄存器结构，信号相关），修改brk堆指针，修改用户程序和内核程序执行时间等，
        		同时对基于栈切换进程的进程切换，会构造栈切换数据结构，将当前寄存器的数据压入子进程PCB页的顶部形成子进程内核栈，
        		也就是构造子进程内核栈在子进程PCB的页顶端；然后申请数据段&堆栈段页目录项（在0地址空间开始），为页表申请内存，
        		将父进程的页表项赋值给新的页表，将新页表地址赋值给页目录项，将子进程的页目录表的地址赋值给CR3寄存器（current指向内存），
        		然后修改父进程和子进程页表为只读，增加mem_map内存映射图中对应页的共享数目；之后调用schedule进行进程调度，
        		schedule首先从任务数组task_table中找到一个就绪态的进程，然后返回任务号，之后使用switch_to执行进程切换，
        		保存PCB，重写tss栈指针（保存intel结构），切换current指针指向切换到的进程，切换ss:esp为切换到的进程的内核栈，然后执行fork的返回，
        		fork返回会恢复寄存器数值，最后使用iret指令恢复进程用户空间程序的cs:eip, ss:esp, eflags，重新回到用户程序执行。
        		
        		vfork的却别在于在复制父进程页表的时候，本来需要修改页表项为只读并且增加mem_map内存映射图的占用数，但是vfork对数据区（数据区分
        		初始化数据区.data和未初始化数据区.bss）的页表项并不设置只读，导致数据区的数据是共享数据，子进程在写共享数据的时候会进行写检查write_verify，
        		发现这个地方为可读，就不会重新分配空间复制这个变量，那么子进程修改的变量和父进程占用的是同一个变量，达到共享内存的全局变量的效果。
        	*/
        	pthread_create(&child_pth_id, NULL, child_pth_fun, NULL);
        	
        		
        	b = a;
        	
        
        	//延时操作
        	//消耗时间片延时
        	/*
        	消耗时间片方法延迟会占用CPU，这个过程主要发生时钟中断，在while消耗CPU时间的时候，会发生时钟中断，时钟中断发生调度，执行其他程序。
        	发生时钟中断的时候进程的运行状态依然是TASK_RUNNING，当while所处进程被重新调度唤醒，会冲洗运行while循环。
        	*/
        	while(val--) ;
        	//通过阻塞延时
        	/*
        	sleep延时方法会使用设置信号系统调用设置进程的ALARM信号，根据延时时间1s和Linux时间片1个10ms，那么会有1s/10ms=100个时钟中断，也就是ALARM=jiffies+100，
        	设置ALARM信号之后，设置进程状态为阻塞状态，然后调用schedule调度程序进行京城调度。当每次时钟中断发生时，会让进程运行时间counter-1,同时会检查每个进程的信号，如果当前jiffies>=ALARM，
        	就会设置那个进程的状态为TASK_RUNNING,然后时钟中断启动schedule系统调度，从TASK_RUNNING的进程中找到一个执行switch_to进程切换。switch_to保存PCB，重置TSS栈，
        	切换current指针，切换内核栈，然后执行从内核空间返回到用户空间操作。如果是sleep所在的进程，就是返回sleep的用户程序执行。
        
        	消耗CPU延时和阻塞延时的却别在于，CPU延时会占用CPU，这个过程可能发生时钟中断让进程放弃CPU，当时状态是TASK_RUNNING，在就绪队列中；
        	阻塞延时会设置进程为TASK_INTERRUPTIBLE并且立即放弃CPU进行进程调度，同时修改ALARM信号，阻塞延时依靠时钟中断检查是否超过ALARM信号设置的时间，等到超过的时候才会设置进程TASK_RUNNING进入就绪队列
        	*/
        	//sleep(1);
         
        	c = a;
        	printf("In main pthread: a=%d, b=%d, c=%d\n", a, b, c);
        	
         	/*
        	pthread_join调用wait调用。wait系统调用等待子进程完成退出之后菜才能退出。当子进程执行自己的程序到右括号}的时候，会调用exit内核函数来杀死进程。
        		exit会清空任务数组中子进程所在位置设置为null，同时释放子进程占用的内存（清除页目录表，清除页表的mem_map位置-1），释放占用文件等等。
        		修改子进程的运行状态为TASK_END。当发生时钟中断的时候，时钟中断会检查所有进程，如果是TASK_END，就会循环任务队列，将子进程对应的父进程
        		等待的子进程数目-1，如果子进程数据变成0，那么父进程将被设置成TASK_RUNNING，然后调用schedule函数进行进程调度。如果调度到父进程，
        		父进程从pthread_join的wait系统调用返回到用户空间
        	
        		如果不适用wait系统调用，那么在父进程右括号}exit退出之后，exit内核退出函数会扫描所有任务队列，对父进程的子进程，因为父进程退出了，会设置
        		子进程的父进程为0进程。0进程执行的程序时while(1）{pause}，也就是0进程他不断触发调度。
        	*/
        	pthread_join(child_pth_id, NULL);
        	return 0;
         
        }
         
        void *child_pth_fun(void *arg){
         
            //子线程修改共享的全局变量
            	a = 4;		
            	printf("In child pthread: a=%d\n", a);
        }
        
        
        //////////////////////汇编代码
        	.file	"testV.c"
        	.text
        	.section	.rodata.str1.1,"aMS",@progbits,1
        .LC0:
        	.string	"In child pthread: a=%d\n"
        	.text
        	.p2align 4
        	.globl	child_pth_fun
        	.type	child_pth_fun, @function
        child_pth_fun:
        .LFB52:
        	.cfi_startproc
        	endbr64
        	subq	$8, %rsp
        	.cfi_def_cfa_offset 16
        	movl	$4, %edx
        	movl	$1, %edi
        	xorl	%eax, %eax
        	leaq	.LC0(%rip), %rsi
        	movl	$4, a(%rip)
        	call	__printf_chk@PLT
        	addq	$8, %rsp
        	.cfi_def_cfa_offset 8
        	ret
        	.cfi_endproc
        .LFE52:
        	.size	child_pth_fun, .-child_pth_fun
        	.section	.rodata.str1.8,"aMS",@progbits,1
        	.align 8
        .LC1:
        	.string	"In main pthread: a=%d, b=%d, c=%d\n"
        	.section	.text.startup,"ax",@progbits
        	.p2align 4
        	.globl	main
        	.type	main, @function
        main:
        .LFB51:
        	.cfi_startproc
        	endbr64
        	subq	$40, %rsp
        	.cfi_def_cfa_offset 48
        	leaq	child_pth_fun(%rip), %rdx
        	xorl	%ecx, %ecx
        	xorl	%esi, %esi
        	movq	%fs:40, %rax
        	movq	%rax, 24(%rsp)
        	xorl	%eax, %eax
        	leaq	16(%rsp), %rdi
        	movl	$10000000, 12(%rsp)
        	call	pthread_create@PLT
        	movl	a(%rip), %edx
        	.p2align 4,,10
        	.p2align 3
        .L5:
        	movl	12(%rsp), %eax
        	leal	-1(%rax), %ecx
        	movl	%ecx, 12(%rsp)
        	testl	%eax, %eax
        	jne	.L5
        	movl	%edx, %r8d
        	movl	%edx, %ecx
        	movl	$1, %edi
        	leaq	.LC1(%rip), %rsi
        	call	__printf_chk@PLT
        	movq	16(%rsp), %rdi
        	xorl	%esi, %esi
        	call	pthread_join@PLT
        	movq	24(%rsp), %rax
        	xorq	%fs:40, %rax
        	jne	.L9
        	xorl	%eax, %eax
        	addq	$40, %rsp
        	.cfi_remember_state
        	.cfi_def_cfa_offset 8
        	ret
        .L9:
        	.cfi_restore_state
        	call	__stack_chk_fail@PLT
        	.cfi_endproc
        .LFE51:
        	.size	main, .-main
        	.globl	a
        	.data
        	.align 4
        	.type	a, @object
        	.size	a, 4
        a:
        	.long	1
        	.ident	"GCC: (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0"
        	.section	.note.GNU-stack,"",@progbits
        	.section	.note.gnu.property,"a"
        	.align 8
        	.long	 1f - 0f
        	.long	 4f - 1f
        	.long	 5
        0:
        	.string	 "GNU"
        1:
        	.align 8
        	.long	 0xc0000002
        	.long	 3f - 2f
        2:
        	.long	 0x3
        3:
        	.align 8
        4:
        
        ```

        ![Screenshot 2022-10-15 184659](实验\操作系统实验\实验5 信号量的实现和应用\Screenshot 2022-10-15 184659.png)

      - volatile编译器优化

        ```
        	.file	"testV.c"
        	.text
        	.globl	a
        	.data
        	.align 4
        	.type	a, @object
        	.size	a, 4
        a:
        	.long	1
        	.section	.rodata
        	.align 8
        .LC0:
        	.string	"In main pthread: a=%d, b=%d, c=%d\n"
        	.text
        	.globl	main
        	.type	main, @function
        main:
        .LFB6:
        	.cfi_startproc
        	endbr64
        	pushq	%rbp
        	.cfi_def_cfa_offset 16
        	.cfi_offset 6, -16
        	movq	%rsp, %rbp
        	.cfi_def_cfa_register 6
        	subq	$32, %rsp
        	movq	%fs:40, %rax
        	movq	%rax, -8(%rbp)
        	xorl	%eax, %eax
        	movl	$10000000, -28(%rbp)
        	leaq	-16(%rbp), %rax
        	movl	$0, %ecx
        	leaq	child_pth_fun(%rip), %rdx
        	movl	$0, %esi
        	movq	%rax, %rdi
        	call	pthread_create@PLT
        	movl	a(%rip), %eax
        	movl	%eax, -24(%rbp)
        	nop
        .L2:
        	movl	-28(%rbp), %eax
        	leal	-1(%rax), %edx
        	movl	%edx, -28(%rbp)
        	testl	%eax, %eax
        	jne	.L2
        	movl	a(%rip), %eax
        	movl	%eax, -20(%rbp)
        	movl	a(%rip), %eax
        	movl	-20(%rbp), %ecx
        	movl	-24(%rbp), %edx
        	movl	%eax, %esi
        	leaq	.LC0(%rip), %rdi
        	movl	$0, %eax
        	call	printf@PLT
        	movq	-16(%rbp), %rax
        	movl	$0, %esi
        	movq	%rax, %rdi
        	call	pthread_join@PLT
        	movl	$0, %eax
        	movq	-8(%rbp), %rsi
        	xorq	%fs:40, %rsi
        	je	.L4
        	call	__stack_chk_fail@PLT
        .L4:
        	leave
        	.cfi_def_cfa 7, 8
        	ret
        	.cfi_endproc
        .LFE6:
        	.size	main, .-main
        	.section	.rodata
        .LC1:
        	.string	"In child pthread: a=%d\n"
        	.text
        	.globl	child_pth_fun
        	.type	child_pth_fun, @function
        child_pth_fun:
        .LFB7:
        	.cfi_startproc
        	endbr64
        	pushq	%rbp
        	.cfi_def_cfa_offset 16
        	.cfi_offset 6, -16
        	movq	%rsp, %rbp
        	.cfi_def_cfa_register 6
        	subq	$16, %rsp
        	movq	%rdi, -8(%rbp)
        	movl	$4, a(%rip)
        	movl	a(%rip), %eax
        	movl	%eax, %esi
        	leaq	.LC1(%rip), %rdi
        	movl	$0, %eax
        	call	printf@PLT
        	nop
        	leave
        	.cfi_def_cfa 7, 8
        	ret
        	.cfi_endproc
        .LFE7:
        	.size	child_pth_fun, .-child_pth_fun
        	.ident	"GCC: (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0"
        	.section	.note.GNU-stack,"",@progbits
        	.section	.note.gnu.property,"a"
        	.align 8
        	.long	 1f - 0f
        	.long	 4f - 1f
        	.long	 5
        0:
        	.string	 "GNU"
        1:
        	.align 8
        	.long	 0xc0000002
        	.long	 3f - 2f
        2:
        	.long	 0x3
        3:
        	.align 8
        4:
        
        ```

        ![Screenshot 2022-10-15 184818](实验\操作系统实验\实验5 信号量的实现和应用\Screenshot 2022-10-15 184818.png)

      volatile变量可以修饰全局变量或者局部变量，主要效果是**cli; mov eax, ss:-xx[ebp]; sti**，一般进程共享全局变量需要用volatile修饰来同步互斥。

**C99引入了5个关键字**

inline， restrict, _Bool, _Complex, _Imaginary

**C11引入了7个关键字**

_Alignas, _Alignof, _Atomic,  _Static_assert,  _Noreturn,  _Thread_local,  _Generic

- _Thread_local

  https://cloud.tencent.com/developer/article/1915012

  https://www.cnblogs.com/gd-luojialin/p/15027719.html

  https://www.cnblogs.com/zhoug2020/p/6497709.html

  http://www.codebaoku.com/it-c/it-c-207197.html

  [重要]https://stackoverflow.com/questions/10810203/what-is-the-fs-gs-register-intended-for#:~:text=FS%20is%20used%20to%20point,function%20in%20FS%3A%5B0x00%5D%20.

  [重要]https://www.kernel.org/doc/html/latest/x86/x86_64/fsgs.html

  https://maskray.me/blog/2021-02-14-all-about-thread-local-storage

  https://stackoverflow.com/questions/32245103/how-does-the-gcc-thread-work

  https://stackoverflow.com/questions/14289634/thread-local-storage-class-specifier-in-c

  [非常重要] https://www.cnblogs.com/abozhang/p/10800332.html

  [非常重要] https://www.educative.io/answers/what-is-the-threadlocal-keyword-in-c

  [非常重要] https://www.cnblogs.com/gd-luojialin/p/15027719.html

  [比较重要-pthread和_thread_local两种实现thread_local] https://blog.csdn.net/aguoxin/article/details/103968031

  [比较重要-Java的thread_local实现] https://blog.csdn.net/pcww12/article/details/125568535

  线程本地存储，在gcc中实现的关键字是thread_local，这种实现是基于编译器的。线程本地存储thread_local_storage(TLS)的含义是变量在进程开始的时候初始化，在进程结束的时候销毁，相当于进程全局变量，而这个变量在其他进程中是不一样的，不会相互影响。

  全局变量的作用域是整个程序，整个程序的每个函数和每个进程都是可见全局变量的，全局变量随着整个程序运行创建，随着整个程序退出被销毁；局部变量作用域在局部变量定义的函数内部，函数调用时创建和初始化，函数退出时销毁；而线程本地存储的作用域在线程内部，它随着线程创建被创建和初始化，随着线程退出而被销毁。

  线程本地存储的实现有很多种，一种结合gcc编译其和fork系统调用的方式是如下面的程序所示。主进程将所有子进程使用的线程本地存储变量汇总到一个.tdata段代表线程本地存储段，当使用thread_create调用fork系统调用创建子进程的时候，会在子进程的内核栈中压入fs段寄存器，fs段寄存器是这样获得的，首先在线程结构体TCB中加入两个变量.tdata代表线程本地存储数据段地址，在进行foke系统调用的时候会重新分配页面复制.tdata段的页到新页，实现新建子进程的时候初始化线程本地存储变量的目的，同时将新的.tdata段的地址压入子进程的内核栈中去作为fs寄存器的参数。这种线程本地存储让每个线程都有一个父进程.tdata的副本，实现了全局变量在子进程中为一个副本的功能，这个副本在子进程创建时初始化，在子进程退出时销毁。

  ```
  #include <stdio.h>
  #include "threads.h"
  #define SIZE 5
  
  int func(void *id)
  {
      //_Thread_local variable 
      static thread_local int var = 5;
      var += 5;
  
      //Print id of current thread and addr of var
      printf("Thread ID:[%d], Value of var: %d\n", *(int*)id, var);
  
      return 0;
  }
  
  int func1(void *id)
  {
      //_Thread_local variable 
      static thread_local int var = 10;
      var += 5;
  
      //Print id of current thread and addr of var
      printf("Thread ID:[%d], Value of var: %d\n", *(int*)id, var);
  
      return 0;
  }
  
  int main(void)
  {
      thrd_t id[SIZE];
  
      //thread ID arr
      int arr[SIZE] = {1, 2, 3, 4, 5};
  
      //Creating 5 threads
      for(int i = 0; i < SIZE/2; i++) {
          thrd_create(&id[i], func, &arr[i]);
      }
      for(int i = SIZE/2; i < SIZE; i++) {
          thrd_create(&id[i], func1, &arr[i]);
      }
  
      //Wait for threads to complete
      for(int i = 0; i < SIZE; i++) {
          thrd_join(id[i], NULL);
      }
  }
  
  
  
  ///////////////////////////////////////
  
  	.file	"static.c"
  	.text
  	.section	.tdata,"awT",@progbits
  	.align 4
  	.type	var.2533, @object
  	.size	var.2533, 4
  var.2533:
  	.long	5
  	.section	.rodata
  	.align 8
  .LC0:
  	.string	"Thread ID:[%d], Value of var: %d\n"
  	.text
  	.globl	func
  	.type	func, @function
  func:
  .LFB0:
  	.cfi_startproc
  	endbr64
  	pushq	%rbp
  	.cfi_def_cfa_offset 16
  	.cfi_offset 6, -16
  	movq	%rsp, %rbp
  	.cfi_def_cfa_register 6
  	subq	$16, %rsp
  	movq	%rdi, -8(%rbp)
  	movl	%fs:var.2533@tpoff, %eax			; movl %fs:-16, %eax ; fs在创建进程时申请内存和设置
  	addl	$5, %eax
  	movl	%eax, %fs:var.2533@tpoff
  	movl	%fs:var.2533@tpoff, %edx
  	movq	-8(%rbp), %rax
  	movl	(%rax), %eax
  	movl	%eax, %esi
  	leaq	.LC0(%rip), %rdi
  	movl	$0, %eax
  	call	printf@PLT
  	movl	$0, %eax
  	leave
  	.cfi_def_cfa 7, 8
  	ret
  	.cfi_endproc
  .LFE0:
  	.size	func, .-func
  	.section	.tdata
  	.align 4
  	.type	var.2537, @object
  	.size	var.2537, 4
  var.2537:
  	.long	10
  	.text
  	.globl	func1
  	.type	func1, @function
  func1:
  .LFB1:
  	.cfi_startproc
  	endbr64
  	pushq	%rbp
  	.cfi_def_cfa_offset 16
  	.cfi_offset 6, -16
  	movq	%rsp, %rbp
  	.cfi_def_cfa_register 6
  	subq	$16, %rsp
  	movq	%rdi, -8(%rbp)
  	movl	%fs:var.2537@tpoff, %eax			; movl %fs:-8, %eax ; fs在创建进程时申请内存和设置
  	addl	$5, %eax
  	movl	%eax, %fs:var.2537@tpoff
  	movl	%fs:var.2537@tpoff, %edx
  	movq	-8(%rbp), %rax
  	movl	(%rax), %eax
  	movl	%eax, %esi
  	leaq	.LC0(%rip), %rdi
  	movl	$0, %eax
  	call	printf@PLT
  	movl	$0, %eax
  	leave
  	.cfi_def_cfa 7, 8
  	ret
  	.cfi_endproc
  .LFE1:
  	.size	func1, .-func1
  	.globl	main
  	.type	main, @function
  main:
  .LFB2:
  	.cfi_startproc
  	endbr64
  	pushq	%rbp
  	.cfi_def_cfa_offset 16
  	.cfi_offset 6, -16
  	movq	%rsp, %rbp
  	.cfi_def_cfa_register 6
  	subq	$96, %rsp
  	movq	%fs:40, %rax
  	movq	%rax, -8(%rbp)
  	xorl	%eax, %eax
  	movl	$1, -80(%rbp)
  	movl	$2, -76(%rbp)
  	movl	$3, -72(%rbp)
  	movl	$4, -68(%rbp)
  	movl	$5, -64(%rbp)
  	movl	$0, -92(%rbp)
  	jmp	.L6
  .L7:
  	leaq	-80(%rbp), %rax
  	movl	-92(%rbp), %edx
  	movslq	%edx, %rdx
  	salq	$2, %rdx
  	addq	%rax, %rdx
  	leaq	-48(%rbp), %rax
  	movl	-92(%rbp), %ecx
  	movslq	%ecx, %rcx
  	salq	$3, %rcx
  	addq	%rcx, %rax
  	leaq	func(%rip), %rsi
  	movq	%rax, %rdi
  	call	thrd_create@PLT
  	addl	$1, -92(%rbp)
  .L6:
  	cmpl	$1, -92(%rbp)
  	jle	.L7
  	movl	$2, -88(%rbp)
  	jmp	.L8
  .L9:
  	leaq	-80(%rbp), %rax
  	movl	-88(%rbp), %edx
  	movslq	%edx, %rdx
  	salq	$2, %rdx
  	addq	%rax, %rdx
  	leaq	-48(%rbp), %rax
  	movl	-88(%rbp), %ecx
  	movslq	%ecx, %rcx
  	salq	$3, %rcx
  	addq	%rcx, %rax
  	leaq	func1(%rip), %rsi
  	movq	%rax, %rdi
  	call	thrd_create@PLT
  	addl	$1, -88(%rbp)
  .L8:
  	cmpl	$4, -88(%rbp)
  	jle	.L9
  	movl	$0, -84(%rbp)
  	jmp	.L10
  .L11:
  	movl	-84(%rbp), %eax
  	cltq
  	movq	-48(%rbp,%rax,8), %rax
  	movl	$0, %esi
  	movq	%rax, %rdi
  	call	thrd_join@PLT
  	addl	$1, -84(%rbp)
  .L10:
  	cmpl	$4, -84(%rbp)
  	jle	.L11
  	movl	$0, %eax
  	movq	-8(%rbp), %rsi
  	xorq	%fs:40, %rsi
  	je	.L13
  	call	__stack_chk_fail@PLT
  .L13:
  	leave
  	.cfi_def_cfa 7, 8
  	ret
  	.cfi_endproc
  .LFE2:
  	.size	main, .-main
  	.ident	"GCC: (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0"
  	.section	.note.GNU-stack,"",@progbits
  	.section	.note.gnu.property,"a"
  	.align 8
  	.long	 1f - 0f
  	.long	 4f - 1f
  	.long	 5
  0:
  	.string	 "GNU"
  1:
  	.align 8
  	.long	 0xc0000002
  	.long	 3f - 2f
  2:
  	.long	 0x3
  3:
  	.align 8
  4:
  ```

- _Aatomic

  原子类型，在C语言里是通过**lock xaddl	%eax, atomic_count(%rip)**指令（CPU原语fetch-and-add, 其他有用的CPU原语cmpxchg用来实现CAS操作从而实现进程同步互斥）来实现的。如果用精简指令集架构可以通过cli/sti关中断实现。原子类型可以时全局变量、静态全局变量、静态局部变量、局部变量，他主要是通过CPU原语fetch-and-add指令直接给变量内存进行加法，实际可以通过关中断之后加法操作。

  ```
  #include <stdio.h>
  #include <pthread.h>
  #include <stdatomic.h>
  
  // making an atomic counter
  _Atomic int atomic_count = 0;
  // making a simple variable
  int count = 0;
  
  // the function which will run in the thread
  void* runner()
  {
      for(int i = 0; i < 1000; i++) {
          count++;
          atomic_count++;
      }
      return 0;
  }
  
  int main()
  {
      // making the essential variables to create threads
      pthread_t threadIDs[5];
      pthread_attr_t attr;
      pthread_attr_init(&attr);
  
      // making 5 threads
      for(int i = 0; i < 8; i++)
          pthread_create(&threadIDs[i], &attr, runner, NULL);
      
      // waiting for all threads to finish
      for(int i = 0; i < 8; i++)
          pthread_join(threadIDs[i], NULL);
  
      // printing the variables
      printf("The atomic counter is %u\n", atomic_count);
      printf("The non-atomic counter is %u\n", count);
  }
  
  
  
  ///////////////////////////
  	.file	"automic.c"
  	.text
  	.globl	atomic_count
  	.bss
  	.align 4
  	.type	atomic_count, @object
  	.size	atomic_count, 4
  atomic_count:
  	.zero	4
  	.globl	count
  	.align 4
  	.type	count, @object
  	.size	count, 4
  count:
  	.zero	4
  	.text
  	.globl	runner
  	.type	runner, @function
  runner:
  .LFB0:
  	.cfi_startproc
  	endbr64
  	pushq	%rbp
  	.cfi_def_cfa_offset 16
  	.cfi_offset 6, -16
  	movq	%rsp, %rbp
  	.cfi_def_cfa_register 6
  	subq	$32, %rsp
  	movq	%fs:40, %rax
  	movq	%rax, -8(%rbp)
  	xorl	%eax, %eax
  	movl	$0, -12(%rbp)
  	jmp	.L2
  .L3:
  	movl	count(%rip), %eax
  	addl	$1, %eax
  	movl	%eax, count(%rip)
  	movl	$1, -20(%rbp)
  	movl	-20(%rbp), %eax
  	lock xaddl	%eax, atomic_count(%rip)
  	movl	%eax, -16(%rbp)
  	addl	$1, -12(%rbp)
  .L2:
  	cmpl	$999, -12(%rbp)
  	jle	.L3
  	movl	$0, %eax
  	movq	-8(%rbp), %rdx
  	xorq	%fs:40, %rdx
  	je	.L5
  	call	__stack_chk_fail@PLT
  .L5:
  	leave
  	.cfi_def_cfa 7, 8
  	ret
  	.cfi_endproc
  .LFE0:
  	.size	runner, .-runner
  	.section	.rodata
  .LC0:
  	.string	"The atomic counter is %u\n"
  .LC1:
  	.string	"The non-atomic counter is %u\n"
  	.text
  	.globl	main
  	.type	main, @function
  main:
  .LFB1:
  	.cfi_startproc
  	endbr64
  	pushq	%rbp
  	.cfi_def_cfa_offset 16
  	.cfi_offset 6, -16
  	movq	%rsp, %rbp
  	.cfi_def_cfa_register 6
  	addq	$-128, %rsp
  	movq	%fs:40, %rax
  	movq	%rax, -8(%rbp)
  	xorl	%eax, %eax
  	leaq	-64(%rbp), %rax
  	movq	%rax, %rdi
  	call	pthread_attr_init@PLT
  	movl	$0, -120(%rbp)
  	jmp	.L7
  .L8:
  	leaq	-112(%rbp), %rax
  	movl	-120(%rbp), %edx
  	movslq	%edx, %rdx
  	salq	$3, %rdx
  	leaq	(%rax,%rdx), %rdi
  	leaq	-64(%rbp), %rax
  	movl	$0, %ecx
  	leaq	runner(%rip), %rdx
  	movq	%rax, %rsi
  	call	pthread_create@PLT
  	addl	$1, -120(%rbp)
  .L7:
  	cmpl	$7, -120(%rbp)
  	jle	.L8
  	movl	$0, -116(%rbp)
  	jmp	.L9
  .L10:
  	movl	-116(%rbp), %eax
  	cltq
  	movq	-112(%rbp,%rax,8), %rax
  	movl	$0, %esi
  	movq	%rax, %rdi
  	call	pthread_join@PLT
  	addl	$1, -116(%rbp)
  .L9:
  	cmpl	$7, -116(%rbp)
  	jle	.L10
  	movl	atomic_count(%rip), %eax
  	movl	%eax, -124(%rbp)
  	movl	-124(%rbp), %eax
  	movl	%eax, %esi
  	leaq	.LC0(%rip), %rdi
  	movl	$0, %eax
  	call	printf@PLT
  	movl	count(%rip), %eax
  	movl	%eax, %esi
  	leaq	.LC1(%rip), %rdi
  	movl	$0, %eax
  	call	printf@PLT
  	movl	$0, %eax
  	movq	-8(%rbp), %rcx
  	xorq	%fs:40, %rcx
  	je	.L12
  	call	__stack_chk_fail@PLT
  .L12:
  	leave
  	.cfi_def_cfa 7, 8
  	ret
  	.cfi_endproc
  .LFE1:
  	.size	main, .-main
  	.ident	"GCC: (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0"
  	.section	.note.GNU-stack,"",@progbits
  	.section	.note.gnu.property,"a"
  	.align 8
  	.long	 1f - 0f
  	.long	 4f - 1f
  	.long	 5
  0:
  	.string	 "GNU"
  1:
  	.align 8
  	.long	 0xc0000002
  	.long	 3f - 2f
  2:
  	.long	 0x3
  3:
  	.align 8
  4:
  ```

**磁盘管理**

磁盘读写通过硬盘中断完成的，磁盘接入计算机系统之后，计算机端口和磁盘控制器件的寄存器相连接，计算机数据总线和磁盘数据总线连接。BIOS提供硬盘中断，硬盘中断需要传入读写的（磁面、磁道、扇区），控制方式（读写），读写缓冲区地址（es:[ebx]，在写磁盘的时候用作保存写的缓冲块地址，在读的时候用作存储从磁盘读取的数据的缓冲块地址）。进程在读写磁盘的时候因为磁盘是同一时间只能服务一个进程，那么多个进程读写磁盘需要阻塞。一个进程续写磁盘的时候，会向磁盘管理程序发送一个读写请求，磁盘管理线程在接收到一堆磁盘读写请求之后，会对这些请求进行电梯调度算法优化排序，之后从队列头部选取一个请求，使用硬盘中断从磁盘中读取数据到指定的内核缓冲区中。

**文件管理**

Linux任何资源都是按照文件进行管理的。read, write系统调用实现对文件的读写操作，read/write根据文件类型的不同会调用不同的实现函数。对块设备类型调用blk_read/blk_write，对于文件类型调用file_read/file_write，对于管道类型调用pipe_read/pipe_wirte，对于字符类型调用char_read/char_write(控制台管理调用的char_read调用put_char/copy_to_cooked/tty_read/con_write，char_write调用tty_write/con_write)

blk_wirte传入的参数有四个，（设备号dev，文件指针，写字符串数组指针，写字符串个数）。blk_write首先根据文件指针计算出这个指针所在的逻辑块号和在逻辑块中的偏移（逻辑块号=文件指针/1k+数据区起始逻辑块号），然后调用buffer.c中的bread函数传入设备号和逻辑块号获取文件指针所在的块放到内核缓冲块中，bread传入两个参数，设备号和逻辑号，bread函数调用blk函数先从内核缓冲区获取一个块，这个块要么是一个空的块，要么就是我们需要的缓冲块，然后bread函数判断getblk函数获取的内核缓冲块数据是否有效，如果无效或者是一个空的块，就会使用blk_dev/ll_rw_blk.c中的ll_rw_blk函数带入设备号和逻辑号从设备中读取对应的逻辑块放入到内核缓冲区(es:[ebx]），这个过程是磁盘完成的，磁盘数据总线连接计算机数据总线指向es:[ebx]的位置，当ll_rw_blk函数调用磁盘中断函数（BIOS提供）从磁盘读取数据后，磁盘控制器程序接管数据加载到计算机缓冲区的工作，这个时候ll_rw_blk函数所在的进程阻塞。当磁盘控制器加载完成一个缓冲块之后，会重新触发一个磁盘中断，这个磁盘中断唤醒阻塞在磁盘读写队列上的进程。进程被重新唤醒之后bread函数返回获得的内核缓冲块的地址。如果是blk_write函数，他会根据之前计算的文件指针的在缓冲块的偏移位置按照用户空间的字符串数组指针和写字符串个数使用get_fs_char将字符写入到内核缓冲块中。如果文件指针超过磁盘缓冲块1k，也就是这个文件指针不在缓冲块中，会重新出发上述blk_write过程。磁盘读也一样，首先使用bread获取要读的缓冲块，然后从文件指针偏移处读n个字符put_fs_char到用户空间数组中。

file_read/file_write和blk_write/blk_read差不多，只不过file_read/file_write传入的参数是i节点指针，文件读写函数从i节点指针获取需要的设备号和文件指针，然后其他的读写操作和blk_write/blk_read一样。

pipe_read/pipe_write管道，管道实际上是一个文件，用于进程通信或者同步。有名管道使用sys_read/sys_write系统调用调用pipe_read/pipe_write底层读写函数，操作的是一个有名的文件，这个文件可以被计算机中所有进程获取。而基于同样pipe_read/pipe_write的无名管道系统调用sys_pipe会创建无名文件，这个文件只能被使用sys_pipe的进程所创建的子进程所使用。对于文件操作部分，实际上跟file_read/file_write， blk_read/blk_write一样， 都是根据设备号和文件指针bread获得一个内核缓冲区，然后对内核缓冲区进行读写。

char_read/char_write(rw_char)是字符设备读写。字符设备在插入计算机系统的时候，他的控制器的寄存器要接入计算机端口包括控制总线和数据总线都要连接到计算机系统，并且需要提供读写设备的驱动程序，在插入的时候读设备的驱动程序被注册成中断，写设备的驱动程序被加载到内核空间并且函数地址放到字符设备结构体的写函数指针中。当进程向字符设备读的时候（read控制台，socket网卡），会调用tty_read函数从字符设备辅助队列读取数据，如果辅助队列为空，就会阻塞进程。当字符设备有数据到达的时候（控制台设备按下键盘按键，网卡到来数据)，会触发对应的中断函数，中断函数将到达设备的字符处理之后放到辅助队列，然后唤醒阻塞在设备辅助队列上的进程。当被阻塞的进程被唤醒之后，会将辅助队列上的字符拷贝到用户空间的变量中。当发生写设备的时候（write控制台，socket网卡），进程调用tty_write函数将数据写入到字符设备结构体的写缓冲队列中，如果队列满就阻塞进程，然后调用保存在字符设备结构体的写字符设备驱动程序将写缓冲队列的数据写入到设备在计算机中对应的端口或者内存中。之后设备的控制程序会处理对应端口的或者对应数据区的数据【对于磁盘等块设备，磁盘中断需要内核数据区以及读写磁盘的中断函数，以及磁盘完成读写的中断函数。块设备和字符设备拥有相似的处理过程。内核中有字符设备结构体（字符设备结构体数组），也有块设备结构体（超级块数组）；在字符设备插入设备时，需要提供字符设备读写驱动程序，读驱动程序被注册成中断，写驱动程序被放入设备结构体的写函数指针中，同样块设备插入系统时，也需要提供块设备读写驱动程序，读写驱动程序被注册称为中断由用户程序调用（字符设备是读驱动程序被注册成中断，而写驱动程序放入字符设备结构体写函数指针，而块设备读写驱动成旭是通过寄存器区分的，是一个程序而不是两个分开的程序，所以读写驱动程序被注册成中断，块设备读写驱动函数只会被程序调用，而不是硬件中断，是一种软件中断，块设备不会主动触发读写驱动程序，这和字符设备不同，字符设备可以主动触发读中断-按下按键/网卡到达数据都会主动触发读中断），块设备还有一个设备完成读写完成的中断，这个中断会唤醒阻塞在块设备结构体的进程，这个中断是设备控制器完成一个块的读写之后触发的；读字符设备的时候，read系统调用的底层实现函数是tty_read，tty_read检查字符设备结构体的辅助队列是否为满，如果满了会阻塞进程，没有满就会从辅助队列读数据put_fs_char到用户空间，而读块设备的时候，read系统调用底层实现函数是blk_read，blk_read首先使用bread获取读数据的内核缓冲块，bread函数首先使用getblk函数获取一个内核缓冲块，这个内核缓冲块要么是一个空闲缓冲块，要么就是以前加载的文件指针所在的缓冲块，然后bread判断这个缓冲块是否有效，如果是空缓冲块或者数据被更改导致缓冲块无效，bread会调用ll_rw_blk函数从磁盘中加载文件指针所在的磁盘快到内核缓冲块，ll_rw_blk会调用磁盘读中断并阻塞进程，然后磁盘控制器会加载磁盘块数据到内核缓冲区，磁盘读中断完成之后，磁盘触发读写完成中断，这个中断会唤醒中断在块设备读队列上的阻塞进程。当进程被唤醒之后，返回ll_rw_blk和bread函数，bread函数返回缓冲块地址，进程从bread返回之后会把用户空间数据拷贝到内核缓冲区的位置；写字符设备的时候，进程write系统调用底层实现函数是tty_write，tty_write检查设备写缓冲队列是否为满，满就阻塞，不满就写入数据，然后调用设备结构体中的写函数指针完成设备写（控制台设备写函数是con_write)，而写块设备的时候，write底层实现函数是blk_write，blk_write函数调用bread函数找到或者创建文件指针对应的内核缓冲块，这个过程可能阻塞，然后将用户空间的数据get_fs_char写入到内核缓冲块，这个过程和字符设备写不同，字符设备写会直接调用写字符设备程序将缓冲的数据直接写入到字符设备，而在块设备写的时候只是写到缓冲区中，而没有进一步写入到块设备中，写到块设备中的操作要到后面释放块设备的时候完成，比如sys_umount，会将缓冲区的所有相关块设备的缓冲块调用ll_rw_blk写入到块设备（文件系统释放文件的时候可以使用fclose函数将文件相关缓冲块写入到块设备）】。

字符设备和块设备驱动的异同可以见下图

![未命名文件 (1)](实验\操作系统实验\实验8 虚拟文件系统的实现\未命名文件 (1).png)



## 操作系统实验总结

### 进程管理

实验3-进程状态跟踪

实验4-基于栈的内核级线程的切换

实验5-信号量的实现

1. 进程控制

   | fork                   | 创建一个新进程                                       |
   | ---------------------- | ---------------------------------------------------- |
   | clone                  | 按指定条件创建子进程                                 |
   | execve                 | 运行可执行文件                                       |
   | exit                   | 中止进程                                             |
   | _exit                  | 立即中止当前进程                                     |
   | getdtablesize          | 进程所能打开的最大文件数                             |
   | getpgid                | 获取指定进程组标识号                                 |
   | setpgid                | 设置指定进程组标志号                                 |
   | getpgrp                | 获取当前进程组标识号                                 |
   | setpgrp                | 设置当前进程组标志号                                 |
   | getpid                 | 获取进程标识号                                       |
   | getppid                | 获取父进程标识号                                     |
   | getpriority            | 获取调度优先级                                       |
   | setpriority            | 设置调度优先级                                       |
   | modify_ldt             | 读写进程的本地描述表                                 |
   | nanosleep              | 使进程睡眠指定的时间                                 |
   | nice                   | 改变分时进程的优先级                                 |
   | pause                  | 挂起进程，等待信号                                   |
   | personality            | 设置进程运行域                                       |
   | prctl                  | 对进程进行特定操作                                   |
   | ptrace                 | 进程跟踪                                             |
   | sched_get_priority_max | 取得静态优先级的上限                                 |
   | sched_get_priority_min | 取得静态优先级的下限                                 |
   | sched_getparam         | 取得进程的调度参数                                   |
   | sched_getscheduler     | 取得指定进程的调度策略                               |
   | sched_rr_get_interval  | 取得按RR算法调度的实时进程的时间片长度               |
   | sched_setparam         | 设置进程的调度参数                                   |
   | sched_setscheduler     | 设置指定进程的调度策略和参数                         |
   | sched_yield            | 进程主动让出处理器,并将自己等候调度队列队尾          |
   | vfork                  | 创建一个子进程，以供执行新程序，常与execve等同时使用 |
   | wait                   | 等待子进程终止                                       |
   | wait3                  | 参见wait                                             |
   | waitpid                | 等待指定子进程终止                                   |
   | wait4                  | 参见waitpid                                          |
   | capget                 | 获取进程权限                                         |
   | capset                 | 设置进程权限                                         |
   | getsid                 | 获取会晤标识号                                       |
   | setsid                 | 设置会晤标识号                                       |

2. 进程通信、传递数据和同步

   | ipc  | 进程间通信总控制调用 |
   | ---- | -------------------- |
   |      |                      |

   - 信号

     | sigaction   | 设置对指定信号的处理方法                               |
     | ----------- | ------------------------------------------------------ |
     | sigprocmask | 根据参数对信号集中的信号执行阻塞/解除阻塞等操作        |
     | sigpending  | 为指定的被阻塞信号设置队列                             |
     | sigsuspend  | 挂起进程等待特定信号                                   |
     | signal      | 参见signal                                             |
     | kill        | 向进程或进程组发信号                                   |
     | *sigblock   | 向被阻塞信号掩码中添加信号,已被sigprocmask代替         |
     | *siggetmask | 取得现有阻塞信号掩码,已被sigprocmask代替               |
     | *sigsetmask | 用给定信号掩码替换现有阻塞信号掩码,已被sigprocmask代替 |
     | *sigmask    | 将给定的信号转化为掩码,已被sigprocmask代替             |
     | *sigpause   | 作用同sigsuspend,已被sigsuspend代替                    |
     | sigvec      | 为兼容BSD而设的信号处理函数,作用类似sigaction          |
     | ssetmask    | ANSI C的信号处理函数,作用类似sigaction                 |

   - 消息队列

     | msgctl | 消息控制操作 |
     | ------ | ------------ |
     | msgget | 获取消息队列 |
     | msgsnd | 发消息       |
     | msgrcv | 取消息       |

   - 管道

     | pipe                            | 无名管道 |
     | ------------------------------- | -------- |
     | read/piperead, write/pipe_write | 有名管道 |

   - 信号量

     | semctl | 信号量控制     |
     | ------ | -------------- |
     | semget | 获取一组信号量 |
     | semop  | 信号量操作     |

   - 共享内存

     | shmctl | 控制共享内存 |
     | ------ | ------------ |
     | shmget | 获取共享内存 |
     | shmat  | 连接共享内存 |
     | shmdt  | 拆卸共享内存 |

**Linux进程创建系统调用sys_fork, sys_vfork, sys_clone**

[(108条消息) pthread_create创建线程_执迷C++ 的菜鸡的博客-CSDN博客_pthread创建线程](https://blog.csdn.net/m0_60663280/article/details/121500441)

Linux内核并不会区分进程和线程，Linux线程就是用进程来实现，他们的数据结构都是task_struct。三者都要掉调用clone内核函数来创建内核线程，只不过他们调用clone的参数flags是不同的，不同的参数可以控制不同task_struct结构中的变量的共享情况。创建线程会共享文件根目录/当前工作目录，打开文件表，数据页表MMU，信号和处理函数等等。

Linux创建并不区分进程和线程，都保存在task_table任务数组中，都是task_struct数据结构，只在用户层面区分。线程可以共享进程中的数据，而fork虽然有写时复制，但是终究不是共享，当要写数据的时候会重新分配内存进行拷贝变量，修改也是在拷贝的变量中，因此fork系统调用创建进程他有分配页写时复制的开销。而pthread_create创建的是轻量级进程，他会共享进程中的代码段、数据段(.data/.bss)、堆和进程PCB中的内容（信号、打开文件表、根目录和工作目录）等，实际上的实现是对于代码段和数据段堆栈段的共享只需要在fork的时候在拷贝父进程页表的时候设置父进程页表为可写就行，不用设置为只读，这样就能实现子进程可以直接在父进程的页中进行修改操作。而信号和打开文件表根目录的共享直需要在task_struct中设置这些值为指针，父子进程指向相同的变量，那么他们的复制就会共享同一个变量。而线程对这些变量的修改需要以来线程之间的同步互斥操作（信号，信号量，共享内存，消息队列，管道）。

![img](https://img-blog.csdnimg.cn/c9b13a4994ba4b53bbff985153186a4f.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5omn6L-3QysrIOeahOiPnOm4oQ==,size_12,color_FFFFFF,t_70,g_se,x_16)

#### 进程

	##### 进程状态五个

##### 进程内存映像（代码段/数据段/堆栈段）

##### 进程创建fork

##### 守护进程创建deamon

##### 进程退出return/exit/_exit

##### 等待进程结束wait/waitpid

##### 执行新程序sys_execve

#### 线程

##### 进程和线程关系

##### 线程创建

##### 线程终止

##### 线程私有数据 pthread_local

##### 线程同步（线程竞争共享资源）（互斥锁、信号）

#### 进程间通信和同步

参考：《Linux C编程实战》

##### 信号

信号是进程通知另一个进程发生某事件的一种通信机制

###### 信号来源

- 硬件信号
  - 键盘中断
  - 除0、无效存储访问等触发硬件错误
- 软件信号
  - 调用kill发送任意信号
  - 使用sleep设置定时器信号

###### 可靠信号（实时信号）和不可靠信号（非实时信号）

信号是否可靠依据信号是否会丢失。可靠信号不会丢失，多次产生的可靠信号会被放入进程PCB的信号队列排队，而不可靠信号只会设置信号位图但是不会入队，这样多次产生的不可靠信号只会被执行一次。

###### 信号优先级

多个同一信号，按到达时间优先级；多个不同信号，按序号小的先处理；同时存在可靠信号和不可靠信号，先处理不可靠信号。

###### 可重入函数和不可重入函数

可重入函数是一个可能导致数据破坏的信号处理函数。他的产生可能有三种:

- 信号处理函数使用了静态数据，如全局变量
- 信号处理函数使用了malloc和free
- 信号处理函数使用了scanf和printf

###### 信号发送函数kill/alarm/abort

kill可以发送任何信号，alarm发送SIGALRM，abort发送SIGABRT

###### 信号捕捉和处理函数signal/sigaction

- signal传递不可靠信号，在一个信号处理过程中和他相同的信号到来不会入队，会被丢弃（只修改signal信号位图造成丢弃）

  ````c
  
  #define _GUN_SORCE
  #include <signal.h>
  #include <stdio.h>
  #include <unistd.h>
  #include <signal.h>
  #include <string.h>
  
  void ouch(int sig)
  {
  	printf("oh, got a signal %d\n", sig);
  	sleep(10) ;
  }
  int main()
  {
  	(void) signal(SIGINT, ouch);
  	while(1) ;
  }
  ````

  ![Screenshot 2022-10-24 155201](实验\1 操作系统实验\杂实验\Screenshot 2022-10-24 155201.png)

  > 从图中可以看到在一个信号处理函数过程中到来的信号不会被执行

- sigaction传递可靠信号，相同信号入队，不会被丢弃

  ```c
  
  #define _GUN_SORCE
  #include <signal.h>
  #include <stdio.h>
  #include <unistd.h>
  #include <signal.h>
  #include <string.h>
  
  void handler_sigint(int sig)
  {
  	printf("oh, got a signal %d\n", sig);
  	sleep(2) ;
  }
  int main()
  {
  	struct sigaction act;
  
  	act.sa_handler = handler_sigint;
  	act.sa_flags = SA_NOMASK ;
  
  	sigaction(SIGINT, &act, NULL) ;
  
  
  	while(1) ;
  }
  ```

  

  ![Screenshot 2022-10-24 160212](实验\1 操作系统实验\杂实验\Screenshot 2022-10-24 160212.png)

  > 可以看到信号没有被丢失

###### 信号屏蔽和解除屏蔽（屏蔽就是阻塞信号）sigpromask/sigsuspend

Linux高版本信号位图不能用32位标识，因为Linux高版本的信号多余32个，所以需要用函数来操作信号变化，这里的信号位图被称为信号集。信号集的操作函数如下

> ![Screenshot 2022-10-24 164424](实验\1 操作系统实验\杂实验\Screenshot 2022-10-24 164424.png)

- sigpromask

  > ![Screenshot 2022-10-24 164905](实验\1 操作系统实验\杂实验\Screenshot 2022-10-24 164905.png)

- sigsuspend

  > ![Screenshot 2022-10-24 165031](实验\1 操作系统实验\杂实验\Screenshot 2022-10-24 165031.png)

###### 使用信号传递数据sigqueue

sigqueue(pid, signal, data)原型pid是进程pid，signal是信号，data是携带的数据

##### 信号量

https://blog.csdn.net/pk296256948/article/details/106674817

https://blog.csdn.net/yimomrik/article/details/123092207

https://blog.csdn.net/CAir2/article/details/124821044

信号量是一个计数器，用来控制多个进程对资源的访问，是一种锁机制

```c
#include <stdio.h>
#include <sys/sem.h>
#include <sys/ipc.h>
#include <errno.h>
#include <unistd.h>


//设置初值结构体
union semun{
    int              val;    /* Value for SETVAL */
    struct semid_ds *buf;    /* Buffer for IPC_STAT, IPC_SET */
    unsigned short  *array;  /* Array for GETALL, SETALL */
    struct seminfo  *__buf;  /* Buffer for IPC_INFO(Linux-specific) */
};



//获取资源
int sem_p(int semid)
{
    struct sembuf buf;
    int ret=-1;
    buf.sem_num=0;
    buf.sem_op=-1;
    buf.sem_flg=SEM_UNDO;
    ret=semop(semid,&buf,1);
    if(ret==-1)
    {
        perror("sem get fail!");
        return -1;
    }
    return 0;
}


//释放资源
int sem_v(int semid)
{
    struct sembuf buf;
    int ret=-1;
    buf.sem_num=0;
    buf.sem_op=+1;
    buf.sem_flg=SEM_UNDO;
    ret=semop(semid,&buf,1);
    if(ret==-1)
    {
        perror("sem get fail!");
        return -1;
    }
    return 0;
}


int main()
{
    int semid=-1;
    int ret=-1;
    //创建信号量
    semid=semget(1234,1,0666|IPC_CREAT);
    if(semid==-1)
    {
        perror("create sem fail!");
        return -1;
    }
    
    
    union semun sem_val;
    //设置信号量初值
    sem_val.val=1;
    ret=semctl(semid,0,SETVAL,sem_val);
    if(ret==-1)
    {
        perror("semctl set sem val fail!");
        return -1;
    }
    
    //创建进程
    int pid=-1;
    pid=fork();
    if(pid==-1)
    {
        perror("fork create fail!");
        return -1;
    }
    else if(pid==0)
    {
        //子进程
        while(1)
        {
            //获取信号量资源
            ret=sem_p(semid);
            if(ret==-1)
            {
                perror("sem_p fail!");
                break;
            }
            
            printf("son folk sem get success!\n");
            sleep(1);
            
            //释放信号量资源
            ret=sem_v(semid);
            if(ret==-1)
            {
                perror("sem_p fail!");
                break;
            }
            
        }
    }
    else
    {
        //父进程
        while(1)
        {
            //获取信号量资源
            ret=sem_p(semid);
            if(ret==-1)
            {
                perror("sem_p fail!");
                break;
            }
            
            printf("father folk sem get success!\n");
            sleep(1);
            
            //释放信号量资源
            ret=sem_v(semid);
            if(ret==-1)
            {
                perror("sem_p fail!");
                break;
            }
        }
    }
    
    //删除信号集
    ret=semctl(semid, 0,IPC_RMID,sem_val);
    if(ret==-1)
    {
         perror("sem delete fail!");
    }
    return 0;
}

```

##### 管道

[(109条消息) Linux管道_表哥抱表弟的博客-CSDN博客_linux 管道](https://blog.csdn.net/weixin_62029250/article/details/123321790)

管道是一种半双工单向通信，是一种无格式字节流通信，只能在具有亲缘关系的进程之间通信（父子进程或者兄弟进程之间的通信）。如果要实现进程双向通信必须开两个管道，管道是保存在内存中的缓冲区的。但是会被按照文件进行管理。

```c
#include<stdio.h>
#include<stdlib.h>
#include<string.h>
#include<sys/types.h>
#include<unistd.h>

void read_from_pipe(int fd){
	char message[100] ;
	read(fd, message, 100) ;
	printf("read from pipe:%s", message) ;
}

void write_to_pipe(int fd){
	char *message = "My Pipe\n" ;
	write(fd, message, strlen(message)+1) ;
}
int main(){
	int fd[2] ;
	pid_t pid ;
	int stat_val ;

	if(pipe(fd)){
		printf("create pipe fail\n") ;
		return 0;
	}
	if( !(pid=fork()) ){	//son close write port
		close(fd[1]) ;
		read_from_pipe(fd[0]) ;
		exit(0) ;
	}else{
		close(fd[0]) ;  //father close read port
		write_to_pipe(fd[1]) ;
		wait(&stat_val) ;
		exit(0) ;
	} 
	return 0;
}
		
```

> 管道只能用于亲缘关系的进程半双工单项通信，在fork创建子进程之前，父进程要打开管道创建一个i节点和两个文件描述符，并且这两个文件描述符fd[0]标识读端，fd[1]表示写端，fork写时复制这两个文件句柄，父进程关闭读端，子进程关闭写端（也可以是父进程关闭写端，子进程关闭读端，实际上是内核中开辟一个缓冲区（大小多少？）按照FIFO队列的形式实现一个端读一个端写。内核保证少量数据的读写操作的原子性。

##### 有名管道

跟管道一样是半双工通信，但是可以在无亲缘关系的进程之间通信。有名管道实际上创建了一个文件，只是这个文件以FIFO的形式进行读写（写进程创建有名管道文件，并且以只写打开，读进程以只读打开）

> **有名管道写端**
>
> ```c
> #include<stdio.h>
> #include<stdlib.h>
> #include<string.h>
> #include<sys/types.h>
> #include<unistd.h>
> #include<fcntl.h>
> #include<sys/stat.h>
> 
> #define FILENAME "myfifo"
> #define BUFFER 1024
> 
> 
> int main(){
> 	int fd;
> 	char buf[BUFFER] = "Hello, named pipe\n" ;
> 	umask(0) ;
> 
> 	printf("aaa\n") ;
> 
> 	if(mkfifo(FILENAME, S_IFIFO | 0666)==-1){
> 		exit(1) ;
> 	}
> 	printf("bbb") ;
> 	if( (fd=open(FILENAME, O_WRONLY) )==-1){
> 		exit(1) ;
> 	}
> 	printf("asdf") ;
> 	write(fd, buf, strlen(buf)+1 ) ;
> 	close(fd) ;
> 	exit(0) ;
> }
> ```
>
> **有名管道读端**
>
> 当运行有名管道写端的时候会阻塞有名写进程，当运行读端的时候会激活写端写
>
> ```c
> #include<stdio.h>
> #include<stdlib.h>
> #include<string.h>
> #include<sys/types.h>
> #include<unistd.h>
> #include<fcntl.h>
> #include<sys/stat.h>
> 
> #define FILENAME "myfifo"
> #define BUFFER 1024
> 
> 
> int main(){
> 	int fd;
> 	char buf[BUFFER] ;
> 	umask(0) ;
> 
> 	fd=open(FILENAME, O_RDONLY) ;
> 
> 	read(fd, buf, BUFFER) ;
> 	printf("Read from named pipe: %s", buf) ;
> 	close(fd) ;
> 	exit(0) ;
> }
> ```
>
> 

##### 共享内存

https://blog.csdn.net/pk296256948/category_9960741.html

https://blog.csdn.net/pk296256948/article/details/106661627

共享内存是最快的通信方式，他是为了克服其他通信方式而开发的，可以让多进程共享内存数据，共享内存总是配合信号量使用

> 共享内存写端
>
> ```c
> #include <sys/ipc.h>
> #include <sys/shm.h>
> #include <sys/types.h>
> #include <unistd.h>
> #include <string.h>
> #include <stdio.h>
> 
> int main()
> {
>     int shmid;
>     char *ptr;
>     char *shm_str="this is a share memory";
>     shmid=shmget(0x90,1024,SHM_W|SHM_R|IPC_CREAT|IPC_EXCL);    //创建共享内存
> 
>     if(-1==shmid)
>     {
>         perror("create share memory");
>     }
> 
>     ptr=(char*)shmat(shmid,0,0);    //获取共享内存首地址
>     if((void *)-1==ptr)
>     {
>         perror("get share memory");
>     }
>     strcpy(ptr,shm_str);    //写入数据
>     shmdt(ptr);     //分离共享内存
> 
>     return 0;
> }
> 
> ```
>
> 共享内存读端
>
> ```c
> #include <sys/ipc.h>
> #include <sys/shm.h>
> #include <sys/types.h>
> #include <unistd.h>
> #include <string.h>
> #include <stdio.h>
> 
> int main()
> {
>     int shmid;
>     char *ptr;
>     
>     shmid=shmget(0x90,1024,SHM_W|SHM_R|IPC_EXCL);    //根据key获取共享内存ID
> 
>     if(-1==shmid)
>     {
>         perror("create share memory");
>     }
> 
>     ptr=(char*)shmat(shmid,0,0);    //获取共享内存首地址
>     if((void *)-1==ptr)
>     {
>         perror("get share memory");
>     }
>     printf("share memory:%s\n",ptr);     //打印数据
> 
>     shmdt(ptr);     //分离共享内存
>     
>     if (shmctl(shmid, IPC_RMID, 0) == -1)     //释放内存
>     {
>         perror("shmctl(IPC_RMID) failed\n");
> 		return -1;
>     }
>     
>     return 0;
> }
> 
> ```
>
> 

##### 消息队列

[(109条消息) linux 消息队列_码农客栈的博客-CSDN博客_linux消息队列](https://blog.csdn.net/ckg3824278/article/details/87907885)

消息队列是加强版的管道，管道不能读有类型的数据，而消息队列传递的是有类型的数据

消息队列是消息的链表，存放在内核中并由消息标识符标记，它克服了信号传递数据量少，管道只能承载无格式字节流并且缓冲区大小受限的缺点。

> **发送端**
>
> ```c
> //msg_send.c
> #include <stdio.h>
> #include <sys/types.h>
> #include <sys/ipc.h>
> #include <stdlib.h>
> #include <sys/types.h>
> #include <sys/ipc.h>
> #include <sys/msg.h>
> #include <errno.h> //错误宏
> #include <string.h>
> #include <stdlib.h>
> #include <unistd.h>
> 
> 
> #define PATH "/home/cheng/Desktop/Linux/work/msg"
> 
> struct msgbuf 
> {
>    long mtype; 
>    char mtext[1024];
> };
> 
> int main()
> {
> 	//创建一个对象的KEY值 
>     key_t key=ftok(PATH,66);
> 	if(key < 0)
> 	{
> 		perror("");
> 		exit(0);
> 	}
> 
> 		
> 	int msgid=0;
> label:	 
> 	//获取消息队列的对象ID 
> 	msgid=msgget(key,IPC_CREAT|IPC_EXCL|0666);
> 	if(msgid < 0)
> 	{
> 		//perror("creat fail\n");
> 		//处理错误信息 
> 		if(errno == EEXIST)
> 		{
> 			//printf("对象ID已经存在啦！\n");
> 			//删除
> 			char del[1024]={0};
> 			sprintf(del,"ipcrm  -Q %d",key);
> 			system(del);
> 			
> 			goto label;
> 		}
> 	}
> 	else 
> 	{
> 		printf("创建消息队列成功\n");
> 	}
> 	struct msgbuf  date;  
> 	date.mtype = 123; //设置类型 
> 	//date.mtext = "hello world";
> 	
> 	while(1)
> 	{
> 		//数据的发送
> 		scanf("%s",date.mtext);
> 		msgsnd(msgid,&date,strlen(date.mtext),0);
> 	}
> 	
> 	//销毁消息队列  
> 	msgctl(msgid,IPC_RMID,NULL);
> 	return 0;
> }
> ```
>
> **接收端**
>
> > ```c
> > //msg_recv.c
> > #include <stdio.h>
> > #include <sys/types.h>
> > #include <sys/ipc.h>
> > #include <stdlib.h>
> > #include <sys/types.h>
> > #include <sys/ipc.h>
> > #include <sys/msg.h>
> > #include <errno.h> //错误宏
> > #include <string.h>
> > #include <stdlib.h>
> > #include <unistd.h>
> > 
> > #define PATH "/home/cheng/Desktop/Linux/work/msg"
> > 
> > struct msgbuf 
> > {
> >    long mtype; 
> >    char mtext[1024];
> > };
> > 
> > int main(int argc,char *argv[])
> > {
> > 	//创建一个对象的KEY值 
> >     key_t key=ftok(PATH,66);
> > 	if(key < 0)
> > 	{
> > 		perror("");
> > 		exit(0);
> > 	}
> > 
> > 	//获取消息队列的对象ID 
> > 	int msgid=msgget(key,IPC_CREAT|0666);
> > 	if(msgid < 0)
> > 	{
> > 		perror("creat fail\n");
> > 	}
> > 	else 
> > 	{
> > 		printf("创建消息队列成功\n");
> > 	}
> > 		
> > 	//读取消息队列中的数据
> > 	while(1)
> > 	{	
> > 		struct msgbuf  date;
> > 		bzero(&date,sizeof(date));		
> > 		msgrcv(msgid,&date,sizeof(date),123,0);
> > 		printf("date = %s\n",date.mtext);
> > 	}
> > 		
> > 	//销毁消息队列  
> > 	msgctl(msgid,IPC_RMID,NULL);
> > 	return 0;
> > 
> > ```



##### 套接字

实现不同机器之间的进程通信

### 内存管理

实验6-共享内存的实现

| brk         | 改变数据段空间的分配         |
| ----------- | ---------------------------- |
| sbrk        | 参见brk                      |
| mlock       | 内存页面加锁                 |
| munlock     | 内存页面解锁                 |
| mlockall    | 调用进程所有内存页面加锁     |
| munlockall  | 调用进程所有内存页面解锁     |
| mmap        | 映射虚拟内存页               |
| munmap      | 去除内存页映射               |
| mremap      | 重新映射虚拟内存地址         |
| msync       | 将映射内存中的数据写回磁盘   |
| mprotect    | 设置内存映像保护             |
| getpagesize | 获取页面大小                 |
| sync        | 将内存缓冲区数据写回硬盘     |
| cacheflush  | 将指定缓冲区中的内容写回磁盘 |

### 设备管理

实验7-终端设备的控制

#### 字符设备管理-控制台管理（涉及硬件鼠标、键盘、显示器）

设备结构体包括termios结构用于存储输出到控制台(显示器)的参数，write函数指针用于保存写控制台设备的写函数，对于控制台管理，写函数时con_write函数写到显示器内存（con_write将控制台设备结构体的写缓冲队列的数据转移到控制台的显卡中（这是一段操作系统内存），包括写缓冲队列，读缓冲队列和辅助队列（循环队列）。

用户程序scanf读数据时，调用read系统调用，read系统调用调用tty_read函数从键盘设备结构体的读缓冲队列读数据，如果发现缓冲队列为空就阻塞到键盘辅助缓冲队列；按下键盘发生键盘中断，键盘扫描码区分使用的键盘中断处理子函数，一般函数是键盘中断函数从键盘端口获取扫描码，键盘中断处理子函数将扫描码用扫描码映射表将扫描码映射到对应的字符之后放入键盘设备结构体的读缓冲队列，然后调用copy_to_cooked函数把键盘读缓冲队列的数据经过规范化转义之后放入辅助队列，如果设置了回显，则还会把这个字符写入到控制台写缓冲队列，然后调用con_write()函数把控制台缓冲队列的数据写到显卡内存中，之后wake_up唤醒阻塞在键盘辅助队列上的进程；当阻塞在键盘辅助队列上的进程被唤醒并重新执行后，进程从辅助缓冲队列读取字符并使用put_fs_char将这个字符写入到用户空间的变量中。

用户程序printf写控制台的时候，调用write系统调用，write系统调用调用tty_write内核函数，tty_write内核函数检查控制台设备结构体的写缓冲队列是否为满，如果满了就阻塞到控制台写缓冲队列，否则将用户空间的字符串get_fs_char拷贝到控制台设备写缓冲队列，然后调用控制台写函数con_write(控制台write函数指针保存con_write函数地址)将数据写出到控制台。

#### 字符设备管理-网络设备管理（涉及硬件网卡）

计算机网络以来网络管理实现，底层调用的是Linux网络管理提供的socket系统调用。

1. 主机网络控制

   | getdomainname | 取域名         |
   | ------------- | -------------- |
   | setdomainname | 设置域名       |
   | gethostid     | 获取主机标识号 |
   | sethostid     | 设置主机标识号 |
   | gethostname   | 获取本主机名称 |
   | sethostname   | 设置主机名称   |

2. Socket控制

- | socketcall  | socket系统调用             |
  | ----------- | -------------------------- |
  | socket      | 建立socket                 |
  | bind        | 绑定socket到端口           |
  | connect     | 连接远程主机               |
  | accept      | 响应socket连接请求         |
  | send        | 通过socket发送信息         |
  | sendto      | 发送UDP信息                |
  | sendmsg     | 参见send                   |
  | recv        | 通过socket接收信息         |
  | recvfrom    | 接收UDP信息                |
  | recvmsg     | 参见recv                   |
  | listen      | 监听socket端口             |
  | select      | 对多路同步I/O进行轮询      |
  | shutdown    | 关闭socket上的连接         |
  | getsockname | 取得本地socket名字         |
  | getpeername | 获取通信对方的socket名字   |
  | getsockopt  | 取端口设置                 |
  | setsockopt  | 设置端口参数               |
  | sendfile    | 在文件或端口间传输数据     |
  | socketpair  | 创建一对已联接的无名socket |

#### 块设备管理-磁盘管理（涉及硬件磁盘）

磁盘管理没有提供太多系统调用，他大多是内核函数，被文件系统调用构成了文件熊的底层驱动磁盘的模块。数据库系统是基于文件管理提供的系统调用来实现的。数据库文件就是一个普通的文件，通过文件的相关系统调用访问。

1. 磁盘管理函数

   bread函数/ll_rw_blk等读写磁盘的驱动程序，被文件系统调用来访问磁盘。

### 文件管理(磁盘块设备; 数据库系统/索引和文件存储)

实验8-虚拟文件系统的实现

- Linux文件系统调用

  Linux文件系统时Linux提供的数据持久化技术。Linux操作系统能提供的数据存储方式有两种，一种是内存管理将数据保存在内存中，随着断电会消失；一种是将数据保存到磁盘文件中，可以实现数据的长期保存，断电不会消失。MySQL等基于磁盘的数据库和Redis等基于内存的数据库的持久化技术都是文件管理系统提供的文件系统调用来操作的。

  1. 文件读写操作

     | fcntl     | 文件控制                     |
     | --------- | ---------------------------- |
     | open      | 打开文件                     |
     | creat     | 创建新文件                   |
     | close     | 关闭文件描述字               |
     | read      | 读文件                       |
     | write     | 写文件                       |
     | readv     | 从文件读入数据到缓冲数组中   |
     | writev    | 将缓冲数组里的数据写入文件   |
     | pread     | 对文件随机读                 |
     | pwrite    | 对文件随机写                 |
     | lseek     | 移动文件指针                 |
     | _llseek   | 在64位地址空间里移动文件指针 |
     | dup       | 复制已打开的文件描述字       |
     | dup2      | 按指定条件复制文件描述字     |
     | flock     | 文件加/解锁                  |
     | poll      | I/O多路转换                  |
     | truncate  | 截断文件                     |
     | ftruncate | 参见truncate                 |
     | umask     | 设置文件权限掩码             |
     | fsync     | 把文件在内存中的部分写回磁盘 |

  2. 文件系统操作

     | access   | 确定文件的可存取性     |
     | -------- | ---------------------- |
     | chdir    | 改变当前工作目录       |
     | fchdir   | 参见chdir              |
     | chmod    | 改变文件方式           |
     | fchmod   | 参见chmod              |
     | chown    | 改变文件的属主或用户组 |
     | fchown   | 参见chown              |
     | lchown   | 参见chown              |
     | chroot   | 改变根目录             |
     | stat     | 取文件状态信息         |
     | lstat    | 参见stat               |
     | fstat    | 参见stat               |
     | statfs   | 取文件系统信息         |
     | fstatfs  | 参见statfs             |
     | readdir  | 读取目录项             |
     | getdents | 读取目录项             |
     | mkdir    | 创建目录               |
     | mknod    | 创建索引节点           |
     | rmdir    | 删除目录               |
     | rename   | 文件改名               |
     | link     | 创建链接               |
     | symlink  | 创建符号链接           |
     | unlink   | 删除链接               |
     | readlink | 读符号链接的值         |
     | mount    | 安装文件系统           |
     | umount   | 卸下文件系统           |
     | ustat    | 取文件系统信息         |
     | utime    | 改变文件的访问修改时间 |
     | utimes   | 参见utime              |
     | quotactl | 控制磁盘配额           |

- C语言文件系统操作函数

  [C library function - fwrite() (tutorialspoint.com)](https://www.tutorialspoint.com/c_standard_library/c_function_fwrite.htm)

  [(108条消息) 【C 语言】文件操作 ( fwrite 函数 )_韩曙亮的博客-CSDN博客_fwrite](https://blog.csdn.net/shulianghan/article/details/117376038)

  [(108条消息) C语言文件操作详解_miqi1227的博客-CSDN博客_c语言文件操作](https://blog.csdn.net/u010994304/article/details/50265681)

  [(108条消息) C语言文件操作（含详细步骤）_zjruiiiiii的博客-CSDN博客_c文件操作](https://blog.csdn.net/ZJRUIII/article/details/120552735)

  [C 库函数 – fscanf() | 菜鸟教程 (runoob.com)](https://www.runoob.com/cprogramming/c-function-fscanf.html)

  C语言文件操作函数是封装Linux操作系统文件系统调用API完成的函数。可以通过C语言文件操作函数实现文件保存和数据持久化技术。

  Linux把输入输出设备都当成文件来处理

  C语言文件结构体FILE定义的内容

  ```
  //Linux0.11 使用的stdio.h
  //其中定义了文件结构体FILE和文件操作函数
  
  #ifndef _STDIO_H
  #define _STDIO_H
  
  /*			s t d i o
   *
   *		Author: C. E. Chew
   *		Date:   August 1989
   *
   * (C) Copyright C E Chew
   *
   * Feel free to copy, use and distribute this software provided:
   *
   *	1. you do not pretend that you wrote it
   *	2. you leave this copyright notice intact.
   *
   * Definitions and user interface for the stream io package.
   *
   * Patchlevel 2.0
   *
   * Edit History:
   */
  
  /* Site specific definitions */
  /*@*/
  #ifndef NULL
  # define NULL	((void *)0)
  #endif
  #define _STDIO_UCHAR_		0
  #define _STDIO_VA_LIST_		char *
  #define _STDIO_SIZE_T_		unsigned int	  /* type returned by sizeof */
  #define _STDIO_USIZE_T_		unsigned int
  /*=*/
  
  /* Definitions based on ANSI compiler */
  #ifdef		__STDC__
  # ifndef	_STDIO_P_
  #   define	_STDIO_P_(x)		x
  # endif
  # ifndef	_STDIO_VA_
  #   define	_STDIO_VA_		, ...
  # endif
  # ifndef	_STDIO_UCHAR_
  #   define	_STDIO_UCHAR_		0
  # endif
  #else
  # ifndef	_STDIO_P_
  #   define	_STDIO_P_(x)		()
  # endif
  # ifndef	_STDIO_VA_
  #   define	_STDIO_VA_
  # endif
  # ifndef	_STDIO_UCHAR_
  #   define	_STDIO_UCHAR_		(0xff)
  # endif
  #endif
  
  #ifndef		_STDIO_VA_LIST_
  #  define	_STDIO_VA_LIST_		void *
  #endif
  
  #ifndef		_STDIO_SIZE_T_
  #  define	_STDIO_SIZE_T_		unsigned int
  #endif
  
  #ifndef		_STDIO_USIZE_T_
  #  define	_STDIO_USIZE_T_		unsigned int
  #endif
  
  /* ANSI Definitions */
  #define BUFSIZ 1024			/* default buffer size */
  
  #ifndef	NULL
  # define NULL		((void *) 0)	/* null pointer */
  #endif
  
  #define EOF		(-1)		/* eof flag */
  #define FOPEN_MAX	16		/* minimum guarantee */
  #define FILENAME_MAX	127		/* maximum length of file name */
  
  #define SEEK_SET	0		/* seek from beginning */
  #define SEEK_CUR	1		/* seek from here */
  #define SEEK_END	2		/* seek from end */
  
  #define TMP_MAX		(0xffff)	/* maximum number of temporaries */
  
  #define L_tmpnam	(5 + 8 + 4 + 1 + 1) /* length of temporary file name */
  
  #ifndef _FPOS_T
  # define _FPOS_T
    typedef long fpos_t;			/* stream positioning */
  #endif
  
  #ifndef	_SIZE_T
  # define _SIZE_T
    typedef _STDIO_SIZE_T_ size_t;	/* sizeof type */
  #endif
  
  #define _IOFBF		000000		/* fully buffered io */
  #define _IOREAD		000001		/* opened for reading */
  #define _IOWRITE	000002		/* opened for writing */
  #define _IONBF		000004		/* unbuffered */
  #define _IOMYBUF	000010		/* allocated buffer */
  #define _IOPOOLBUF	000020		/* buffer belongs to pool */
  #define _IOEOF		000040		/* eof encountered */
  #define _IOERR		000100		/* error encountered */
  #define _IOSTRING	000200		/* strings */
  #define _IOLBF		000400		/* line buffered */
  #define _IORW		001000		/* opened for reading and writing */
  #define _IOAPPEND	002000		/* append mode */
  #define _IOINSERT	004000		/* insert into __iop chain */
  #define _IOSTDX		030000		/* standard stream */
  
  #define _IOSTDIN	010000		/* stdin indication */
  #define _IOSTDOUT	020000		/* stdout indication */
  #define _IOSTDERR	030000		/* stderr indication */
  
  #define _IORETAIN	(_IOSTDX | _IOINSERT)	/* flags to be retained */
  
  /* Implementation Definitions */
  
  typedef char __stdiobuf_t;		/* stdio buffer type */
  typedef _STDIO_USIZE_T_ __stdiosize_t;	/* unsigned size_t */
  
  typedef struct __iobuf {
    __stdiobuf_t *__rptr;			/* pointer into read buffer */
    __stdiobuf_t *__rend;			/* point at end of read buffer */
    __stdiobuf_t *__wptr;			/* pointer into write buffer */
    __stdiobuf_t *__wend;			/* point at end of write buffer */
    __stdiobuf_t *__base;			/* base of buffer */
    __stdiosize_t __bufsiz;		/* size of buffer */
    short __flag;				/* flags */
    char __file;				/* channel number */
    __stdiobuf_t __buf;			/* small buffer */
    int (*__filbuf) _STDIO_P_((struct __iobuf *));      /* fill input buffer */
    int (*__flsbuf) _STDIO_P_((int, struct __iobuf *)); /* flush output buffer */
    int (*__flush) _STDIO_P_((struct __iobuf *));	/* flush buffer */
    struct __iobuf *__next;		/* next in chain */
  } FILE;
  
  extern FILE __stdin;			/* stdin */
  extern FILE __stdout;			/* stdout */
  extern FILE __stderr;			/* stderr */
  
  #define stdin		(&__stdin)
  #define stdout		(&__stdout)
  #define stderr		(&__stderr)
  
  /* ANSI Stdio Requirements */
  
  int	getc		_STDIO_P_((FILE *));
  #if	_STDIO_UCHAR_
  # define getc(p)	((p)->__rptr>=(p)->__rend\
  			 ?(*(p)->__filbuf)(p)\
  			 :(int)(*(p)->__rptr++&_STDIO_UCHAR_))
  #else
  # define getc(p)	((p)->__rptr>=(p)->__rend\
  			 ?(*(p)->__filbuf)(p)\
  			 :(int)((unsigned char)(*(p)->__rptr++)))
  #endif
  
  int	getchar		_STDIO_P_((void));
  #define getchar()	getc(stdin)
  
  int	putc		_STDIO_P_((int, FILE *));
  #if	_STDIO_UCHAR_
  # define putc(x,p)	((p)->__wptr>=(p)->__wend\
                           ?(*(p)->__flsbuf)((x),(p))\
  	                 :(int)(*(p)->__wptr++=(x)&_STDIO_UCHAR_))
  #else
  # define putc(x,p)	((p)->__wptr>=(p)->__wend\
                           ?(*(p)->__flsbuf)((x),(p))\
  	                 :(int)((unsigned char)(*(p)->__wptr++=(x))))
  #endif
  
  int	putchar		_STDIO_P_((int));
  #define	putchar(x)	putc(x,stdout)
  
  int	feof		_STDIO_P_((FILE *));
  #define feof(p)		(((p)->__flag&_IOEOF)!=0)
  
  int	ferror		_STDIO_P_((FILE *));
  #define ferror(p)	(((p)->__flag&_IOERR)!=0)
  
  void	clearerr	_STDIO_P_((FILE *));
  #define clearerr(p)	((p)->__flag&=~(_IOEOF|_IOERR))
  
  FILE 	*fopen		_STDIO_P_((const char *, const char *));
  FILE	*freopen	_STDIO_P_((const char *, const char *, FILE *));
  int	fflush		_STDIO_P_((FILE *));
  int	fclose		_STDIO_P_((FILE *));
  
  int	fgetpos		_STDIO_P_((FILE *, fpos_t *));
  int	fsetpos		_STDIO_P_((FILE *, fpos_t *));
  long	ftell		_STDIO_P_((FILE *));
  int	fseek		_STDIO_P_((FILE *, long, int));
  void	rewind		_STDIO_P_((FILE *));
  
  int	fgetc		_STDIO_P_((FILE *));
  int	fputc		_STDIO_P_((int, FILE *));
  __stdiosize_t	fread	_STDIO_P_((void *, __stdiosize_t,
  				   __stdiosize_t, FILE *));
  __stdiosize_t	fwrite	_STDIO_P_((void *, __stdiosize_t,
  				   __stdiosize_t, FILE *));
  
  int	getw		_STDIO_P_((FILE *));
  int	putw		_STDIO_P_((int, FILE *));
  char	*gets		_STDIO_P_((char *));
  char	*fgets		_STDIO_P_((char *, int, FILE *));
  int	puts		_STDIO_P_((const char *));
  int	fputs		_STDIO_P_((const char *, FILE *));
  
  int	ungetc		_STDIO_P_((int, FILE *));
  
  int	printf		_STDIO_P_((const char * _STDIO_VA_));
  int	fprintf		_STDIO_P_((FILE *, const char * _STDIO_VA_));
  int	sprintf		_STDIO_P_((char *, const char * _STDIO_VA_));
  int	vprintf		_STDIO_P_((const char *, _STDIO_VA_LIST_));
  int	vfprintf	_STDIO_P_((FILE *, const char *, _STDIO_VA_LIST_));
  int	vsprintf	_STDIO_P_((char *, const char *, _STDIO_VA_LIST_));
  int	scanf		_STDIO_P_((const char * _STDIO_VA_));
  int	fscanf		_STDIO_P_((FILE *, const char * _STDIO_VA_));
  int	sscanf		_STDIO_P_((const char *, const char * _STDIO_VA_));
  
  void	setbuf		_STDIO_P_((FILE *, char *));
  int	setvbuf		_STDIO_P_((FILE *, char *, int, __stdiosize_t));
  
  int	rename		_STDIO_P_((const char *, const char *));
  int	remove		_STDIO_P_((const char *));
  
  void	perror		_STDIO_P_((const char *));
  
  char *	tmpnam		_STDIO_P_((char *));
  FILE *	tmpfile		_STDIO_P_((void));
  
  /* Posix Definitions */
  int	unlink		_STDIO_P_((const char *));
  #define remove(x)	unlink((x))
  
  #define L_ctermid	9
  char *	ctermid		_STDIO_P_((char *s));
  
  #define L_cuserid	9
  char *	cuserid		_STDIO_P_((char *s));
  
  FILE	*fdopen		_STDIO_P_((int, const char *));
  
  int	fileno		_STDIO_P_((FILE *));
  #define fileno(p)	((p)->__file)
  
  #undef	_STDIO_P_
  #undef	_STDIO_VA_
  #undef	_STDIO_VA_LIST_
  /*ndef	_STDIO_UCHAR_*/
  #undef	_STDIO_SIZE_T_
  #undef	_STDIO_USIZE_T_
  #endif
  ```

  | 函数原型                                                     | 参数说明和函数作用                                           |
  | ------------------------------------------------------------ | ------------------------------------------------------------ |
  | FILE* fopen(char* pname, char *mode)                         | 打开文件，传递文件名和打开方式（只读、只写、可读写，还有一个概念是访问权限，这是文件inode节点保存的） |
  | int fclose(FILE* fp)                                         | 关闭文件，传递参数要关闭的文件文件指针                       |
  | int fgetc(FILE* fp)                                          | 从文件指针fp中读取一个字符（文件指针fp中有一个变量f_pos指向当前文件读写位置，这个f_pos也是lseek移动的位置，lseek会使用的三个位置变量是文件起始地址，文件结束地址和当前位置） |
  | int fputc(int ch, FILE* fp)                                  | 将字符写入文件                                               |
  | char* fgets(char* str, int n, FILE *fp)                      | 从文件指针fp中读取n-1个字符并放到用户变量str中，并在str中添加'\0'字符代表字符串结束，返回str首地址 |
  | int fputs(char* str, FILE* fp)                               | 将str字符串除去'\0'字符后写入文件指针fp，返回写入成功字符个数 |
  | int fscanf(FILE* fp, const char* format, arg_list)           | 类似scanf，从文件中读格式化数据                              |
  | int fprintf(FILE* fp, char* format, arg_list)                | 类似printf，往文件写格式化数据                               |
  | int fread(void* buff, unsigned size, unsigned elem, FILE* fp) | 从文件指针fp中读取size*elem个字符到buff数据指针中            |
  | int fwite(void* buff, unsigned size, unsigned elem, FILE* fp) | 将数据指针buff的size*elem个字符输出到文件，返回成功个数      |
  | int getw(FILE* fp)                                           | 从文件指针fp中读一个整数                                     |
  | int putw(int n, FILE* fp)                                    | 写一个整数到文件指针fp中，返回写如的整数                     |
  | int feof(FILE* fp)                                           | 判断文件是否结束                                             |
  | int ferror(FILE* fp)                                         | 检查由fp指定的文件在读写啊时是否出错                         |
  | void clearerr(FILE* fp)                                      | 秦楚由fp指定文件的错误标志                                   |
  | long ftell(FILE* fp)                                         | 取得文件读写位置，用和文件开头偏移量表示                     |
  | void rewind(FILE* fp)                                        | 重置文件读写指针到文件开头位置                               |
  | int fseek(FILE* fp, long offset, int base)                   | 使文件指针fp的读写位置移动到base+offset处，返回移动后的读写位置 |
  | void exit(int status)                                        | 进程退出程序，在其中会将缓冲区数据写出到磁盘文件并且关闭文件 |
  | int feof(FILE* fp)                                           | 判断文件是否结束。                                           |

Linux文件系统调用实现：

#### 文件创建/打开/关闭系统调用sys_create/sys_open/sys_close

```c
/*
 *  linux/fs/open.c
 *
 *  (C) 1991  Linus Torvalds
 */

/* #include <string.h> */
#include <errno.h>
#include <fcntl.h>
#include <sys/types.h>
#include <utime.h>
#include <sys/stat.h>

#include <linux/sched.h>
#include <linux/tty.h>
#include <linux/kernel.h>
#include <asm/segment.h>

int sys_ustat(int dev, struct ustat * ubuf)
{
	return -ENOSYS;
}

int sys_utime(char * filename, struct utimbuf * times)
{
	struct m_inode * inode;
	long actime,modtime;

	if (!(inode=namei(filename)))
		return -ENOENT;
	if (times) {
		actime = get_fs_long((unsigned long *) &times->actime);
		modtime = get_fs_long((unsigned long *) &times->modtime);
	} else
		actime = modtime = CURRENT_TIME;
	inode->i_atime = actime;
	inode->i_mtime = modtime;
	inode->i_dirt = 1;
	iput(inode);
	return 0;
}

/*
 * XXX should we use the real or effective uid?  BSD uses the real uid,
 * so as to make this call useful to setuid programs.
 */
int sys_access(const char * filename,int mode)
{
	struct m_inode * inode;
	int res, i_mode;

	mode &= 0007;
	if (!(inode=namei(filename)))
		return -EACCES;
	i_mode = res = inode->i_mode & 0777;
	iput(inode);
	if (current->uid == inode->i_uid)
		res >>= 6;
	else if (current->gid == inode->i_gid)
		res >>= 6;
	if ((res & 0007 & mode) == mode)
		return 0;
	/*
	 * XXX we are doing this test last because we really should be
	 * swapping the effective with the real user id (temporarily),
	 * and then calling suser() routine.  If we do call the
	 * suser() routine, it needs to be called last. 
	 */
	if ((!current->uid) &&
	    (!(mode & 1) || (i_mode & 0111)))
		return 0;
	return -EACCES;
}

int sys_chdir(const char * filename)
{
	struct m_inode * inode;

	if (!(inode = namei(filename)))
		return -ENOENT;
	if (!S_ISDIR(inode->i_mode)) {
		iput(inode);
		return -ENOTDIR;
	}
	iput(current->pwd);
	current->pwd = inode;
	return (0);
}

int sys_chroot(const char * filename)
{
	struct m_inode * inode;

	if (!(inode=namei(filename)))
		return -ENOENT;
	if (!S_ISDIR(inode->i_mode)) {
		iput(inode);
		return -ENOTDIR;
	}
	iput(current->root);
	current->root = inode;
	return (0);
}

int sys_chmod(const char * filename,int mode)
{
	struct m_inode * inode;

	if (!(inode=namei(filename)))
		return -ENOENT;
	if ((current->euid != inode->i_uid) && !suser()) {
		iput(inode);
		return -EACCES;
	}
	inode->i_mode = (mode & 07777) | (inode->i_mode & ~07777);
	inode->i_dirt = 1;
	iput(inode);
	return 0;
}

int sys_chown(const char * filename,int uid,int gid)
{
	struct m_inode * inode;

	if (!(inode=namei(filename)))
		return -ENOENT;
	if (!suser()) {
		iput(inode);
		return -EACCES;
	}
	inode->i_uid=uid;
	inode->i_gid=gid;
	inode->i_dirt=1;
	iput(inode);
	return 0;
}

/*
打开文件操作：从进程打开文件表中找到一个null的文件句柄fd，从系统打开表file_table找到一个空文件描述符，使用open_namei根据名字从磁盘中加载对应的inode节点到inode表inode_table中，如果不存在并且打开文件方式不是create，那么报错，否则创建一个新inode节点在磁盘中并且加载到inode_table，之后设置文件句柄指向文件描述符，设置文件描述符参数，将inode指针赋值给文件描述符。*/
int sys_open(const char * filename,int flag,int mode)
{
	struct m_inode * inode;
	struct file * f;
	int i,fd;

	mode &= 0777 & ~current->umask;
	for(fd=0 ; fd<NR_OPEN ; fd++)
		if (!current->filp[fd])
			break;
	if (fd>=NR_OPEN)
		return -EINVAL;
	current->close_on_exec &= ~(1<<fd);
	f=0+file_table;
	for (i=0 ; i<NR_FILE ; i++,f++)
		if (!f->f_count) break;
	if (i>=NR_FILE)
		return -EINVAL;
	(current->filp[fd]=f)->f_count++;
	if ((i=open_namei(filename,flag,mode,&inode))<0) {
		current->filp[fd]=NULL;
		f->f_count=0;
		return i;
	}
/* ttys are somewhat special (ttyxx major==4, tty major==5) */
	if (S_ISCHR(inode->i_mode)) {
		if (MAJOR(inode->i_zone[0])==4) {
			if (current->leader && current->tty<0) {
				current->tty = MINOR(inode->i_zone[0]);
				tty_table[current->tty].pgrp = current->pgrp;
			}
		} else if (MAJOR(inode->i_zone[0])==5)
			if (current->tty<0) {
				iput(inode);
				current->filp[fd]=NULL;
				f->f_count=0;
				return -EPERM;
			}
	}
/* Likewise with block-devices: check for floppy_change */
	if (S_ISBLK(inode->i_mode))
		check_disk_change(inode->i_zone[0]);
	f->f_mode = inode->i_mode;
	f->f_flags = flag;
	f->f_count = 1;
	f->f_inode = inode;
	f->f_pos = 0;
	return (fd);
}

//sys_create使用sys_open来创立文件
int sys_creat(const char * pathname, int mode)
{
	return sys_open(pathname, O_CREAT | O_TRUNC, mode);
}

/*
关闭文件：令文件句柄为null，减少对应文件描述符的文件句柄引用数量，如果引用数量为0，那么iput释放这个inode到磁盘。
*/
int sys_close(unsigned int fd)
{	
	struct file * filp;

	if (fd >= NR_OPEN)
		return -EINVAL;
	current->close_on_exec &= ~(1<<fd);
	if (!(filp = current->filp[fd]))
		return -EINVAL;
	current->filp[fd] = NULL;
	if (filp->f_count == 0)
		panic("Close: file count is 0");
	if (--filp->f_count)
		return (0);
	iput(filp->f_inode);
	return (0);
}
```



#### 读写文件和移动文件读写指针系统调用sys_read/sys_write/sys_lseek的实现

**fs/read_write.c**实现了sys_read/sys_write/sys_lseek，对于sys_read/sys_write而言，计算机把所有可以被读写的设备都当成文件来处理，所以sys_read/sys_write是一个顶层函数，具体读取文件的操作会根据文件类型i_node->i_mode来具体调用读写函数。

```c
/*
 *  linux/fs/read_write.c
 *
 *  (C) 1991  Linus Torvalds
 */

#include <sys/stat.h>
#include <errno.h>
#include <sys/types.h>

#include <linux/kernel.h>
#include <linux/sched.h>
#include <asm/segment.h>

extern int rw_char(int rw,int dev, char * buf, int count, off_t * pos);
extern int read_pipe(struct m_inode * inode, char * buf, int count);
extern int write_pipe(struct m_inode * inode, char * buf, int count);
extern int block_read(int dev, off_t * pos, char * buf, int count);
extern int block_write(int dev, off_t * pos, char * buf, int count);
extern int file_read(struct m_inode * inode, struct file * filp,
		char * buf, int count);
extern int file_write(struct m_inode * inode, struct file * filp,
		char * buf, int count);
		
extern int proc_read(int dev,char* buf,int count,unsigned long *pos);

/*
移动文件读写指针系统调用传入参数：文件句柄fd，相对基准位置origin的偏移位置offset。origin有三种类型,SEEK_SET=0代表文件开头，SEEK_CUR=1代表当前文件读写指针位置，SEEK_END=2代表文件尾部，文件尾部可以通过FILE->f_inode->i_size从文件inode结构体获得文件总的size大小得到。
lseek根据origin和offset获取移动的文件指针，然后赋值到系统打开表文件句柄所对应的文件描述符项的文件读写指针FILE->f_pos，最后返回新的读写指针FILE->f-pos。
*/
int sys_lseek(unsigned int fd,off_t offset, int origin)
{
	struct file * file;
	int tmp;

	if (fd >= NR_OPEN || !(file=current->filp[fd]) || !(file->f_inode)
	   || !IS_SEEKABLE(MAJOR(file->f_inode->i_dev)))
		return -EBADF;
	if (file->f_inode->i_pipe)
		return -ESPIPE;
	switch (origin) {
		case 0:
			if (offset<0) return -EINVAL;
			file->f_pos=offset;
			break;
		case 1:
			if (file->f_pos+offset<0) return -EINVAL;
			file->f_pos += offset;
			break;
		case 2:
			if ((tmp=file->f_inode->i_size+offset) < 0)
				return -EINVAL;
			file->f_pos = tmp;
			break;
		default:
			return -EINVAL;
	}
	return file->f_pos;
}

/*
sys_read根据FILE->f_inode->i_mode中文件类型来选择对应的读写函数读写对应的设备
传入的参数是文件句柄fd，读入到用户缓冲区的指针buf，读入的字符个数，在调用对应的读写函数的时候要首先verify_area检查分配的线性空间是否可读，如果存在不可读的用户内存就要write_verify写时复制
*/
int sys_read(unsigned int fd,char * buf,int count)
{
	struct file * file;
	struct m_inode * inode;

	if (fd>=NR_OPEN || count<0 || !(file=current->filp[fd]))
		return -EINVAL;
	if (!count)
		return 0;
	verify_area(buf,count);
	inode = file->f_inode;
	if (inode->i_pipe)
		return (file->f_mode&1)?read_pipe(inode,buf,count):-EIO;
	if (S_ISCHR(inode->i_mode))
		return rw_char(READ,inode->i_zone[0],buf,count,&file->f_pos);
	if (S_ISBLK(inode->i_mode))
		return block_read(inode->i_zone[0],&file->f_pos,buf,count);
	if (S_ISDIR(inode->i_mode) || S_ISREG(inode->i_mode)) {
		if (count+file->f_pos > inode->i_size)
			count = inode->i_size - file->f_pos;
		if (count<=0)
			return 0;
		return file_read(inode,file,buf,count);
	}
	if (S_ISPROC(inode->i_mode))
		return proc_read(inode->i_zone[0],&file->f_pos,buf,count);
		
	printk("(Read)inode->i_mode=%06o\n\r",inode->i_mode);
	return -EINVAL;
}

int sys_write(unsigned int fd,char * buf,int count)
{
	struct file * file;
	struct m_inode * inode;
	
	if (fd>=NR_OPEN || count <0 || !(file=current->filp[fd]))
		return -EINVAL;
	if (!count)
		return 0;
	inode=file->f_inode;
	if (inode->i_pipe)
		return (file->f_mode&2)?write_pipe(inode,buf,count):-EIO;
	if (S_ISCHR(inode->i_mode))
		return rw_char(WRITE,inode->i_zone[0],buf,count,&file->f_pos);
	if (S_ISBLK(inode->i_mode))
		return block_write(inode->i_zone[0],&file->f_pos,buf,count);
	if (S_ISREG(inode->i_mode))
		return file_write(inode,file,buf,count);
	printk("(Write)inode->i_mode=%06o\n\r",inode->i_mode);
	return -EINVAL;
}
```

##### sys_read/sys_write读写普通文件的底层读写磁盘的内核函数file_read/file_write的实现

实现了sys_read/sys_write读写普通文件的底层读写磁盘的内核函数file_read/file_write

**进程打开文件表/系统打开表/文件inode结构**

> 进程打开文件表在进程PCB中定义为FILE* filep[NR_OPEN]，其中NR_OPEN=20表示进程最多打开文件数。进程打开文件表在**include/linux/sched.c**中定义为进程PCB结构的变量。进程打开文件表中的文件描述符的指针指向系统打开文件表中的文件描述符表表项，系统打开文件表在**include/linux/fs.h**中定义为外部变量，在**fs/file_table.c**中实际定义为文件描述符数组struct file file_table[NR_FILE]。
>
> 在Linux操作系统启动的时候挂载磁盘，会加载磁盘超级块到超级块数组，加载磁盘i节点位图到缓冲块并且将缓冲块指针赋值给超级块的i节点位图表中，加载逻辑位图到缓冲块并且将缓冲块指针赋值给超级块的逻辑块位图指针中。
>
> 当打开文件的时候，会根据文件名映射到对应的inode节点并从磁盘中读取inode节点信息保存到磁盘中，从系统打开表中找到一个空表项将inode赋值进去，初始化f_pos读写指针，打开文件方式flags，文件句柄数1，然后从进程打开文件表中获取一个空文件句柄，将新建的文件描述符指针赋值给这个文件句柄。
>
> ```
> extern struct m_inode inode_table[NR_INODE]; //inode数组，在fs/inode.c中定义，最多32项，一个inode标记一个记录一个文件的
> 											 //信息，inode数组在Linux操作系统启动的时候创建
> extern struct file file_table[NR_FILE];		 //系统打开表，在fs/file_table.c中定义，最多64项
> extern struct super_block super_block[NR_SUPER];	//超级块数组，一个超级块定义了一个磁盘的信息，最多8项
> extern struct buffer_head * start_buffer;			//内核缓冲块开始的位置，由编译器设置
> ```
>
> ```c
> // include/linux/sched.c中定义了PCB结构包含打开文件表
> struct task_struct {
> /* these are hardcoded - don't touch */
> 	long state;	/* -1 unrunnable, 0 runnable, >0 stopped */
> 	long counter;
> 	long priority;
> 	long signal;
> 	struct sigaction sigaction[32];
> 	long blocked;	/* bitmap of masked signals */
> /* various fields */
> 	int exit_code;
> 	unsigned long start_code,end_code,end_data,brk,start_stack;
> 	long pid,father,pgrp,session,leader;
> 	unsigned short uid,euid,suid;
> 	unsigned short gid,egid,sgid;
> 	long alarm;
> 	long utime,stime,cutime,cstime,start_time;
> 	unsigned short used_math;
> /* file system info */
> 	int tty;		/* -1 if no tty, so it must be signed */
> 	unsigned short umask;
> 	struct m_inode * pwd;
> 	struct m_inode * root;
> 	struct m_inode * executable;
> 	unsigned long close_on_exec;
> 	struct file * filp[NR_OPEN];
> /* ldt for this task 0 - zero 1 - cs 2 - ds&ss */
> 	struct desc_struct ldt[3];
> /* tss for this task */
> 	struct tss_struct tss;
> };
> ```
>
> ```c
> // fs/file_table.c定义了系统打开表（一个文件描述符数组，NR_FILE=64是系统文件最多数目）
> struct file file_table[NR_FILE];
> ```
>
> ```c
> // include/linux/fs.h定义了文件描述符结构体，inode结构体
> /*
>  * This file has definitions for some important file table
>  * structures etc.
>  */
> 
> #ifndef _FS_H
> #define _FS_H
> 
> #include <sys/types.h>
> 
> /* devices are as follows: (same as minix, so we can use the minix
>  * file system. These are major numbers.)
>  *
>  * 0 - unused (nodev)
>  * 1 - /dev/mem
>  * 2 - /dev/fd
>  * 3 - /dev/hd
>  * 4 - /dev/ttyx
>  * 5 - /dev/tty
>  * 6 - /dev/lp
>  * 7 - unnamed pipes
>  */
> 
> #define IS_SEEKABLE(x) ((x)>=1 && (x)<=3)
> 
> #define READ 0
> #define WRITE 1
> #define READA 2		/* read-ahead - don't pause */
> #define WRITEA 3	/* "write-ahead" - silly, but somewhat useful */
> 
> void buffer_init(long buffer_end);
> 
> #define MAJOR(a) (((unsigned)(a))>>8)
> #define MINOR(a) ((a)&0xff)
> 
> #define NAME_LEN 14
> #define ROOT_INO 1
> 
> #define I_MAP_SLOTS 8
> #define Z_MAP_SLOTS 8
> #define SUPER_MAGIC 0x137F
> 
> #define NR_OPEN 20
> #define NR_INODE 32
> #define NR_FILE 64
> #define NR_SUPER 8
> #define NR_HASH 307
> #define NR_BUFFERS nr_buffers
> #define BLOCK_SIZE 1024
> #define BLOCK_SIZE_BITS 10
> #ifndef NULL
> #define NULL ((void *) 0)
> #endif
> 
> #define INODES_PER_BLOCK ((BLOCK_SIZE)/(sizeof (struct d_inode)))
> #define DIR_ENTRIES_PER_BLOCK ((BLOCK_SIZE)/(sizeof (struct dir_entry)))
> 
> #define PIPE_HEAD(inode) ((inode).i_zone[0])
> #define PIPE_TAIL(inode) ((inode).i_zone[1])
> #define PIPE_SIZE(inode) ((PIPE_HEAD(inode)-PIPE_TAIL(inode))&(PAGE_SIZE-1))
> #define PIPE_EMPTY(inode) (PIPE_HEAD(inode)==PIPE_TAIL(inode))
> #define PIPE_FULL(inode) (PIPE_SIZE(inode)==(PAGE_SIZE-1))
> #define INC_PIPE(head) \
> __asm__("incl %0\n\tandl $4095,%0"::"m" (head))
> 
> typedef char buffer_block[BLOCK_SIZE];	//一个缓冲块的大小是1K
> 
> //在Linux启动的时候，会在[start_buffer, 4M]的中间位置，从两端向中间依次分配内存一个buffer_head和buffer_block的内存用来存储buffer_head和buffer_block，知道中间的内存无法再分配。这样我们就构建了一个buffer_head双向循环队列（每个buffer_head的b_prev_free和b_next_free被设置）
> // 用来保存从磁盘中读取到的数据块，
> // 缓冲块可以缓冲i节点位图缓冲块，然后把i节点位图缓冲块赋值给超级块表的i节点位图表
> // 缓冲块可以缓冲逻辑块位图，然后把逻辑块位图赋值给超级块表的逻辑块位图表
> struct buffer_head {							//缓冲块头结构，用来管理缓冲块
> 	char * b_data;			/* pointer to data block (1024 bytes) */
>     											//记录缓冲块起始地址
> 	unsigned long b_blocknr;	/* block number */
>     											//缓冲块对应磁盘块逻辑块号
> 	unsigned short b_dev;		/* device (0 = free) */
>     											//缓冲块对应磁盘块的设备，用设备号标识，每个标识含义可以看上面
> 	unsigned char b_uptodate;					//更新标志
> 	unsigned char b_dirt;		/* 0-clean,1-dirty */
>     											//修改标志
> 	unsigned char b_count;		/* users using this block */
>     											//使用这个缓冲块的用户数
> 	unsigned char b_lock;		/* 0 - ok, 1 -locked */
>     											//锁标志
> 	struct task_struct * b_wait;				//等待这个缓冲块的用户进程
> 	struct buffer_head * b_prev;				//哈希链表使用的双向指针
> 	struct buffer_head * b_next;
> 	struct buffer_head * b_prev_free;			//组织缓冲头的循环链表结构
> 	struct buffer_head * b_next_free;
> };
> 
> //存储在磁盘的超级块数据结构，超级块保存磁盘信息
> struct d_super_block {
> 	unsigned short s_ninodes;		//inode数，保存在磁盘的文件个数
> 	unsigned short s_nzones;		//逻辑块数，磁盘一共多少逻辑块
> 	unsigned short s_imap_blocks;	//i节点位图占用的逻辑块数
> 	unsigned short s_zmap_blocks;	//逻辑块位图所占用的逻辑块数
> 	unsigned short s_firstdatazone;	//第一个数据块的逻辑块号
> 	unsigned short s_log_zone_size;	
> 	unsigned long s_max_size;		//一个文件最大字节数
> 	unsigned short s_magic;			//文件魔数
> };
> 
> //存储在内存的超级快数据结构
> //内存有一个超级块表
> struct super_block {
> 	unsigned short s_ninodes;
> 	unsigned short s_nzones;
> 	unsigned short s_imap_blocks;
> 	unsigned short s_zmap_blocks;
> 	unsigned short s_firstdatazone;
> 	unsigned short s_log_zone_size;
> 	unsigned long s_max_size;
> 	unsigned short s_magic;
> /* These are only in memory */
> 	struct buffer_head * s_imap[8];	//i节点位图保存在内存中的缓冲块指针，可以由8个i节点位图缓冲块
>     								//i节点位图的每一个比特位可以用来表明一个i节点是否有效，在磁盘中，磁盘被划分为6块
>     								//引导块：由BIOS加载的驱动读写磁盘的程序
>     								//超级块：记录磁盘信息
>     								//i节点位图：每个比特位标明i节点块中的一个i节点是否有效，是否被分配给一个文件
>     								//逻辑块位图：标明逻辑块是否被分配，主要是用来标明数据块是否被使用
>     								//i节点区：保存i节点
>     								//数据区：保存文件数据的区域，数据区的数据块号和逻辑块号不一样，数据块号是从
>     								//		 第一个数据块开始计数，而逻辑块号是从0开始计数，第一个数据块的逻辑块号被保存在
>     								//		 磁盘超级块中，并且被加载到内存超级块表中
> 	struct buffer_head * s_zmap[8];	//8个逻辑块位图 缓冲块。
> 	unsigned short s_dev;			//超级块所属的设备号
> 	struct m_inode * s_isup;		
> 	struct m_inode * s_imount;
> 	unsigned long s_time;			//修改时间
> 	struct task_struct * s_wait;	//等待磁盘的进程
> 	unsigned char s_lock;			//锁标志
> 	unsigned char s_rd_only;		//只读标志
> 	unsigned char s_dirt;			//修改标志
> };
> 
> 
> 
> //存储再磁盘上的inode结构
> struct d_inode {
> 	unsigned short i_mode;			//访问权限和类型
> 	unsigned short i_uid;			//创建用户
> 	unsigned long i_size;			//文件大小
> 	unsigned long i_time;			//修改时间
> 	unsigned char i_gid;			//创建用户的用户组
> 	unsigned char i_nlinks;			//硬连接数目，当这个为0时文件可以被删除（新建文件的时候可以被用于分配来新建文件）
> 	unsigned short i_zone[9];		//文件使用的数据块表，保存文件使用的数据块的逻辑块号，在MINIX1.0文件系统中，	
>     								//0-6这7个数组项是直接块号，也就是说文件小于7K，那么可以直接使用这7个盘块号访问到使用的
>     								//逻辑块，当文件大于7K，需要间接盘块号辅助来获取盘块号
> };
> 
> //存储在内存的inode结构，他会在内核中新建一个inode表，m_inode inode_table[NR_INODE]，这个inode表会在操作系统启动的时候初始化为磁盘上的文件inode，他会获取磁盘上文件inode信息放到m_inode中，同时增加一些项。
> //内存有一个inode表，在系统启动的时候和超级块表一起被初始化
> struct m_inode {
> 	unsigned short i_mode;
> 	unsigned short i_uid;
> 	unsigned long i_size;
> 	unsigned long i_mtime;
> 	unsigned char i_gid;
> 	unsigned char i_nlinks;
> 	unsigned short i_zone[9];
> /* these are in memory also */
> 	struct task_struct * i_wait;	//等待文件的进程
> 	unsigned long i_atime;			//最后访问时间
> 	unsigned long i_ctime;			//最后修改时间
> 	unsigned short i_dev;			//inode所在的设备（文件所在设备号）
> 	unsigned short i_num;			//inode节点号（inode所在磁盘的inode位图下标）
> 	unsigned short i_count;			//inode被使用的次数（文件被使用的次数）
> 	unsigned char i_lock;			//锁定标识（文件被锁定）
> 	unsigned char i_dirt;			//修改标志
> 	unsigned char i_pipe;			//管道文件标志
> 	unsigned char i_mount;			//安装标志
> 	unsigned char i_seek;			//lseek标志
> 	unsigned char i_update;			//更新标志
> };
> 
> //内存有一个打开文件表file_table
> struct file {
> 	unsigned short f_mode;			//打开文件方式（读写）
> 	unsigned short f_flags;			//打开文件标志（添加/覆盖/没有就创建等）
> 	unsigned short f_count;			//文件句柄数，文件句柄是进程打开文件时将文件对应的inode赋值系统打开表
>     								//file_table中的一个表项，然后把这个表项文件描述符赋值给进程代开文件表filp
>     								//的一个位置，这个位置下标就被称为文件句柄。current->filp[fd]可以获得打开文件表的文件
>     								//描述符指针
> 	struct m_inode * f_inode;		//文件描述符对应的文件inode指针
> 	off_t f_pos;					//本文件描述符对应的读写指针。一个文件可以被多个进程打开，每个进程打开就会在
>     								//系统打开表创建一个文件描述符, 当进程使用fork创建子进程的时候会复制打开文件表，
>     								//同时增加系统打开表的文件描述符的文件句柄数
> };
> 
> struct dir_entry {					//目录结构
> 	unsigned short inode;
> 	char name[NAME_LEN];
> };
> 
> extern struct m_inode inode_table[NR_INODE];
> extern struct file file_table[NR_FILE];
> extern struct super_block super_block[NR_SUPER];
> extern struct buffer_head * start_buffer;
> extern int nr_buffers;
> 
> extern void check_disk_change(int dev);
> extern int floppy_change(unsigned int nr);
> extern int ticks_to_floppy_on(unsigned int dev);
> extern void floppy_on(unsigned int dev);
> extern void floppy_off(unsigned int dev);
> extern void truncate(struct m_inode * inode);
> extern void sync_inodes(void);
> extern void wait_on(struct m_inode * inode);
> extern int bmap(struct m_inode * inode,int block);
> extern int create_block(struct m_inode * inode,int block);
> extern struct m_inode * namei(const char * pathname);
> extern int open_namei(const char * pathname, int flag, int mode,
> 	struct m_inode ** res_inode);
> extern void iput(struct m_inode * inode);
> extern struct m_inode * iget(int dev,int nr);
> extern struct m_inode * get_empty_inode(void);
> extern struct m_inode * get_pipe_inode(void);
> extern struct buffer_head * get_hash_table(int dev, int block);
> extern struct buffer_head * getblk(int dev, int block);
> extern void ll_rw_block(int rw, struct buffer_head * bh);
> extern void brelse(struct buffer_head * buf);
> extern struct buffer_head * bread(int dev,int block);
> extern void bread_page(unsigned long addr,int dev,int b[4]);
> extern struct buffer_head * breada(int dev,int block,...);
> extern int new_block(int dev);
> extern void free_block(int dev, int block);
> extern struct m_inode * new_inode(int dev);
> extern void free_inode(struct m_inode * inode);
> extern int sync_dev(int dev);
> extern struct super_block * get_super(int dev);
> extern int ROOT_DEV;
> 
> extern void mount_root(void);
> 
> #endif
> ```
>
> 

```c
/*
 *  linux/fs/file_dev.c
 *
 *  (C) 1991  Linus Torvalds
 */

#include <errno.h>
#include <fcntl.h>

#include <linux/sched.h>
#include <linux/kernel.h>
#include <asm/segment.h>

#define MIN(a,b) (((a)<(b))?(a):(b))
#define MAX(a,b) (((a)>(b))?(a):(b))

//传入参数inode指针和FILE指针，从文件描述符FILE中获得文件读写指针，从inode中获得文件所在设备
//（设备号，文件读写指针）唯一标识磁盘中的一个位置
//file_read向（设备号，文件读写指针）位置写count个字节，返回实际写入的字节个数

int file_read(struct m_inode * inode, struct file * filp, char * buf, int count)
{
	int left,chars,nr;
	struct buffer_head * bh;

	if ((left=count)<=0)
		return 0;
	while (left) {
        //bmap根据文件数据块号获得文件数据块在磁盘上的逻辑块号，nr为读写指针所在的数据块块号
		if ((nr = bmap(inode,(filp->f_pos)/BLOCK_SIZE))) {
            //bread从格局逻辑块号从设备中读取逻辑块到内核缓冲块中，内核缓冲块在内核缓冲区中
            //由Linux操作系统初始化的时候初始化，bh返回为要读的数据块所在缓冲块的缓冲头的地址
			if (!(bh=bread(inode->i_dev,nr)))
				break;
		} else
			bh = NULL;
        //nr获取读写指针在数据快的偏移，加上缓冲块的地址bh->data，得到读写指针在缓冲块的地址
        //从缓冲块的读写指针位置读取数据到用户空间put_fs_byte，并且修改inode修改时间
		nr = filp->f_pos % BLOCK_SIZE;
		chars = MIN( BLOCK_SIZE-nr , left );
		filp->f_pos += chars;
		left -= chars;
		if (bh) {
			char * p = nr + bh->b_data;
			while (chars-->0)
				put_fs_byte(*(p++),buf++);
			brelse(bh);
		} else {
			while (chars-->0)
				put_fs_byte(0,buf++);
		}
	}
	inode->i_atime = CURRENT_TIME;
	return (count-left)?(count-left):-ERROR;
}


//往读写指针位置除添加数据
int file_write(struct m_inode * inode, struct file * filp, char * buf, int count)
{
	off_t pos;
	int block,c;
	struct buffer_head * bh;
	char * p;
	int i=0;

/*
 * ok, append may not work when many processes are writing at the same time
 * but so what. That way leads to madness anyway.
 */
    
	if (filp->f_flags & O_APPEND)
		pos = inode->i_size;
	else
		pos = filp->f_pos;
	while (i<count) {
        //根据读写指针所在的数据块读取逻辑块，如果这个逻辑块没有分配给文件，那么分配一个数据块给文件，返回数据块号
        //接着使用这个数据块号读取磁盘的数据块到内核缓冲区，返回内核缓冲块头指针。
		if (!(block = create_block(inode,pos/BLOCK_SIZE)))
			break;
		if (!(bh=bread(inode->i_dev,block)))
			break;
        
        //计算读写指针在缓冲块的位置p，将用户缓冲数据写入到内核缓冲块中，并且设置缓冲块被修改标志，写完之后释放这个缓冲块
		c = pos % BLOCK_SIZE;
		p = c + bh->b_data;
		bh->b_dirt = 1;
		c = BLOCK_SIZE-c;
		if (c > count-i) c = count-i;
		pos += c;
		if (pos > inode->i_size) {
			inode->i_size = pos;
			inode->i_dirt = 1;
		}
		i += c;
		while (c-->0)
			*(p++) = get_fs_byte(buf++);
		brelse(bh);
	}
    
    //设置文件inode修改时间和使用时间，设置file文件描述符读写指针
	inode->i_mtime = CURRENT_TIME;
	if (!(filp->f_flags & O_APPEND)) {
		filp->f_pos = pos;
		inode->i_ctime = CURRENT_TIME;
	}
	return (i?i:-1);
}
```

##### 管理内核缓冲区的读写函数：bread(getblk)读磁盘块到缓冲块/brelse释放缓冲块/sync将inode节点和置修改标志的缓冲块写回磁盘**

> bread函数首先调用getblk函数分配缓冲块来读取磁盘缓冲块，getblk得到函数有两种情况，一种是磁盘块已经被分配了缓冲块，缓冲块中有一个块就是（设备号，逻辑块号）和我们想要的一样，另外一种情况是分配一个没有被其他程序占用的（没有被锁定lock标志的）、进程占用数为0的空闲缓冲块，getblk函数执行流程如下
>
> > ![Screenshot 2022-10-20 203350](D:\JavaBackend\实验\1 操作系统实验\实验8 虚拟文件系统的实现\Screenshot 2022-10-20 203350.png)
> >
> > getblk函数通过哈希链表寻找，如果发现一个设备号/逻辑块号等于需要的缓冲块直接返回；如果没有找到，就要分配一个空闲缓冲块，他会从空闲队列开始查找空闲链表，判断这个缓冲块是否被进程占用（锁标志），是否被修改过（修改标志），是否在高速缓冲中（中断造成其他进程获得这个缓冲块操作），如果没有通过检查，进程会挂起 等待回到getblk开头位置执行，如果通过检查，就将获得一个没有被其他进程占用的空闲缓冲块，于是将他插入对应哈希链表的头节点和空闲链表的尾部
>
> bread通过getblk获得一个已经在内存的缓冲块或者是一个空缓冲块，这个时候他检查缓冲块更新标志（更新标志标明现在缓冲块是刚从磁盘块读取出来的，这个缓冲块和磁盘块数据一致，当数据被修改时，除了置修改标志为，也会置更更新标志位为非更新），看他是否是最新的，如果不是或者是空缓冲块，就调用磁盘底层io驱动程序ll_rw_blk根据设备号和逻辑号从磁盘中读取需要的磁盘块，否则就直接 返回缓冲块头指针。file_read/file_write会修改缓冲块头的修改标志，以及对应文件的inode节点的修改标志，修改时间和最后读时间。bread函数流程图
>
> > ![Screenshot 2022-10-20 204807](D:\JavaBackend\实验\1 操作系统实验\实验8 虚拟文件系统的实现\Screenshot 2022-10-20 204807.png)
>
> fs/buffer.c定义了bread函数，getblk函数，定义了哈希链表hash_table建立的缓冲头节点指针
>
> ```c
> /*
>  *  linux/fs/buffer.c
>  *
>  *  (C) 1991  Linus Torvalds
>  */
> 
> /*
>  *  'buffer.c' implements the buffer-cache functions. Race-conditions have
>  * been avoided by NEVER letting a interrupt change a buffer (except for the
>  * data, of course), but instead letting the caller do it. NOTE! As interrupts
>  * can wake up a caller, some cli-sti sequences are needed to check for
>  * sleep-on-calls. These should be extremely quick, though (I hope).
>  */
> 
> /*
>  * NOTE! There is one discordant note here: checking floppies for
>  * disk change. This is where it fits best, I think, as it should
>  * invalidate changed floppy-disk-caches.
>  */
> 
> #include <stdarg.h>
> 
> #include <linux/config.h>
> #include <linux/sched.h>
> #include <linux/kernel.h>
> #include <asm/system.h>
> #include <asm/io.h>
> 
> extern int end;
> extern void put_super(int);
> extern void invalidate_inodes(int);
> 
> struct buffer_head * start_buffer = (struct buffer_head *) &end;
> struct buffer_head * hash_table[NR_HASH];
> static struct buffer_head * free_list;
> static struct task_struct * buffer_wait = NULL;
> int NR_BUFFERS = 0;
> 
> static inline void wait_on_buffer(struct buffer_head * bh)
> {
> 	cli();
> 	while (bh->b_lock)
> 		sleep_on(&bh->b_wait);
> 	sti();
> }
> 
> //将缓冲区中修改标志置位的块写入磁盘 ，将inode节点都写入磁盘
> int sys_sync(void)
> {
> 	int i;
> 	struct buffer_head * bh;
> 
> 	sync_inodes();		/* write out inodes into buffers */
> 	bh = start_buffer;
> 	for (i=0 ; i<NR_BUFFERS ; i++,bh++) {
> 		wait_on_buffer(bh);
> 		if (bh->b_dirt)
> 			ll_rw_block(WRITE,bh);
> 	}
> 	return 0;
> }
> 
> int sync_dev(int dev)
> {
> 	int i;
> 	struct buffer_head * bh;
> 
> 	bh = start_buffer;
> 	for (i=0 ; i<NR_BUFFERS ; i++,bh++) {
> 		if (bh->b_dev != dev)
> 			continue;
> 		wait_on_buffer(bh);
> 		if (bh->b_dev == dev && bh->b_dirt)
> 			ll_rw_block(WRITE,bh);
> 	}
> 	sync_inodes();
> 	bh = start_buffer;
> 	for (i=0 ; i<NR_BUFFERS ; i++,bh++) {
> 		if (bh->b_dev != dev)
> 			continue;
> 		wait_on_buffer(bh);
> 		if (bh->b_dev == dev && bh->b_dirt)
> 			ll_rw_block(WRITE,bh);
> 	}
> 	return 0;
> }
> 
> void inline invalidate_buffers(int dev)
> {
> 	int i;
> 	struct buffer_head * bh;
> 
> 	bh = start_buffer;
> 	for (i=0 ; i<NR_BUFFERS ; i++,bh++) {
> 		if (bh->b_dev != dev)
> 			continue;
> 		wait_on_buffer(bh);
> 		if (bh->b_dev == dev)
> 			bh->b_uptodate = bh->b_dirt = 0;
> 	}
> }
> 
> /*
>  * This routine checks whether a floppy has been changed, and
>  * invalidates all buffer-cache-entries in that case. This
>  * is a relatively slow routine, so we have to try to minimize using
>  * it. Thus it is called only upon a 'mount' or 'open'. This
>  * is the best way of combining speed and utility, I think.
>  * People changing diskettes in the middle of an operation deserve
>  * to loose :-)
>  *
>  * NOTE! Although currently this is only for floppies, the idea is
>  * that any additional removable block-device will use this routine,
>  * and that mount/open needn't know that floppies/whatever are
>  * special.
>  */
> void check_disk_change(int dev)
> {
> 	int i;
> 
> 	if (MAJOR(dev) != 2)
> 		return;
> 	if (!floppy_change(dev & 0x03))
> 		return;
> 	for (i=0 ; i<NR_SUPER ; i++)
> 		if (super_block[i].s_dev == dev)
> 			put_super(super_block[i].s_dev);
> 	invalidate_inodes(dev);
> 	invalidate_buffers(dev);
> }
> 
> #define _hashfn(dev,block) (((unsigned)(dev^block))%NR_HASH)
> #define hash(dev,block) hash_table[_hashfn(dev,block)]
> 
> static inline void remove_from_queues(struct buffer_head * bh)
> {
> /* remove from hash-queue */
> 	if (bh->b_next)
> 		bh->b_next->b_prev = bh->b_prev;
> 	if (bh->b_prev)
> 		bh->b_prev->b_next = bh->b_next;
> 	if (hash(bh->b_dev,bh->b_blocknr) == bh)
> 		hash(bh->b_dev,bh->b_blocknr) = bh->b_next;
> /* remove from free list */
> 	if (!(bh->b_prev_free) || !(bh->b_next_free))
> 		panic("Free block list corrupted");
> 	bh->b_prev_free->b_next_free = bh->b_next_free;
> 	bh->b_next_free->b_prev_free = bh->b_prev_free;
> 	if (free_list == bh)
> 		free_list = bh->b_next_free;
> }
> 
> static inline void insert_into_queues(struct buffer_head * bh)
> {
> /* put at end of free list */
> 	bh->b_next_free = free_list;
> 	bh->b_prev_free = free_list->b_prev_free;
> 	free_list->b_prev_free->b_next_free = bh;
> 	free_list->b_prev_free = bh;
> /* put the buffer in new hash-queue if it has a device */
> 	bh->b_prev = NULL;
> 	bh->b_next = NULL;
> 	if (!bh->b_dev)
> 		return;
> 	bh->b_next = hash(bh->b_dev,bh->b_blocknr);
> 	hash(bh->b_dev,bh->b_blocknr) = bh;
> 	bh->b_next->b_prev = bh;
> }
> 
> static struct buffer_head * find_buffer(int dev, int block)
> {		
> 	struct buffer_head * tmp;
> 
> 	for (tmp = hash(dev,block) ; tmp != NULL ; tmp = tmp->b_next)
> 		if (tmp->b_dev==dev && tmp->b_blocknr==block)
> 			return tmp;
> 	return NULL;
> }
> 
> /*
>  * Why like this, I hear you say... The reason is race-conditions.
>  * As we don't lock buffers (unless we are readint them, that is),
>  * something might happen to it while we sleep (ie a read-error
>  * will force it bad). This shouldn't really happen currently, but
>  * the code is ready.
>  */
> struct buffer_head * get_hash_table(int dev, int block)
> {
> 	struct buffer_head * bh;
> 
> 	for (;;) {
> 		if (!(bh=find_buffer(dev,block)))
> 			return NULL;
> 		bh->b_count++;
> 		wait_on_buffer(bh);
> 		if (bh->b_dev == dev && bh->b_blocknr == block)
> 			return bh;
> 		bh->b_count--;
> 	}
> }
> 
> /*
>  * Ok, this is getblk, and it isn't very clear, again to hinder
>  * race-conditions. Most of the code is seldom used, (ie repeating),
>  * so it should be much more efficient than it looks.
>  *
>  * The algoritm is changed: hopefully better, and an elusive bug removed.
>  */
> #define BADNESS(bh) (((bh)->b_dirt<<1)+(bh)->b_lock)
> struct buffer_head * getblk(int dev,int block)
> {
> 	struct buffer_head * tmp, * bh;
> 
> repeat:
> 	if ((bh = get_hash_table(dev,block)))
> 		return bh;
> 	tmp = free_list;
> 	do {
> 		if (tmp->b_count)
> 			continue;
> 		if (!bh || BADNESS(tmp)<BADNESS(bh)) {
> 			bh = tmp;
> 			if (!BADNESS(tmp))
> 				break;
> 		}
> /* and repeat until we find something good */
> 	} while ((tmp = tmp->b_next_free) != free_list);
> 	if (!bh) {
> 		sleep_on(&buffer_wait);
> 		goto repeat;
> 	}
> 	wait_on_buffer(bh);
> 	if (bh->b_count)
> 		goto repeat;
> 	while (bh->b_dirt) {
> 		sync_dev(bh->b_dev);
> 		wait_on_buffer(bh);
> 		if (bh->b_count)
> 			goto repeat;
> 	}
> /* NOTE!! While we slept waiting for this block, somebody else might */
> /* already have added "this" block to the cache. check it */
> 	if (find_buffer(dev,block))
> 		goto repeat;
> /* OK, FINALLY we know that this buffer is the only one of it's kind, */
> /* and that it's unused (b_count=0), unlocked (b_lock=0), and clean */
> 	bh->b_count=1;
> 	bh->b_dirt=0;
> 	bh->b_uptodate=0;
> 	remove_from_queues(bh);
> 	bh->b_dev=dev;
> 	bh->b_blocknr=block;
> 	insert_into_queues(bh);
> 	return bh;
> }
> 
> void brelse(struct buffer_head * buf)
> {
> 	if (!buf)
> 		return;
> 	wait_on_buffer(buf);
> 	if (!(buf->b_count--))
> 		panic("Trying to free free buffer");
> 	wake_up(&buffer_wait);
> }
> 
> /*
>  * bread() reads a specified block and returns the buffer that contains
>  * it. It returns NULL if the block was unreadable.
>  */
> struct buffer_head * bread(int dev,int block)
> {
> 	struct buffer_head * bh;
> 
> 	if (!(bh=getblk(dev,block)))
> 		panic("bread: getblk returned NULL\n");
> 	if (bh->b_uptodate)
> 		return bh;
> 	ll_rw_block(READ,bh);
> 	wait_on_buffer(bh);
> 	if (bh->b_uptodate)
> 		return bh;
> 	brelse(bh);
> 	return NULL;
> }
> 
> #define COPYBLK(from,to) \
> __asm__("cld\n\t" \
> 	"rep\n\t" \
> 	"movsl\n\t" \
> 	::"c" (BLOCK_SIZE/4),"S" (from),"D" (to) \
> 	)
> 
> /*
>  * bread_page reads four buffers into memory at the desired address. It's
>  * a function of its own, as there is some speed to be got by reading them
>  * all at the same time, not waiting for one to be read, and then another
>  * etc.
>  */
> void bread_page(unsigned long address,int dev,int b[4])
> {
> 	struct buffer_head * bh[4];
> 	int i;
> 
> 	for (i=0 ; i<4 ; i++)
> 		if (b[i]) {
> 			if ((bh[i] = getblk(dev,b[i])))
> 				if (!bh[i]->b_uptodate)
> 					ll_rw_block(READ,bh[i]);
> 		} else
> 			bh[i] = NULL;
> 	for (i=0 ; i<4 ; i++,address += BLOCK_SIZE)
> 		if (bh[i]) {
> 			wait_on_buffer(bh[i]);
> 			if (bh[i]->b_uptodate)
> 				COPYBLK((unsigned long) bh[i]->b_data,address);
> 			brelse(bh[i]);
> 		}
> }
> 
> /*
>  * Ok, breadaaaaa can be used as bread, but additionally to mark other
>  * blocks for reading as well. End the argument list with a negative
>  * number.
>  */
> struct buffer_head * breada(int dev,int first, ...)
> {
> 	va_list args;
> 	struct buffer_head * bh, *tmp;
> 
> 	va_start(args,first);
> 	if (!(bh=getblk(dev,first)))
> 		panic("bread: getblk returned NULL\n");
> 	if (!bh->b_uptodate)
> 		ll_rw_block(READ,bh);
> 	while ((faaaaaaaaaairst=va_arg(args,int))>=0) {
> 		tmp=getblk(dev,first);
> 		if (tmp) {
> 			if (!tmp->b_uptodate)
> 				ll_rw_block(READA,bh);
> 			tmp->b_count--;
> 		}
> 	}
> 	va_end(args);
> 	wait_on_buffer(bh);
> 	if (bh->b_uptodate)
> 		return bh;
> 	
>     
> 	return (NULL);
> }
> 
> void buffer_init(long buffer_end)
> {
> 	struct buffer_head * h = start_buffer;
> 	void * b;
> 	int i;
> 
> 	if (buffer_end == 1<<20)
> 		b = (void *) (640*1024);
> 	else
> 		b = (void *) buffer_end;
> 	while ( (b -= BLOCK_SIZE) >= ((void *) (h+1)) ) {
> 		h->b_dev = 0;
> 		h->b_dirt = 0;
> 		h->b_count = 0;
> 		h->b_lock = 0;
> 		h->b_uptodate = 0;
> 		h->b_wait = NULL;
> 		h->b_next = NULL;
> 		h->b_prev = NULL;
> 		h->b_data = (char *) b;
> 		h->b_prev_free = h-1;
> 		h->b_next_free = h+1;
> 		h++;
> 		NR_BUFFERS++;
> 		if (b == (void *) 0x100000)
> 			b = (void *) 0xA0000;
> 	}
> 	h--;
> 	free_list = start_buffer;
> 	free_list->b_prev_free = h;
> 	h->b_next_free = free_list;
> 	for (i=0;i<NR_HASH;i++)
> 		hash_table[i]=NULL;
> }	
> ```
>
> brelse函数释放一个缓冲块，首先等待这个缓冲块解锁**while(bh->block) sleep_on(bh->wait)**，当缓冲块被解锁（被进程释放）之后，他会减少缓冲块进程引用次数bh->count--，然后唤醒等待分配缓冲块的进程队列中的进程buffer_wait(在fs/buffer中定义为全局变量)

##### 管理i节点读写的函数：iget/iput将inode节点读取或者写回磁盘

> iget函数根据设备号和i节点号nr（i节点位图下标），从磁盘中读取i节点号为nr的i节点到inode表inode_table，置引用次数为1，如果inode表中已经存在这个inode节点，就增加他的引用次数。iput将inode节点写回磁盘。
>
> bmap函数根据根据文件设备号和数据块号（读写指针/BLOCK_SIZE一个数据块大小)将文件数据块映射到磁盘数据块的逻辑块号。
>
> 寻找根据i节点号nr（i节点位图下标）获取i节点所在磁盘块号：i节点nr所在磁盘块=引导块数+超级块数+i节点位图数据块数+逻辑块位图数据块数+nr*i节点大小/BLOCK_SIZE每个数据块大小，这样就可以根据i节点号nr获得对应的i节点文件信息，这在iget和iput中根据i节点号nr获取对应的i节点所在数据块得到使用。iget和iput获取超级块/i节点位图/逻辑块位图/i节点数据块（inode数据，存储文件元信息）/逻辑块数据块（普通数据块（存储文件数据））等都通过bread函数获取对应的数据块，bread读取的时候需要使用设备号和逻辑块号，逻辑块号的获得对inode节点来说是通过超级块的磁盘信息（存放逻辑块位图数据块数和i节点位图数据块数）等来计算的，对于给定i节点号nr的i节点所在的逻辑块的逻辑块号是**引导快数+超级块数+i节点位图数据块数+逻辑块位图数据块数+nr\*inode节点大小/BLOCK_SIZE**；对于文件数据块来说获得对应逻辑块号是**bmap**函数获得的，bmap函数传入文件i节点和数据块号f_pos/BLOCK_SIZE。
>
> bmap函数根据文件数据块号获取对应的盘块号，基本操作是文件i节点保存的i_zone[9]数组是文件使用的逻辑块数组，他保存了文件使用的数据块的逻辑号，对于nr=f_pos/BLOCK_SIZE的数据块，他对应的逻辑号是inode->i_zone[nr]，这里要保证nr<7，因为大于他会使用到间接盘块号，就不能像使用inode->i_zone[nr]直接映射得到了。
>
> ```c
> /*
>  *  linux/fs/inode.c
>  *
>  *  (C) 1991  Linus Torvalds
>  */
> 
> #include <string.h> 
> #include <sys/stat.h>
> 
> #include <linux/sched.h>
> #include <linux/kernel.h>
> #include <linux/mm.h>
> #include <asm/system.h>
> 
> struct m_inode inode_table[NR_INODE]={{0,},};
> 
> static void read_inode(struct m_inode * inode);
> static void write_inode(struct m_inode * inode);
> 
> static inline void wait_on_inode(struct m_inode * inode)
> {
> 	cli();
> 	while (inode->i_lock)
> 		sleep_on(&inode->i_wait);
> 	sti();
> }
> 
> static inline void lock_inode(struct m_inode * inode)
> {
> 	cli();
> 	while (inode->i_lock)
> 		sleep_on(&inode->i_wait);
> 	inode->i_lock=1;
> 	sti();
> }
> 
> static inline void unlock_inode(struct m_inode * inode)
> {
> 	inode->i_lock=0;
> 	wake_up(&inode->i_wait);
> }
> 
> void invalidate_inodes(int dev)
> {
> 	int i;
> 	struct m_inode * inode;
> 
> 	inode = 0+inode_table;
> 	for(i=0 ; i<NR_INODE ; i++,inode++) {
> 		wait_on_inode(inode);
> 		if (inode->i_dev == dev) {
> 			if (inode->i_count)
> 				printk("inode in use on removed disk\n\r");
> 			inode->i_dev = inode->i_dirt = 0;
> 		}
> 	}
> }
> 
> void sync_inodes(void)
> {
> 	int i;
> 	struct m_inode * inode;
> 
> 	inode = 0+inode_table;
> 	for(i=0 ; i<NR_INODE ; i++,inode++) {
> 		wait_on_inode(inode);
> 		if (inode->i_dirt && !inode->i_pipe)
> 			write_inode(inode);
> 	}
> }
> 
> static int _bmap(struct m_inode * inode,int block,int create)
> {
> 	struct buffer_head * bh;
> 	int i;
> 
> 	if (block<0)
> 		panic("_bmap: block<0");
> 	if (block >= 7+512+512*512)
> 		panic("_bmap: block>big");
> 	if (block<7) {
> 		if (create && !inode->i_zone[block])
> 			if ((inode->i_zone[block]=new_block(inode->i_dev))) {
> 				inode->i_ctime=CURRENT_TIME;
> 				inode->i_dirt=1;
> 			}
> 		return inode->i_zone[block];
> 	}
> 	block -= 7;
> 	if (block<512) {
> 		if (create && !inode->i_zone[7])
> 			if ((inode->i_zone[7]=new_block(inode->i_dev))) {
> 				inode->i_dirt=1;
> 				inode->i_ctime=CURRENT_TIME;
> 			}
> 		if (!inode->i_zone[7])
> 			return 0;
> 		if (!(bh = bread(inode->i_dev,inode->i_zone[7])))
> 			return 0;
> 		i = ((unsigned short *) (bh->b_data))[block];
> 		if (create && !i)
> 			if ((i=new_block(inode->i_dev))) {
> 				((unsigned short *) (bh->b_data))[block]=i;
> 				bh->b_dirt=1;
> 			}
> 		brelse(bh);
> 		return i;
> 	}
> 	block -= 512;
> 	if (create && !inode->i_zone[8])
> 		if ((inode->i_zone[8]=new_block(inode->i_dev))) {
> 			inode->i_dirt=1;
> 			inode->i_ctime=CURRENT_TIME;
> 		}
> 	if (!inode->i_zone[8])
> 		return 0;
> 	if (!(bh=bread(inode->i_dev,inode->i_zone[8])))
> 		return 0;
> 	i = ((unsigned short *)bh->b_data)[block>>9];
> 	if (create && !i)
> 		if ((i=new_block(inode->i_dev))) {
> 			((unsigned short *) (bh->b_data))[block>>9]=i;
> 			bh->b_dirt=1;
> 		}
> 	brelse(bh);
> 	if (!i)
> 		return 0;
> 	if (!(bh=bread(inode->i_dev,i)))
> 		return 0;
> 	i = ((unsigned short *)bh->b_data)[block&511];
> 	if (create && !i)
> 		if ((i=new_block(inode->i_dev))) {
> 			((unsigned short *) (bh->b_data))[block&511]=i;
> 			bh->b_dirt=1;
> 		}
> 	brelse(bh);
> 	return i;
> }
> 
> int bmap(struct m_inode * inode,int block)
> {
> 	return _bmap(inode,block,0);
> }
> 
> int create_block(struct m_inode * inode, int block)
> {
> 	return _bmap(inode,block,1);
> }
> 		
> void iput(struct m_inode * inode)
> {
> 	if (!inode)
> 		return;
> 	wait_on_inode(inode);
> 	if (!inode->i_count)
> 		panic("iput: trying to free free inode");
> 	if (inode->i_pipe) {
> 		wake_up(&inode->i_wait);
> 		if (--inode->i_count)
> 			return;
> 		free_page(inode->i_size);
> 		inode->i_count=0;
> 		inode->i_dirt=0;
> 		inode->i_pipe=0;
> 		return;
> 	}
> 	if (!inode->i_dev) {
> 		inode->i_count--;
> 		return;
> 	}
> 	if (S_ISBLK(inode->i_mode)) {
> 		sync_dev(inode->i_zone[0]);
> 		wait_on_inode(inode);
> 	}
> repeat:
> 	if (inode->i_count>1) {
> 		inode->i_count--;
> 		return;
> 	}
> 	if (!inode->i_nlinks) {
> 		truncate(inode);
> 		free_inode(inode);
> 		return;
> 	}
> 	if (inode->i_dirt) {
> 		write_inode(inode);	/* we can sleep - so do again */
> 		wait_on_inode(inode);
> 		goto repeat;
> 	}
> 	inode->i_count--;
> 	return;
> }
> 
> struct m_inode * get_empty_inode(void)
> {
> 	struct m_inode * inode;
> 	static struct m_inode * last_inode = inode_table;
> 	int i;
> 
> 	do {
> 		inode = NULL;
> 		for (i = NR_INODE; i ; i--) {
> 			if (++last_inode >= inode_table + NR_INODE)
> 				last_inode = inode_table;
> 			if (!last_inode->i_count) {
> 				inode = last_inode;
> 				if (!inode->i_dirt && !inode->i_lock)
> 					break;
> 			}
> 		}
> 		if (!inode) {
> 			for (i=0 ; i<NR_INODE ; i++)
> 				printk("%04x: %6d\t",inode_table[i].i_dev,
> 					inode_table[i].i_num);
> 			panic("No free inodes in mem");
> 		}
> 		wait_on_inode(inode);
> 		while (inode->i_dirt) {
> 			write_inode(inode);
> 			wait_on_inode(inode);
> 		}
> 	} while (inode->i_count);
> 	memset(inode,0,sizeof(*inode));
> 	inode->i_count = 1;
> 	return inode;
> }
> 
> struct m_inode * get_pipe_inode(void)
> {
> 	struct m_inode * inode;
> 
> 	if (!(inode = get_empty_inode()))
> 		return NULL;
> 	if (!(inode->i_size=get_free_page())) {
> 		inode->i_count = 0;
> 		return NULL;
> 	}
> 	inode->i_count = 2;	/* sum of readers/writers */
> 	PIPE_HEAD(*inode) = PIPE_TAIL(*inode) = 0;
> 	inode->i_pipe = 1;
> 	return inode;
> }
> 
> struct m_inode * iget(int dev,int nr)
> {
> 	struct m_inode * inode, * empty;
> 
> 	if (!dev)
> 		panic("iget with dev==0");
> 	empty = get_empty_inode();
> 	inode = inode_table;
> 	while (inode < NR_INODE+inode_table) {
> 		if (inode->i_dev != dev || inode->i_num != nr) {
> 			inode++;
> 			continue;
> 		}
> 		wait_on_inode(inode);
> 		if (inode->i_dev != dev || inode->i_num != nr) {
> 			inode = inode_table;
> 			continue;
> 		}
> 		inode->i_count++;
> 		if (inode->i_mount) {
> 			int i;
> 
> 			for (i = 0 ; i<NR_SUPER ; i++)
> 				if (super_block[i].s_imount==inode)
> 					break;
> 			if (i >= NR_SUPER) {
> 				printk("Mounted inode hasn't got sb\n");
> 				if (empty)
> 					iput(empty);
> 				return inode;
> 			}
> 			iput(inode);
> 			dev = super_block[i].s_dev;
> 			nr = ROOT_INO;
> 			inode = inode_table;
> 			continue;
> 		}
> 		if (empty)
> 			iput(empty);
> 		return inode;
> 	}
> 	if (!empty)
> 		return (NULL);
> 	inode=empty;
> 	inode->i_dev = dev;
> 	inode->i_num = nr;
> 	read_inode(inode);
> 	return inode;
> }
> 
> static void read_inode(struct m_inode * inode)
> {
> 	struct super_block * sb;
> 	struct buffer_head * bh;
> 	int block;
> 
> 	lock_inode(inode);
> 	if (!(sb=get_super(inode->i_dev)))
> 		panic("trying to read inode without dev");
> 	block = 2 + sb->s_imap_blocks + sb->s_zmap_blocks +
> 		(inode->i_num-1)/INODES_PER_BLOCK;
> 	if (!(bh=bread(inode->i_dev,block)))
> 		panic("unable to read i-node block");
> 	*(struct d_inode *)inode =
> 		((struct d_inode *)bh->b_data)
> 			[(inode->i_num-1)%INODES_PER_BLOCK];
> 	brelse(bh);
> 	unlock_inode(inode);
> }
> 
> static void write_inode(struct m_inode * inode)
> {
> 	struct super_block * sb;
> 	struct buffer_head * bh;
> 	int block;
> 
> 	lock_inode(inode);
> 	if (!inode->i_dirt || !inode->i_dev) {
> 		unlock_inode(inode);
> 		return;
> 	}
> 	if (!(sb=get_super(inode->i_dev)))
> 		panic("trying to write inode without device");
> 	block = 2 + sb->s_imap_blocks + sb->s_zmap_blocks +
> 		(inode->i_num-1)/INODES_PER_BLOCK;
> 	if (!(bh=bread(inode->i_dev,block)))
> 		panic("unable to read i-node block");
> 	((struct d_inode *)bh->b_data)
> 		[(inode->i_num-1)%INODES_PER_BLOCK] =
> 			*(struct d_inode *)inode;
> 	bh->b_dirt=1;
> 	inode->i_dirt=0;
> 	brelse(bh);
> 	unlock_inode(inode);
> }
> ```

##### 根据文件名映射到对应inode节点的函数namei, open_namei

> Linux系统中目录也是一个文件，用i节点来标记一个目录文件。1进程开始的时候会加载磁盘，设置进程根目录和工作目录执行目录的i节点,current->root, current->pwd, current->exct。在解析路径的时候如果"/xxx"以"/"开始的目录会从current->root根目录开始，其他的会从crrent->pwd当前工作目录开始找，当获得一级目录的时候，通过目录i节点的i_zone获得文件使用的数据块，加载这些数据块保存到内存里面的内容是目录项数据，目录项结构在**include/linux/fs.h**中定义为 **struct dir_entry{ int inode, char name[LEN]}**，也就是目录文件中保存的一个目录项是目录项文件的i节点号和目录项文件的文件名称。就这样通过find_entry函数可以一级一级获取目录文件，匹配目录项结构，从目录项结构获得下一级目录的i节点号号，iget函数根据设备号和i节点号加载i节点信息到i节点表中，根据这个目录i节点访问目录文件获得下一级目录。最后我们访问到我们需要的文件的i节点，返回这个i节点。
>
> ```c
> /*
>  *  linux/fs/namei.c
>  *
>  *  (C) 1991  Linus Torvalds
>  */
> 
> /*
>  * Some corrections by tytso.
>  */
> 
> #include <linux/sched.h>
> #include <linux/kernel.h>
> #include <asm/segment.h>
> 
> #include <string.h> 
> #include <fcntl.h>
> #include <errno.h>
> #include <const.h>
> #include <sys/stat.h>
> 
> #define ACC_MODE(x) ("\004\002\006\377"[(x)&O_ACCMODE])
> 
> /*
>  * comment out this line if you want names > NAME_LEN chars to be
>  * truncated. Else they will be disallowed.
>  */
> /* #define NO_TRUNCATE */
> 
> #define MAY_EXEC 1
> #define MAY_WRITE 2
> #define MAY_READ 4
> 
> /*
>  *	permission()
>  *
>  * is used to check for read/write/execute permissions on a file.
>  * I don't know if we should look at just the euid or both euid and
>  * uid, but that should be easily changed.
>  */
> static int permission(struct m_inode * inode,int mask)
> {
> 	int mode = inode->i_mode;
> 
> /* special case: not even root can read/write a deleted file */
> 	if (inode->i_dev && !inode->i_nlinks)
> 		return 0;
> 	else if (current->euid==inode->i_uid)
> 		mode >>= 6;
> 	else if (current->egid==inode->i_gid)
> 		mode >>= 3;
> 	if (((mode & mask & 0007) == mask) || suser())
> 		return 1;
> 	return 0;
> }
> 
> /*
>  * ok, we cannot use strncmp, as the name is not in our data space.
>  * Thus we'll have to use match. No big problem. Match also makes
>  * some sanity tests.
>  *
>  * NOTE! unlike strncmp, match returns 1 for success, 0 for failure.
>  */
> static int match(int len,const char * name,struct dir_entry * de)
> {
> 	register int same ;
> 
> 	if (!de || !de->inode || len > NAME_LEN)
> 		return 0;
> 	if (len < NAME_LEN && de->name[len])
> 		return 0;
> 	__asm__("cld\n\t"
> 		"fs ; repe ; cmpsb\n\t"
> 		"setz %%al"
> 		:"=a" (same)
> 		:"0" (0),"S" ((long) name),"D" ((long) de->name),"c" (len)
> 		);
> 	return same;
> }
> 
> /*
>  *	find_entry()
>  *
>  * finds an entry in the specified directory with the wanted name. It
>  * returns the cache buffer in which the entry was found, and the entry
>  * itself (as a parameter - res_dir). It does NOT read the inode of the
>  * entry - you'll have to do that yourself if you want to.
>  *
>  * This also takes care of the few special cases due to '..'-traversal
>  * over a pseudo-root and a mount point.
>  */
> static struct buffer_head * find_entry(struct m_inode ** dir,
> 	const char * name, int namelen, struct dir_entry ** res_dir)
> {
> 	int entries;
> 	int block,i;
> 	struct buffer_head * bh;
> 	struct dir_entry * de;
> 	struct super_block * sb;
> 
> #ifdef NO_TRUNCATE
> 	if (namelen > NAME_LEN)
> 		return NULL;
> #else
> 	if (namelen > NAME_LEN)
> 		namelen = NAME_LEN;
> #endif
> 	entries = (*dir)->i_size / (sizeof (struct dir_entry));
> 	*res_dir = NULL;
> 	if (!namelen)
> 		return NULL;
> /* check for '..', as we might have to do some "magic" for it */
> 	if (namelen==2 && get_fs_byte(name)=='.' && get_fs_byte(name+1)=='.') {
> /* '..' in a pseudo-root results in a faked '.' (just change namelen) */
> 		if ((*dir) == current->root)
> 			namelen=1;
> 		else if ((*dir)->i_num == ROOT_INO) {
> /* '..' over a mount-point results in 'dir' being exchanged for the mounted
>    directory-inode. NOTE! We set mounted, so that we can iput the new dir */
> 			sb=get_super((*dir)->i_dev);
> 			if (sb->s_imount) {
> 				iput(*dir);
> 				(*dir)=sb->s_imount;
> 				(*dir)->i_count++;
> 			}
> 		}
> 	}
> 	if (!(block = (*dir)->i_zone[0]))
> 		return NULL;
> 	if (!(bh = bread((*dir)->i_dev,block)))
> 		return NULL;
> 	i = 0;
> 	de = (struct dir_entry *) bh->b_data;
> 	while (i < entries) {
> 		if ((char *)de >= BLOCK_SIZE+bh->b_data) {
> 			brelse(bh);
> 			bh = NULL;
> 			if (!(block = bmap(*dir,i/DIR_ENTRIES_PER_BLOCK)) ||
> 			    !(bh = bread((*dir)->i_dev,block))) {
> 				i += DIR_ENTRIES_PER_BLOCK;
> 				continue;
> 			}
> 			de = (struct dir_entry *) bh->b_data;
> 		}
> 		if (match(namelen,name,de)) {
> 			*res_dir = de;
> 			return bh;
> 		}
> 		de++;
> 		i++;
> 	}
> 	brelse(bh);
> 	return NULL;
> }
> 
> /*
>  *	add_entry()
>  *
>  * adds a file entry to the specified directory, using the same
>  * semantics as find_entry(). It returns NULL if it failed.
>  *
>  * NOTE!! The inode part of 'de' is left at 0 - which means you
>  * may not sleep between calling this and putting something into
>  * the entry, as someone else might have used it while you slept.
>  */
> static struct buffer_head * add_entry(struct m_inode * dir,
> 	const char * name, int namelen, struct dir_entry ** res_dir)
> {
> 	int block,i;
> 	struct buffer_head * bh;
> 	struct dir_entry * de;
> 
> 	*res_dir = NULL;
> #ifdef NO_TRUNCATE
> 	if (namelen > NAME_LEN)
> 		return NULL;
> #else
> 	if (namelen > NAME_LEN)
> 		namelen = NAME_LEN;
> #endif
> 	if (!namelen)
> 		return NULL;
> 	if (!(block = dir->i_zone[0]))
> 		return NULL;
> 	if (!(bh = bread(dir->i_dev,block)))
> 		return NULL;
> 	i = 0;
> 	de = (struct dir_entry *) bh->b_data;
> 	while (1) {
> 		if ((char *)de >= BLOCK_SIZE+bh->b_data) {
> 			brelse(bh);
> 			bh = NULL;
> 			block = create_block(dir,i/DIR_ENTRIES_PER_BLOCK);
> 			if (!block)
> 				return NULL;
> 			if (!(bh = bread(dir->i_dev,block))) {
> 				i += DIR_ENTRIES_PER_BLOCK;
> 				continue;
> 			}
> 			de = (struct dir_entry *) bh->b_data;
> 		}
> 		if (i*sizeof(struct dir_entry) >= dir->i_size) {
> 			de->inode=0;
> 			dir->i_size = (i+1)*sizeof(struct dir_entry);
> 			dir->i_dirt = 1;
> 			dir->i_ctime = CURRENT_TIME;
> 		}
> 		if (!de->inode) {
> 			dir->i_mtime = CURRENT_TIME;
> 			for (i=0; i < NAME_LEN ; i++)
> 				de->name[i]=(i<namelen)?get_fs_byte(name+i):0;
> 			bh->b_dirt = 1;
> 			*res_dir = de;
> 			return bh;
> 		}
> 		de++;
> 		i++;
> 	}
> 	brelse(bh);
> 	return NULL;
> }
> 
> /*
>  *	get_dir()
>  *
>  * Getdir traverses the pathname until it hits the topmost directory.
>  * It returns NULL on failure.
>  */
> static struct m_inode * get_dir(const char * pathname)
> {
> 	char c;
> 	const char * thisname;
> 	struct m_inode * inode;
> 	struct buffer_head * bh;
> 	int namelen,inr,idev;
> 	struct dir_entry * de;
> 
> 	if (!current->root || !current->root->i_count)
> 		panic("No root inode");
> 	if (!current->pwd || !current->pwd->i_count)
> 		panic("No cwd inode");
> 	if ((c=get_fs_byte(pathname))=='/') {
> 		inode = current->root;
> 		pathname++;
> 	} else if (c)
> 		inode = current->pwd;
> 	else
> 		return NULL;	/* empty name is bad */
> 	inode->i_count++;
> 	while (1) {
> 		thisname = pathname;
> 		if (!S_ISDIR(inode->i_mode) || !permission(inode,MAY_EXEC)) {
> 			iput(inode);
> 			return NULL;
> 		}
> 		for(namelen=0;(c=get_fs_byte(pathname++))&&(c!='/');namelen++)
> 			/* nothing */ ;
> 		if (!c)
> 			return inode;
> 		if (!(bh = find_entry(&inode,thisname,namelen,&de))) {
> 			iput(inode);
> 			return NULL;
> 		}
> 		inr = de->inode;
> 		idev = inode->i_dev;
> 		brelse(bh);
> 		iput(inode);
> 		if (!(inode = iget(idev,inr)))
> 			return NULL;
> 	}
> }
> 
> /*
>  *	dir_namei()
>  *
>  * dir_namei() returns the inode of the directory of the
>  * specified name, and the name within that directory.
>  */
> static struct m_inode * dir_namei(const char * pathname,
> 	int * namelen, const char ** name)
> {
> 	char c;
> 	const char * basename;
> 	struct m_inode * dir;
> 
> 	if (!(dir = get_dir(pathname)))
> 		return NULL;
> 	basename = pathname;
> 	while ((c=get_fs_byte(pathname++)))
> 		if (c=='/')
> 			basename=pathname;
> 	*namelen = pathname-basename-1;
> 	*name = basename;
> 	return dir;
> }
> 
> /*
>  *	namei()
>  *
>  * is used by most simple commands to get the inode of a specified name.
>  * Open, link etc use their own routines, but this is enough for things
>  * like 'chmod' etc.
>  */
> struct m_inode * namei(const char * pathname)
> {
> 	const char * basename;
> 	int inr,dev,namelen;
> 	struct m_inode * dir;
> 	struct buffer_head * bh;
> 	struct dir_entry * de;
> 
> 	if (!(dir = dir_namei(pathname,&namelen,&basename)))
> 		return NULL;
> 	if (!namelen)			/* special case: '/usr/' etc */
> 		return dir;
> 	bh = find_entry(&dir,basename,namelen,&de);
> 	if (!bh) {
> 		iput(dir);
> 		return NULL;
> 	}
> 	inr = de->inode;
> 	dev = dir->i_dev;
> 	brelse(bh);
> 	iput(dir);
> 	dir=iget(dev,inr);
> 	if (dir) {
> 		dir->i_atime=CURRENT_TIME;
> 		dir->i_dirt=1;
> 	}
> 	return dir;
> }
> 
> /*
>  *	open_namei()
>  *
>  * namei for open - this is in fact almost the whole open-routine.
>  */
> int open_namei(const char * pathname, int flag, int mode,
> 	struct m_inode ** res_inode)
> {
> 	const char * basename;
> 	int inr,dev,namelen;
> 	struct m_inode * dir, *inode;
> 	struct buffer_head * bh;
> 	struct dir_entry * de;
> 
> 	if ((flag & O_TRUNC) && !(flag & O_ACCMODE))
> 		flag |= O_WRONLY;
> 	mode &= 0777 & ~current->umask;
> 	mode |= I_REGULAR;
> 	if (!(dir = dir_namei(pathname,&namelen,&basename)))
> 		return -ENOENT;
> 	if (!namelen) {			/* special case: '/usr/' etc */
> 		if (!(flag & (O_ACCMODE|O_CREAT|O_TRUNC))) {
> 			*res_inode=dir;
> 			return 0;
> 		}
> 		iput(dir);
> 		return -EISDIR;
> 	}
> 	bh = find_entry(&dir,basename,namelen,&de);
> 	if (!bh) {
> 		if (!(flag & O_CREAT)) {
> 			iput(dir);
> 			return -ENOENT;
> 		}
> 		if (!permission(dir,MAY_WRITE)) {
> 			iput(dir);
> 			return -EACCES;
> 		}
> 		inode = new_inode(dir->i_dev);
> 		if (!inode) {
> 			iput(dir);
> 			return -ENOSPC;
> 		}
> 		inode->i_uid = current->euid;
> 		inode->i_mode = mode;
> 		inode->i_dirt = 1;
> 		bh = add_entry(dir,basename,namelen,&de);
> 		if (!bh) {
> 			inode->i_nlinks--;
> 			iput(inode);
> 			iput(dir);
> 			return -ENOSPC;
> 		}
> 		de->inode = inode->i_num;
> 		bh->b_dirt = 1;
> 		brelse(bh);
> 		iput(dir);
> 		*res_inode = inode;
> 		return 0;
> 	}
> 	inr = de->inode;
> 	dev = dir->i_dev;
> 	brelse(bh);
> 	iput(dir);
> 	if (flag & O_EXCL)
> 		return -EEXIST;
> 	if (!(inode=iget(dev,inr)))
> 		return -EACCES;
> 	if ((S_ISDIR(inode->i_mode) && (flag & O_ACCMODE)) ||
> 	    !permission(inode,ACC_MODE(flag))) {
> 		iput(inode);
> 		return -EPERM;
> 	}
> 	inode->i_atime = CURRENT_TIME;
> 	if (flag & O_TRUNC)
> 		truncate(inode);
> 	*res_inode = inode;
> 	return 0;
> }
> 
> int sys_mknod(const char * filename, int mode, int dev)
> {
> 	const char * basename;
> 	int namelen;
> 	struct m_inode * dir, * inode;
> 	struct buffer_head * bh;
> 	struct dir_entry * de;
> 	
> 	if (!suser())
> 		return -EPERM;
> 	if (!(dir = dir_namei(filename,&namelen,&basename)))
> 		return -ENOENT;
> 	if (!namelen) {
> 		iput(dir);
> 		return -ENOENT;
> 	}
> 	if (!permission(dir,MAY_WRITE)) {
> 		iput(dir);
> 		return -EPERM;
> 	}
> 	bh = find_entry(&dir,basename,namelen,&de);
> 	if (bh) {
> 		brelse(bh);
> 		iput(dir);
> 		return -EEXIST;
> 	}
> 	inode = new_inode(dir->i_dev);
> 	if (!inode) {
> 		iput(dir);
> 		return -ENOSPC;
> 	}
> 	inode->i_mode = mode;
> 	if (S_ISBLK(mode) || S_ISCHR(mode)  || S_ISPROC(mode) )
> 		inode->i_zone[0] = dev;
> 	inode->i_mtime = inode->i_atime = CURRENT_TIME;
> 	inode->i_dirt = 1;
> 	bh = add_entry(dir,basename,namelen,&de);
> 	if (!bh) {
> 		iput(dir);
> 		inode->i_nlinks=0;
> 		iput(inode);
> 		return -ENOSPC;
> 	}
> 	de->inode = inode->i_num;
> 	bh->b_dirt = 1;
> 	iput(dir);
> 	iput(inode);
> 	brelse(bh);
> 	return 0;
> }
> 
> int sys_mkdir(const char * pathname, int mode)
> {
> 	const char * basename;
> 	int namelen;
> 	struct m_inode * dir, * inode;
> 	struct buffer_head * bh, *dir_block;
> 	struct dir_entry * de;
> 
> 	if (!suser())
> 		return -EPERM;
> 	if (!(dir = dir_namei(pathname,&namelen,&basename)))
> 		return -ENOENT;
> 	if (!namelen) {
> 		iput(dir);
> 		return -ENOENT;
> 	}
> 	if (!permission(dir,MAY_WRITE)) {
> 		iput(dir);
> 		return -EPERM;
> 	}
> 	bh = find_entry(&dir,basename,namelen,&de);
> 	if (bh) {
> 		brelse(bh);
> 		iput(dir);
> 		return -EEXIST;
> 	}
> 	inode = new_inode(dir->i_dev);
> 	if (!inode) {
> 		iput(dir);
> 		return -ENOSPC;
> 	}
> 	inode->i_size = 32;
> 	inode->i_dirt = 1;
> 	inode->i_mtime = inode->i_atime = CURRENT_TIME;
> 	if (!(inode->i_zone[0]=new_block(inode->i_dev))) {
> 		iput(dir);
> 		inode->i_nlinks--;
> 		iput(inode);
> 		return -ENOSPC;
> 	}
> 	inode->i_dirt = 1;
> 	if (!(dir_block=bread(inode->i_dev,inode->i_zone[0]))) {
> 		iput(dir);
> 		free_block(inode->i_dev,inode->i_zone[0]);
> 		inode->i_nlinks--;
> 		iput(inode);
> 		return -ERROR;
> 	}
> 	de = (struct dir_entry *) dir_block->b_data;
> 	de->inode=inode->i_num;
> 	strcpy(de->name,".");
> 	de++;
> 	de->inode = dir->i_num;
> 	strcpy(de->name,"..");
> 	inode->i_nlinks = 2;
> 	dir_block->b_dirt = 1;
> 	brelse(dir_block);
> 	inode->i_mode = I_DIRECTORY | (mode & 0777 & ~current->umask);
> 	inode->i_dirt = 1;
> 	bh = add_entry(dir,basename,namelen,&de);
> 	if (!bh) {
> 		iput(dir);
> 		free_block(inode->i_dev,inode->i_zone[0]);
> 		inode->i_nlinks=0;
> 		iput(inode);
> 		return -ENOSPC;
> 	}
> 	de->inode = inode->i_num;
> 	bh->b_dirt = 1;
> 	dir->i_nlinks++;
> 	dir->i_dirt = 1;
> 	iput(dir);
> 	iput(inode);
> 	brelse(bh);
> 	return 0;
> }
> 
> /*
>  * routine to check that the specified directory is empty (for rmdir)
>  */
> static int empty_dir(struct m_inode * inode)
> {
> 	int nr,block;
> 	int len;
> 	struct buffer_head * bh;
> 	struct dir_entry * de;
> 
> 	len = inode->i_size / sizeof (struct dir_entry);
> 	if (len<2 || !inode->i_zone[0] ||
> 	    !(bh=bread(inode->i_dev,inode->i_zone[0]))) {
> 	    	printk("warning - bad directory on dev %04x\n",inode->i_dev);
> 		return 0;
> 	}
> 	de = (struct dir_entry *) bh->b_data;
> 	if (de[0].inode != inode->i_num || !de[1].inode || 
> 	    strcmp(".",de[0].name) || strcmp("..",de[1].name)) {
> 	    	printk("warning - bad directory on dev %04x\n",inode->i_dev);
> 		return 0;
> 	}
> 	nr = 2;
> 	de += 2;
> 	while (nr<len) {
> 		if ((void *) de >= (void *) (bh->b_data+BLOCK_SIZE)) {
> 			brelse(bh);
> 			block=bmap(inode,nr/DIR_ENTRIES_PER_BLOCK);
> 			if (!block) {
> 				nr += DIR_ENTRIES_PER_BLOCK;
> 				continue;
> 			}
> 			if (!(bh=bread(inode->i_dev,block)))
> 				return 0;
> 			de = (struct dir_entry *) bh->b_data;
> 		}
> 		if (de->inode) {
> 			brelse(bh);
> 			return 0;
> 		}
> 		de++;
> 		nr++;
> 	}
> 	brelse(bh);
> 	return 1;
> }
> 
> int sys_rmdir(const char * name)
> {
> 	const char * basename;
> 	int namelen;
> 	struct m_inode * dir, * inode;
> 	struct buffer_head * bh;
> 	struct dir_entry * de;
> 
> 	if (!suser())
> 		return -EPERM;
> 	if (!(dir = dir_namei(name,&namelen,&basename)))
> 		return -ENOENT;
> 	if (!namelen) {
> 		iput(dir);
> 		return -ENOENT;
> 	}
> 	if (!permission(dir,MAY_WRITE)) {
> 		iput(dir);
> 		return -EPERM;
> 	}
> 	bh = find_entry(&dir,basename,namelen,&de);
> 	if (!bh) {
> 		iput(dir);
> 		return -ENOENT;
> 	}
> 	if (!(inode = iget(dir->i_dev, de->inode))) {
> 		iput(dir);
> 		brelse(bh);
> 		return -EPERM;
> 	}
> 	if ((dir->i_mode & S_ISVTX) && current->euid &&
> 	    inode->i_uid != current->euid) {
> 		iput(dir);
> 		iput(inode);
> 		brelse(bh);
> 		return -EPERM;
> 	}
> 	if (inode->i_dev != dir->i_dev || inode->i_count>1) {
> 		iput(dir);
> 		iput(inode);
> 		brelse(bh);
> 		return -EPERM;
> 	}
> 	if (inode == dir) {	/* we may not delete ".", but "../dir" is ok */
> 		iput(inode);
> 		iput(dir);
> 		brelse(bh);
> 		return -EPERM;
> 	}
> 	if (!S_ISDIR(inode->i_mode)) {
> 		iput(inode);
> 		iput(dir);
> 		brelse(bh);
> 		return -ENOTDIR;
> 	}
> 	if (!empty_dir(inode)) {
> 		iput(inode);
> 		iput(dir);
> 		brelse(bh);
> 		return -ENOTEMPTY;
> 	}
> 	if (inode->i_nlinks != 2)
> 		printk("empty directory has nlink!=2 (%d)",inode->i_nlinks);
> 	de->inode = 0;
> 	bh->b_dirt = 1;
> 	brelse(bh);
> 	inode->i_nlinks=0;
> 	inode->i_dirt=1;
> 	dir->i_nlinks--;
> 	dir->i_ctime = dir->i_mtime = CURRENT_TIME;
> 	dir->i_dirt=1;
> 	iput(dir);
> 	iput(inode);
> 	return 0;
> }
> 
> int sys_unlink(const char * name)
> {
> 	const char * basename;
> 	int namelen;
> 	struct m_inode * dir, * inode;
> 	struct buffer_head * bh;
> 	struct dir_entry * de;
> 
> 	if (!(dir = dir_namei(name,&namelen,&basename)))
> 		return -ENOENT;
> 	if (!namelen) {
> 		iput(dir);
> 		return -ENOENT;
> 	}
> 	if (!permission(dir,MAY_WRITE)) {
> 		iput(dir);
> 		return -EPERM;
> 	}
> 	bh = find_entry(&dir,basename,namelen,&de);
> 	if (!bh) {
> 		iput(dir);
> 		return -ENOENT;
> 	}
> 	if (!(inode = iget(dir->i_dev, de->inode))) {
> 		iput(dir);
> 		brelse(bh);
> 		return -ENOENT;
> 	}
> 	if ((dir->i_mode & S_ISVTX) && !suser() &&
> 	    current->euid != inode->i_uid &&
> 	    current->euid != dir->i_uid) {
> 		iput(dir);
> 		iput(inode);
> 		brelse(bh);
> 		return -EPERM;
> 	}
> 	if (S_ISDIR(inode->i_mode)) {
> 		iput(inode);
> 		iput(dir);
> 		brelse(bh);
> 		return -EPERM;
> 	}
> 	if (!inode->i_nlinks) {
> 		printk("Deleting nonexistent file (%04x:%d), %d\n",
> 			inode->i_dev,inode->i_num,inode->i_nlinks);
> 		inode->i_nlinks=1;
> 	}
> 	de->inode = 0;
> 	bh->b_dirt = 1;
> 	brelse(bh);
> 	inode->i_nlinks--;
> 	inode->i_dirt = 1;
> 	inode->i_ctime = CURRENT_TIME;
> 	iput(inode);
> 	iput(dir);
> 	return 0;
> }
> 
> int sys_link(const char * oldname, const char * newname)
> {
> 	struct dir_entry * de;
> 	struct m_inode * oldinode, * dir;
> 	struct buffer_head * bh;
> 	const char * basename;
> 	int namelen;
> 
> 	oldinode=namei(oldname);
> 	if (!oldinode)
> 		return -ENOENT;
> 	if (S_ISDIR(oldinode->i_mode)) {
> 		iput(oldinode);
> 		return -EPERM;
> 	}
> 	dir = dir_namei(newname,&namelen,&basename);
> 	if (!dir) {
> 		iput(oldinode);
> 		return -EACCES;
> 	}
> 	if (!namelen) {
> 		iput(oldinode);
> 		iput(dir);
> 		return -EPERM;
> 	}
> 	if (dir->i_dev != oldinode->i_dev) {
> 		iput(dir);
> 		iput(oldinode);
> 		return -EXDEV;
> 	}
> 	if (!permission(dir,MAY_WRITE)) {
> 		iput(dir);
> 		iput(oldinode);
> 		return -EACCES;
> 	}
> 	bh = find_entry(&dir,basename,namelen,&de);
> 	if (bh) {
> 		brelse(bh);
> 		iput(dir);
> 		iput(oldinode);
> 		return -EEXIST;
> 	}
> 	bh = add_entry(dir,basename,namelen,&de);
> 	if (!bh) {
> 		iput(dir);
> 		iput(oldinode);
> 		return -ENOSPC;
> 	}
> 	de->inode = oldinode->i_num;
> 	bh->b_dirt = 1;
> 	brelse(bh);
> 	iput(dir);
> 	oldinode->i_nlinks++;
> 	oldinode->i_ctime = CURRENT_TIME;
> 	oldinode->i_dirt = 1;
> 	iput(oldinode);
> 	return 0;
> }
> 
> ```

##### ll_rw_blk：读写块设备的底层驱动程序，被bread调用读取数据，被sync调用回写覆盖磁盘数据，iget使用bread读数据，iput使用sync_dev回写i节点到磁盘

> 内核管理块设备的数据结构是块设备表和请求项队列，块设备结构体blk_dev_struct和请求项结构体request在include/blk_dev/blk.h中定义。块设备表和请求项队列组成一个数组链表结构，他的结构见下图，
>
> ![Screenshot 2022-10-21 023240](实验\1 操作系统实验\实验8 虚拟文件系统的实现\Screenshot 2022-10-21 023240.png)
>
> ```c
> // include/blk_drv.h，定义了块设备结构体，块设备表，请求项结构体，请求项表，组织块设备表和请求项表构成数组链表结构
> // include/chr_drv.h, 定义了字符设备结构体，字符设备表
> 
> #ifndef _BLK_H
> #define _BLK_H
> 
> #define NR_BLK_DEV	7
> /*
>  * NR_REQUEST is the number of entries in the request-queue.
>  * NOTE that writes may use only the low 2/3 of these: reads
>  * take precedence.
>  *
>  * 32 seems to be a reasonable number: enough to get some benefit
>  * from the elevator-mechanism, but not so much as to lock a lot of
>  * buffers when they are in the queue. 64 seems to be too many (easily
>  * long pauses in reading when heavy writing/syncing is going on)
>  */
> #define NR_REQUEST	32
> 
> /*
>  * Ok, this is an expanded form so that we can use the same
>  * request for paging requests when that is implemented. In
>  * paging, 'bh' is NULL, and 'waiting' is used to wait for
>  * read/write completion.
>  */
> struct request {
> 	int dev;		/* -1 if no request */				//请求项请求读写的设备号。
> 	int cmd;		/* READ or WRITE */					//读或写命令
> 	int errors;											//执行的错误数
> 	unsigned long sector;								//起始扇区号
> 	unsigned long nr_sectors;							//读写扇区数
> 	char * buffer;										//数据缓冲区（磁盘一次读写一个扇区，而一个数据块不仅一个扇区，需要缓冲
>     													//区缓冲，当读磁盘的时候每读完一个扇区会放到缓冲区中，磁盘发出磁盘
>     													//读中断，读中断会将缓冲区拷贝到内核缓冲块，如果还有扇区没有读完会
>     													//继续，否则会唤醒阻塞在本请求项的进程和唤醒一个阻塞在磁盘等待队列
>     													//的进程，执行下一个请求项。
> 	struct task_struct * waiting;						//等待该请求项的进程
> 	struct buffer_head * bh;							//缓冲块头指针
> 	struct request * next;								//下一个请求项
> };
> extern struct request request[NR_REQUEST];				//请求项队列
> struct blk_dev_struct {
> 	void (*request_fn)(void);							//设备操作函数（根据请求想的cmd来判断操作函数是读还是写）
> 	struct request * current_request;					//请求项指针
> };						
> extern struct blk_dev_struct blk_dev[NR_BLK_DEV];		//块设备表
> extern struct task_struct * wait_for_request;			//等待设备的进程
> 
> /*
>  * This is used in the elevator algorithm: Note that
>  * reads always go before writes. This is natural: reads
>  * are much more time-critical than writes.
>  */
> #define IN_ORDER(s1,s2) \
> ((s1)->cmd<(s2)->cmd || ((s1)->cmd==(s2)->cmd && \
> ((s1)->dev < (s2)->dev || ((s1)->dev == (s2)->dev && \
> (s1)->sector < (s2)->sector))))
> 
> #ifdef MAJOR_NR
> 
> /*
>  * Add entries as needed. Currently the only block devices
>  * supported are hard-disks and floppies.
>  */
> 
> #if (MAJOR_NR == 1)
> /* ram disk */
> #define DEVICE_NAME "ramdisk"
> #define DEVICE_REQUEST do_rd_request
> #define DEVICE_NR(device) ((device) & 7)
> #define DEVICE_ON(device) 
> #define DEVICE_OFF(device)
> 
> #elif (MAJOR_NR == 2)
> /* floppy */
> #define DEVICE_NAME "floppy"
> #define DEVICE_INTR do_floppy
> #define DEVICE_REQUEST do_fd_request
> #define DEVICE_NR(device) ((device) & 3)
> #define DEVICE_ON(device) floppy_on(DEVICE_NR(device))
> #define DEVICE_OFF(device) floppy_off(DEVICE_NR(device))
> 
> #elif (MAJOR_NR == 3)
> /* harddisk */
> #define DEVICE_NAME "harddisk"
> #define DEVICE_INTR do_hd
> #define DEVICE_REQUEST do_hd_request
> #define DEVICE_NR(device) (MINOR(device)/5)
> #define DEVICE_ON(device)
> #define DEVICE_OFF(device)
> 
> #elif
> /* unknown blk device */
> #error "unknown blk device"
> 
> #endif
> 
> #define CURRENT (blk_dev[MAJOR_NR].current_request)
> #define CURRENT_DEV DEVICE_NR(CURRENT->dev)
> 
> #ifdef DEVICE_INTR
> void (*DEVICE_INTR)(void) = NULL;
> #endif
> static void (DEVICE_REQUEST)(void);
> 
> static inline void unlock_buffer(struct buffer_head * bh)
> {
> 	if (!bh->b_lock)
> 		printk(DEVICE_NAME ": free buffer being unlocked\n");
> 	bh->b_lock=0;
> 	wake_up(&bh->b_wait);
> }
> 
> static inline void end_request(int uptodate)
> {
> 	DEVICE_OFF(CURRENT->dev);
> 	if (CURRENT->bh) {
> 		CURRENT->bh->b_uptodate = uptodate;
> 		unlock_buffer(CURRENT->bh);
> 	}
> 	if (!uptodate) {
> 		printk(DEVICE_NAME " I/O error\n\r");
> 		printk("dev %04x, block %d\n\r",CURRENT->dev,
> 			CURRENT->bh->b_blocknr);
> 	}
> 	wake_up(&CURRENT->waiting);
> 	wake_up(&wait_for_request);
> 	CURRENT->dev = -1;
> 	CURRENT = CURRENT->next;
> }
> 
> #define INIT_REQUEST \
> repeat: \
> 	if (!CURRENT) \
> 		return; \
> 	if (MAJOR(CURRENT->dev) != MAJOR_NR) \
> 		panic(DEVICE_NAME ": request list destroyed"); \
> 	if (CURRENT->bh) { \
> 		if (!CURRENT->bh->b_lock) \
> 			panic(DEVICE_NAME ": block not locked"); \
> 	}
> 
> #endif
> 
> #endif
> ```
>
> ll_rw_blk函数根据块设备号和逻辑块号和读写命令组织起一个请求项，检查请求项列表是否有空间存放，如果没有那么进程阻塞到块设备阻塞队列wait_request上。否则，将请求项添加到请求项队列中去，这个添加按照电梯调度算法添加，目的是减少磁头移动次数。如果添加请求项的位置是头节点，那么直接执行这个请求项的操作函数request_fn，对于磁盘来说，这个操作函数是do_hd_request，定义在kernel/blk_drv/hd.c中，执行磁盘操作函数的时候，进程给磁盘控制器传递参数和控制命令，然后自己阻塞到请求项的阻塞队列上。当磁盘控制器读写完一个扇区之后，触发磁盘中断，分为磁盘读中断和磁盘写中断，如果是磁盘都终端read_intr，他会把请求项缓冲区的一个扇区数据拷贝到内核缓冲区，然后检查有没有还有数据，如果还有会继续读数据到请求项缓冲区，然后触发读中断，知道所有扇区读完，读中断会唤醒阻塞在这个请求项和阻塞在磁盘上的进程；如果是写磁盘，进程调用do_hd_request之后会项控制器传递参数和写磁盘控制命令，然后阻塞自己到请求项阻塞队列中，磁盘控制器在写完一个扇区之后会发生写中断，发现还有数据要写会继续调用写磁盘，直到缓冲块数据写完到磁盘。读写磁盘中断完成的最后，是唤醒阻塞在请求项的进程和阻塞在磁盘上的进程，之后删除这个请求项，执行下一个请求项的。在执行do_hd_request的开头是锁定内核缓冲块（在缓冲块头设置锁标志），如果发现是写磁盘并且文件没有修改或读磁盘但是文件被更新，那么说明这个缓冲块可以直接用，直接返回，否则才会触发磁盘读写函数do_hd_request.
>
> ```
> //ll_rw_request.c
> /*
>  *  linux/kernel/blk_dev/ll_rw.c
>  *
>  * (C) 1991 Linus Torvalds
>  */
> 
> /*
>  * This handles all read/write requests to block devices
>  */
> #include <errno.h>
> #include <linux/sched.h>
> #include <linux/kernel.h>
> #include <asm/system.h>
> 
> #include "blk.h"
> 
> /*
>  * The request-struct contains all necessary data
>  * to load a nr of sectors into memory
>  */
> struct request request[NR_REQUEST];
> 
> /*
>  * used to wait on when there are no free requests
>  */
> struct task_struct * wait_for_request = NULL;
> 
> /* blk_dev_struct is:
>  *	do_request-address
>  *	next-request
>  */
> struct blk_dev_struct blk_dev[NR_BLK_DEV] = {
> 	{ NULL, NULL },		/* no_dev */
> 	{ NULL, NULL },		/* dev mem */
> 	{ NULL, NULL },		/* dev fd */
> 	{ NULL, NULL },		/* dev hd */
> 	{ NULL, NULL },		/* dev ttyx */
> 	{ NULL, NULL },		/* dev tty */
> 	{ NULL, NULL }		/* dev lp */
> };
> 
> static inline void lock_buffer(struct buffer_head * bh)
> {
> 	cli();
> 	while (bh->b_lock)
> 		sleep_on(&bh->b_wait);
> 	bh->b_lock=1;
> 	sti();
> }
> 
> static inline void unlock_buffer(struct buffer_head * bh)
> {
> 	if (!bh->b_lock)
> 		printk("ll_rw_block.c: buffer not locked\n\r");
> 	bh->b_lock = 0;
> 	wake_up(&bh->b_wait);
> }
> 
> /*
>  * add-request adds a request to the linked list.
>  * It disables interrupts so that it can muck with the
>  * request-lists in peace.
>  */
> static void add_request(struct blk_dev_struct * dev, struct request * req)
> {
> 	struct request * tmp;
> 
> 	req->next = NULL;
> 	cli();
> 	if (req->bh)
> 		req->bh->b_dirt = 0;
> 	if (!(tmp = dev->current_request)) {
> 		dev->current_request = req;
> 		sti();
> 		(dev->request_fn)();
> 		return;
> 	}
> 	for ( ; tmp->next ; tmp=tmp->next)
> 		if ((IN_ORDER(tmp,req) || 
> 		    !IN_ORDER(tmp,tmp->next)) &&
> 		    IN_ORDER(req,tmp->next))
> 			break;
> 	req->next=tmp->next;
> 	tmp->next=req;
> 	sti();
> }
> 
> static void make_request(int major,int rw, struct buffer_head * bh)
> {
> 	struct request * req;
> 	int rw_ahead;
> 
> /* WRITEA/READA is special case - it is not really needed, so if the */
> /* buffer is locked, we just forget about it, else it's a normal read */
> 	if ((rw_ahead = (rw == READA || rw == WRITEA))) {
> 		if (bh->b_lock)
> 			return;
> 		if (rw == READA)
> 			rw = READ;
> 		else
> 			rw = WRITE;
> 	}
> 	if (rw!=READ && rw!=WRITE)
> 		panic("Bad block dev command, must be R/W/RA/WA");
> 	lock_buffer(bh);
> 	if ((rw == WRITE && !bh->b_dirt) || (rw == READ && bh->b_uptodate)) {
> 		unlock_buffer(bh);
> 		return;
> 	}
> repeat:
> /* we don't allow the write-requests to fill up the queue completely:
>  * we want some room for reads: they take precedence. The last third
>  * of the requests are only for reads.
>  */
> 	if (rw == READ)
> 		req = request+NR_REQUEST;
> 	else
> 		req = request+((NR_REQUEST*2)/3);
> /* find an empty request */
> 	while (--req >= request)
> 		if (req->dev<0)
> 			break;
> /* if none found, sleep on new requests: check for rw_ahead */
> 	if (req < request) {
> 		if (rw_ahead) {
> 			unlock_buffer(bh);
> 			return;
> 		}
> 		sleep_on(&wait_for_request);
> 		goto repeat;
> 	}
> /* fill up the request-info, and add it to the queue */
> 	req->dev = bh->b_dev;
> 	req->cmd = rw;
> 	req->errors=0;
> 	req->sector = bh->b_blocknr<<1;
> 	req->nr_sectors = 2;
> 	req->buffer = bh->b_data;
> 	req->waiting = NULL;
> 	req->bh = bh;
> 	req->next = NULL;
> 	add_request(major+blk_dev,req);
> }
> 
> void ll_rw_block(int rw, struct buffer_head * bh)
> {
> 	unsigned int major;
> 
> 	if ((major=MAJOR(bh->b_dev)) >= NR_BLK_DEV ||
> 	!(blk_dev[major].request_fn)) {
> 		printk("Trying to read nonexistent block-device\n\r");
> 		return;
> 	}
> 	make_request(major,rw,bh);
> }
> 
> void blk_dev_init(void)
> {
> 	int i;
> 
> 	for (i=0 ; i<NR_REQUEST ; i++) {
> 		request[i].dev = -1;
> 		request[i].next = NULL;
> 	}
> }
> ```
>
> ```
> //hd.c
> /*
>  *  linux/kernel/hd.c
>  *
>  *  (C) 1991  Linus Torvalds
>  */
> 
> /*
>  * This is the low-level hd interrupt support. It traverses the
>  * request-list, using interrupts to jump between functions. As
>  * all the functions are called within interrupts, we may not
>  * sleep. Special care is recommended.
>  * 
>  *  modified by Drew Eckhardt to check nr of hd's from the CMOS.
>  */
> 
> #include <linux/config.h>
> #include <linux/sched.h>
> #include <linux/fs.h>
> #include <linux/kernel.h>
> #include <linux/hdreg.h>
> #include <asm/system.h>
> #include <asm/io.h>
> #include <asm/segment.h>
> 
> #define MAJOR_NR 3
> #include "blk.h"
> 
> #define CMOS_READ(addr) ({ \
> outb_p(0x80|addr,0x70); \
> inb_p(0x71); \
> })
> 
> /* Max read/write errors/sector */
> #define MAX_ERRORS	7
> #define MAX_HD		2
> 
> static void recal_intr(void);
> 
> static int recalibrate = 1;
> static int reset = 1;
> 
> /*
>  *  This struct defines the HD's and their types.
>  */
> struct hd_i_struct {
> 	int head,sect,cyl,wpcom,lzone,ctl;
> 	};
> #ifdef HD_TYPE
> struct hd_i_struct hd_info[] = { HD_TYPE };
> #define NR_HD ((sizeof (hd_info))/(sizeof (struct hd_i_struct)))
> #else
> struct hd_i_struct hd_info[] = { {0,0,0,0,0,0},{0,0,0,0,0,0} };
> static int NR_HD = 0;
> #endif
> 
> static struct hd_struct {
> 	long start_sect;
> 	long nr_sects;
> } hd[5*MAX_HD]={{0,0},};
> 
> #define port_read(port,buf,nr) \
> __asm__("cld;rep;insw"::"d" (port),"D" (buf),"c" (nr))
> 
> #define port_write(port,buf,nr) \
> __asm__("cld;rep;outsw"::"d" (port),"S" (buf),"c" (nr))
> 
> extern void hd_interrupt(void);
> extern void rd_load(void);
> 
> /* This may be used only once, enforced by 'static int callable' */
> int sys_setup(void * BIOS)
> {
> 	static int callable = 1;
> 	int i,drive;
> 	unsigned char cmos_disks;
> 	struct partition *p;
> 	struct buffer_head * bh;
> 
> 	if (!callable)
> 		return -1;
> 	callable = 0;
> #ifndef HD_TYPE
> 	for (drive=0 ; drive<2 ; drive++) {
> 		hd_info[drive].cyl = *(unsigned short *) BIOS;
> 		hd_info[drive].head = *(unsigned char *) (2+BIOS);
> 		hd_info[drive].wpcom = *(unsigned short *) (5+BIOS);
> 		hd_info[drive].ctl = *(unsigned char *) (8+BIOS);
> 		hd_info[drive].lzone = *(unsigned short *) (12+BIOS);
> 		hd_info[drive].sect = *(unsigned char *) (14+BIOS);
> 		BIOS += 16;
> 	}
> 	if (hd_info[1].cyl)
> 		NR_HD=2;
> 	else
> 		NR_HD=1;
> #endif
> 	for (i=0 ; i<NR_HD ; i++) {
> 		hd[i*5].start_sect = 0;
> 		hd[i*5].nr_sects = hd_info[i].head*
> 				hd_info[i].sect*hd_info[i].cyl;
> 	}
> 
> 	/*
> 		We querry CMOS about hard disks : it could be that 
> 		we have a SCSI/ESDI/etc controller that is BIOS
> 		compatable with ST-506, and thus showing up in our
> 		BIOS table, but not register compatable, and therefore
> 		not present in CMOS.
> 
> 		Furthurmore, we will assume that our ST-506 drives
> 		<if any> are the primary drives in the system, and 
> 		the ones reflected as drive 1 or 2.
> 
> 		The first drive is stored in the high nibble of CMOS
> 		byte 0x12, the second in the low nibble.  This will be
> 		either a 4 bit drive type or 0xf indicating use byte 0x19 
> 		for an 8 bit type, drive 1, 0x1a for drive 2 in CMOS.
> 
> 		Needless to say, a non-zero value means we have 
> 		an AT controller hard disk for that drive.
> 
> 		
> 	*/
> 
> 	if ((cmos_disks = CMOS_READ(0x12)) & 0xf0)
> 		if (cmos_disks & 0x0f)
> 			NR_HD = 2;
> 		else
> 			NR_HD = 1;
> 	else
> 		NR_HD = 0;
> 	for (i = NR_HD ; i < 2 ; i++) {
> 		hd[i*5].start_sect = 0;
> 		hd[i*5].nr_sects = 0;
> 	}
> 	for (drive=0 ; drive<NR_HD ; drive++) {
> 		if (!(bh = bread(0x300 + drive*5,0))) {
> 			printk("Unable to read partition table of drive %d\n\r",
> 				drive);
> 			panic("");
> 		}
> 		if (bh->b_data[510] != 0x55 || (unsigned char)
> 		    bh->b_data[511] != 0xAA) {
> 			printk("Bad partition table on drive %d\n\r",drive);
> 			panic("");
> 		}
> 		p = 0x1BE + (void *)bh->b_data;
> 		for (i=1;i<5;i++,p++) {
> 			hd[i+5*drive].start_sect = p->start_sect;
> 			hd[i+5*drive].nr_sects = p->nr_sects;
> 		}
> 		brelse(bh);
> 	}
> 	if (NR_HD)
> 		printk("Partition table%s ok.\n\r",(NR_HD>1)?"s":"");
> 	rd_load();
> 	mount_root();
> 	return (0);
> }
> 
> static int controller_ready(void)
> {
> 	int retries=10000;
> 
> 	while (--retries && (inb_p(HD_STATUS)&0xc0)!=0x40);
> 	return (retries);
> }
> 
> static int win_result(void)
> {
> 	int i=inb_p(HD_STATUS);
> 
> 	if ((i & (BUSY_STAT | READY_STAT | WRERR_STAT | SEEK_STAT | ERR_STAT))
> 		== (READY_STAT | SEEK_STAT))
> 		return(0); /* ok */
> 	if (i&1) i=inb(HD_ERROR);
> 	return (1);
> }
> 
> static void hd_out(unsigned int drive,unsigned int nsect,unsigned int sect,
> 		unsigned int head,unsigned int cyl,unsigned int cmd,
> 		void (*intr_addr)(void))
> {
> 	register int port asm("dx");
> 
> 	if (drive>1 || head>15)
> 		panic("Trying to write bad sector");
> 	if (!controller_ready())
> 		panic("HD controller not ready");
> 	do_hd = intr_addr;
> 	outb_p(hd_info[drive].ctl,HD_CMD);
> 	port=HD_DATA;
> 	outb_p(hd_info[drive].wpcom>>2,++port);
> 	outb_p(nsect,++port);
> 	outb_p(sect,++port);
> 	outb_p(cyl,++port);
> 	outb_p(cyl>>8,++port);
> 	outb_p(0xA0|(drive<<4)|head,++port);
> 	outb(cmd,++port);
> }
> 
> static int drive_busy(void)
> {
> 	unsigned int i;
> 
> 	for (i = 0; i < 10000; i++)
> 		if (READY_STAT == (inb_p(HD_STATUS) & (BUSY_STAT|READY_STAT)))
> 			break;
> 	i = inb(HD_STATUS);
> 	i &= BUSY_STAT | READY_STAT | SEEK_STAT;
> 	if (i == (READY_STAT | SEEK_STAT))
> 		return(0);
> 	printk("HD controller times out\n\r");
> 	return(1);
> }
> 
> static void reset_controller(void)
> {
> 	int	i;
> 
> 	outb(4,HD_CMD);
> 	for(i = 0; i < 100; i++) nop();
> 	outb(hd_info[0].ctl & 0x0f ,HD_CMD);
> 	if (drive_busy())
> 		printk("HD-controller still busy\n\r");
> 	if ((i = inb(HD_ERROR)) != 1)
> 		printk("HD-controller reset failed: %02x\n\r",i);
> }
> 
> static void reset_hd(int nr)
> {
> 	reset_controller();
> 	hd_out(nr,hd_info[nr].sect,hd_info[nr].sect,hd_info[nr].head-1,
> 		hd_info[nr].cyl,WIN_SPECIFY,&recal_intr);
> }
> 
> void unexpected_hd_interrupt(void)
> {
> 	printk("Unexpected HD interrupt\n\r");
> }
> 
> static void bad_rw_intr(void)
> {
> 	if (++CURRENT->errors >= MAX_ERRORS)
> 		end_request(0);
> 	if (CURRENT->errors > MAX_ERRORS/2)
> 		reset = 1;
> }
> 
> static void read_intr(void)
> {
> 	if (win_result()) {
> 		bad_rw_intr();
> 		do_hd_request();
> 		return;
> 	}
> 	port_read(HD_DATA,CURRENT->buffer,256);
> 	CURRENT->errors = 0;
> 	CURRENT->buffer += 512;
> 	CURRENT->sector++;
> 	if (--CURRENT->nr_sectors) {
> 		do_hd = &read_intr;
> 		return;
> 	}
> 	end_request(1);
> 	do_hd_request();
> }
> 
> static void write_intr(void)
> {
> 	if (win_result()) {
> 		bad_rw_intr();
> 		do_hd_request();
> 		return;
> 	}
> 	if (--CURRENT->nr_sectors) {
> 		CURRENT->sector++;
> 		CURRENT->buffer += 512;
> 		do_hd = &write_intr;
> 		port_write(HD_DATA,CURRENT->buffer,256);
> 		return;
> 	}
> 	end_request(1);
> 	do_hd_request();
> }
> 
> static void recal_intr(void)
> {
> 	if (win_result())
> 		bad_rw_intr();
> 	do_hd_request();
> }
> 
> void do_hd_request(void)
> {
> 	int i,r = 0;
> 	unsigned int block,dev;
> 	unsigned int sec,head,cyl;
> 	unsigned int nsect;
> 
> 	INIT_REQUEST;
> 	dev = MINOR(CURRENT->dev);
> 	block = CURRENT->sector;
> 	if (dev >= 5*NR_HD || block+2 > hd[dev].nr_sects) {
> 		end_request(0);
> 		goto repeat;
> 	}
> 	block += hd[dev].start_sect;
> 	dev /= 5;
> 	__asm__("divl %4":"=a" (block),"=d" (sec):"0" (block),"1" (0),
> 		"r" (hd_info[dev].sect));
> 	__asm__("divl %4":"=a" (cyl),"=d" (head):"0" (block),"1" (0),
> 		"r" (hd_info[dev].head));
> 	sec++;
> 	nsect = CURRENT->nr_sectors;
> 	if (reset) {
> 		reset = 0;
> 		recalibrate = 1;
> 		reset_hd(CURRENT_DEV);
> 		return;
> 	}
> 	if (recalibrate) {
> 		recalibrate = 0;
> 		hd_out(dev,hd_info[CURRENT_DEV].sect,0,0,0,
> 			WIN_RESTORE,&recal_intr);
> 		return;
> 	}	
> 	if (CURRENT->cmd == WRITE) {
> 		hd_out(dev,nsect,sec,head,cyl,WIN_WRITE,&write_intr);
> 		for(i=0 ; i<3000 && !(r=inb_p(HD_STATUS)&DRQ_STAT) ; i++)
> 			/* nothing */ ;
> 		if (!r) {
> 			bad_rw_intr();
> 			goto repeat;
> 		}
> 		port_write(HD_DATA,CURRENT->buffer,256);
> 	} else if (CURRENT->cmd == READ) {
> 		hd_out(dev,nsect,sec,head,cyl,WIN_READ,&read_intr);
> 	} else
> 		panic("unknown hd-command");
> }
> 
> void hd_init(void)
> {
> 	blk_dev[MAJOR_NR].request_fn = DEVICE_REQUEST;
> 	set_intr_gate(0x2E,&hd_interrupt);
> 	outb_p(inb_p(0x21)&0xfb,0x21);
> 	outb(inb_p(0xA1)&0xbf,0xA1);
> }
> ```

#### 执行可执行文件系统调用exec

**execve函数加载器原理**

[argc argv_百度百科 (baidu.com)](https://baike.baidu.com/item/argc argv/10826112)

[(108条消息) Linux 执行新程序：execve() 函数_GeneralSandman的博客-CSDN博客](https://blog.csdn.net/qq_33955922/article/details/53956547)

argc和argv是shell传递的参数，当向shell键入程序执行命令**./aa ab cd**的时候shell向**aa**执行程序的main函数传递2个参数，一个是参数数量argc，一个是参数地址argv，argv[0]保存的是可执行程序**aa**的路径名，其他项是传入的参数**aa, cd **。

execve这个Linux加载程序并执行函数原理是替换调用execve函数的进程的代码段数据段为需要被加载的程序，然后修改cs:eip为main函数起点位置开始执行程序。这个过程利用了旧进程的数据结构和内存，并没有创建新的进程，也不是函数调用。

```
//old.c
#include<stdio.h>
#include<unistd.h>
#include<stdlib.h>
#include<sys/types.h>
#include<string.h>
int main(int argc,char * argv[]){
    char * argVec[10];
    char * envVec[]={"环境变量1","环境变量2",NULL};
    argVec[0]=argv[0];
    argVec[1]=argv[1];
    argVec[2]="参数1";
    execve(argv[1],argVec,envVec);
    printf("the progress can't to here\n");
    exit(EXIT_SUCCESS);
}




//new.c
#include<stdio.h>
#include<unistd.h>
#include<stdlib.h>
#include<sys/types.h>
extern char ** environ;
int main(int argc,char * argv[]){
    int i=0;
    char ** ep;
    printf("new progress\n");
    printf("参数\n");
    for(i=0;i<argc;i++)
        printf("\t%s\n",argv[i]);
    printf("环境变量：\n");
    for(ep=environ;*ep!=NULL;ep++)
        printf("\t%s\n",*ep);
    printf("new progress over\n");
    exit(EXIT_SUCCESS);
    return 0;
}
```

![Screenshot 2022-10-22 010317](实验\1 操作系统实验\实验8 虚拟文件系统的实现\Screenshot 2022-10-22 010317.png)

**sys_execve程序加载和执行系统调用的实现**

> 可执行文件文件结构划分为7个部分，执行头/代码段(.data)/数据段(.data存储已初始化全局或者静态变量，.bss没有因为他没有初始化数据)/代码重定位部分/数据重定位部分/符号表部分/字符串表部分。每个执行文件都以执行头开始，执行头数据结构如下
>
> ```c
> struct exec{
> 	unsigned long a_midmag;
> 	unsigned long a_text ;	//代码段大小
> 	unsigned long a_data ;	//已初始化数据区大小
> 	unsigned long a_bss;	//未初始化数据区大小
> 	unsigned long a_syms;	
> 	unsigned long a_entry;	//程序入口地址偏移，可以用来计算程
>     						//序入口地址的逻辑地址
>     						//a_entry-sizeof(struct exec)
> 	unsigned long a_trsize;
> 	unsigned long a_drsize;
> }
> ```
>
> 创建进程2的fork系统调用的时候会设置子进程的页表指向进程1的页表，复制进程1的打开文件表，复位信号，设置进程PCB结构体。execve被调用的时候，清空进程2的所有数据堆栈段和代码段页表，释放原来进程所占用的页面free_page，然后根据可执行文件名读取文件i节点，通过i节点bread函数读取可执行文件的执行头，可执行文件执行头中包含了代码段数据段大小(a_text, a_data+a_bss)，根据可执行文件头的数据段和代码段大小设置数据段和代码段的段基址和段限长，根据bss段大小设置进程结构体的堆指针current->brk，在数据段的末端加载参数和环境变量（将参数和环境变量加载到栈里面，为了保持栈的干净，进程0和进程1都不会 使用用户占user_stack，并且fork/pause等系统调用函数调用需要使用用户栈，也将fork/pause系统调用变成内联函数而保证了不会使用用户栈，也就保证了不会弄乱用户栈，保证了从进程0fork到进程1再fork到进程2的过程不会使用用户栈，也就不会弄乱进程2的用户栈），然后修改进程PCB中信号位图复位，修改用户组和用户，修改用户可执行文件i节点指针current->executable，修改execve系统调用中cs:eip为新程序入口地址（这个程序入口地址就是可执行文件执行头的a_entry，他是程序入口地址在代码段的偏移，他是一个逻辑地址），修改execve系统调用中的ss:esp指向用户栈地址（这个用户栈地址是压入参数和环境变量以及argc和argv的栈，argv指针指向参数和环境变量开始的在栈上的地址），execve函数还会初始化bss段的数据为0。这样在程序从系统调用sys_execve中返回的时候会返回到新程序的入口地址执行，并且使用的栈是新程序的用户栈。当执行新程序的入口地址的代码时，通关段表获得线性地址后发现对应的页表没有页面，就发生缺页中断。缺页中断根据进程可执行文件i节点current->executable获取设备号，将逻辑地址加上对应段的基地址得到文件读写指针，然后把这个文件读写指针/BLOCK_SIZE磁盘数据块的大小，可以获得这个文件读写指针所在的数据块，然后根据这个数据块块号使用文件i节点的i_zone逻辑块映射数组得到数据块对应的逻辑块（bmap函数），使用得到的逻辑块和设备号，我们就可以读取对应代码或者已初始化变量所在的磁盘块到内核缓冲区，然后分配一个页面，将内核缓冲区的数据拷贝到这页面中，然后把这个页面赋值给需要的代码或者数据的页表项中填写。这样，我们实际只需要清空页表，就会自动调用缺页中断加载代码和已初始化数据段。
>
> ```c
> // fs/exec.c文件中定义了sys_exec中断处理函数do_execve
> /*
>  *  linux/fs/exec.c
>  *
>  *  (C) 1991  Linus Torvalds
>  */
> 
> /*
>  * #!-checking implemented by tytso.
>  */
> 
> /*
>  * Demand-loading implemented 01.12.91 - no need to read anything but
>  * the header into memory. The inode of the executable is put into
>  * "current->executable", and page faults do the actual loading. Clean.
>  *
>  * Once more I can proudly say that linux stood up to being changed: it
>  * was less than 2 hours work to get demand-loading completely implemented.
>  */
> 
> #include <errno.h>
> #include <string.h>
> #include <sys/stat.h>
> #include <a.out.h>
> 
> #include <linux/fs.h>
> #include <linux/sched.h>
> #include <linux/kernel.h>
> #include <linux/mm.h>
> #include <asm/segment.h>
> 
> extern int sys_exit(int exit_code);
> extern int sys_close(int fd);
> 
> /*
>  * MAX_ARG_PAGES defines the number of pages allocated for arguments
>  * and envelope for the new program. 32 should suffice, this gives
>  * a maximum env+arg of 128kB !
>  */
> #define MAX_ARG_PAGES 32
> 
> /*
>  * create_tables() parses the env- and arg-strings in new user
>  * memory and creates the pointer tables from them, and puts their
>  * addresses on the "stack", returning the new stack pointer value.
>  */
> static unsigned long * create_tables(char * p,int argc,int envc)
> {
> 	unsigned long *argv,*envp;
> 	unsigned long * sp;
> 
> 	sp = (unsigned long *) (0xfffffffc & (unsigned long) p);
> 	sp -= envc+1;
> 	envp = sp;
> 	sp -= argc+1;
> 	argv = sp;
> 	put_fs_long((unsigned long)envp,--sp);
> 	put_fs_long((unsigned long)argv,--sp);
> 	put_fs_long((unsigned long)argc,--sp);
> 	while (argc-->0) {
> 		put_fs_long((unsigned long) p,argv++);
> 		while (get_fs_byte(p++)) /* nothing */ ;
> 	}
> 	put_fs_long(0,argv);
> 	while (envc-->0) {
> 		put_fs_long((unsigned long) p,envp++);
> 		while (get_fs_byte(p++)) /* nothing */ ;
> 	}
> 	put_fs_long(0,envp);
> 	return sp;
> }
> 
> /*
>  * count() counts the number of arguments/envelopes
>  */
> static int count(char ** argv)
> {
> 	int i=0;
> 	char ** tmp;
> 
> 	if ((tmp = argv))
> 		while (get_fs_long((unsigned long *) (tmp++)))
> 			i++;
> 
> 	return i;
> }
> 
> /*
>  * 'copy_string()' copies argument/envelope strings from user
>  * memory to free pages in kernel mem. These are in a format ready
>  * to be put directly into the top of new user memory.
>  *
>  * Modified by TYT, 11/24/91 to add the from_kmem argument, which specifies
>  * whether the string and the string array are from user or kernel segments:
>  * 
>  * from_kmem     argv *        argv **
>  *    0          user space    user space
>  *    1          kernel space  user space
>  *    2          kernel space  kernel space
>  * 
>  * We do this by playing games with the fs segment register.  Since it
>  * it is expensive to load a segment register, we try to avoid calling
>  * set_fs() unless we absolutely have to.
>  */
> static unsigned long copy_strings(int argc,char ** argv,unsigned long *page,
> 		unsigned long p, int from_kmem)
> {
> 	char *tmp, *pag=NULL;
> 	int len, offset = 0;
> 	unsigned long old_fs, new_fs;
> 
> 	if (!p)
> 		return 0;	/* bullet-proofing */
> 	new_fs = get_ds();
> 	old_fs = get_fs();
> 	if (from_kmem==2)
> 		set_fs(new_fs);
> 	while (argc-- > 0) {
> 		if (from_kmem == 1)
> 			set_fs(new_fs);
> 		if (!(tmp = (char *)get_fs_long(((unsigned long *)argv)+argc)))
> 			panic("argc is wrong");
> 		if (from_kmem == 1)
> 			set_fs(old_fs);
> 		len=0;		/* remember zero-padding */
> 		do {
> 			len++;
> 		} while (get_fs_byte(tmp++));
> 		if (p-len < 0) {	/* this shouldn't happen - 128kB */
> 			set_fs(old_fs);
> 			return 0;
> 		}
> 		while (len) {
> 			--p; --tmp; --len;
> 			if (--offset < 0) {
> 				offset = p % PAGE_SIZE;
> 				if (from_kmem==2)
> 					set_fs(old_fs);
> 				if (!(pag = (char *) page[p/PAGE_SIZE]) &&
> 				    !(pag = (char *) page[p/PAGE_SIZE] =
> 				      (unsigned long *) get_free_page())) 
> 					return 0;
> 				if (from_kmem==2)
> 					set_fs(new_fs);
> 
> 			}
> 			*(pag + offset) = get_fs_byte(tmp);
> 		}
> 	}
> 	if (from_kmem==2)
> 		set_fs(old_fs);
> 	return p;
> }
> 
> static unsigned long change_ldt(unsigned long text_size,unsigned long * page)
> {
> 	unsigned long code_limit,data_limit,code_base,data_base;
> 	int i;
> 
> 	code_limit = text_size+PAGE_SIZE -1;
> 	code_limit &= 0xFFFFF000;
> 	data_limit = 0x4000000;
> 	code_base = get_base(current->ldt[1]);
> 	data_base = code_base;
> 	set_base(current->ldt[1],code_base);
> 	set_limit(current->ldt[1],code_limit);
> 	set_base(current->ldt[2],data_base);
> 	set_limit(current->ldt[2],data_limit);
> /* make sure fs points to the NEW data segment */
> 	__asm__("pushl $0x17\n\tpop %%fs"::);
> 	data_base += data_limit;
> 	for (i=MAX_ARG_PAGES-1 ; i>=0 ; i--) {
> 		data_base -= PAGE_SIZE;
> 		if (page[i])
> 			put_page(page[i],data_base);
> 	}
> 	return data_limit;
> }
> 
> /*
>  * 'do_execve()' executes a new program.
>  */
> int do_execve(unsigned long * eip,long tmp,char * filename,
> 	char ** argv, char ** envp)
> {
> 	struct m_inode * inode;
> 	struct buffer_head * bh;
> 	struct exec ex;
> 	unsigned long page[MAX_ARG_PAGES];
> 	int i,argc,envc;
> 	int e_uid, e_gid;
> 	int retval;
> 	int sh_bang = 0;
> 	unsigned long p=PAGE_SIZE*MAX_ARG_PAGES-4;
> 
> 	if ((0xffff & eip[1]) != 0x000f)
> 		panic("execve called from supervisor mode");
> 	for (i=0 ; i<MAX_ARG_PAGES ; i++)	/* clear page-table */
> 		page[i]=0;
> 	if (!(inode=namei(filename)))		/* get executables inode */
> 		return -ENOENT;
> 	argc = count(argv);
> 	envc = count(envp);
> 	
> restart_interp:
> 	if (!S_ISREG(inode->i_mode)) {	/* must be regular file */
> 		retval = -EACCES;
> 		goto exec_error2;
> 	}
> 	i = inode->i_mode;
> 	e_uid = (i & S_ISUID) ? inode->i_uid : current->euid;
> 	e_gid = (i & S_ISGID) ? inode->i_gid : current->egid;
> 	if (current->euid == inode->i_uid)
> 		i >>= 6;
> 	else if (current->egid == inode->i_gid)
> 		i >>= 3;
> 	if (!(i & 1) &&
> 	    !((inode->i_mode & 0111) && suser())) {
> 		retval = -ENOEXEC;
> 		goto exec_error2;
> 	}
> 	if (!(bh = bread(inode->i_dev,inode->i_zone[0]))) {
> 		retval = -EACCES;
> 		goto exec_error2;
> 	}
> 	ex = *((struct exec *) bh->b_data);	/* read exec-header */
> 	if ((bh->b_data[0] == '#') && (bh->b_data[1] == '!') && (!sh_bang)) {
> 		/*
> 		 * This section does the #! interpretation.
> 		 * Sorta complicated, but hopefully it will work.  -TYT
> 		 */
> 
> 		char buf[1023], *cp, *interp, *i_name, *i_arg;
> 		unsigned long old_fs;
> 
> 		strncpy(buf, bh->b_data+2, 1022);
> 		brelse(bh);
> 		iput(inode);
> 		buf[1022] = '\0';
> 		if ((cp = strchr(buf, '\n'))) {
> 			*cp = '\0';
> 			for (cp = buf; (*cp == ' ') || (*cp == '\t'); cp++);
> 		}
> 		if (!cp || *cp == '\0') {
> 			retval = -ENOEXEC; /* No interpreter name found */
> 			goto exec_error1;
> 		}
> 		interp = i_name = cp;
> 		i_arg = 0;
> 		for ( ; *cp && (*cp != ' ') && (*cp != '\t'); cp++) {
>  			if (*cp == '/')
> 				i_name = cp+1;
> 		}
> 		if (*cp) {
> 			*cp++ = '\0';
> 			i_arg = cp;
> 		}
> 		/*
> 		 * OK, we've parsed out the interpreter name and
> 		 * (optional) argument.
> 		 */
> 		if (sh_bang++ == 0) {
> 			p = copy_strings(envc, envp, page, p, 0);
> 			p = copy_strings(--argc, argv+1, page, p, 0);
> 		}
> 		/*
> 		 * Splice in (1) the interpreter's name for argv[0]
> 		 *           (2) (optional) argument to interpreter
> 		 *           (3) filename of shell script
> 		 *
> 		 * This is done in reverse order, because of how the
> 		 * user environment and arguments are stored.
> 		 */
> 		p = copy_strings(1, &filename, page, p, 1);
> 		argc++;
> 		if (i_arg) {
> 			p = copy_strings(1, &i_arg, page, p, 2);
> 			argc++;
> 		}
> 		p = copy_strings(1, &i_name, page, p, 2);
> 		argc++;
> 		if (!p) {
> 			retval = -ENOMEM;
> 			goto exec_error1;
> 		}
> 		/*
> 		 * OK, now restart the process with the interpreter's inode.
> 		 */
> 		old_fs = get_fs();
> 		set_fs(get_ds());
> 		if (!(inode=namei(interp))) { /* get executables inode */
> 			set_fs(old_fs);
> 			retval = -ENOENT;
> 			goto exec_error1;
> 		}
> 		set_fs(old_fs);
> 		goto restart_interp;
> 	}
> 	brelse(bh);
> 	if (N_MAGIC(ex) != ZMAGIC || ex.a_trsize || ex.a_drsize ||
> 		ex.a_text+ex.a_data+ex.a_bss>0x3000000 ||
> 		inode->i_size < ex.a_text+ex.a_data+ex.a_syms+N_TXTOFF(ex)) {
> 		retval = -ENOEXEC;
> 		goto exec_error2;
> 	}
> 	if (N_TXTOFF(ex) != BLOCK_SIZE) {
> 		printk("%s: N_TXTOFF != BLOCK_SIZE. See a.out.h.", filename);
> 		retval = -ENOEXEC;
> 		goto exec_error2;
> 	}
> 	if (!sh_bang) {
> 		p = copy_strings(envc,envp,page,p,0);
> 		p = copy_strings(argc,argv,page,p,0);
> 		if (!p) {
> 			retval = -ENOMEM;
> 			goto exec_error2;
> 		}
> 	}
> /* OK, This is the point of no return */
> 	if (current->executable)
> 		iput(current->executable);
> 	current->executable = inode;
> 	for (i=0 ; i<32 ; i++)
> 		current->sigaction[i].sa_handler = NULL;
> 	for (i=0 ; i<NR_OPEN ; i++)
> 		if ((current->close_on_exec>>i)&1)
> 			sys_close(i);
> 	current->close_on_exec = 0;
> 	free_page_tables(get_base(current->ldt[1]),get_limit(0x0f));
> 	free_page_tables(get_base(current->ldt[2]),get_limit(0x17));
> 	if (last_task_used_math == current)
> 		last_task_used_math = NULL;
> 	current->used_math = 0;
> 	p += change_ldt(ex.a_text,page)-MAX_ARG_PAGES*PAGE_SIZE;
> 	p = (unsigned long) create_tables((char *)p,argc,envc);
> 	current->brk = ex.a_bss +
> 		(current->end_data = ex.a_data +
> 		(current->end_code = ex.a_text));
> 	current->start_stack = p & 0xfffff000;
> 	current->euid = e_uid;
> 	current->egid = e_gid;
> 	i = ex.a_text+ex.a_data;
> 	while (i&0xfff)
> 		put_fs_byte(0,(char *) (i++));
> 	eip[0] = ex.a_entry;		/* eip, magic happens :-) */
> 	eip[3] = p;			/* stack pointer */
> 	return 0;
> exec_error2:
> 	iput(inode);
> exec_error1:
> 	for (i=0 ; i<MAX_ARG_PAGES ; i++)
> 		free_page(page[i]);
> 	return(retval);
> }
> ```
>
> ````c
> // kernel/system_call.s定义了sys_execve系统调用
> /*
>  *  linux/kernel/system_call.s
>  *
>  *  (C) 1991  Linus Torvalds
>  */
> 
> /*
>  *  system_call.s  contains the system-call low-level handling routines.
>  * This also contains the timer-interrupt handler, as some of the code is
>  * the same. The hd- and flopppy-interrupts are also here.
>  *
>  * NOTE: This code handles signal-recognition, which happens every time
>  * after a timer-interrupt and after each system call. Ordinary interrupts
>  * don't handle signal-recognition, as that would clutter them up totally
>  * unnecessarily.
>  *
>  * Stack layout in 'ret_from_system_call':
>  *
>  *	 0(%esp) - %eax
>  *	 4(%esp) - %ebx
>  *	 8(%esp) - %ecx
>  *	 C(%esp) - %edx
>  *	10(%esp) - %fs
>  *	14(%esp) - %es
>  *	18(%esp) - %ds
>  *	1C(%esp) - %eip
>  *	20(%esp) - %cs
>  *	24(%esp) - %eflags
>  *	28(%esp) - %oldesp
>  *	2C(%esp) - %oldss
>  */
> 
> SIG_CHLD	= 17
> 
> EAX		= 0x00
> EBX		= 0x04
> ECX		= 0x08
> EDX		= 0x0C
> FS		= 0x10
> ES		= 0x14
> DS		= 0x18
> EIP		= 0x1C
> CS		= 0x20
> EFLAGS		= 0x24
> OLDESP		= 0x28
> OLDSS		= 0x2C
> 
> state	= 0		# these are offsets into the task-struct.
> counter	= 4
> priority = 8
> signal	= 12
> sigaction = 16		# MUST be 16 (=len of sigaction)
> blocked = (33*16)
> 
> # offsets within sigaction
> sa_handler = 0
> sa_mask = 4
> sa_flags = 8
> sa_restorer = 12
> 
> nr_system_calls = 78
> 
> /*
>  * Ok, I get parallel printer interrupts while using the floppy for some
>  * strange reason. Urgel. Now I just ignore them.
>  */
> .globl system_call,sys_fork,timer_interrupt,sys_execve
> .globl hd_interrupt,floppy_interrupt,parallel_interrupt
> .globl device_not_available, coprocessor_error
> 
> .align 2
> bad_sys_call:
> 	movl $-1,%eax
> 	iret
> .align 2
> reschedule:
> 	pushl $ret_from_sys_call
> 	jmp schedule
> .align 2
> system_call:
> 	cmpl $nr_system_calls-1,%eax
> 	ja bad_sys_call
> 	push %ds
> 	push %es
> 	push %fs
> 	pushl %edx
> 	pushl %ecx		# push %ebx,%ecx,%edx as parameters
> 	pushl %ebx		# to the system call
> 	movl $0x10,%edx		# set up ds,es to kernel space
> 	mov %dx,%ds
> 	mov %dx,%es
> 	movl $0x17,%edx		# fs points to local data space
> 	mov %dx,%fs
> 	call sys_call_table(,%eax,4)
> 	pushl %eax
> 	movl current,%eax
> 	cmpl $0,state(%eax)		# state
> 	jne reschedule
> 	cmpl $0,counter(%eax)		# counter
> 	je reschedule
> ret_from_sys_call:
> 	movl current,%eax		# task[0] cannot have signals
> 	cmpl task,%eax
> 	je 3f
> 	cmpw $0x0f,CS(%esp)		# was old code segment supervisor ?
> 	jne 3f
> 	cmpw $0x17,OLDSS(%esp)		# was stack segment = 0x17 ?
> 	jne 3f
> 	movl signal(%eax),%ebx
> 	movl blocked(%eax),%ecx
> 	notl %ecx
> 	andl %ebx,%ecx
> 	bsfl %ecx,%ecx
> 	je 3f
> 	btrl %ecx,%ebx
> 	movl %ebx,signal(%eax)
> 	incl %ecx
> 	pushl %ecx
> 	call do_signal
> 	popl %eax
> 3:	popl %eax
> 	popl %ebx
> 	popl %ecx
> 	popl %edx
> 	pop %fs
> 	pop %es
> 	pop %ds
> 	iret
> 
> .align 2
> coprocessor_error:
> 	push %ds
> 	push %es
> 	push %fs
> 	pushl %edx
> 	pushl %ecx
> 	pushl %ebx
> 	pushl %eax
> 	movl $0x10,%eax
> 	mov %ax,%ds
> 	mov %ax,%es
> 	movl $0x17,%eax
> 	mov %ax,%fs
> 	pushl $ret_from_sys_call
> 	jmp math_error
> 
> .align 2
> device_not_available:
> 	push %ds
> 	push %es
> 	push %fs
> 	pushl %edx
> 	pushl %ecx
> 	pushl %ebx
> 	pushl %eax
> 	movl $0x10,%eax
> 	mov %ax,%ds
> 	mov %ax,%es
> 	movl $0x17,%eax
> 	mov %ax,%fs
> 	pushl $ret_from_sys_call
> 	clts				# clear TS so that we can use math
> 	movl %cr0,%eax
> 	testl $0x4,%eax			# EM (math emulation bit)
> 	je math_state_restore
> 	pushl %ebp
> 	pushl %esi
> 	pushl %edi
> 	call math_emulate
> 	popl %edi
> 	popl %esi
> 	popl %ebp
> 	ret
> 
> .align 2
> timer_interrupt:
> 	push %ds		# save ds,es and put kernel data space
> 	push %es		# into them. %fs is used by _system_call
> 	push %fs
> 	pushl %edx		# we save %eax,%ecx,%edx as gcc doesn't
> 	pushl %ecx		# save those across function calls. %ebx
> 	pushl %ebx		# is saved as we use that in ret_sys_call
> 	pushl %eax
> 	movl $0x10,%eax
> 	mov %ax,%ds
> 	mov %ax,%es
> 	movl $0x17,%eax
> 	mov %ax,%fs
> 	incl jiffies
> 	movb $0x20,%al		# EOI to interrupt controller #1
> 	outb %al,$0x20
> 	movl CS(%esp),%eax
> 	andl $3,%eax		# %eax is CPL (0 or 3, 0=supervisor)
> 	pushl %eax
> 	call do_timer		# 'do_timer(long CPL)' does everything from
> 	addl $4,%esp		# task switching to accounting ...
> 	jmp ret_from_sys_call
> 
> .align 2
> sys_execve:
> 	lea EIP(%esp),%eax
> 	pushl %eax
> 	call do_execve
> 	addl $4,%esp
> 	ret
> 
> .align 2
> sys_fork:
> 	call find_empty_process
> 	testl %eax,%eax
> 	js 1f
> 	push %gs
> 	pushl %esi
> 	pushl %edi
> 	pushl %ebp
> 	pushl %eax
> 	call copy_process
> 	addl $20,%esp
> 1:	ret
> 
> hd_interrupt:
> 	pushl %eax
> 	pushl %ecx
> 	pushl %edx
> 	push %ds
> 	push %es
> 	push %fs
> 	movl $0x10,%eax
> 	mov %ax,%ds
> 	mov %ax,%es
> 	movl $0x17,%eax
> 	mov %ax,%fs
> 	movb $0x20,%al
> 	outb %al,$0xA0		# EOI to interrupt controller #1
> 	jmp 1f			# give port chance to breathe
> 1:	jmp 1f
> 1:	xorl %edx,%edx
> 	xchgl do_hd,%edx
> 	testl %edx,%edx
> 	jne 1f
> 	movl $unexpected_hd_interrupt,%edx
> 1:	outb %al,$0x20
> 	call *%edx		# "interesting" way of handling intr.
> 	pop %fs
> 	pop %es
> 	pop %ds
> 	popl %edx
> 	popl %ecx
> 	popl %eax
> 	iret
> 
> floppy_interrupt:
> 	pushl %eax
> 	pushl %ecx
> 	pushl %edx
> 	push %ds
> 	push %es
> 	push %fs
> 	movl $0x10,%eax
> 	mov %ax,%ds
> 	mov %ax,%es
> 	movl $0x17,%eax
> 	mov %ax,%fs
> 	movb $0x20,%al
> 	outb %al,$0x20		# EOI to interrupt controller #1
> 	xorl %eax,%eax
> 	xchgl do_floppy,%eax
> 	testl %eax,%eax
> 	jne 1f
> 	movl $unexpected_floppy_interrupt,%eax
> 1:	call *%eax		# "interesting" way of handling intr.
> 	pop %fs
> 	pop %es
> 	pop %ds
> 	popl %edx
> 	popl %ecx
> 	popl %eax
> 	iret
> 
> parallel_interrupt:
> 	pushl %eax
> 	movb $0x20,%al
> 	outb %al,$0x20
> 	popl %eax
> 	iret
> ````
>
> 

### 网络管理(网卡字符设备驱动; 网络协议栈TCP/IP,HTTP, socket)

Linux网络管理是基于设备管理的网络设备管理的。类似于文件系统管理，文件系统管理提供了文件系统调用，他是基于磁盘设备管理的。磁盘管理提供了底层数据的存储，而文件系统基于底层数据的存储的内核函数设计了文件相关的系统调用；同样，Linux网络管理系统调用也是基于字符设备网络设备的读写内核函数实现的；控制台IO系统调用底层实现内核函数是控制台设备读写函数tty_read/tty_write/keyboard_interrupt/con_write等完成的，普通文件系统调用底层实现函数是file_read/file_write，管道文件底层实现内核函数是pipe_read/pipe_write，块设备读写函数blk_read/blk_write，同样网络设备读写内核底层函数是网络设备读写函数，这些涉及到外部设备（控制台/键盘，网卡，磁盘）的读写函数因为要等待外部设备资源服务，基本都需要阻塞在读写函数内。网络管理系统调用socket/connect/



### 其他不重要的

#### Linux操作系统启动

实验1-Linux操作系统启动

**Linux操作系统启动**

计算机加电启动执行BIOS提供的自检程序，加载BIOS中断到中断向量表中，然后执行BIOS操作系统启动中断，转入操作系统启动；Linux操作系统启动，会先调用boot/bootsect.s, boot/setup.s, boot/head.c等程序设置内存结构，将内存结构划分为内核区、缓冲区、虚拟盘区、主存区，设置内核区地址划分（页目录表4k一页，页表4K*4页，head.c部分代码，中断描述符表2k，全局秒描述符表2k，init/main.c代码，kernel代码，mm代码，fs代码，lib代码）。然后调用init/main.c函数执行系统初始化和进程0，1，2的创建工作，init/main.c前部分执行代码是处于进程0的内核态，当使用move_to_user_mode之后进入进程0的用户态执行，在任务0的内核态时，会调用进程初始化，内存初始化，设备初始化（字符设备，块设备，控制台初始化，磁盘初始化hd_init）等初始化工作，在进程初始化过程中，会设置进程0任务数据结构（任务0任务数据结构的数据被宏定义在sched.h中），设置任务0数据结构的数据段在内核0地址开始处，设置任务0用户空间在user_stack处(内核内存kernel/sche.c的那个部分)，任务0进程的线性地址空间0-640K，内核地址空间0-16M，内核代码在0-4M之间，end-16M之间分配内核缓冲区。

init/main.c初始化设置完成之后move_to_user_mode进入任务0用户态执行，处在用户态的任务0会使用内嵌fork系统调用创建任务1执行init函数，任务1的init函数会加载磁盘文件系统并且打开stdin，stdout，stderr三个标准输入输出错误输出文件，最后创建任务2调用execve系统调用加载并执行shell程序，进程1等待任务2的执行完毕。任务2执行完毕以后任务1循环继续创建任务2加载shell程序执行。

任务0在创建任务1进程后的代码时执行一个循环**while(1) pause**不断调用pause系统调用刺激调度程序调度。

init/main.c执行的过程加下图和下面代码

![Screenshot 2022-10-21 151411](实验\1 操作系统实验\实验8 虚拟文件系统的实现\Screenshot 2022-10-21 151411.png)

```c
/*
 *  linux/init/main.c
 *
 *  (C) 1991  Linus Torvalds
 */

#define __LIBRARY__
#include <unistd.h>
#include <time.h>

/*
 * we need this inline - forking from kernel space will result
 * in NO COPY ON WRITE (!!!), until an execve is executed. This
 * is no problem, but for the stack. This is handled by not letting
 * main() use the stack at all after fork(). Thus, no function
 * calls - which means inline code for fork too, as otherwise we
 * would use the stack upon exit from 'fork()'.
 *
 * Actually only pause and fork are needed inline, so that there
 * won't be any messing with the stack from main(), but we define
 * some others too.
 */
static inline _syscall0(int,fork)
static inline _syscall0(int,pause)
static inline _syscall1(int,setup,void *,BIOS)
static inline _syscall0(int,sync)

/*新增mkdir和mknode系统调用*/
_syscall2(int,mkdir,const char*,name,mode_t,mode)
_syscall3(int,mknod,const char *,filename,mode_t,mode,dev_t,dev)
    

#include <linux/tty.h>
#include <linux/sched.h>
#include <linux/head.h>
#include <asm/system.h>
#include <asm/io.h>

#include <stddef.h>
#include <stdarg.h>
#include <unistd.h>
#include <fcntl.h>
#include <sys/types.h>

#include <linux/fs.h>

static char printbuf[1024];

extern int vsprintf();
extern void init(void);
extern void blk_dev_init(void);
extern void chr_dev_init(void);
extern void hd_init(void);
extern void floppy_init(void);
extern void mem_init(long start, long end);
extern long rd_init(long mem_start, int length);
extern long kernel_mktime(struct tm * tm);
extern long startup_time;

/*
 * This is set up by the setup-routine at boot-time
 */
#define EXT_MEM_K (*(unsigned short *)0x90002)
#define DRIVE_INFO (*(struct drive_info *)0x90080)
#define ORIG_ROOT_DEV (*(unsigned short *)0x901FC)

/*
 * Yeah, yeah, it's ugly, but I cannot find how to do this correctly
 * and this seems to work. I anybody has more info on the real-time
 * clock I'd be interested. Most of this was trial and error, and some
 * bios-listing reading. Urghh.
 */

#define CMOS_READ(addr) ({ \
outb_p(0x80|addr,0x70); \
inb_p(0x71); \
})

#define BCD_TO_BIN(val) ((val)=((val)&15) + ((val)>>4)*10)

static void time_init(void)
{
	struct tm time;

	do {
		time.tm_sec = CMOS_READ(0);
		time.tm_min = CMOS_READ(2);
		time.tm_hour = CMOS_READ(4);
		time.tm_mday = CMOS_READ(7);
		time.tm_mon = CMOS_READ(8);
		time.tm_year = CMOS_READ(9);
	} while (time.tm_sec != CMOS_READ(0));
	BCD_TO_BIN(time.tm_sec);
	BCD_TO_BIN(time.tm_min);
	BCD_TO_BIN(time.tm_hour);
	BCD_TO_BIN(time.tm_mday);
	BCD_TO_BIN(time.tm_mon);
	BCD_TO_BIN(time.tm_year);
	time.tm_mon--;
	startup_time = kernel_mktime(&time);
}

static long memory_end = 0;
static long buffer_memory_end = 0;
static long main_memory_start = 0;

struct drive_info { char dummy[32]; } drive_info;

void main(void)		/* This really IS void, no error here. */
{			/* The startup routine assumes (well, ...) this */
/*
 * Interrupts are still disabled. Do necessary setups, then
 * enable them
 */
 	ROOT_DEV = ORIG_ROOT_DEV;
 	drive_info = DRIVE_INFO;
	memory_end = (1<<20) + (EXT_MEM_K<<10);
	memory_end &= 0xfffff000;
	if (memory_end > 16*1024*1024)
		memory_end = 16*1024*1024;
	if (memory_end > 12*1024*1024) 
		buffer_memory_end = 4*1024*1024;
	else if (memory_end > 6*1024*1024)
		buffer_memory_end = 2*1024*1024;
	else
		buffer_memory_end = 1*1024*1024;
	main_memory_start = buffer_memory_end;
#ifdef RAMDISK
	main_memory_start += rd_init(main_memory_start, RAMDISK*1024);
#endif
	mem_init(main_memory_start,memory_end);
	trap_init();
	blk_dev_init();
	chr_dev_init();
	tty_init();
	time_init();
	sched_init();
	buffer_init(buffer_memory_end);
	hd_init();
	floppy_init();
	sti();
	move_to_user_mode();
	if (!fork()) {		/* we count on this going ok */
		init();
	}
/*
 *   NOTE!!   For any other task 'pause()' would mean we have to get a
 * signal to awaken, but task0 is the sole exception (see 'schedule()')
 * as task 0 gets activated at every idle moment (when no other tasks
 * can run). For task0 'pause()' just means we go check if some other
 * task can run, and if not we return here.
 */
	for(;;) pause();
}

static int printf(const char *fmt, ...)
{
	va_list args;
	int i;

	va_start(args, fmt);
	write(1,printbuf,i=vsprintf(printbuf, fmt, args));
	va_end(args);
	return i;
}

static char * argv_rc[] = { "/bin/sh", NULL };
static char * envp_rc[] = { "HOME=/", NULL };

static char * argv[] = { "-/bin/sh",NULL };
static char * envp[] = { "HOME=/usr/root", NULL };

void init(void)
{
	int pid,i;

	setup((void *) &drive_info);
	(void) open("/dev/tty0",O_RDWR,0);
	(void) dup(0);
	(void) dup(0);
	
	mkdir("/proc",0755);
	mknod("/proc/psinfo",S_IFPROC|0444,0);
	mknod("/proc/hdinfo",S_IFPROC|0444,1);
	mknod("/proc/inodeinfo",S_IFPROC|0444,2);

	printf("%d buffers = %d bytes buffer space\n\r",NR_BUFFERS,
		NR_BUFFERS*BLOCK_SIZE);
	printf("Free mem: %d bytes\n\r",memory_end-main_memory_start);
	if (!(pid=fork())) {
		close(0);
		if (open("/etc/rc",O_RDONLY,0))
			_exit(1);
		execve("/bin/sh",argv_rc,envp_rc);
		_exit(2);
	}
	if (pid>0)
		while (pid != wait(&i))
			/* nothing */;
	while (1) {
		if ((pid=fork())<0) {
			printf("Fork failed in init\r\n");
			continue;
		}
		if (!pid) {
			close(0);close(1);close(2);
			setsid();
			(void) open("/dev/tty0",O_RDWR,0);
			(void) dup(0);
			(void) dup(0);
			_exit(execve("/bin/sh",argv,envp));
		}
		while (1)
			if (pid == wait(&i))
				break;
		printf("\n\rchild %d died with code %04x\n\r",pid,i);
		sync();
	}
	_exit(0);	/* NOTE! _exit, not exit() */
}
```

#### Linux系统调用编写

实验2-编写系统调用

- **系统控制系统调用**

  | ioctl            | I/O总控制函数                            |
  | ---------------- | ---------------------------------------- |
  | _sysctl          | 读/写系统参数                            |
  | acct             | 启用或禁止进程记账                       |
  | getrlimit        | 获取系统资源上限                         |
  | setrlimit        | 设置系统资源上限                         |
  | getrusage        | 获取系统资源使用情况                     |
  | uselib           | 选择要使用的二进制函数库                 |
  | ioperm           | 设置端口I/O权限                          |
  | iopl             | 改变进程I/O权限级别                      |
  | outb             | 低级端口操作                             |
  | reboot           | 重新启动                                 |
  | swapon           | 打开交换文件和设备                       |
  | swapoff          | 关闭交换文件和设备                       |
  | bdflush          | 控制bdflush守护进程                      |
  | sysfs            | 取核心支持的文件系统类型                 |
  | sysinfo          | 取得系统信息                             |
  | adjtimex         | 调整系统时钟                             |
  | alarm            | 设置进程的闹钟                           |
  | getitimer        | 获取计时器值                             |
  | setitimer        | 设置计时器值                             |
  | gettimeofday     | 取时间和时区                             |
  | settimeofday     | 设置时间和时区                           |
  | stime            | 设置系统日期和时间                       |
  | time             | 取得系统时间                             |
  | times            | 取进程运行时间                           |
  | uname            | 获取当前UNIX系统的名称、版本和主机等信息 |
  | vhangup          | 挂起当前终端                             |
  | nfsservctl       | 对NFS守护进程进行控制                    |
  | vm86             | 进入模拟8086模式                         |
  | create_module    | 创建可装载的模块项                       |
  | delete_module    | 删除可装载的模块项                       |
  | init_module      | 初始化模块                               |
  | query_module     | 查询模块信息                             |
  | *get_kernel_syms | 取得核心符号,已被query_module代替        |

#### Linux向C程序提供的服务

C语言程序执行需要的服务主要又两种，一种时编译器提供的将C语言转换成对应的汇编语言和可执行程序，一种是Linxu对可执行程序的系统调用支持。编译器服务主要是对C语言关键字的解析和翻译成汇编语言，比如对存储类型分配数据区内存和栈区内存，使用变量的逻辑地址替换指令中的符号变量，使用Linux或者其他C语言函数库替换C原因指令翻译成汇编指令，对指令的翻译重点有循环结构的翻译、条件语句的翻译、函数调用的翻译。Linxu对C语言程序提供的系统调用支持主要分为五个模块: **进程系统调用-fork/vfork/wait/waitpid/pause/(sleep)/信号/信号量/共享内存/消息队列/管道、内存系统调用-malloc堆区分配内存、文件系统调用（Linux提供的持久化方式，可用于数据库系统持久化数据，底层是磁盘设备管理提供IO）-fopen/fscanf/fprintf/fclose/exec加载器、网络系统调用（Linux提供远程进程通信方式，底层是网卡设备管理提供IO）-socket/bind/listen/accept/connect/send(write)/recv(read)/close、控制台系统调用（控制台IO方式，底层是键盘中断和控制台设备管理读写程序tty_read/tty_write/keyboard_interrupt/con_write）-scanf/printf。**

## 进程管理 CPU管理

- 系统调用write很耗时，耗时是普通用户程序加法运算的1e6，IO指令执行非常慢。也就是IO为主的进程和计算为主的进程他们要多道程序设计的原因。后来因为多用户，引入了分时系统，这两个本质都是多进程，核心是进程调度和切换。

- 并发：一个CPU在多个程序上交替执行

  并行：多个任务在多个CPU或计算机上同时执行，每个CPU执行一个任务

  并发和并行都是为了提高CPU执行效率

- 每个任务（进程）需要一个PCB存放当前寄存器的数据和PC指针，这样才能切换任务。

- 操作系统在执行main.c的main函数时i，会初始化操作系统管理的设备，同时fork一个进程执行init()，init函数执行的是shell程序，shell程序在获得一个命令之后会fork一个进程来执行这个命令。所以任何时刻计算机系统存在main进程和shell进程，当执行用户程序的时候会创建新进程

- 操作系统组织、管理、感知进程依赖PCB，操作系统组织进程方式，就绪队列、磁盘等待队列等把进程PCB组织成一个链表

### 进程状态-怎么组织进程

新建态的进程PCB被放入就绪队列，进入就绪态；CPU调度获得这个进程之后进入执行态；执行完毕进入终止态；执行态划分时间片用完或者等待IO进入阻塞态，进入阻塞队列

- 新建态
- 就绪态
- 运行态
- 终止态
- 阻塞态

### 进程创建和切换-用户级线程、核心级线程、多进程

##### 用户级线程 

基于栈和Yield函数的线程切换

这种线程切换是用户自己管理的线程切换，而不管内核线程，是用户级线程，线程切换的Yield函数需要用户自己编写

线程TCB只包含一个栈，他不仅保存函数调用返回地址，也包含线程切换返回地址。

这种用户级线程是在用户态执行的，用户自己编写的线程切换，内核无法感知到这种线程。他的缺点是当一个线程发生IO阻塞，那么用户级线程的进程会陷入系统内核态去执行IO，造成一个线程阻塞而其他线程跟着阻塞的情况。好处是用户可以精确控制线程的切换。

所有的进程都是内核进程，因为进程需要分配资源，分配资源的工作是收到操作系统管理的，在setup.s, head.s 和main.c中初始化的功能。没有用户级进程，因为进程总是要分配资源，必须处于内核态，就只能是内核级进程。

线程切换只是切换指令PC，而不涉及切换资源。

用户级线程是并发执行的，不是并行执行的，一个线程阻塞会导致其他线程阻塞

用户级线程需要用户自己编写切换函数，实际上是一种调度算法，用户级线程可以实现用户自己调度线程，很灵活，而内核级线程是内核实现的调度算法。

- 切换过程

  用户进程包含多个线程，这些线程相互之间运用Yield函数进行切换到另外的线程，每个线程只需要拥有一个栈来保存返回地址，在切换的时候只需要从要被切换的线程的栈弹出返回地址给PC指针就行，而不需要在线程TCB中保存一个PC指针。

  ```
  //A线程
  100: A()
  101: {
  102: call B() //执行这句话会在A线程的栈esp压入103返回地址，然后PC指针跳转到200
  103: ...
  }
  200: B()
  201: {
  202: yeild C线程 //执行这句话会把203压入A线程栈esp，然后PC跳转到C线程首地址，同时CPU.esp=TCBc.esp
  203: 
  }
  
  //C线程
  300: C()
  301: {
  302: call D() //执行这句话会在C线程栈压入303，并且PC跳转到400
  303:
  }
  400: D()
  401: {
  402: yeild A线程 //执行这句话会让403压入C线程栈TCBc.esp,同时CPU.esp=TCBa.esp,同时从TCBa.esp弹出返回地址给CPU.PC
  403:
  }
  ```

- 配合上述切换过程的线程控制块TCB的创建

  ```
  void ThreadCreate(A){
  	TCB *tcb = malloc() ; //分配内存给A线程TCB
  	*stack = malloc() ; //分配栈
  	*statk = A; //把线程A的代码首地址A放入栈，CPU加载A线程TCB的时候会从TCB.esp栈指针返回线程A的程序地址。
  	tcb.esp = stack ; //tcb只包含一个栈
  }
  
  这样内存布局是:
  Yield代码区
  TCBa.esp所在的栈内存
  TCBc.esp所在的栈内存
  剩余的heap堆区
  AC线程所在进程的数据区
  AC线程所在进程的代码区，分别保存A线程代码和C线程代码
  
  在创建线程的时候实际只是创建了一个TCBa的stack指针TCBa.esp和TCBc，放到内存
  让CPU获取TCBa, CPU.esp = TCBa.esp,CPU.PC=TCBa.esp弹出的地址，这样就能执行TCBa
  当TCBa要切换到TCBc，首先让CPU.esp=TCBc.esp，然后CPU.PC = TCBc.PC，执行TCBc
  ```

##### 核心级线程

- 多处理器是多进程的基础，一个进程运行在一个处理器上，一个处理器包括内存映射表MMU、高速缓存Cache以及一个或者多个核心CPU。如果一个处理器包含多个核心CPU，那么他是多核处理器，多核处理器是多线程的基础。如果不是多处理器，俺么进程只能并发执行，如果没有多核处理器，那么线程只能并发执行。一个进程被分配给一个处理器，他的线程被分给多个核心进行并行处理

  如果系统不支持核心级线程的化，多核是没有用的，因为一个处理器被分配给一个进程，之后实现了核心级线程才能让多核共享MMU地址映射设备。

  用户级线程和多进程都不能发挥多核的效用，前者是计算机不能感知到多线程，后者是一个进程占用一个处理器。要利用多核，必须支持核心级线程

- 用户级线程使用内核级线程进行线程切换的时候需要切换两套栈，一套是用户级线程的切换，另外一套是内核级线程的切换

- 用户栈是用来利用用户程序调用，内核栈是用来支持内核函数调用，比如系统调用sys_fork会调用copy_process等内核函数，所以要添加内核栈来执行内核函数。每个用户线程要有两套栈，一个是用户栈，一个是内核栈，分别用来执行用户程序和内核程序，TCB会保存这两个栈的地址到esp和esp0.

- 核心级线程一定支持用户级线程，在创建线程的时候会调用系统中断创建用户栈和内核栈以及TCB，用户栈被压入用户程序的入口地址，TCP的esp和esp0分别指向用户栈和内核栈。当TCB被分配到CPU执行，他会初始化CPU的各个变量和count时钟，当他执行到一个系统调用的时候，调用int 0x80中断进入中断处理程序sys_...，同时把用户栈的地址放到内核栈0、1位置，把当前执行的用户代码的位置放到内核栈3、4位置，然后执行对应的系统调用。当从系统调用返回的时候，会从系统调用返回IRET，IRET会把内核栈的用户栈地址和用户代码地址重新赋值给CPU，从而实现CPU切换回用户代码。

- 当内核态的线程切换的时候，内核态的线程TCB tCur的当前执行的代码的位置放到tCur的内核栈的位置，然后从tNew的内核线程弹出另外内核线程的旧的PC值。

- 用户线程切换的是用户栈，而内核级线程切换的是内核栈，TCB只用保存一个内核栈就行。核心级线程的切换只需要切换内核栈，内核栈的顶部存放被调度时正在执行的内核函数的地址，可以内核栈顶部地址恢复内核线程PC，当执行完内核函数的时候，可以通过内核栈3、4位置恢复用户代码位置，通过0、1位置恢复用户栈位置。

- 核心级线程的切换

  ```
  TCB[cur].esp = %esp ;
  %esp=TCB[next].esp ;
  cur 的TCB入队
  
  如果设计到两个不同进程的线程的切换，还需要切换地址引射表
  TCB[cur].ldtr = %ldtr
  %ldtr = TCB[next].ldtr
  ```

- 核心级线程的创建

  ```
  ThreadCreate(){
  	TCB tcb = get_free_page(); //用户程序调用c语言库函数malloc分配内存，在内核中执行内核函数get_free_page分配内存
  							   //这里分配内存是在setup时期初始化的mem_map位图进行管理的内存，
  							   //创建tcb
  	*krlstack = get_free_page();//创建内核栈
  	*userstack用户栈地址如*krlstack的0、1位置，返回用户程序地址放入*krlstack的3、4位置
  	tcb.esp=krlstack; //tcb栈指针到内核栈指针
  	tcb入队
  }
  ```

##### 多进程系统

```c
int main(){ //打印AB进程
	if(!fork()){
		while(1){
			printf("A") ; //打印A进程
		}
	}
	if(!fork()){
		while(1){
			printf("B") ; //打印B进程
		}
	}
    wait();
}
```

在Linux系统启动的时候会启动shell

```c
int main(){
	while( cmp!= null){
		if(!fork()){
			exec(cmp) ;
		}
	}
}
```

当在shell中启动AB.exe的时候，c语言库函数会调用系统中断sys_fork来处理，sys_fork是Linux系统调用，他的方法是

```
sys_fork:
	pushl ... //创建AB京城的用户栈并把AB程序内存首地址压入用户栈，同时创建AB进程的内核栈并且内核栈的0、1地址指向AB进程用户栈					的地址，内核栈的3、4位置存放返回AB进程的返回地址
	call copy_process //创建AB进程的PCB，其中包括eip指向AB线程执行地址，esp指向用户栈，esp0指向内核栈
	ret        //返回调用c语言fork库函数的地址
```

调用fork库函数创建好AB进程的PCB之后，AB进程PCB被加入就绪队列，AB进程可以被调度

当AB进程被调度时，他创建了打印A和B进程，创建好打印A进程的用户栈和内核栈以及打印A和B进程PCB。之后AB进程调用c语言库函数wait，这个库函数调用Linux系统调用sys_waitpid，这个系统调用的功能是

```c
sys_waitpid()
	current->state=TSK_INTERRUPTIBLY;
	schedule()
```

他会把当前运行进程的state变成阻塞状态，然后执行schedule内核函数执行CPU调度. 也就是AB进程会被阻塞，此时就绪队列只有A和B进程。执行schedule内核函数CPU调度

CPU调度会把当前CPU执行进程的PCB赋值给pCur，然后放到就绪队列，同时从就绪队列拿到一个PCB把他赋值给CPU，这样就完成了CPU的调度和进程的切换。

导致CPU调度除了进程主动抛弃CPU进入调度函数schedule，还有一种情况是时间片用完，这种情况的实现是依赖时钟中断

CPU里面在调度的时候除了初始化PCB中的参数，还有一个初始化count参数记录时间片。

```
do_timer:
	if( --current->counter>0 ) 
		return ;
	current->counter  =0 ;
	schedule()
```

时钟中断会在将CPU的count不断减1，直到count为0会触发新的CPU调度。如此上面的AB进程会执行交替打印A和B

### 进程调度-怎么切换进程 CPU调度

- 为什么要C语言嵌入汇编代码？可以使用汇编代码更加精细的控制，因为汇编代码使用的寄存器和使用的内存是确定的

- **对于一个IO进程进行切换的过程**

  设置当前PCB pCur的state状态为waiting，并且放入IO阻塞队列

  然后从就绪队列中按调度算法获取一个PCB pNew

  然后CPU切换到pNew执行，先按照pNew的PC指针和各种寄存器恢复现场，然后按照PC进行执行。

  ```
  switch_to(pCur, pNew){
  	pCur.ax = CPU.ax ;
  	pcur.bx = CPU.bx ;
  	...
  	pCur.cs = pNew.cs ;
  	pCur.retpc = pNew.pc ;
  
  	CPU.ax = pNew.ax ;
  	CPU.bx = pNew.bx ;
  	...
  	CPU.cs = pNew.cs ;
  	CPU.retpc = pNew.pc ;
  }
  ```

- 线程资源包括代码、栈、PCB、现场、映射表

- 评判调度算法好坏的标准

  - 周转时间：从任务开始到结束的时间。想要快点完成任务，就让周转时间小
  - 响应时间：从操作发生到响应的时间。想要实时性就要响应时间短
  - 吞吐量：完成的任务量。CPU执行用户代码时间站总时间比，因为有IO等阻塞时间

- 评判标准的矛盾

  - 响应时间短就要切换频繁，切换频繁造成大量时间用于线程或者进程切换，从而系统执行代码时间少，吞吐量小
  - 前台任务关注效应时间，后台任务关注周转时间

- 优先级调度坏处可能会导致饥饿

#### 先来先服务FIFO

取就绪队列的第一个进程执行，缺点是没有优先级

#### 短作业优先SJF

执行时间越短的先执行。相较于先来先服务降低了平均周转时间

#### 时间片轮转RR

每个进程执行一个时间片之后就放入就绪队列，好处是保证响应时间小，一个进程最多等n*t，n时前面任务数，t时时间片，要保证响应时间很小，那么限制n的个数并且让t很小

### 进程内存分离-内存管理

通过映射表实现地址空间分离，防止实际地址错误，各个进程操纵自己的内存空间而不能访问到其他进程的内存空间-地址映射

```
//A进程
mov [100],ax ;//将ax送到内存100位置

//B进程
100: 00101

如果没有内存分离，A进程的A[100]会访问到B进程的100内存地址，造成错误。
因此要分离A进程和B进程使用的内存地址，在进程中给出的是虚拟地址100，而不是
实际地址100，虚拟地址要添加映射表中的项获得真正的地址
```

### 进程同步-多进程合作完成任务

多进程共享内存变量造成共享变量不同步

#### 生产者消费者模型-信号量

信号量标记可以被使用的资源的数目，当一个进程申请信号量的时候要信号量-1，当一个进程释放信号量的时候信号量+1，当进程发现信号量小于等于0就阻塞。如果为-n，表示有n个进程正在等待。信号量为正可以用来标记还有多少可用资源，信号量为辐可以用来标记还有多少个进程在等待

```java
//使用信号零实现生产者消费者模型
class Producer implements Runnable{
	Semaphore empty ; //标记还有多少个空位可以供生产者使用
	Semaphore mutex ;//互斥信号量，同步阻塞
	Semaphore full ;//标记生产者生产了多少个产品
	//生产品每次生产一个产品，就要唤醒一个消费者进行消费
	
	ArrayList<String> list ;
	
	public Producer(Semaphore empty, Semaphore mutex,
					Semaphore full, ArrayList<String> list) {
		this.empty = empty ;
		this.mutex = mutex ;
		this.full = full ;
		this.list = list ;
	}
	
	public void run() {
		try {
			this.empty.acquire();
		} catch (InterruptedException e1) {
			// TODO Auto-generated catch block
			e1.printStackTrace();
		}//还有多少个空位
		try {
			this.mutex.acquire();
		} catch (InterruptedException e) {
			// TODO Auto-generated catch block
			e.printStackTrace();
		}//互斥信号量
		
		list.add( String.valueOf(Thread.currentThread().getName() ) ) ;
		
		mutex.release();//互斥信号量释放
		full.release();//唤醒一个消费者线程
	}
}
class Consumer implements Runnable{
	Semaphore empty ; //标记还有多少个空位可以供生产者使用
	Semaphore mutex ;//互斥信号量，同步阻塞
	Semaphore full ;//标记生产者生产了多少个产品
	//生产品每次生产一个产品，就要唤醒一个消费者进行消费
	
	ArrayList<String> list ;
	
	String name ;
	
	public Consumer(Semaphore empty, Semaphore mutex,
					Semaphore full, ArrayList<String> list,
					String name) {
		this.empty = empty ;
		this.mutex = mutex ;
		this.full = full ;
		this.list = list ;
		this.name = name ;
	}
	
	public void run() {
		try {
			Thread.sleep(1000);
		} catch (InterruptedException e1) {
			// TODO Auto-generated catch block
			e1.printStackTrace();
		}
		
		try {
			full.acquire();
		} catch (InterruptedException e) {
			// TODO Auto-generated catch block
			e.printStackTrace();
		}
		try {
			mutex.acquire();
		} catch (InterruptedException e) {
			// TODO Auto-generated catch block
			e.printStackTrace();
		}
		String s = list.get(0) ;
		list.remove(0) ;
		System.out.println(name+" consumes "+ s) ;
		
		mutex.release();
		empty.release();
	}
}
public class Main {
	
	public static void main(String[] args) throws InterruptedException {
		ArrayList<String> s =new ArrayList<String>(2) ;
		Semaphore empty = new Semaphore(2) ;
		Semaphore mutex = new Semaphore(1) ;
		Semaphore full = new Semaphore(0) ;
		
		
		ArrayList<Thread> threadList = new ArrayList<Thread>(100) ;
		for(int i=0;i<4;i++) {
			Thread thread = new Thread(new Producer(empty, mutex, full, s)) ;
			thread.start(); 			
			threadList.add(thread) ;
		}
		
		ArrayList<Thread> consumerList = new ArrayList<Thread>(100) ;
		for( int i=0;i<5;i++) {
			new Thread( new Consumer(empty, mutex, full, s, "Consumer "+i)).start() ;
		}
		
		Thread.sleep(500);
		for(Thread thread: threadList) {
			System.out.println(thread.getName()+" "+thread.getState() ) ;
		}
		
		
		Thread.sleep(2000);
		for(Thread thread: threadList) {
			System.out.println(thread.getName()+" "+thread.getState() ) ;
		}
			
	}
}
```

```java
//阻塞队列实现生产者消费者模型

class Producer implements Runnable{
	BlockingQueue<Integer> que ;
	
	public Producer(BlockingQueue<Integer> q) {
		que = q ;
	}
	
	public void run() {
		for( int i=0;i<10;i++) {
			try {
				que.put(i) ;
			} catch (InterruptedException e) {
				// TODO Auto-generated catch block
				e.printStackTrace();
			}
		}
	}
}
class Consumer implements Runnable{
	BlockingQueue<Integer> que ;
	public Consumer(BlockingQueue<Integer> q) {
		que = q ;
	}
	@Override
	public void run() {
		for(int i=0;i<10;i++) {
			try {
				Thread.sleep(2000);
			} catch (InterruptedException e) {
				// TODO Auto-generated catch block
				e.printStackTrace();
			}
			int a = 0;
			try {
				a = que.take();
			} catch (InterruptedException e) {
				// TODO Auto-generated catch block
				e.printStackTrace();
			}
			
			System.out.println(a) ;
		}
	}
}
public class Main {
	
	public static void main(String[] args) throws InterruptedException {
		
		BlockingQueue<Integer> que = new ArrayBlockingQueue<Integer>(3) ;
		
		Thread producer = new Thread(new Producer(que)) ;
		producer.start();
		Thread consumer = new Thread(new Consumer(que)) ;
		consumer.start();
		
	}
}
```

#### 同步互斥方法

##### 信号量为1保证原子性

```java
class MyRunnable implements Runnable{
	Semaphore mutex ;
	
	public MyRunnable(Semaphore mutex) {
		this.mutex = mutex ;
	}
	
	@Override
	public void run() {
		try {
			mutex.acquire();
		} catch (InterruptedException e) {
			// TODO Auto-generated catch block
			e.printStackTrace();
		}
		
		System.out.println(1);
		System.out.println(2) ;
		System.out.println(3) ;
		
		mutex.release();
	}
}
public class Main {
	
	public static void main(String[] args) throws InterruptedException {
		Semaphore mutex = new Semaphore(1) ;
		
		for(int i=0;i<3;i++) {
			new Thread(new MyRunnable(mutex)).start();
		}
			
	}
}
```

信号量的加减使用的时Unsafe类的直接内存的state变量，是CAS基于CPU原语的原子操作。信号量不能重入，如果信号量调用了一个同样使用信号量互斥同步的代码，那么他会死锁

临界区用来保护信号量，用信号量来保证进程同步

**信号保护**

只能是临界区代码才能修改信号量

**临界区代码保护原则**

- 互斥进入，如果一个临界区在执行，则其他进程不能执行，这保证了临界区执行
- 有空让进：有若干进程要求进入临界区时就尽快使进程进入临界区
- 有限等待：从进程发出进入请求到允许进入，不能无限等待，方正进程饥饿

**进入临界区的方法**

- 轮换法

  ```
  //进程p0
  while(turn != 0);
  临界区
  turn = 1 ;
  
  //进程p1
  while(turn != 1);
  临界区
  turn = 0;
  
  上述进程依赖turn的转换，每转换一次就触发一次临界区，这种方法只适合两个进程
  ```

- 标记法

  ```
  每个进程维护自己的标记，他试图进入临界区就将标记变成true，然后检查其他地方标记，如果其他地方标记都是false，那么他才执行临界区
  
  //A进程
  flag[0] = true ;
  while(flag[1]) ;
  临界区
  flag[0] = false ;
  
  //B进程
  flag[1] = true ; //B想进入设置
  while(flag[0]); //查看A是否已经进入
  临界区
  flag[1] = false ;
  ```

- Peterson算法

  ```
  //A进程
  flag[0] = true ;
  turn = 1 ;
  while( flag[1] && turn == 1) ;
  临界区
  flag[0] = false ;
  
  //B进程
  flag[1] = true ;
  turn = 0 ;
  while(flag[0] && turn == 0) ;
  临界区
  flag[1] = false ;
  
  皮特森算法才能真正保护临界区，前面两个可能死锁，这里介绍的三个算法都只能用于两个进程。多进程版本看下一个算法，面包店算法
  ```

- 面包店算法

  多进程实现对临界区（修改临界变量的代码）互斥同步（临界区原子操作）的代码

  ```
  //进程Pi
  choosing[i] = true; //如果进程在选号，那么要进入临界区的进程自旋等待
  num[i] = max(num[j])+1; j=1,2,...,n //给第i号进程选号为当前最大的+1
  choosing[i] = false;
  for(int i=0;i<n;i++){
  	while( choosing[j]) ; //如果有进程在选号，那么进程自旋等待
  	while( num[j] !=0 && (num[j]<num[i] ||(num[j]==num[i] && j<i)) ) ; 
  		//如果进程被分配了号并且不是最小的号，那么自旋等待，如果分配到了同样的号并且不是下表最小的进程，那么自选等待
  }
  临界区
  num[i] = 0 ;
  
  
  面包店算法显示给每个进程分配一个号码，每次总是选择最小的那个号码的进程执行，如果最小的号码有多个进程，那么选择
  下表最小的那个进程执行。
  ```

- 关中断

  上面的算法是软件算法，关中断是硬件设计

  关中断的思想是关掉CPU调度，从而让一个进程得到执行。

  CPU调度是部分基于中断实现的，只要来子多方面

  - 时钟中断，每个CPU有一个count寄存器保存时间，每过一定时间时钟中断发生让count-1，当count为0，会置CPU的INTR寄存器（中断寄存器）为1，从而让CPU执行响应的中断处理程序
  - IO中断

  ```
  cli(): //关中断指令
  临界区
  sti(); //开中断指令
  ```

  关中断只能在单CPU上表现好，因为关中断总是关一个进程的中断，但是在多处理器的时候，你关一个CPU中断并不能组织其他进程不能进入临界区

- 硬件原子指令

  类似Java的Unsafe类的原子操作CAS，利用的是CPU原语，如cmpxchg

##### 基于锁的方法

- synchronized 重锁悲观锁
- ReentrantLock重锁悲观锁

##### 基于CAS的方法

CAS是一种乐观锁，他底层使用Unsafe类的CAS操作，是一种CPU原语，可以保证操作原子性

#### 死锁

多个进程互相等待对方持有的资源造成谁都没法执行的情况就是死锁

##### 死锁产生的四个必要条件

- 互斥使用

  资源只能被一个进程使用

- 不可抢占

  占有资源的进程不能被抢占资源，只能自己释放

- 请求保持

  进程必须占有资源并去申请新资源

- 循环等待

  形成循环等待链

##### 死锁处理

###### 死锁预防

破坏死锁的必要条件

**具体方法**

- **破坏请求保持条件**

  在进程开始前一次性分配资源，而不是占有一些资源还去申请新的资源

  **缺点1：** 需要预知所有需要的资源，变成困难

  **缺点2：** 资源被进程占用但是要过很久才会被使用，资源利用率第

- **破坏循环等待条件**

  对资源进行排序，资源申请必须按序进行，不会出现环路等待

  **缺点：** 造成资源浪费 

###### 死锁避免

每次请求资源的时候判断是否会产生死锁，如果造成死锁就拒绝这次资源请求

**具体方法- 银行家算法 **

判断是否有一个安全序列可以让进程继续执行

```
available //资源剩余量列表
allocation[1,2,...,n] //资源已经分配了的列表
need[1,2,...,n] //进程请求资源列表
work //保存资源量
finish[1,2,3,...,n] = false//记录进程是否执行完毕

while(1){
	for( int i=1;i<=n;i++){
		if(!finish[i] && need[i]<work){//如果进程要求的资源小于work，就分配给他让他执行完毕，之后回收他的资源
			work = work+need[i] ;
			finish[i] = true ;//进程执行完毕
			break ;
		}
		else{
			goto end;//如果没有死锁或者产生死锁不能need[i]<work
		}
	}
}
end:
	for(int i=1;i<=n;i++){//如果还存在没有执行完成的进程，就死锁
		if( !finish[i])
			return "deadlock" ;
	}
	

```

上面的方法是O(mn^2)，缺点是每次申请资源都要执行，会造成CPU浪费

###### 死锁检测和死锁恢复

检测到发生死锁，就让一些进程回滚让出资源

因为死锁避免每申请资源就执行浪费CPU资源，所以考虑把银行家算法放到后面。

死锁检测和恢复定期执行，先调用银行家算法发现是否产生死锁并且记录死锁的进程，然后选择几个占有资源多的进程回滚。

死锁检测和恢复算法需要对进程进行回滚，回滚算法是核心也是难点，恢复很难

###### 死锁忽略

为什么可以忽略死锁

- 死锁忽略效率高，死锁避免（一次性分配资源和按序分配资源）资源利用率低，死锁预防（银行家算法）没分配资源都要执行浪费CPU资源；死锁检测和恢复需要进程回滚，这很困难。
- 发生死锁概率低
- 可以通过重启电脑解决死锁

## 内存管理

在编译的时候编译器会把程序转成汇编语言，在汇编语言中，会把调用函数安排到对应的地方，并且产生一个行号（偏移）作为程序调用的跳转的位置。每个指令在汇编里都会分配一个相较于程序入口地址的偏移量作为执行这个语句跳转的地址。如果我们把这个地址放到真实的物理地址，就会从0地址开始存放这个代码，会占用操作系统代码地址，这是不被允许的。分配内存的时候应该应该找一块空闲内存分配内存让他进来，同时修改代码的逻辑地址为真实的物理地址（重定位）。程序编译器编译之后放到磁盘，在执行的时候会被载入到内存。

**重定位方式**

编译时重定位，适合嵌入式系统，比如航天系统，程序被放到内存固定位置，效率高，不灵活

载入时重定位，载入时根据空闲内存替换逻辑地址为真实地址，比编译时重定位灵活。载入程序内就不能动了

运行时重定位，因为载入时重定位载入之后程序在内存就不能动了，而内存很宝贵，一些不常用的进程应该被返回磁盘，所以程序的逻辑地址不应该直接替换，应该在运行时重定位。实现方式是使用基址寄存器base记录程序占用的物理内存的起始地址，每次执行一条指令就使用基址base+逻辑地址（偏移量）得到真正的物理地址。基址寄存器的数值base在创建进程的时候进程代码会被加载到内存，创建进程的时候会把加载到内存的起始地址放到PCB的基址寄存器里面，每次切换PCB的时候会切换基址寄存器

**交换**

内存资源很宝贵，如果一个进程代码长时间不使用，应该把他放回磁盘

### 内存分段

分段后程序执行情况

操作 赋值给进程LDT表，然后把进程LDT表保存到进程PCB中，创建用户栈，把代码段基址放到用户栈，然后把PCB加入到就绪队列等待CPU调度。当进程从代码段获得一个逻辑地址，如果他是数据段地址，会查找LDT表获得数据段基址，然后把这个数据逻辑地址加上数据段基址得到物理地址。

- 分段符合用户逻辑习惯，程序划分为代码段（不会增长）、数据段（不增长，常量池，方法区）、堆栈段等

- 比较高效，如果程序被放入一起，而不是分段，那么对于栈这一块，他会增长，当他因为分配的内存不够时，需要重新定位程序，这个过程旧的程序代码段数据段堆栈段和新的程序地址需要复制数据并且不可被使用，这很浪费内存

- 内存分段之后不能和之前不分段直接分配一个大内存一样只需要一个基址寄存器存放程序入口地址，而是需要保存每个段的地址，因此分段进程的PCB要保存每个段的地址的基址，这个就是进程段表。

  操作系统也有一个段表，就是GDT表

  操作系统GDT表不仅保存操作系统所有的段，而且存放进程LDT表，进程给出一个逻辑地址，操作系统查找进程的在GDT表中的LDT表，从而找到进程逻辑地址的段基址，段基址加上逻辑地址变成逻辑地址的物理地址，完成重定位。

  用户程序段表时LDT表，LDT表实际上就是地址映射表MMU

  | 段号 | 基址 | 长度 | 保护 |
  | ---- | ---- | ---- | ---- |
  | 0`   | 180k | 140k | R/W  |



将每个段载入到空闲内存，怎么载入。

**固定分区和可变分区**

固定分区：操作系统吧内存分为大小相同的分区，每次以多个分区分配给进程的每个段

可变分区：操作系统不区分内存分区，只是每次来请求一个段，就分配一个段的大小

#### 可变分区实现

**实现方法**

操作系统维护一个空闲分区表，每次分配一个段的大小。如果有内存发生释放，那就再空闲分区表中添一项新的空闲分区项。空闲分区表不是现代操作系统实现的方法，现代操作系统时用分页解决内存分区。

空闲分区表

| 始址 | 长度 |
| ---- | ---- |
| 350k | 150K |
| 200K | 50K  |

已分配分区表

| 始址 | 长度 | 标志 |
| ---- | ---- | ---- |
| 0    | 100K | OS   |
| 100K | 200K | seg0 |

**空闲分区表产生问题**

像上面的空闲分区表，如果有一个段需要分配地址所有项都可以分配，那么使用哪一个项去分配。

- 首次适配

  扫描空闲分区表找到第一个可以被分配的项

  首次适配速度快

- 最佳适配

  扫描空闲分区表找到最小的可以分配的项分配

  最佳适配和最差适配都是线性复杂度，最佳适配会产生很多小内存，发生外部碎片

- 最差适配

  总是选择最大的可悲分配的项

**可变分区产生的问题**

使用空闲列表进行内存分配的方式会造成内存碎片，当来了一个比较大的段，空闲分区表没有一个表项可以给这个段分配内存，而实际上总的内存是足够的，这个时候就会产生外部碎片。

解决内存碎片（外部碎片的方法）：内存紧缩。

当无法分配一个大的段的时候，将内存中已经分配的表项都移动到一起，变成紧密的内存块，然后可以得到一个大的空闲分区，在这个空闲分区上分配内存给段。

但是内存紧缩是很耗时的行为，如果内存复制1M内存用1s，那么复制1G内存就要17分钟，在这个过程用户进程得不到执行，用户体验很不好。

### 内存分页

操作系统把内存分页，在mem_map中每一项都是4K大小，内存分配以一页（4K）进行分配。

当给用户段分配内存时，总是以一页分配，这样每个段被划分为多个页。

用户程序被划分为多个页，操作系统内存被划分为多个页，用户程序被分配内存时总是以一个页被分配内存，并且建立页表保存用户页号和内存页框号之间的映射关系

| 页号 | 页框号 | 模式 |
| ---- | ------ | ---- |
| 0··  | 3      | R    |
| 1    | 2      | R    |
| 2    | 5      | R    |

用户程序的逻辑地址，比如0x2240，会被MMU操作0x2240/4K（4K是操作系统页大小）=0x2 ... 0x240 ；

也就是这个逻辑地址对应用户程序分页页号2，我们查页表发现是内存页号5，而页内偏移是0x240，这样我们可以获得实际物理地址0x5*4K+0x24 = 0x524

分页存储用户的页表存放在PCB的CR3寄存器。

**内存分页问题**

为了提高空间利用率，页大小应该尽量小，但是这样会造成页表变大。多级页表+TLB表

分页是存储器用户程序给出的逻辑地址是不连续的地址，也就是说他的地址新城的页号是不连续的，不是0、1、2、3、4...这种连续的，他的某些部分的页号是没有对应的页框号的，比如2号没有对应的页框号，这样造成的结果是如果我们想要保证一次访存获得页框号，我们必须保证随机访问，就要保留这些没有页框号的页表项，这样会增大页表，如果极端情况一个进程的逻辑地址从内存最后一个到内存第一个，对于32为内存（4G），我们要为这个进程维护的页表的大小是4M(4G/4K，4K是每个页面大小)，这样很浪费内存。如果我们不保证随机访问，可以将没有页框号的页表项删除，那么我们可以遍历整个页表或者二分查找整个页表来找到页号对应的页表项，这样会增加访存次数，而访存是很浪费时间的，时间效率太低。因此我们宁愿牺牲空间保证时间。

这样我们可以引出多级页表，对于刚刚的4M的页表，他的中间很多是没有页框号的，我们可以用4K作为一个单位，重新建立一个对这个页表的页表，只是这个页表对没有页框号的那部分表项没有分配页框号，也就不用分配内存个哪些页表项。这样我们的二级页表的大学是4M/4K = 1K，而一级页表里有页表项的哪些页都被二级页表按4K大小保存，加入这个1K的二级页表中有15个项有页框号，那么整个一级和二级页表加起来大小是15*4K + 1K=61K，远远小于4M大小的页表。按照这个道理，可以划分多级页表

除了多级页表，我们可以之家把逻辑地址页号到物理地址页框号的映射放到TLB里面，当应用程序给出逻辑地址的时候，直接在TLB里面查找到页框号，然后利用这个页框号组成内存物理地址访问一次内存

使用多级页表访问物理内存如果是2级页表，那么会访问三次内存，一次是取以及页表页框号，第二次根据前面的页框号访问一级页表得到页框号，最后组成这个物理地址访问物理内存，三次访问内存

使用一级页表和TLB访问内存期望时间

T = HitR*(TLB+MA) + (1-HitR)*(TLB+2MA)

其中HitR是命中TLB概率，MA是访问内存时间

为什么TLB有用，TLB基于程序空间局部性原理，最近访问过的内存区域在未来可能还会被访问。

### 段页式存储器（分段+分页）

操作系统维护了空闲列表来分配段，这个内存分配是虚拟空间的内存分配，实际的内存分配采用的是分页分配，虚拟空间的分配只是形成了一个虚拟地址。操作系统维护了这个虚拟地址空间，然后操作系统对这个虚拟空间的每个段按照页进行分配内存并且保存在内存中。这样段也是存储器分配内存，进程PCB有段寄存器和页表寄存器。用户程序给出的是一个逻辑地址，这个逻辑地址是根据段的逻辑偏移，比如mov [0x24] %eax; 这个0x24是相对于数据段的偏移0x24，操作系统首先获取段表的数据段基址，把0x24加到这个段基址获得虚拟地址；这个虚拟地址被按照分页方式计算实际地址。假设至于一个页表，虚拟地址%4K=页号...页内偏移，可以获得页号，然后查找这个页号在页表中可以获得页框号，然后根据页框号*4K+页内偏移我们可以获得实际物理地址。（页目录号，页号）（页号，页框号）

段页式存储器用于自动转换地址的部件是MMU，他需要放入LDT表（段表）和页表才能计算，而段表和页表是进程相关的。

**写时复制**

把父进程fork到子进程的时候，子进程的LDT表和页表复制为父进程的段表和页表保存在MMU，并且设置子进程的页表为只读。当子进程写变量的时候会查找到父进程的页表并且发现是只读，这样就会分配一个新的页框并且复制到子进程的页表，从而重新按照新页框号计算得到实际物理地址，这样就完成了写时复制。

### 内存换入和换出

通过内存换入和换出可以实现虚拟内存，让用户感觉自己可以使用4G完整的内存。

#### 内存换入

在创建用户程序PCB的过程会分配PCB、用户栈、内核栈、同时分配内存加载用户程序到内存，建立用户程序的段表和页表。建立用户程序段表是完整的，但是建立并加载用户程序页表可能是不完整的，他只会从磁盘中读取应用程序的一个页加载到内存并且建立页表。这样造成的结果是，CPU通过用户栈获得用户程序的程序入口地址，给出程序的逻辑地址发送给MMU，MMU通过逻辑地址其分成段号和段内偏移，查找MMU内的GDT表找到段号对应的段基址，通过段基址+段内偏移找到虚拟内存地址虚拟地址，通过虚拟地址%4K=页号...页内偏移，用页号去查找页表发现页表里面没有页号对应的项，发生缺页中断。缺页中断会从磁盘中找到缺失的页并把那个页加载到内存，同时建立好页表中对应的缺失项。从而通过MMC可以在内存中访问到需要的指令和数据。

缺页中断是在setup.s head.s main.c初始化的时候创建的，在main.c里面与一个trap_init()方法设置缺页中断处理程序。当发生缺页中断时，MMU设置CPU的INTR中断寄存器位1，CPU发生缺页中断并且执行缺页中断指令。

#### 内存换出

**选择哪一页换出-页面置换算法**

评价页面置换算法的标准-缺页次数

- 先入先出

  选择最先换入的页

- 最远被使用

  选择将来最远被使用的也换出，这是最优的算法，但是不能实现，因为你要预测未来到达的页

- 最近最少使用-LRU算法

  选择最近的最少使用的页换出

  **LRU算法**

  - 基于时间戳的算法

    每一页维护一个时间戳，如果发生缺页，就把时间戳最小的那一项替换，这种方法在计算机是不能实现的，这是因为首先每次缺页都要计算时间戳并且遍历页框找到最小的那一项替换，这很耗时，同时你的时间戳会溢出，导致不能用。

  - 基于页码栈的算法（实际上的LinkedHashMap)

    维护一个页码栈，如果页码栈有空余空间就压入，如果没有，检查当前要压入的代码是否在压栈存在，如果存在就把那个页码浮到栈顶，如果不存在，就把这个页码压入栈，而栈底元素会被压出删除。

- 近似LRU算法- Clock算法

**给进程分配多少页框-决定页表大小**

如果分配的太多，那么能够容纳的进程个数减少，内存利用率降低

如果分配太少，缺页率增大，造成频繁内存和外存换页，在进程很多的时候，进程总是等待调页，CPU利用率降低，造成系统抖动颠簸。CPU效率低。

Linux的Swap分区就是用来处理缺页中断的换页的。

内存换入换出时实现虚拟内存的核心，实现虚拟内存是实现段页式存储器的关键。

CPU管理和内存管理是操作系统核心。



1. 异步同步、阻塞非阻塞，他们之间有联系吗，synchronized，放在各个地方锁的是啥，一个synchronized静态方法，一个普通的synchronized方法，访问静态方法后还能访问普通方法吗，锁的对象是一样的吗。

2. synchronized底层原理讲解（3分钟）

3. ReentrantLock底层原理（1.5分钟）

4. 线程池处理任务的流程（2分钟）

5. HashMap底层数据结构（2.5分钟）

6. ConcurrentHashMap底层原理（1分钟）

7. 并发情况下HashMap什么时候会修改失败（1分钟）

8. 

9. 进程线程的区别，进程的切换过程

10. 虚拟内存，为什么要有虚拟内存，进程的虚拟内存联系起来

11. 线程池的参数

    1. 每个参数解释一遍
    2. 然后面试官设置了每个参数，给了是个线程，让描述出完整的线程池执行的流程

12. Linux了解么

    1. 怎么查看系统负载
    2. Cpu load的参数如果为4，描述一下现在系统处于什么情况
    3. Linux，查找磁盘上最大的文件的命令
    4. Linux，如何查看系统日志文件
    5. Linux关于网络的指令
    6. Linux内存管理

13. 线程有哪些实现方式

14. 线程池有哪些

15. 锁有哪些

16. 可重入锁机制

17. 

18. 线程的状态 ： { new ,runnalbe , wait , time-wait , block , terminated }

19.  进程 、 线程 、 协程 的含义和区别   // 个人理解 是一组渐进提出的概念

20. 进程间通信方式 ： { 管道 、FIFO 、 信号量 、 共享内存 、 消息队列 、 Socket }

21. 如何避免死锁 ？ 死锁的四个必要条件

22.  Sleep和wait的区别

23. Sychronized 和 lock 的区别 ？Sychronized的底层优化 ： { 无锁、偏向锁、轻量级锁 、重量级锁 }

24. volatile的作用 : { 指令重拍 、 保证变量的可见性（设计JMM）}

25.  ThreadLocal 底层原理

26. 线程池

    线程池构造器涉及哪些参数 : { corePoolSize , maximumPoolSzie , timeout ， timeUnit ， RejectHandler ， 等待队列 ， 线程工厂 } 

       介绍线程池工作过程?
        线程池拒绝策略那些？ 
        适用Executor创建线程池的弊端？

27. AQS 框架原理和 源码理解

28. Select poll epoll的区别

29. 用户态和内核态的区别

30. fork()作用

31. 虚拟内存作用？ 内存分页的作用？

32. 缺页异常的介绍

33. OOM问题和 StackOverFlow的区别



# 数据库相关

视频资料

[哈工大战德臣数据库系统](https://www.bilibili.com/video/BV1PJ411F78b?spm_id_from=333.337.search-card.all.click)

[马士兵数据库视频](https://www.bilibili.com/video/BV1eb4y1h7mf?p=2&spm_id_from=pageDriver)

[世界数据库排名-技术选型](https://db-engines.com/en/ranking/relational+dbms)

## 数据库系统实验

[数据库的最简单实现 - 阮一峰的网络日志 (ruanyifeng.com)](http://www.ruanyifeng.com/blog/2014/07/database_implementation.html)

[从零写一个数据库 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/c_1092493324325388288)

[MySQL · 源码分析 · Semi-join优化执行代码分析 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/382416772)

### 实验1-最基本的SQL/索引/存储数据库

[数据库的最简单实现 - 阮一峰的网络日志 (ruanyifeng.com)](http://www.ruanyifeng.com/blog/2014/07/database_implementation.html)

**数据库功能**

最基本的两个功能是存储方式和索引方式，其他高级功能包括SQL语言解析、数据库连接、数据库事务、数据库备份、远程操作

- 存储方式。基于磁盘的数据库以文件来保存数据库（MySQL，SQLServer，Oracle），基于内存的数据库以虚拟磁盘的方式保存数据在内存中（Redis）。磁盘数据库依赖Linux操作系统的文件管理系统调用，Linux文件相关系统调用和函数有文件创建/打开/关闭/删除，文件读写（file_read/file_write)，文件执行（exec)。一般将表的每个记录设为等长方便查询数据。create table这个MySQL语句相当于创建了一个结构体，而整个数据库文件相当于table结构体的数组。

- 索引方式。访问数据库中的某一条记录，我们不是直接从磁盘中获得的，因为磁盘是块设备存储，块设备的访问需要使用硬盘中断传入（读写操作命令r/w，磁盘号，磁道号，扇区号，es:[ebx]内存缓冲块地址）这几项参数，然后硬件中断设置进程阻塞状态，等待磁盘控制器将es:[ebx]指向的缓冲区的512个字节写入到磁盘或者将磁盘一个扇区（512B）写入到es:[ebx]所指向的内核缓冲区。CPU只能随机访问内存，不能随机访问磁盘，CPU总是使用硬盘中断读入磁盘一个扇区到内存或者写入内存一个扇区的数据到磁盘。因此CPU要访问数据库数据必须将存储在磁盘中的数据读入内存进行处理。数据库在磁盘中以文件进行存储，实际上是被分散到不同的扇区，MySQL数据库总是以一页内存大小的单位来组织数据块，也就是以8个扇区作为一个数据块，每次读取磁盘的时候总是以8个连续扇区读取到一个内存页中。4K大小的数据块被组织成一个链表，数据块的末尾是指向下一个数据块的指针（这个指针以（磁盘/磁道/扇区来表示和存储））。一般情况下要获取一条记录，我们只知道记录的主键，想要通过主键访问到数据库文件中的记录，我们只有不断把数据库的磁盘数据块读入内核缓冲区，然后读入一条记录到用户空间，主键，如果是就停止，否则移动文件指针lseek（inode, sizeof(entry) ）到下一条记录，重新file_read一条记录sizeof(entry)个字符串到用户空间。这种遍历的方式，有size/blk_size次将磁盘数据块拷贝到内核缓冲区的操作，以及size/sizeof(entry)次将内核缓冲区数据拷贝到用户空间put_fs_char进行比较的操作，这种遍历的方式很耗时。这种方式的伪代码是

  ```c
  for i in size/sizeof(entry):  
  	record=file_read(inode, sizeof(entry) ); 
  	if record == key: 
  		return record; 
  	lseek(inode, sizeof(entry) ;
  ```

  为了获得主键对应的记录，主要是获得记录的文件指针，我们可以用B+树建立索引来保存记录的文件指针。这种把主键进行组织成B+树的形式并且只要在B+树中找到主键就能从主键中获取对应的文件指针，从而根据这个文件指针直接file_read这个文件指针所对应的记录，可以减少访问磁盘的次数和比较的次数。B+数的深度是log(记录数)，每个B+树节点是主键key值，每个主键key值对应一个文件指针指向这个key所对应的条目的地址。我们通过**log(记录数)**次读取磁盘到内存并比较**log(记录数)*每个B+树节点对应记录数**次就可以找到主键和主键对应的文件指针，我们通过文件指针file_read这个文件指针就可以找到那一条记录，这样我们实际读取磁盘块的次数是**log(记录数)\*节点度数+1**和比较次数**log(记录数)\*节点度数**，远远小于遍历的方式。B+树文件需要额外存储为一个索引文件，可以放到数据库文件对应的文件夹里面，每个B+树节点占用一个磁盘数据块。B+树节点有参数（主键，文件指针），为了方便数据库文件在磁盘块上连续存储。这种实现方式伪代码

  ```c
  find_filep(B_node):
  	for record in B_node:
  		if record.key== key:
  			return record.filep
  		if record.key>key:
  			return find_filep(newB_node= record.blkp)
  filep= find_filep(B_node)
  record = file_read(filep, sizeof(entry) )
  return record
  ```

- SQL语言解析。将SQL语句转换成对应的ISAM（Indexed Sequential Access Method 索引顺序访问方法）方法，执行数据库的访问。select对应读数据库，具体实现是按照上诉索引查找到主键位置和对应的文件指针，然后通过文件指针file_read访问磁盘数据库文件，读取对应的记录put_fs_char到用户空间；update对应更新数据库，首先按照上诉的索引找到主键对应的文件指针，file_wirte（文件指针，用户空间更新数组，字节数）将数据写入到内核缓冲块，最后调用iput将缓冲块写到磁盘文件；delete只需要修改B+树索引文件就可以了，我们可以增加主键结构的一位用来保存这个主键是否可用，这样我们在select和update查询B+树的时候发现有主键不可用，那么就返回失败没有那一个主键条目；insert对应增加一个条目到数据库中他首先获取数据库末尾指针把这个末尾指针和主键一起加入B+树，然后file_write文件末尾增加一个记录到数据库文件。

- 数据库连接：将两个数据库表合并到一起，包括左连右连全外连接内连接等等。数据库连接通过SQL的join语句完成。数据库连接优化怎么做需要自己实现

- 数据库事务：保证原子性执行的一段数据库指令。当事务不能执行的时候需要回滚操作

- 数据库备份：保存数据库副本的操作。远程数据库备份需要哨兵机制

- 远程操作：远程访问数据库，需要实现TCP/IP等通信协议。

**scanf/gets/编译器字面值 都会添加\0字符，忽略\n字符**

https://www.runoob.com/cprogramming/c-function-sscanf.html

sscanf/sprintf读写字符串, scanf/printf/gets/puts读写控制台stdio，fscanf/fprintf/fgets/fputs读写文件

```c
#include <stdio.h>

int main () {
	char a[10] ;
	scanf("%s", a) ;
	if( a[1]=='\0'){
		printf("scanf will add \\0 into char list\n");
	}else{
		printf("scanf will not add \\0 into char list\n") ;
	}
	return 0; 
}
```

![Screenshot 2022-10-18 155158](实验\操作系统实验\实验5 信号量的实现和应用\Screenshot 2022-10-18 155158.png)

**获取文件读写位置函数fgetpos/fsetpos，可以被索引文件保存为对应主键的读写位置**

https://www.tutorialspoint.com/c_standard_library/c_function_fgetpos.htm

https://www.javatpoint.com/fprintf-fscanf-in-c

```c
// test1.c
#include <stdio.h>
int main () {
   FILE *fp;
   fpos_t position;

   fp = fopen("file.txt","w+");
   fgetpos(fp, &position);
   fputs("Hello, World!", fp);
  
   fsetpos(fp, &position);
   fputs("This is going to override previous content", fp);
   fclose(fp);
   
   return(0);
}

//test2.c
#include <stdio.h>

int main () {
   FILE *fp;
   int c;
   int n = 0;

   fp = fopen("file.txt","r");
   
   while(1) {
      c = fgetc(fp);
      if( feof(fp) ) {
         break ;
      }
      printf("%c", c);
   }

   fclose(fp);

   return(0);
}
```

fscanf/fprintf

```c
#include <stdio.h>  
main(){  
   FILE *fp;  
   fp = fopen("file.txt", "w");//opening file  
   fprintf(fp, "Hello file by fprintf...\n");//writing data into file  
   fclose(fp);//closing file  
}  



///
#include <stdio.h>  
main(){  
   FILE *fp;  
   char buff[255];//creating char array to store data of file  
   fp = fopen("file.txt", "r");  
   while(fscanf(fp, "%s", buff)!=EOF){  
   printf("%s ", buff );  
   }  
   fclose(fp);  
}  
```

**数据库实验-实现SQL语言解析/索引/数据库文件存储的数据库**

```c


#include<stdio.h>


#define NOT_VALID 0
#define VALID 1


typedef struct {
	int key;
	long Fpos;
	long Ipos ;
	int valid;	
}Index;
Index index[10] ;



void select(FILE* fp, int key){
	int col1, col2 ;
	long pos= index[key].Fpos;
	fseek(fp, pos, SEEK_SET) ;
	fscanf(fp, "%d %d %d",&key,&col1,&col2) ;
	//printf("%d: %ld\n",key, pos) ;
	
	printf("%d %d %d\n", key, col1, col2) ;
}
int main(){
/*
	sql interpreter
		C a.db: create file a.db as database
			char fname[10]
			scanf("%c %s", &op, fname) ;
			FILE* fp = fopen(fname, "rw") ; 
			FILE* ifp= fopen(fname.index,"rw");
			
			idx=0;
			while(!feof(fp)){
				fgets("%d%d%d",index[idx].key, index[idx].pos, index[idx].val) ;
				idx++;
			}
		I a.db 1 2 3: insert into a.db values(1,2,3)
			fseek(fp,0, SEEK_END);    // move rw position to the end to write
			int pos = ftell( fp) ;    // rw postion
			index[key]={key,pos,1} ;  // 1 indicates that the index of key is 
						   // valid, key has not been deleted
			fputs("%d,%d,%d",key,col1,col2) ;	
			
		D 1 from a.db: delete from a.db where key=1
			int valid = index[key].valid;
			if not valid:
				printf("dont exit") ;
				return ;
			index[key].valid = NOT_VALID
		U 1 (3,4) from a.db: update a.db set col1=3, col2=4 where key=1
			int valid=index[1].valid;
			if not valid:
				printf("dont exit") ;
				return ;
			int pos = index[1].pos;
			fseek(fp, pos, SEEK_SET);
			fputs(%d,%d,%d",key,col1,col2) ;
	 	S 1 from a.db: select * from a.db where key=1
	 		int valid=index[1].valid;
	 		if not valid:
	 			printf("don't exist")    ;
	 			return ;
	 		int pos= index[1].pos;
	 		fseek(fp, pos, SEEK_SET) ;
	 		fgets("%d,%d,%d",&key,&col1,&col2) ;
	
	index
		use hash table to index
		in MySQl, use B+ tree to index
	
	storage
		use file to store database file
*/
	/*
	stdio/stderr, scanf/printf, gets/puts
	fileio, fscanf/fprintf, fgets/fputs
	*/
	char fname[20] ;
	char idxname[40] ;
	char row[100];
	FILE *fp, *ifp ;
	char op ;
	int cnt ;
	while(1){
		printf("Command C, I, D, U, S, P, Q: ") ;
		gets(row);
		
		if( row[0] == 'Q'){
			break ;
		}else if( row[0]=='C' ){
			sscanf(row, "C %s", fname) ;
			
			sprintf(idxname, "%s.idx", fname) ;
		
			if( !(fp = fopen(fname,"r") ) ){
				fp = fopen(fname,"w") ;
				fclose(fp) ;
			}
			fp = fopen(fname,"r+") ;
			
			if( !(ifp = fopen(idxname,"r") ) ){
				ifp = fopen(idxname,"w") ;
				fclose(ifp) ;
			}
			ifp = fopen(idxname,"r+") ;
			 
			int idx=1;
			//printf("Index:\n") ;
			while(!feof(ifp)){
				fscanf(ifp,"%d %ld %ld %d",&index[idx].key, &index[idx].Fpos, &index[idx].Ipos, &index[idx].valid) ;
			
				idx++;
			}
			cnt = idx-1 ;
			printf("Comand C: cnt=%d\n",cnt) ;
		}else if( row[0] == 'I'){
			int key= cnt++, col1, col2 ;
			sscanf(row, "I %d %d", &col1, &col2) ;
		
			fseek(fp,0, SEEK_END);    // move rw position to the end to write
			long pos = ftell( fp) ;    // rw postion
			
			fseek(ifp,0, SEEK_END);
			long Ipos = ftell( ifp) ;
			index[key].key = key ;
			index[key].Fpos = pos ;
			index[key].Ipos = Ipos ;
			index[key].valid = VALID ;  // 1 indicates that the index of key is 
						   // valid, key has not been deleted
			fprintf(fp, "%d %d %d\n",key,col1,col2) ;
			
			fprintf(ifp, "%d %ld %ld %d\n", key, pos, Ipos, VALID) ;
			
			printf("%d: %d %d, Fpos=%ld Ipos=%ld %d\n", key, col1, col2, pos, Ipos, VALID) ;
		}else if( row[0] == 'D'){
			int key, col1, col2 ;
			sscanf(row, "D %d", &key) ;
		
			int valid = index[key].valid;
			if( key<1 || key>=cnt || !valid){
				printf("invalid id\n") ;
				continue ;
			}
			index[key].valid = NOT_VALID ;
			fseek(ifp, index[key].Ipos, SEEK_SET) ;
			fprintf(ifp, "%d %ld %ld %d\n", key, index[key].Fpos, index[key].Ipos, NOT_VALID) ;
			
			printf("%d: de-Valid\n",key) ;
		}else if( row[0] == 'U'){
			int key, col1, col2 ;
			sscanf(row, "U %d %d %d", &key, &col1, &col2) ;
			
			int valid = index[key].valid;
			if( key<1 || key>=cnt || !valid){
				printf("invalid id\n") ;
				continue ;
			}
			
			long pos = index[key].Fpos;
			fseek(fp, pos, SEEK_SET);
			fprintf(fp, "%d %d %d\n",key,col1,col2) ;
			
			printf("%d: update\n",key) ;
		}else if( row[0] == 'S'){
			int key, col1, col2 ;
			sscanf(row, "S %d", &key) ;
			
			int valid = index[key].valid;
			if( key<1 || key>=cnt || !valid){
				printf("invalid id\n") ;
				continue ;
			}
			
			select(fp, key) ;
	 	}else if( row[0] == 'P'){
			if( row[1]=='F'){ //display databasea
				for( int i=1;i<cnt;i++){
		 			if( index[i].valid == VALID){
		 				select(fp, i) ;
		 			}
		 		}
		 	}else if( row[1]=='I'){//display index file
		 		for(int i=1;i<cnt;i++){
		 			
		 			if( index[i].valid == VALID){
		 				printf("%d %ld %ld %d\n",index[i].key, index[i].Fpos, index[i].Ipos, index[i].valid) ;
		 			}
		 		}
		 	}
	 	}
		
	}
	fclose(fp) ;
	fclose(ifp) ;
	
	return 0;
}

```

![Screenshot 2022-10-18 211906](实验\数据库实验\实验1-实现SQL解析、索引、文件存储的简单数据库\实验截图\Screenshot 2022-10-18 211906.png)

## 数据库设计原则

### 范式

1. 第一范式：字段原子性
2. 第二范式：消除对主键的部份依赖
3. 第三范式：消除对非主属性的依赖
4. BCNF范式：对于关系模式R，若 R为第一范式，且每个属性都不部分依赖于候选键也不传递依赖于候选键，则R称之为BC范式。

### 事务

#### 事务特性

1. 原子性：事务操作要么全部成功，要么势必回滚
2. 一致性：事务必须从提交前的一致状态转移到提交后的一致状态
3. 隔离性：并发事务不相互 干扰
4. 持久性：事务一旦提交，对数据库的改变是持久的，就算数据库故障也不丢失

#### 事务隔离级别

1. Read uncommitted

   A事务修改了数据但是没有写回，此时B事务读取了这个数据，B事务发生了脏数据

2. Read Commited（ SQLServer 和Oracle默认隔离级别）

   事务只能读到其他食物已经提交的数据（解决了脏读），但是A事务读的时候，另一个事务修改并提交，A事务再次读发现数据不一致，则第一个事务发生不可重复读

3. Repeated Read（MySQL默认隔离级别）

   一个事务获取一个数据时，其他事务不能修改这个数据（解决了脏读和不可重复读），但是如果第一个事务进行中，另一个事务增加或删除了数据，可能会影响第一个事务的数据，即第一个事务出现幻读

4. Serializable

   事务串行化按序执行，解决了脏读、不可重复读、幻读，但是不并行效率低

#### 解决幻读

MVCC模式：Multi-version concurrent control， 多版本并发控制。解决了保证数据一致性的前提下，提供高并发性能的需求，时MySQL解决默认隔离级别下幻读的方式

MVCC模式，类似COW，事务读取数据时创建数据拷贝，对数据修改在事务本地拷贝进行，对其他事务不可见，事务的提交不会覆盖原有的数据，而是产生多个历史版本数据，但是同一时刻只有最新版本有效

### 数据库优化

### 时间处理

```
DATE_FORMAT(<colName>, '%Y-%m-%d %H:%i:%s')
```

- 按小时取：

  ```
  SELECT DATE_FORMAT(<dateCol>, '%Y-%m-%d %H') as `hour`, COUNT(*)
  FROM <tableName>
  GROUP BY `hour`
  ```

- 按每隔一段时间（30min为例），使用`CONCAT()`构造出`GROUP BY`条件：

  ```
  SELECT
  	DATE_FORMAT(
  		CONCAT( DATE( <dateCol> ), ' ', HOUR ( <dateCol> ), ':', 
      	( FLOOR( MINUTE ( <dateCol> ) / 30 ) * 30 ) ),
  		'%Y-%m-%d %H:%i' 
  		) AS `min`,
      COUNT(*)
  FROM
  	<tableName>
  GROUP BY `min`
  ```

### 查询题目

1. 查询成绩前三的数据（tab）：

   | id   | name | score |
   | ---- | ---- | ----- |
   | 1    | a    | 100   |

   ```
   SELECT * FROM tab WHERE score IN(
   	SELECT score FROM(
       	SELECT DISTINCT score FROM t ORDER BY score DESC LIMIT 3
       ) as t
   )
   ```

### 聚集索引和非聚集索引

聚集索引是一个表只有一个，一般是主键索引；非聚集索引一般是非主键索引，用于频繁访问

## 数据库事务

数据库事务（transaction）时由多个SQL语句构成的操作序列，数据库系统要保证事务的所有语句要么全部执行成功，要么全部不执行。

### 数据库事务的特性ACID

**Atomicity 原子性**：一个事务中的SQL序列，要么全部执行，要么全部不执行，不会出现部分执行的情况，一旦出现错误，就会回滚，就像这个事务没有执行过一样

**Consistency 一致性**：事务结束前后，数据库的完整性没有被破坏，这表示写入的资料必须完全符合所有预设的规则，包括数据的精度、串联性以及后续数据库可以自发性的完成预定的工作。

**Isolation 隔离性**：防止多个事务并发执行时数据不一致。事务隔离级别包括读未提交、读已提交、可重复读、串行化

**Durabiliity 持久性**：事务结束后，对数据库的修改是永久的，即使系统故障也不会丢失。

### 数据库事务的隔离级别

[link](https://www.cnblogs.com/fengzheng/p/12557762.html)

| Isolation Level  | 脏读（Dirty Read） | 不可重复读（Non Repeatable Read） | 幻读（Phantom Read） |
| :--------------- | :----------------- | :-------------------------------- | :------------------- |
| Read Uncommitted | Yes                | Yes                               | Yes                  |
| Read Committed   | -                  | Yes                               | Yes                  |
| Repeatable Read  | -                  | -                                 | Yes                  |
| Serializable     | -                  | -                                 | -                    |

### JDBC实现事务

```java
Connection conn = openConnection();
try {
    // 关闭自动提交:
    conn.setAutoCommit(false);
    // 执行多条SQL语句:
    insert(); update(); delete();
    // 提交事务:
    conn.commit();
} catch (SQLException e) {
    // 回滚事务:
    conn.rollback();
} finally {
    conn.setAutoCommit(true);
    conn.close();
}
```

开启事务的关键代码时conn.setAutoCommit(false)，表示关闭自动提交，conn默认时执行一条SQL语句就提交一句。

设定事务的隔离级别

```java
conn.setTransactionIsolation(Connection.TRANSACTION_READ_COMMITTED);
```

如果没有设置事务的隔离级别，那么使用数据库的默认隔离级别，MySQL的默认隔离级别是REPEATABLE_READ

## 数据库基本知识

- 数据库保存在磁盘中而不是内存中，磁盘寻址速度是毫秒级别，存储容量很大，数据传输带宽是G或者M；内存寻址速度是纳秒级别，存储容量较小，带宽很大；可见内存寻址速度是磁盘寻址速度的100万倍。磁盘分区的大小是512B，也就是磁盘基本单位是512B，而操作系统一次读取数据是4K，为什么操作系统读取数据大小比磁盘基本单位大，因为为了节约地址总线个数，节约成本，减少寻址的粒度。

- 使用文件系统保存数据的缺点是无法建立索引，需要全局查找，效率低，而且全局查找需要IO读入所有数据，更造成巨大的读磁盘开销。而使用数据库的优点就是可以建立索引加快查找速度。查询文件速度慢原因：一个是要顺序查找，时间复杂度O(n)，另一个是要全部读完数据，访问磁盘太多，而访问磁盘是IO瓶颈

- 数据库按4K存储数据，这和操作系统访问数据一次读取数据大小相同，这样设计数据存储数据大小大于等于4K的好处是不会浪费一次访问磁盘读取的数据大小。如果数据库设计存储单元大小小于4K，比如1K，操作系统一次读取依旧是4K，这样就有3K是浪费的了。而这样造成的结果就是增加操作系统访问磁盘次数。所以数据库基本单元设计要是4K的倍数。如果数据库仅仅只是使用4K作为存储单元，并没有比文件系统更好，查找他依旧是全量IO，这个时候引申出索引。

- 关系型数据库在创建数据库的时候需要一个schema，这个schema确定之后，那么数据库存储一行数据的大小就确定了，那么数据库的每一块存放的数据库的条数也就确定了。

- 数据库索引保存在磁盘里，B+树的非叶节点存储的是关键字和儿子节点的索引，这些关键字和儿子节点的索引被分成4K大小存放。在运行的时候，操作系统会读取数据库B+树索引的根节点到内存。每次访问数据库约束的时候，操作系统根据B+树根节点找到关键字所处的儿子节点，然后根据儿子节点地址访问磁盘获得新的B+树非叶子节点的新的4K块，如果访问这个非叶子节点找到关键字所在的叶子节点，那么查询这个叶子节点的关键字数组，找到对应的关键字，而关键字里面保存着这个关键字所对应的行数据，这样你就可以返回得到你要查找的数据。

  B+树叶子节点只需要保存Key和Key多对应的行数据就行。

  B+树有两种节点，一种是非叶节点，一种是叶子节点。非叶节点包含单纯的key和指向儿子节点的指针；叶节点的key需要存储行数据，并且他没有儿子节点指针，但是他有一个链表指针。

  创建B+树的时候初始化一个叶子节点A作为根节点。然后不断给这个根节点假数据key_数据，直到这个叶节点分裂，分裂的时候创建一个非叶节点B，这个非叶节点增加一个关键字是A的中间关键字，这里只是给非叶节点的关键字数据增加一个关键字而已，而不是增加关键字和数据组合。增加关键字后，非叶子节点B添加两个分别指向分裂的A节点的指针A1和A2，然后把你的key和数据重新从B节点遍历，找到他应该去的位置，或者是A1或者是A2进行插入。这样就完成了B+树索引的创建和B+树数据的插入。在这个过程中，A节点保存在内存 中，需要一次分裂移动。数据项key插入之后，查找数据的小于key的节点和大于key的节点找到他的前驱节点和后继节点，然后把新的key数据节点插入到这个链表里面。这样就能形成一条链表，支持范围查询。为了方便获得前驱和后继节点，这也是为什么B+树关键字是按照数字1，2，3来的，因为可以通过直接加减1获得前去和后继节点。这样的好处还有一个是如果要删除一个节点，你不需要变动B+树，你只需要把对应的叶节点的Key节点删除就行了。B+树所有叶节点是登高的，因为所有的叶节点都是从初始的叶节点开始分裂得到的，一个新的叶节点总是一个叶节点分裂创建的。

- 数据库表很大是否会造成SQL性能下降？

  如果是少量SQL指令，不会；但是如果并发度太大，那么请求磁盘量增大，会触发IO瓶颈，造成SQL性能下降。

  磁盘级数据库（数据库保存在磁盘，对应的是内存级数据库，数据库保存在内存）在数据库表很大的时候，在高并发的情况会造成IO瓶颈从而导致SQL性能下降。这个时候提出了缓存的概念，比如Redis。

  Redis可以达到秒级十万操作，这个操作数远远大于MySQL等关系型数据库，他是秒级一千操作。

- Redis相较于MemChached的优势

  两个都是关系型数据库，但是Redis的优势是有数据类型，而MemChached没有数据类型的概念，他的所有存储都是字符串。这样造成的结果是，当客户端请求key-value中value的某一项数据的时候，Redis和MemChached性能不一样。MemeChached会返回所有的Key所对应value，需要用户自己去解析value中的某一项数据。这不仅增加了客户端写代码的复杂，而且返回的value中存在很多冗余数据，造成的结果是增加IO网络瓶颈。而Redis有类型的概念，这些类型提供了很多方法处理每个类型，这样，客户端请求数据的时候如果是value的某一项，比如value是一个数组类型，那么取数组中的一项之后返回给客户端，这样不会有冗余数据并且不会让客户端写代码处理数据，非常高效。这个在服务端完成对用户数据请求的解析的过程叫做计算向数据移动。
  
- 同步与异步  阻塞与非阻塞

  [参考](https://www.zhihu.com/question/19732473)

  [参考](https://www.cnblogs.com/loveer/p/11479249.html#!comments)

  从大的概念来说，同步和异步描述的是函数调用时两个函数之间的关系，关注的是函数调用的消息通知机制，如果A调用B，A必须等待B返回结果，那么这个过程是同步的；如果A调用B，A不用等待B返回最终的结果，可以是返回一个部分的或者null的结果，A继续执行，而B在准备好结果之后使用状态或者通知机制通知A处理返回结果，这个过程就是异步。从大的概念，阻塞和非阻塞关注的是一个对象的状态，关注的是函数调用时调用者的状态，如果A调用B，A被阻塞挂起，处于waiting状态，那么就是A就是阻塞的；如果A调用B，A没有挂起而是依旧处于Running状态，那就是非阻塞的。

  在UNIX的IO里，同步是指调用进程使用IO系统调用之后需要等待操作系统执行完数据准备和数据从内核缓冲区拷贝到用户缓冲区后才能继续执行后面的操作；而异步是指进程使用IO系统调用之后进程不用等待操作操纵系统完成数据准备和数据拷贝到用户缓冲区这个过程完成，而是可以直接执行后面的操作，操作系统在完成数据准备和拷贝到用户缓冲区之后会使用进程提供的处理函数进行处理或者通知进程处理。而阻塞是指进程在调用IO系统调用后等待操作系统完成数据准备和拷贝用户空间的状态，如果进程被挂起处于waiting状态，那么就是阻塞式IO，如果没有被挂起而是使用轮询不断检查操作系统是否准备好数据并且处于Running状态，那就是非阻塞式IO。

### SQL

#### 查询

```
//求任意两个老师的薪水差额
select t1.name as t1n, t2.name as t2n, t1.salary-t2.salary
from Teacher t1, Teacher t2
where t1.salary>t2.salary;

//根据学生年龄计算学生出生年份，当前年时2015
select s.name as name, 2015-s.age as year
from Student s ;

//聚集函数
count //求个数
sum //求和
avg //求平均
max //求最大
min //求最小

//求教师总工资
select sum(t.salary) 
from Teacher t ;

//求计算机系老师总工资
select sum(t.salary)
from Teacher t, Department d
where d.name='计算机' and d.tid=t.tid;

//分组查询和分组过滤
//查询计算机系老师的总人数
select d.name as name, count(d.tid) as number
from Department d
group by d.name;

//查询不及格课程成绩超过两门的所有学生学号
//分组过滤
select s.sid
from Student s
where s.score<60
group by s.sid 
having count(*)>2 ;


//求课程不及格超过两门的学生的平均成绩
select s.sid as sid, avg(s.score) as score
from Student s
where s.sid in 
	(select s1.sid 
	from Student s1
	where s1.score<60
	group by s1.sid
	having count(*)>2)
group by s.sid;


//学生成绩前十个
select *
from student
where score>60
order by score
limit 10;
```

#### 集合运算

```
//求学过2号课或者3号可的学生学学号，与
select s.sid
from student s
where s.cid=2
union
select s.sid
from student s
where s.cid=3;

//求学过2号课和3号课的学生学学号，交
select s.sid
from student s
where s.cid=2
intersect
select s.sid
from student s
where s.cid=3;

//求所有没有学过2号课的学生，差
select s.sid 
from student s
except
select s.sid
from student s
where s.cid = 2;
```

#### 空值

```
//找出年龄为空的学生姓名
select s.sid 
from student s
where s.age is null;
```

#### 关系运算

```
//内连接
//求所有老师的课程并按教师号排序
select Teacher.name, Course.name
from Teacher Inne Join Course
on Teacher.tid = Course.tid
order by Teacher.tid

//左外连接 left outer join
//右外连接 right outer join
//全外连接 full outer join
```

### 范式

1NF，属性原子性

2NF，在满足1NF条件下，非主属性完全依赖于候选键

3NF，在满足2NF条件下，非码属性不传递依赖于非码属性

BCNF，不存在函数依赖不依赖候选键。

### 数据库存储和检索

数据库存在磁盘上

#### 数据在磁盘上如何组织

1. 操作系统管理文件的方式：

   文件存储在磁盘块中，每一块512B，操作系统使用文件目录表和FAT（File Allocation Table）文件分配表管理文件系统。文件夹（文件目录）保存了文件的第一个磁盘块所在的位置（一个指向磁盘块的块号），文件分配表FAT按链表保存下一个磁盘块的位置，读取文件以链表的方式根据目录表和FAT表从磁盘中读取。

2. 操作系统内存管理：

   内存被划分成一块一块的（页号），寻址总是以页号：页内偏移找到内存记录的，一个页面对应磁盘的磁盘块。

3. 数据库存储的方式

   

**磁盘管理**

磁盘由（盘面：磁道：扇区）组织

磁盘读写单位是块，一个块是多个连续的扇区

读磁盘方式：读写臂移动到对应的磁道（寻道时间在1-20ms），然后旋转盘面找到对应的磁盘块扇区（旋转时间在0-10ms），然后传输数据（传输时间在每4k小于1ms）

一个磁盘基本信息示例：

- 磁盘示例：一个磁盘由8个圆盘（16个盘面，上下两个盘面），每个盘面由2^16=65536个磁道，每个磁道由2^8=256个扇区，每个扇区由2^12=4096个字节，标准扇区字节大小是512B

- 磁盘以7200转/min，那么8.333ms转一圈
- 读写臂从启动到停止要时间1ms，读写臂每移动一个磁道勇士1ms，也就是移动一个磁道勇士0.00025ms内移动一个磁道，从最内圈磁道移动到最外圈磁道65536个磁道移动用时17.38ms
- 磁道中扇区间的空隙大约占整个磁道百分之十的空间
- 一个磁盘块由4个扇区。
- 读取一个磁盘块的最小时间只有传输时间，比如传输时间0.13ms；最长时间是寻道时间+旋转时间+传输时间=17.38+8.33+0.13=25.84ms

磁盘存取算法考虑的关键

- 降低IO次数
- 降低排队等待时间
- 降低寻道/旋转延迟时间
  - 同一磁道连续块存储
  - 同一柱面不同磁道并行块存储
  - 读个磁盘并行块存储



## Redis

- Unix网络编程

  [基础介绍](https://www.jianshu.com/p/b8203d46895c)

  [基础介绍](https://www.jianshu.com/p/397449cadc9a)

  [多路复用IO的三种实现方式select poll epoll](https://zhuanlan.zhihu.com/p/400798093)

  [epoll底层实现原理](https://zhuanlan.zhihu.com/p/487497556)

  Unix进程IO分为两个阶段，操作系统准备数据阶段和操作系统从内核缓冲区拷贝数据到用户缓冲区。Unix进程IO分为五个方式，其中第四个方式不常用

  - BIO, 阻塞IO（Blocking IO)

    用户调用recvfrom系统调用请求操作系统准备数据，然后自己被阻塞。操作系统准备好数据并且把数据从内核空间拷贝到用户空间之后，会检查阻塞队列并且唤醒用户进程，用户进程继续执行。这个过程的特定是用户进程在操作系统准备数据和把数据拷贝到用户空间两个过程都被阻塞

  - NIO，非阻塞IO（NonBlocking IO）

    用户调用recvfrom之后不是被阻塞，而是操作系统返回一个EWOULDBLOCK的响应，用户进程通过这个响应自循环，直到操作系统准备好数据，而用户调用recvfrom系统调用之后操作系统会把用户进程阻塞，直到把内核空间数据拷贝到内核空间之后才返回，把用户进程解除阻塞，让用户进程重新执行。这个过程的特点是用户进程在操作系统准备数据阶段没有被阻塞，但是在拷贝数据到用户空间的时候会被阻塞

  - 多路复用IO

    一个用户进程监控多个Socket描述符。用户进程使用select、poll、epoll等监控多个socket描述符，自己被阻塞，等到操作系统将他唤醒，之后用户进程调用recvfrom系统调用让操作系统拷贝数据到用户空间，用户进程被阻塞，直到拷贝完成重新唤醒执行后面的操作。

    - select

      select是一种多路复用IO的实现方式，他被用户进程调用，然后他阻塞用户进程，用户进程传递一个fd_set作为文件描述符集合，每次用户调用一次select那么select就会把这个集合拷贝到内核空间，select会轮询监视这个bitmap的文件描述符，如果发现一个或者多个数据准备好了，就会返回和唤醒用户进程，用户进程调用recvfrom让操作系统拷贝数据到用户空间，这个过程用户进程接着阻塞。然后用户进程重复上面的过程。

      select的好处是

      使用一个进程处理多个socket描述符，避免了多进程阻塞IO（BIO）时维护多进程和进程切换的开销，而每次进程切换都要花几纳秒。这里的复用指的是只有一个线程。

      select的缺点是

      1. 每次到用select就要拷贝fd_set到内核空间，增加开销
      2. 底层使用轮询检查文件描述符是否准备就绪，增加开销
      3. 支持监视的文件描述符有限，只有1024个

    - poll

      poll是select的改进版本，底层使用链表实现，他的文件描述符的结构和select不同，他也需要拷贝文件描述符集合到内存空间，并且轮询检查文件描述符集合返回给用户准备好了的文件描述符集合。他相较与select的优点是他支持的文件描述符个数没有限制，而select最多1024

    - epoll

      epoll底层用红黑树保存文件描述符，使用链表保存就序列表，增加查询文件描述符效率。用户使用epoll_create创建一个epoll数据结构，然后调用epool_ctl将socket添加到数据结构上，之后调用epoll_wait把自己阻塞。当操作系统接收到完整的数据的时候，会把文件描述符从红黑树取下来包装成epitem放到就绪队列里面，并且在阻塞队列里面通知阻塞进程去执行这些就绪队列的数据。epoll检查就绪不是使用轮询，而是使用事件驱动，减少了轮询开销。

      epoll在高并发环境是很高效的，高并发条件下复用的进程根本不会被阻塞，因为就绪队列总是有数据，那么他调用epoll_wait的时候总是会去执行数据处理。

      epoll在少量数据连接的时候可能使用阻塞IO更好

  - 信号驱动IO

  - AIO，异步IO，常用于文件处理而不是网路处理

    用户进程调用aio_read系统调用之后操作系统准备数据，而进程不会被阻塞，而是继续执行。之后操作系统准备好数据并拷贝到用户空间之后通知用户进程处理或者直接使用用户进程提供的处理方法处理。

- Redis是单进程单线程单实例处理用户请求

  使用epoll的NIO机制处理IO请求。

- 使用Redis

  Redis默认准备了16个库，获取数据的时候可以指定存储的库，通过select选择使用的库

  ```
  select 1 //选择1号库
  set a hello
  get a  //会返回hello字符串
  select 8 //选择八号库
  get a  //返回(nil)
  ```

  ```
  //基本操作指令
  keys * //返回所有创建的key
  FLUSHDB //清空Redis所有缓存，删库
  ```

### Redis设计与实现

#### Redis数据类型和存储结构的实现

Redis有一个redisDB的数据结构作为Redis的数据库，其中一个db指针保存了所有数据库

```c

//src/redis.h
typedef struct redisDb {

    // 数据库键空间，保存着数据库中的所有键值对
    dict *dict;                 /* The keyspace for this DB */

    // 键的过期时间，字典的键为键，字典的值为过期事件 UNIX 时间戳
    dict *expires;              /* Timeout of keys with a timeout set */

    // 正处于阻塞状态的键
    dict *blocking_keys;        /* Keys with clients waiting for data (BLPOP) */

    // 可以解除阻塞的键
    dict *ready_keys;           /* Blocked keys that received a PUSH */

    // 正在被 WATCH 命令监视的键
    dict *watched_keys;         /* WATCHED keys for MULTI/EXEC CAS */

    struct evictionPoolEntry *eviction_pool;    /* Eviction pool of keys */

    // 数据库号码
    int id;                     /* Database ID */

    // 数据库的键的平均 TTL ，统计信息
    long long avg_ttl;          /* Average TTL, just for stats */

} redisDb;
```

```c
// src/dict.h

/*
 * 哈希表节点
 */
typedef struct dictEntry {
    
    // 键
    void *key;

    // 值
    union {
        void *val;
        uint64_t u64;
        int64_t s64;
    } v;

    // 指向下个哈希表节点，形成链表
    struct dictEntry *next;

} dictEntry;


/*
 * 字典类型特定函数
 */
typedef struct dictType {

    // 计算哈希值的函数
    unsigned int (*hashFunction)(const void *key);

    // 复制键的函数
    void *(*keyDup)(void *privdata, const void *key);

    // 复制值的函数
    void *(*valDup)(void *privdata, const void *obj);

    // 对比键的函数
    int (*keyCompare)(void *privdata, const void *key1, const void *key2);

    // 销毁键的函数
    void (*keyDestructor)(void *privdata, void *key);
    
    // 销毁值的函数
    void (*valDestructor)(void *privdata, void *obj);

} dictType;


/* This is our hash table structure. Every dictionary has two of this as we
 * implement incremental rehashing, for the old to the new table. */
/*
 * 哈希表
 *
 * 每个字典都使用两个哈希表，从而实现渐进式 rehash 。
 */
typedef struct dictht {
    
    // 哈希表数组
    dictEntry **table;

    // 哈希表大小
    unsigned long size;
    
    // 哈希表大小掩码，用于计算索引值
    // 总是等于 size - 1
    unsigned long sizemask;

    // 该哈希表已有节点的数量
    unsigned long used;

} dictht;

/*
 * 字典
 */
typedef struct dict {

    // 类型特定函数
    dictType *type;

    // 私有数据
    void *privdata;

    // 哈希表
    dictht ht[2];

    // rehash 索引
    // 当 rehash 不在进行时，值为 -1
    int rehashidx; /* rehashing not in progress if rehashidx == -1 */

    // 目前正在运行的安全迭代器的数量
    int iterators; /* number of iterators currently running */

} dict;

```

可以在redisDB中设置数据库的个数（一个变量保存个数）。可以通过select来选择使用哪一个db（默认使用db[0]），为了防止多客户端（多进程）访问数据库造成数据库混乱（客户端忘了切换数据库而造成本来访问的是db[0]结果访问的是db[0]），必须切换数据库。每个数据库是一个哈希链表结构来保存的。Redis是一个key-value数据库，他的key总是字符串类型string，二他的value却可以是5种数据类型string/list/hash/set/sorted set，每种类型用一个公共接口管理redisObject，

```c
//src/redis.h
typedef struct redisObject {

    // 类型
    unsigned type:4;

    // 编码
    unsigned encoding:4;

    // 对象最后一次被访问的时间
    unsigned lru:REDIS_LRU_BITS; /* lru time (relative to server.lruclock) */

    // 引用计数
    int refcount;

    // 指向实际值的指针
    void *ptr;

} robj;
```

redisObject记录了这个数据是什么类型type，存储方式encoding，指向实际存储的对象的指针。给定一个命令set aa bb，key=aa会先使用murmur2算法计算他的哈希值（这个算法保证哈希值的随机性，让哈希表均匀分布），然后使用这个哈希值和哈希表取余获得index，然后插入index这个哈希链表，一个哈希链表结构是一个{*key, *value, *next}的结构

```c
/*
 * 哈希表节点
 */
typedef struct dictEntry {
    
    // 键
    void *key;

    // 值
    union {
        void *val;
        uint64_t u64;
        int64_t s64;
    } v;

    // 指向下个哈希表节点，形成链表
    struct dictEntry *next;

} dictEntry;
```

也就是说每个哈希链表节点的key指向key的存储对象，这个存储对象是一个SDS结构的，SDS结构如下

```c
//src/sds.h

/*
 * 保存字符串对象的结构
 */
struct sdshdr {
    
    // buf 中已占用空间的长度
    int len;

    // buf 中剩余可用空间的长度
    int free;

    // 数据空间
    char buf[];
};
```

哈希表的key是一个string类型，但是value却是5中类型，string/list/hash/set/sorted set，这五种类型分别有不同的存储结构（为了优化内存和效率）

**五种数据类型的存储类型**

![Screenshot 2022-10-29 135140](实验\6 Web设计\图片\Screenshot 2022-10-29 135140.png)

**Redis数据库结构**

![Screenshot 2022-10-29 133903](实验\1 操作系统实验\杂实验\Screenshot 2022-10-29 133903.png)

**为什么使用SDS数据结构存储字符串而不是使用C语言字符串**

- 常数复杂度获取字符串

  C语言字符串只有一个char*指针，要获取他的长度必须遍历找到'\0'字符，这不是常数复杂度的

- 杜绝缓冲区溢出

  C语言字符串只有一个char*指针，不会进行字符串内存大小检查，在拼接字符串的时候如果程序员忘了进行边界检查容量是否够，那么拼接字符串将会缓冲区溢出到超出本字符串的范围

- 减少修改字符串的内存重分配次数

  SDS分配内存的时候总是分配比字符串更多的内存用于形成内存池，实现预分配和惰性释放的效果。当拼接字符串的时候如果内存不够，将会使用预分配的内存，如果还不够才会使用Linux的malloc内存分配函数从堆上重新分配一个内存，在缩减字符串长度的时候，也只会修改len和free变量实现缩减。而C语言字符串每次遇到大于内存的变量总是会重新分配内存，这很慢

- 保证二进制安全

  C语言字符串的'\0'字符有特殊的含义，这会危害二进制数据，二进制数据中间包含\0字符将会被C语言字符串截断，而SDS总是使用len来获取数据，不会截断

- 兼容部分C字符串函数

**C语言多态的实现**

C语言函数根据传入的不同的类型调用相应的处理函数，这是一个判断过程

**有序集合使用跳跃表加哈希表的原因**

跳跃表支持范围查询，可以支持我们范围查询，从查询到的键访问哈希表得到我们需要的数据，如果单纯哈希表他的键随机分布，我们要范围查询必须遍历整个哈希表。

**Redis清理内存，键删除策略**

https://redis.io/commands/expire/

https://blog.csdn.net/embelfe_segge/article/details/126553288

Redis的键如果不设置过期时间，默认是永不过期的，当内存不足的时候将会促发LRU持久化操作将数据写到磁盘。

- 惰性删除

  惰性删除是在键引用清空的时候触发删除操作，这种实现不足的地方在于如果一个键不被访问，他将永不过期，那么可以认为那个内存泄漏了

- 定期删除

  Redis定期在expires的过期哈希表中查找过期的键删除。这依赖设置过期时间，如果不设置那么键默认永不过期

**过期键多RDB持久化和AOF持久化的影响**

- 在写入RDB文件的时候不会写入过期的键，在载入RDB文件的时候检查键过期的不会载入
- 在写入AOF文件的时候会写入过期的键，当过期的键被惰性删除或者定期删除的时候会像AOF文件显示写入一条DEL指令来显示删除这个键并向客户端返回空回复
- 在主从Redis服务器中，键的删除由主服务器控制，为了保证主从服务器数据一致性。客户端访问从服务器的时候，如果是过期的键，他不会删除而是正常返回，当访问主服务器的过期键的时候主服务器会发送DEL指令让从服务器删除键并且向客户端返回空回复。

#### RDB持久化和AOF持久化

Redis在加载数据库的时候如果设置了AOF会优先从AOF中恢复数据，而不是RDB。RDB保存的是键值对，而AOF保存的是写操作命令

- RDB持久化

  RDB写入所有没有过期的键，载入的时候剔除过期的键。RDB保存的命令由两个save和bgsave，save在redis主进程执行，会阻塞主服务器，bgsave会开一个子进程执行，不会阻塞。触发写入的方式除了手动调用save和bgsave命令，还可以是设置save（不是save命令）选项来触发bgsave命令，如果不设置save选项会有默认的save选项。这个方式由redis定期函数（这个函数也处理定期删除过期键的命令）执行。当执行bgsave的时候服务器会正常处理请求，但是对保存save/bgsave等指令会拒绝。

- AOF持久化

  每次新建或者删除一个键的时候回想AOF文件追加一条指令，这条指令被被缓冲在文件的内核缓冲块中，为了保证一致性，有三种方式，一种是每追加一条指令就写入磁盘，这是最慢的也是最安全的，一种是每隔一秒写入，一种是由操作系统控制（内核缓冲区满写入？）

  写命令请求会被放入AOF缓冲区，以让AOF持久化，在AOF开启持久化过程中，会fork一个进程（这里是fork而不是thread，因为fork不会共享主进程变量）进行持久化操作，在这个持久化过程中主进程可以操作，同时发生的主进程的写操作会放入AOF重写缓冲区，当AOF重写程序完成之后拷贝重写缓冲区的内容到AOF文件，完成重写之后覆盖原来的AOF文件。

  AOF重写是根据当前数据库键状态来重写的，比如一个列表会重写成**lpush lst a b c d**一条指令，而不是多条**lpush**插入。

### Redis数据类型

key数据结构包括key、value type、encoding等，这些属性可以用来检测一些异常，可以类型总是string的，只有value有物种类型

value类型

- string

  string类型可以具体分为字符串、数值、bitmap

  - 字符串操作有set\get\append\setrange\getrange\strlen

  - 数值有incr自增，这个方法的好处是对于不是很重要的数据，比如秒杀、抢购等数据可以很快自增而不需要使用MySQL数据库进行事务处理，可以很快返回数据给客户端。但是这个方式不适用银行等数据，他必须使用事务持久化，所以不能用于Redis缓存。
  - bitmp类型

  可以对字符串value的操作

  ```
  set key 123
  get key 
  setrange key offset value
  getrange key start end
  append key value
  type key //描述value的类型
  ```

  字符串还有支持对数值的操作，这依赖于string用数值进行编码，这样使用object encoding key命令可以查看对应key的value被用什么编码，编码方式有int, enstr, raw等，可以对应支持不同操作。

  ```
  object encoding key
  ```

  Redis一些命令会改变value的类型，比如如果是raw的99，调用incr会加一成为10000，同时类型变成int，但是你调用strlen的时候，他依然是按照字符的方式返回字符的个数。

  getset命令的好处，本来用户可以先使用get获得数据，再使用set更改，但是这样会发送两条指令，所以把他们合并就只会发送一个指令，也只会像网络发送一个数据包。

  Redis获取的数据是按照二进制数据的方式保存在数组里，而不是按照一定的编码方式保存数据。这样，Redis可以保存任何类型的数据，包括媒体类型和字符类型。因为他的数据保存和读取是没有类型的，而是二进制的。Redis默认的数据类型是ASCII码，如果你使用中文编码，他不会显示中文，而是直接返回给你十六进制数，当你在启动客户端的时候使用

  ```
  redis-cli -raw
  ```

  他能使用中文编码显示。

   对bitmap的操作，bitmap是按照字节保存的，每个字节是8位，setbit key 1 1，会在第一个字节的第二个比特位放1，setbit key 9 1会在key的第二个字节的第二个比特位置一。

  bitmap的用法

  - 统计用户登录天数，你可以用MySQL来存，但是完全可以用Redis位图来做更快。bitmap把每一位当成一天，某天登录就把那一天的位置为1，这样就可以统计位数个数得到登录天数。一年365天,365/8=46，46个字节就可以保存一个登录天数。

    ```
    setbit 1 1 1
    setbit 1 2 1
    setbit 1 7 1
    bitcount 1
    ```

  - 统计活跃用户

    ```
    setbit 20190101 1 1
    setbit 20190102 7 1
    setbit 20190102 1 1
    
    bitop or destkey 20190101 20190102 //按位或操作
    bitcount destkey 0 -1
    ```

    制作一个按天的bitmap，将天数按位或，得到destkey，统计destkey的1的位数得到活跃用户数

- List

  list是一个包含头节点和为节点head和tail的双向链表

  ```
  lpush key 1 2 3 4 5 //头插法
  rpush key 1 2 3 4 5 //尾插法
  lpop key //头部弹出
  rpop key //尾部弹出
  
  lrange key 0 -1 //打印所有列表内容，key支持正负索引
  lindex key 0 //索引下标，类似数组
  lrem key 2 a //从头节点开始删除2个a
  ```

  List作用是可以实现栈和队列

- hash

  ```
  hset sean name zzl age 18 address bj //创建sean:{
  													name:zzl
  													age :18
  													address:bj
  												}
  hget sean name age //取值
  hkeys sean //取sean的key
  hvalues sean //取sean的values
  hgetall sean //取key和values
  ```

  哈希可以用来保存用户详情页（喜欢点赞等）

- set

  List是有序的可重复的。set是无序的去重的集合。支持集合操作，支持从集合中随机取一个shu

  ```
  sadd key1 1 2 3
  sadd key2 3 4 5 
  smembers key1
  sinter key key1 key2 //交集到key
  sdiff key key1 key2  //减法
  sunion key key1 key2 //并集
  
  srandmember 用来做抽奖程序
  ```

- zset( sorted_set)

  ```
  zadd k1 8 apple 2 banana 3 orange
  
  zrange k1 1 2  //前两个大小
  ```

  用处，歌曲排行榜前十名，也可以集合操作

  zset使用跳跃表保存数据。

### Redis为什么快

- 数据量很大的时候需要集群，集群分为主从式（约束：配置相同、同步、副本高可用），分片（约束：每一台不完整，聚合数据成本高，甚至不支持）。Redis不支持聚合操作。Redis做集合运算并不快。

### Redis事务

Redis事务提交提案检查指令的语法合法才提交，一旦提交会全部执行，即使中间有报错也不会回滚

```
multi //开始事务
set a 1
set b 2
exec  //执行事务
```

Redis事务只保证原子性，不支持回滚，在执行过程不会被其他线程打断。

Redis不支持回滚一是认为失败应该由编写方完成，而是不支持回滚可以保持事务的简洁快速。



微服务-服务治理

脚手架：spring boot, netty

中间件：SSM

底层：计组，内核，网络、IO

其他：分布式解决方案（锁、事务、一致性、幂等性）- kafka - ISR，CAP，设计模式，算法

### Redis使用场景

- 五大数据类型
- 用于缓存
- 为了服务无状态
- 无锁化

### Redis是单线程还是多线程，Redis是线程安全的

1. 无论什么版本，工作线程都只有一个
2. 6.x版本之后，IO线程出现了多线程，但是工作线程依旧只是一个。在以前，工作线程需要自己负责recvfrom系统调用对每一个就绪的描述符，而现在这个过程被IO多线程处理。这里的IO线程是用户进程通知操作系统把内核数据拷贝到用户空间。IO多线程造成数据输入输出并行，但是工作线程负责计算，依旧线性的。
3. Redis工作线程是单线程，但是IO线程是多线程。好处是执行时间更短，更好压榨系统和硬件资源。
4. Redis工作线程是单线程的，他的计算是串行的，所以是线程安全的，但是外部事务在使用的时候要保证自己的顺序。

### 缓存穿透、缓存击穿、缓存雪崩

1. 缓存穿透：数据库没有这个缓存：布隆过滤器，锁（挡住无效请求和重复请求）

2. 缓存击穿：热点数据过期

3. 缓存雪崩：大量热点数据过期。

   分布式微服务，微服务扩缩容

### 缓存如何过期、淘汰、回收，缓存预热

- 如何回收

  1. 后台线程轮询，分批分段删除过期key
  2. 请求数据的时候判断数据是否过期

- 如果淘汰

  内存空间不足，一种机制是不允许淘汰，其他的是LRU LFU random TTL

- 缓存预热

  提前把热数据放到缓存，因为我们不知道什么是热数据，依然会产生很多缓存不命中，那么我们可以采用加锁处理

### 如何处理缓存和数据库不一致

canal binlog

MQ  函数式编程  server less

Redis是缓存，倾向于有时差。

架构：用户层、接入层、业务层、服务层、基础设施层

### Redis主从不一致问题 Redis主从复制原理

1. redis默认弱一致性，异步的同步
2. 所不能主从，单实例/分片集群/redlock，redisson
3. 咋配置中提供了多个client连接同步，趋向一致性
4. wait 2 0

- 主从复制原理

  master和slave连接正常时，maste发送命令流保持对slave更新

  当master和slave连接断开或超时，slave重新连接上master时会部分重同步恢复在没有连接的数据

  如果部分重同步 失败，会触发全量重同步。

### Redis持久化原理和方式

- 方式

  1. RDB， AOF
  2. 主从同步也是持久化
  3. 高版本开启AOF，可以通过执行日志得到全部内存数据

- 原理：

  阻塞当前线程，异步后台进程完成持久化，fork+copy on write

  RDB会按时fork一个进程拷贝数据到磁盘，如果想获得完整数据，不适合RDB，因为是隔一段时间执行，Redis宕机会丢失数据。

  AOF往AOF文件追加命令到日志文件。AOF会造成新能下降。但是你想保证数据完整新就要取舍。AOF在很大的时候，Redis可以对AOF进行重写（一些指令可以被取消

### 为什么使用setnx

原子操作，可以实现分布式锁

### Redis集群方案

- 常见集群分类

  主从复制集群

  分片集群

- Redis有哪些集群

  主从复制集群，手动切换

  带有哨兵的主从复制集群

  客户端实现路由索引的分片集群

  使用中间件代理层的分片集群

  Redis自身实现的cluster分片集群

### Redis

- 包含数据类型：string字符串、hash散列、list列表、set集合、zset有序集合；
- 使用C语言编写，数据是基于内存的，支持持久化（重启也会重新加载到内存），单线程，默认无密码，不分用户；
- 默认端口号：**6379**；
- 默认**16**个Redis实例，可以修改配置文件修改。

### 缓存问题

#### 缓存穿透

- 问题：key在Redis中根本不存在，直接访问数据库；
- 解决：布隆过滤器，一定不存在的被拦截。

#### 缓存击穿

- 问题：某个经常被访问的key（热点数据）过期，产生大量数据库读取操作；
- 解决：使用互斥锁挡住后续请求，自身访问数据库并写会缓存，由于锁被挡住的请求自己进入等待；

#### 缓存雪崩

- 问题：大量key在同一时刻过期，请求全部转到数据库；
- 解决：使用锁或队列，保证单线程写/失效时间分散。

### Redis持久化

为了解决内存数据丢失，使用持久化功能**RDB** *Redis DataBase*和**AOF** *Append Only File*将数据保存到硬盘，重启Redis时把硬盘的数据重新加载到内存，在redis.confz中修改默认策略。

#### RDB（默认）

指定时间间隔内，Redis执行了一定次数的写操作，自动触发一次持久化操作。

- 默认RDB策略：**15min内1次**；**5min内10次**；**1min内10000次**；
- stop-writes-on-bgsave-error：快照操作出错时停止写入磁盘，保证内存与硬盘的数据一致性；
- rdbcompression：是否使用LZF算法进行压缩；
- rdbchecksum：存储快照后CRC64算法校验数据；
- dbfilename：RDB持久化的文件名，默认**dump.rbd**；
- dir：RDB持久化文件保存的目录，默认**./**。

#### AOF

为了避免RDB最后几次操作丢失，AOF使用操作日志记录Redis的每一次写操作，下次启动Redis时全部重新执行写操作。

- appendfilename：AOF持久化文件名；

- appendfsync：AOF异步持久化策略

  *always*：每次数据变化都立刻写入硬盘；

  *everysec*：默认，每秒记录1次；

  *no*：由操作系统决定。

- no-appendfsync-on-rewrite：重写时是否使用appendfsync，默认不使用；

### Redis事务（部分原子性）

`multi`开启事务队列，后续所有命令都进入这一事务队列，`exec`启动事务队列中的命令，`discard`清空事务队列并结束，`watch <key>`/`unwatch <key>`监控/放弃监控某个key来实现CAS。

- 原子性

  进入事务队列过程中的命令出错，所有队列命令不执行，满足原子性；

  进入事务队列过程没出错，执行过程出错，错误行受影响，不满足原子性；

### Redis淘汰策略

#### 定期删除

默认每隔100ms随机抽取设置过expire的key，如果过期就删除；之所以使用随机，是为了避免CPU负载。

#### 惰性删除

从来没有被定期删除的key，只有被查询过，知道key已过期，才会被删除。

#### 内存淘汰机制

为了解决定期删除+惰性删除造成内存被占用，在配置文件中声明maxmemory来限制内存使用量（0为无限制），当达到了maxmemory时，进行内存淘汰：

- no-eviction：写入报错，不会删除数据（Redis默认内存淘汰机制）；
- volatile-lru：过期的数据中LRU淘汰；
- volatile-lfu：过期的数据中最不经常使用的淘汰；
- volatile-random：过期的数据中任选淘汰；
- volatile-ttl：选择将要过期的淘汰；
- allkeys-lru：所有数据中LRU淘汰；
- allkeys-lfu：所有数据中LFU淘汰；
- allkeys-random：所有数据中随机淘汰。

### Redis集群

#### 主从复制

master进行写操作并复制到slave，slave进行读操作，读写分离；查看主从关系：`info replication`；master可以有多个slave，slave还可以有自己的slave，每次写操作都是自动同步的。

- 绑定

  slave执行命令`slaveof <master-host> <master-port>`即可绑定到master；

- 解绑

  `salveof no one`；

- master宕机/重启

  slave不受影响，可以继续读；

- slave宕机/重启

  重启后不再是slave，需要重新绑定到master。

#### 哨兵模式

监控master，master挂掉立刻找一个slave成为新master，新加入的自动成为master的slave：

1. 创建配置文件sentinel.conf：

   ```
   sentinel monitor <sentinel-name> <master-host> <master-port> <poll-num>
   ```

2. 启动哨兵监控：`redis-sentinel <sentinel-conf-file>`。

#### 集群

### Redis消息发布与订阅

- `subscribe <channel>`订阅一个`<channel>`或以上频道的信息；
- `publish <channel> <context>`发布消息`<context>`到指定频道`<channel>`。

### Redis数据类型

- string：默认最大512M，可以存储任何类型的数据（二进制、JSON、序列化数据等）；
- list：按插入顺序排序，底层为双向链表；
- set：无序不重复集合；
- hash：适合存储POJO；
- zset：根据分数排序的不重复集合。

### Redis相关命令

#### 服务相关

- 启动服务：`redis-server &`，关闭服务：`redis-cli shutdown`；
- 进入客户端：`redis-cli`（相当于`mysql`）;
- 切换数据库实例：`select <index>`，默认0～15；
- 数据库实例条目数：`dbsize`，数据库实例中全部key：`keys *`；
- 清空数据库实例：`flushdb`/`flushall`。

#### key相关

- 查找key：`keys <pattern>`，pattern可以用`*`代表0或多个字符，`?`代表1个字符，`[]`代表1个正则表达式字符；
- 删除key：`del <key>`，返回删除数量，多个key用空格分隔；
- 是否存在key：`exists <key>`，多个key用空格分隔；
- 查找key的类型：`type <key>`；
- 移动key的数据到其他数据库实例：`mv <key> <index>`；
- 重命名key：`rename <oldKey> <newKey>`；
- **设置生存时间**：`expire <key> <seconds>`；
- 剩余生存时间：`ttl <key>`，-1永久，-2不存在。

## MySQL

### 索引

#### 唯一索引和非唯一索引

唯一索引是这样一种索引，它通过确保表中没有两个数据行具有完全相同的键值来帮助维护数据完整性。

为包含数据的现有表创建唯一索引时，会检查组成索引键的列或表达式中的值是否唯一。如果该表包含具有重复键值的行，那么索引创建过程会失败。为表定义了唯一索引之后，每当在该索引内添加或更改键时就会强制执行唯一性。此强制执行包括插入、更新、装入、导入和设置完整性以命名一些键。除了强制数据值的唯一性以外，唯一索引还可用来提高查询处理期间检索数据的性能。

非唯一索引不用于对与它们关联的表强制执行约束。相反，非唯一索引通过维护频繁使用的数据值的排序顺序，仅仅用于提高查询性能。

#### 聚集索引和非聚集索引（辅助索引）



### MySQL的存储引擎

MySQL 数据库提供了独有的插件式存储引擎，常见存储引擎有 **InnoDB**、**MyISAM**、NDB、Memory、Archive、Federated、Maria 等等，并且不同的存储引擎有着完全不同的功能，建表的时候可以指定存储引擎的类型，若不指定存储引擎类型，MySQL8.0 默认的存储引擎就是 InnoDB。

#### InnoDB 存储引擎

InnoDB 存储引擎最大的特点是支持事务，它主要应用于事务（OLTP）相关的数据存储。它的功能特点有**行锁、支持外键**，并且一般操作查询不会产生锁。InnoDB 存储引擎从 MySLQ 5.5之后的版本都是其默认的存储引擎。
InnoDB 有多版本并发控制，并且有 4 种隔离级别，这种隔离级别分别为 **顺序读(SERIALIZABLE)、可重复读(REPEATABLE READ)、读已提交(READ COMMITTED)、读未提交(READ UNCOMMITTED)**。

##### InnoDB索引

InnoDB索引是一种聚集索引，他用B+树实现，他的叶节点不想MyISAM存储的是行记录的地址，他是一条行记录，InnoDB的数据文件本身就是按照B+树进行组织的索引结构，这个索引的Key是数据表的主键，因此InnoDB是一种主键索引。

![img](https://img-blog.csdn.net/20170307100611325?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZG9uZ2hhaXhpYW9sb25nd2FuZw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)



#### MyISAM 存储引擎

MyISAM 存储引擎是 MySQL 5.5 版本以前默认使用的存储引擎，其不支持事务，MyISAM 存储引擎表由 MYD 和 MYI 组成，其中 MYD 用来存放数据的文件，`MYI` 用来存放索引的文件。

##### MyISAM支持三种索引

1. B-Tree 索引

​	B-Tree 索引，顾名思义，就是所有的索引节点都按照 balance tree 的数据结构来存储，所有的索引数据节点都在叶节点。

2. R-Tree 索引

​	R-Tree 索引的存储方式和 b-tree 索引有一些区别，主要设计用于为存储空间和多维数据的字段做索引，所以对于目前的 MySQL 版本	来说，也仅支持 geometry 类型的字段作索引。

3. Full-text 索引

​	Full-text 索引就是全文索引，它的存储结构也是 b-tree。主要是为了解决需要用 like 查询时的低效问题。

​	MyISAM 上面三种索引类型中，最经常使用的就是 B-Tree 索引了，偶尔会使用到 Full-text，但是 R-Tree 索引一般系统中都是很少用到	的。另外 MyISAM 的 B-Tree 索引有一个较大的限制，那就是参与一个索引的所有字段的长度之和不能超过 1000 字节。

##### MyISAM优缺点

优点：

- 占用空间小
- 访问速度快，对事务完整性没有要求或以 SELECT、INSERT 为主的应用基本上都可以使用这个引擎来创建表
- 可以配合锁，实现操作系统下的复制备份
- 支持全文检索（InnoDB 在 MySQL 5.6 版本以后也支持全文检索）
- 数据紧凑存储，因此可获得更小的索引和更快的全表扫描性能。

缺点：

- 不支持事务的完整性和并发性
- 不支持行级锁，使用表级锁，并发性差
- 主机宕机后，MyISAM表易损坏，灾难恢复性不佳
- 数据库崩溃后无法安全恢复
- 只缓存索引，数据的缓存是利用操作系统缓冲区来实现的，可能会引发过多的系统调用，且效率不佳

##### MyISAM索引

MyISAM索引存储结构是B+树，他的叶节点存储的是行的引用，这是一种非聚集索引。它支持在有相同值的列上建立索引

![img](https://img-blog.csdn.net/20170307100553013?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZG9uZ2hhaXhpYW9sb25nd2FuZw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)

### 数据库并发控制

如何控制并发是数据库领域中非常重要的问题之一，不过到今天为止事务并发的控制已经有了很多成熟的解决方案，而这些方案的原理就是这篇文章想要介绍的内容，文章中会介绍最为常见的三种并发控制机制：

分别是悲观并发控制、乐观并发控制和多版本并发控制，其中悲观并发控制其实是最常见的并发控制机制，也就是锁；而乐观并发控制其实也有另一个名字：乐观锁，乐观锁其实并不是一种真实存在的锁，我们会在文章后面的部分中具体介绍；最后就是多版本并发控制（MVCC）了，与前两者对立的命名不同，MVCC 可以与前两者中的任意一种机制结合使用，以提高数据库的读性能。

#### 悲观锁

互斥锁，最简单的、应用最广的方法就是使用锁来解决，当事务需要对资源进行操作时需要先获得资源对应的锁，保证其他事务不会访问该资源后，在对资源进行各种操作；在悲观并发控制中，数据库程序对于数据被修改持悲观的态度，在数据处理的过程中都会被锁定，以此来解决竞争的问题。

两阶段协议，产生死锁，死锁产生四个条件，死锁预防，死锁避免

#### 乐观锁

##### 基于时间戳的协议

##### 基于验证的协议

#### 多版本并发控制MVCC

到目前为止我们介绍的并发控制机制其实都是通过延迟或者终止相应的事务来解决事务之间的竞争条件（Race condition）来保证事务的可串行化；虽然前面的两种并发控制机制确实能够从根本上解决并发事务的可串行化的问题，但是在实际环境中数据库的事务大都是只读的，读请求是写请求的很多倍，如果写请求和读请求之前没有并发控制机制，那么最坏的情况也是读请求读到了已经写入的数据，这对很多应用完全是可以接受的。

**多版本并发控制（MVCC）** 是通过保存数据在某个时间点的快照来实现并发控制的。也就是说，不管事务执行多长时间，事务内部看到的数据是不受其它事务影响的，根据事务开始的时间不同，每个事务对同一张表，同一时刻看到的数据可能是不一样的。

简单来说，**多版本并发控制** 的思想就是保存数据的历史版本，通过对数据行的多个版本管理来实现数据库的并发控制。这样我们就可以通过比较版本号决定数据是否显示出来，读取数据的时候不需要加锁也可以保证事务的隔离效果。

可以认为 **多版本并发控制（MVCC）** 是行级锁的一个变种，但是它在很多情况下避免了加锁操作，因此开销更低。虽然实现机制有所不同，但大都实现了非阻塞的读操作，写操作也只锁定必要的行。

MySQL的大多数事务型存储引擎实现的都不是简单的行级锁。基于提升并发性能的考虑，它们一般都同时实现了多版本并发控制（MVCC）。不仅是MySQL，包括Oracle、PostgreSQL等其他数据库系统也都实现了MVCC，但各自的实现机制不尽相同，因为MVCC没有一个统一的实现标准，典型的有**乐观（optimistic）并发控制**和**悲观（pessimistic）并发控制**。

### 最左匹配原则

MySQL中的索引可以以一定顺序引用多列，这种索引叫作联合索引。如User表的name和city加联合索引就是(name,city)，**而最左前缀原则指的是，如果查询的时候查询条件精确匹配索引的左边连续一列或几列，则此列就可以被用到**。如下：

```
select * from user where name=xx and city=xx ; ／／可以命中索引
select * from user where name=xx ; // 可以命中索引
select * from user where city=xx ; // 无法命中索引            
```

 

这里需要注意的是，查询的时候如果两个条件都用上了，但是顺序不同，如 `city= xx and name ＝xx`，那么现在的**查询引擎会自动优化为匹配联合索引的顺序，这样是能够命中索引的**。

由于最左前缀原则，在创建联合索引时，索引字段的顺序需要考虑字段值去重之后的个数，较多的放前面。ORDER BY子句也遵循此规则。

#### 什么是最左匹配原则

顾名思义：最左优先，以最左边的为起点任何连续的索引都能匹配上。同时遇到范围查询(>、<、between、like)就会停止匹配。
例如：如果建立(a,b)顺序的索引，我们的条件只有b=xxx，是匹配不到(a,b)索引的；但是如果查询条件是a = 1 and b = 2或者b=2 and a=1就可以，因为优化器会自动调整a,b的顺序，并不需要严格按照索引的顺序来；再比如a = 1 and b = 2 and c > 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，因为c字段是一个范围查询，它之后的字段会停止匹配

#### 为什么会形成最左匹配原则

首先要知道，最左匹配原则都是针对联合索引来说的，所以我们有必要了解一下联合索引的原理。了解了联合索引，那么为什么会有最左匹配原则这种说法也就理解了。

我们都知道索引的底层是一颗B+树，那么联合索引当然还是一颗B+树，只不过联合索引的健值数量不是一个，而是多个。构建一颗B+树只能根据一个值来构建，因此数据库依据联合索引最左的字段来构建B+树。
例子：假如创建一个（a,b)的联合索引，那么它的索引树是这样的

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200910005504881.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzI2ODkzMw==,size_16,color_FFFFFF,t_70#pic_center)
可以看到a的值是有顺序的，1，1，2，2，3，3，而b的值是没有顺序的1，2，1，4，1，2。所以b = 2这种查询条件没有办法利用索引，因为联合索引首先是按a排序的，b是无序的。

同时我们还可以发现在a值相等的情况下，b值又是按顺序排列的，但是这种顺序是相对的。所以最左匹配原则遇上范围查询就会停止，剩下的字段都无法使用索引。例如a = 1 and b = 2 a,b字段都可以使用索引，因为在a值确定的情况下b是相对有序的，而a>1and b=2，a字段可以匹配上索引，但b值不可以，因为a的值是一个范围，在这个范围中b是无序的。

 **最左匹配原则** 

最左匹配原则就是指在联合索引中，如果你的 SQL 语句中用到了联合索引中的最左边的索引，那么这条 SQL 语句就可以利用这个联合索引去进行匹配。例如某表现有索引(a,b,c)，现在你有如下语句：

```javascript
select * from t where a=1 and b=1 and c =1;     #这样可以利用到定义的索引（a,b,c）,用上a,b,c

select * from t where a=1 and b=1;     #这样可以利用到定义的索引（a,b,c）,用上a,b

select * from t where b=1 and a=1;     #这样可以利用到定义的索引（a,b,c）,用上a,c（mysql有查询优化器）

select * from t where a=1;     #这样也可以利用到定义的索引（a,b,c）,用上a

select * from t where b=1 and c=1;     #这样不可以利用到定义的索引（a,b,c）

select * from t where a=1 and c=1;     #这样可以利用到定义的索引（a,b,c），但只用上a索引，b,c索引用不到
```

也就是说通过最左匹配原则你可以定义一个联合索引，但是使得多数查询条件都可以用到该索引。 值得注意的是，当遇到范围查询(>、<、between、like)就会停止匹配。也就是：

```javascript
select * from t where a=1 and b>1 and c =1; #这样a,b可以用到（a,b,c），c索引用不到
```

这条语句只有 a,b 会用到索引，c 都不能用到索引。这个原因可以从联合索引的结构来解释。

但是如果是建立(a,c,b)联合索引，则a,b,c都可以使用索引，因为优化器会自动改写为最优查询语句

```javascript
select * from t where a=1 and b >1 and c=1;  #如果是建立(a,c,b)联合索引，则a,b,c都可以使用索引
#优化器改写为
select * from t where a=1 and c=1 and b >1;
```

这也是最左前缀原理的一部分，索引index1:(a,b,c)，只会走a、a,b、a,b,c 三种类型的查询，其实这里说的有一点问题，a,c也走，但是只走a字段索引，不会走c字段。

```javascript
另外还有一个特殊情况说明下，select * from table where a = '1' and b > ‘2’ and c='3' 这种类型的也只会有 a与b 走索引，c不会走。
select * from table where a = '1' and b > ‘2’ and c='3'
```

这种类型的sql语句，在a、b走完索引后，c肯定是无序了，所以c就没法走索引，[数据库](https://cloud.tencent.com/solution/database?from=10680)会觉得还不如全表扫描c字段来的快。

以index （a,b,c）为例建立这样的索引相当于建立了索引a、ab、abc三个索引。一个索引顶三个索引当然是好事，毕竟每多一个索引，都会增加写操作的开销和磁盘空间的开销。

#### 最左匹配原则的原理

最左匹配原则都是针对联合索引来说的，所以我们可以从联合索引的原理来了解最左匹配原则。

我们都知道索引的底层是一颗 B+ 树，那么联合索引当然还是一颗 B+ 树，只不过联合索引的键值数量不是一个，而是多个。构建一颗 B+ 树只能根据一个值来构建，因此数据库依据联合索引最左的字段来构建 B+ 树。例子：假如创建一个（a,b,c)的联合索引，那么它的索引树是这样的：

![img](https://ask.qcloudimg.com/http-save/yehe-1052551/g3h2lfrw60.png?imageView2/2/w/1620)

该图就是一个形如(a,b,c)联合索引的 b+ 树，其中的非叶子节点存储的是第一个关键字的索引 a，而叶子节点存储的是三个关键字的数据。这里可以看出 a 是有序的，而 b，c 都是无序的。但是当在 a 相同的时候，b 是有序的，b 相同的时候，c 又是有序的。通过对联合索引的结构的了解，那么就可以很好的了解为什么最左匹配原则中如果遇到范围查询就会停止了。以 select * from t where a=5 and b>0 and c =1; #这样a,b可以用到（a,b,c），c不可以 为例子，当查询到 b 的值以后（这是一个范围值），c 是无序的。所以就不能根据联合索引来确定到底该取哪一行。

#### 总结

在 InnoDB 中联合索引只有先确定了前一个（左侧的值）后，才能确定下一个值。如果有范围查询的话，那么联合索引中使用范围查询的字段后的索引在该条 SQL 中都不会起作用。值得注意的是，in 和 = 都可以乱序，比如有索引（a,b,c），语句 select * from t where c =1 and a=1 and b=1，这样的语句也可以用到最左匹配，因为 [MySQL](https://cloud.tencent.com/product/cdb?from=10680) 中有一个优化器，他会分析 SQL 语句，将其优化成索引可以匹配的形式，即 select * from t where a =1 and a=1 and c=1

### 为什么要使用联合索引

- 1、减少开销。建一个联合索引(col1,col2,col3)，实际相当于建了(col1),(col1,col2),(col1,col2,col3)三个索引。每多一个索引，都会增加写操作的开销和磁盘空间的开销。对于大量数据的表，使用联合索引会大大的减少开销！
- 2、覆盖索引。对联合索引(col1,col2,col3)，如果有如下的sql: select col1,col2,col3 from test where col1=1 and col2=2。那么MySQL可以直接通过遍历索引取得数据，而无需回表，这减少了很多的随机io操作。减少io操作，特别的随机io其实是dba主要的优化策略。所以，在真正的实际应用中，覆盖索引是主要的提升性能的优化手段之一。
- 3、效率高。索引列越多，通过索引筛选出的数据越少。有1000W条数据的表，有如下sql:select from table where col1=1 and col2=2 and col3=3,假设假设每个条件可以筛选出10%的数据，如果只有单值索引，那么通过该索引能筛选出1000W10%=100w条数据，然后再回表从100w条数据中找到符合col2=2 and col3= 3的数据，然后再排序，再分页；如果是联合索引，通过索引筛选出1000w10% 10% *10%=1w，效率提升可想而知！

### **使用索引优化查询问题：** 

1、创建单列索引还是多列索引？如果查询语句中的where、order by、group 涉及多个字段，一般需要创建多列索引，比如：

```javascript
select * from user where nick_name = 'ligoudan' and job = 'dog';
```

- 2、多列索引的顺序如何选择？一般情况下，把选择性高的字段放在前面，比如：查询sql：

```javascript
select * from user where age = '20' and name = 'zh' order by nick_name;
```

这时候如果建索引的话，首字段应该是age，因为age定位到的数据更少，选择性更高。但是务必注意一点，满足了某个查询场景就可能导致另外一个查询场景更慢。

- 3、避免使用范围查询 很多情况下，范围查询都可能导致无法使用索引。
- 4、尽量避免查询不需要的数据

```javascript
explain select * from user where job like '%ligoudan%';
explain select job from user where job like '%ligoudan%';
```

同样的查询，不同的返回值，第二个就可以使用覆盖索引，第一个只能全表遍历了。

- 5、查询的数据类型要正确

```javascript
explain select * from user where create_date >= now();
explain select * from user where create_date >= '2020-05-01 00:00:00';
```

第一条语句就可以使用create_date的索引，第二个就不可以。

### MySQL Binlog

MySQL 的 Binlog 日志是一种二进制格式的日志，Binlog 记录所有的 DDL 和 DML 语句(除了数据查询语句SELECT、SHOW等)，以 Event 的形式记录，同时记录语句执行时间。

Binlog 的主要作用有两个：

1. 数据恢复

   因为 Binlog 详细记录了所有修改数据的 SQL，当某一时刻的数据误操作而导致出问题，或者数据库宕机数据丢失，那么可以根据 Binlog 来回放历史数据。

2. 主从复制

   想要做多机备份的业务，可以去监听当前写库的 Binlog 日志，同步写库的所有更改。

### MySQL主从复制

#### 主从复制框架

1. 一主一从 / 一主多从

2. 多主一从

3. 双主复制

4. 级联复制

   ![1](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjx1mr6mxzj30z60hg40u.jpg)

#### 主从复制原理

MySQL 主从复制涉及到三个线程：

一个在主节点的线程：`log dump thread`

从库会生成两个线程：一个 I/O 线程，一个 SQL 线程

![4](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjx1ms5ezhj312s0imtb5.jpg)

主库会生成一个 log dump 线程,用来给从库 I/O 线程传 Binlog 数据。

从库的 I/O 线程会去请求主库的 Binlog，并将得到的 Binlog 写到本地的 relay log (中继日志)文件中。

SQL 线程,会读取 relay log 文件中的日志，并解析成 SQL 语句逐一执行。

![5](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjx1mvsnp5j31040iyad2.jpg)

#### 主从复制模式

##### 异步模式

主节点执行完客户端提交的食物后返回给客户端，不会关心从库是否已经接收并处理。这样造成的问题如果此时主节点崩了，主节点已经提交的事务可能没有传到从节点上，如果此时将从节点提升到主机节点，那么会造成新主节点数据缺失

![6](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjx1mu02wbj31160kk0vj.jpg)

##### 半同步模式

主节点在执行完客户端事务后不会立即返回客户给客户端，而是等待至少一个从库接收并写道relay log中才返回成功信息给客户端（只能保证主库中的Binlog至少传输到一个从节点上），否则需要等到超时时间然后切换陈异步模式再提交。

![7](https://tva1.sinaimg.cn/large/007S8ZIlgy1gjx1muypwdj31420jg41q.jpg)

##### 全同步模式

主库执行完客户端事务后，等到全部从库都复制了这个事务并成功返回后才返回成功信息给客户端。这种设计要主库等到所有从库都复制了这个事务，会造成性能低。

### MySQL分库分表

在文章开头先抛几个问题：

（1）什么时候才需要分库分表呢？我们的评判标准是什么？

（2）一张表存储了多少数据的时候，才需要考虑分库分表？

（3）数据增长速度很快，每天产生多少数据，才需要考虑做分库分表？

这些问题你都搞清楚了吗？相信看完这篇文章会有答案。

#### 为什么要分库分表？

首先回答一下为什么要分库分表，答案很简单：`数据库出现性能瓶颈`。用大白话来说就是数据库快扛不住了。

数据库出现性能瓶颈，对外表现有几个方面：

- 大量请求阻塞

  在高并发场景下，大量请求都需要操作数据库，导致连接数不够了，请求处于阻塞状态。

- SQL 操作变慢

  如果数据库中存在一张上亿数据量的表，一条 SQL 没有命中索引会全表扫描，这个查询耗时会非常久。

- 存储出现问题

  业务量剧增，单库数据量越来越大，给存储造成巨大压力。

从机器的角度看，性能瓶颈无非就是 CPU、内存、磁盘、网络这些，要解决性能瓶颈最简单粗暴的办法就是提升机器性能，但是通过这种方法成本和收益投入比往往又太高了，不划算，所以重点还是要从软件角度入手。

#### 数据库优化方案

数据库优化方案很多，主要分为两大类：软件层面、硬件层面。

软件层面包括：SQL 调优、表结构优化、读写分离、数据库集群、分库分表等；

硬件层面主要是增加机器性能。

##### SQL 调优（尽量命中索引）

SQL 调优往往是解决数据库问题的第一步，往往投入少部分精力就能获得较大的收益。

SQL 调优主要目的是尽可能地让那些慢 SQL 变快，手段其实也很简单，就是让 SQL 执行尽量命中索引。

**开启慢 SQL 记录**

如果你使用的是 Mysql，只需要在 Mysql 配置文件中配置几个参数即可。

```
slow_query_log=on
long_query_time=1
slow_query_log_file=/path/to/log
```

**调优的工具**

常常会用到 explain 这个命令来查看 SQL 语句的执行计划，通过观察执行结果很容易就知道该 SQL 语句是不是全表扫描、有没有命中索引。

```
select id, age, gender from  user where name = '爱笑的架构师';
```

返回有一列叫“type”，常见取值有：

ALL、index、range、 ref、eq_ref、const、system、NULL（从左到右，性能从差到好）。

ALL 代表这条 SQL 语句全表扫描了，需要优化。一般来说需要达到 range 级别及以上。

##### 表结构优化（添加冗余字段，适合更新不高的列）

以一个场景举例说明：

“user”表中有 user_id、nickname 等字段，“order”表中有 order_id、user_id 等字段，如果想拿到用户昵称怎么办？一般情况是通过 join 关联表操作，在查询订单表时关联查询用户表，从而获取到用户昵称。

但是随着业务量增加，订单表和用户表肯定也是暴增，这时候通过两个表关联数据就比较费力了，为了取一个昵称字段而不得不关联查询几十上百万的用户表，其速度可想而知。

这个时候可以尝试将 nickname 这个字段加到 order 表中（order_id、user_id、nickname），这种做法通常叫做数据库表冗余字段。这样做的好处是展示订单列表时不需要再关联查询用户表了。

冗余字段的做法也有一个弊端，如果这个字段更新会同时涉及到多个表的更新，因此在选择冗余字段时要尽量选择不经常更新的字段。

##### 架构优化（分布式架构，主服务器写，从服务器读）

当单台数据库实例扛不住，我们可以增加实例组成集群对外服务。

当发现读请求明显多于写请求时，我们可以让主实例负责写，从实例对外提供读的能力；

如果读实例压力依然很大，可以在数据库前面加入缓存如 redis，让请求优先从缓存取数据减少数据库访问。

缓存分担了部分压力后，数据库依然是瓶颈，这个时候就可以考虑分库分表的方案了，后面会详细介绍。

##### 硬件优化

硬件成本非常高，一般来说不可能一遇到数据库性能瓶颈就去升级硬件。

在前期业务量比较小的时候，升级硬件数据库性能可以得到较大提升；但是在后期，升级硬件得到的收益就不那么明显了。

##### 分库分表

下面我们以一个商城系统为例逐步讲解数据库是如何一步步演进。

###### 单应用单数据库

在早期创业阶段想做一个商城系统，基本就是一个系统包含多个基础功能模块，最后打包成一个 war 包部署，这就是典型的单体架构应用。

![图片](https://mmbiz.qpic.cn/mmbiz_png/RXvHpViaz3EoV34cNZS5Tiarq71DRQlKt4H6C2QMSEB3jDd5rpDz7A9Jiccovf6KECfAtZEgnEQFZWpib4PCl2fmtQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)商城项目使用单数据库

如上图，商城系统包括主页 Portal 模板、用户模块、订单模块、库存模块等，所有的模块都共有一个数据库，通常数据库中有非常多的表。

因为用户量不大，这样的架构在早期完全适用，开发者可以拿着 demo 到处找（骗）投资人。

一旦拿到投资人的钱，业务就要开始大规模推广，同时系统架构也要匹配业务的快速发展。

###### 多应用单数据库

在前期为了抢占市场，这一套系统不停地迭代更新，代码量越来越大，架构也变得越来越臃肿，现在随着系统访问压力逐渐增加，系统拆分就势在必行了。

为了保证业务平滑，系统架构重构也是分了几个阶段进行。

第一个阶段将商城系统单体架构按照功能模块拆分为子服务，比如：Portal 服务、用户服务、订单服务、库存服务等。

![图片](https://mmbiz.qpic.cn/mmbiz_png/RXvHpViaz3EoV34cNZS5Tiarq71DRQlKt4uH6bcPL5sWtibBeuUOAUuCrj9Uqrh7hlgx3WveyiceMwKFojcyBSmrDQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)多应用单数据库

如上图，多个服务共享一个数据库，这样做的目的是底层数据库访问逻辑可以不用动，将影响降到最低。

###### 多应用多数据库

随着业务推广力度加大，数据库终于成为了瓶颈，这个时候多个服务共享一个数据库基本不可行了。我们需要将每个服务相关的表拆出来单独建立一个数据库，这其实就是“分库”了。

单数据库能够支撑的并发量是有限的，拆成多个库可以使服务间不用竞争，提升服务的性能。

![图片](https://mmbiz.qpic.cn/mmbiz_png/RXvHpViaz3EoV34cNZS5Tiarq71DRQlKt4bUydnbxpxuPYTibgDwrp4lzxuD5zkPpSTqpjxib0V6Bm02gIcjicdwY1w/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)多应用多数据库

如上图，从一个大的数据中分出多个小的数据库，每个服务都对应一个数据库，这就是系统发展到一定阶段必须要做的“分库”操作。

现在非常火的微服务架构也是一样的，如果只拆分应用不拆分数据库，不能解决根本问题，整个系统也很容易达到瓶颈。

###### 分表

说完了分库，那什么时候分表呢？

如果系统处于高速发展阶段，拿商城系统来说，一天下单量可能几十万，那数据库中的订单表增长就特别快，增长到一定阶段数据库查询效率就会出现明显下降。

因此，当单表数据增量过快，业界流传是超过 500 万的数据量就要考虑分表了。当然 500 万只是一个经验值，大家可以根据实际情况做出决策。

那如何分表呢？

分表有几个维度，一是水平拆分和垂直拆分，二是单库内分表和多库内分表。

**水平拆分和垂直拆分**

就拿用户表（user）来说，表中有 7 个字段：id,name,age,sex,nickname,description，如果 nickname 和 description 不常用，我们可以将其拆分为另外一张表：用户详细信息表，这样就由一张用户表拆分为了用户基本信息表+用户详细信息表，两张表结构不一样相互独立。但是从这个角度来看垂直拆分并没有从根本上解决单表数据量过大的问题，因此我们还是需要做一次水平拆分。

![图片](https://mmbiz.qpic.cn/mmbiz_png/RXvHpViaz3EoV34cNZS5Tiarq71DRQlKt4ZqcpAmkAPD6xhCZIAzg5AVkWbwW4D9L96InqRibGegoHY4vbaXloD0g/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)拆分表

还有一种拆分方法，比如表中有一万条数据，我们拆分为两张表，id 为奇数的：1，3，5，7……放在 user1 中， id 为偶数的：2，4，6，8……放在 user2 中，这样的拆分办法就是水平拆分了。

水平拆分的方式有很多，除了上面说的按照 id 拆表，还可以按照时间维度去拆分，比如订单表，可以按每日、每月等进行拆分。

- 每日表：只存储当天的数据。
- 每月表：可以起一个定时任务将前一天的数据全部迁移到当月表。
- 历史表：同样可以用定时任务把时间超过 30 天的数据迁移到 history 表。

总结一下水平拆分和垂直拆分的特点：

- 垂直拆分：基于表或字段划分，表结构不同。
- 水平拆分：基于数据划分，表结构相同，数据不同。

**单库内拆分和多库拆分**

拿水平拆分为例，每张表都拆分为了多个子表，多个子表存在于同一数据库中。比如下面用户表拆分为用户 1 表、用户 2 表。

![图片](https://mmbiz.qpic.cn/mmbiz_png/RXvHpViaz3EoV34cNZS5Tiarq71DRQlKt4GWSZ2tibgHbEkOL4EkQiaamRicgKiaWFKRNZQ4Qou7y3BakAialibAicVugBQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)单库拆分

在一个数据库中将一张表拆分为几个子表在一定程度上可以解决单表查询性能的问题，但是也会遇到一个问题：单数据库存储瓶颈。

所以在业界用的更多的还是将子表拆分到多个数据库中。比如下图中，用户表拆分为两个子表，两个子表分别存在于不同的数据库中。

![图片](https://mmbiz.qpic.cn/mmbiz_png/RXvHpViaz3EoV34cNZS5Tiarq71DRQlKt4qHF5G2BC021l1wuHbTibQ9cVnPx1c7jSbic5wAORrDdWiaAHl74fiafBVw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)多库拆分

一句话总结：分表主要是为了减少单张表的大小，解决单表数据量带来的性能问题。

###### 分库分表带来的复杂性

既然分库分表这么好，那我们是不是在项目初期就应该采用这种方案呢？不要激动，冷静一下，分库分表的确解决了很多问题，但是也给系统带来了很多复杂性，下面简要说一说。

**（1）跨库关联查询**

在单库未拆分表之前，我们可以很方便使用 join 操作关联多张表查询数据，但是经过分库分表后两张表可能都不在一个数据库中，如何使用 join 呢？

有几种方案可以解决：

- 字段冗余：把需要关联的字段放入主表中，避免 join 操作；
- 数据抽象：通过 ETL 等将数据汇合聚集，生成新的表；
- 全局表：比如一些基础表可以在每个数据库中都放一份；
- 应用层组装：将基础数据查出来，通过应用程序计算组装；

**（2）分布式事务**

单数据库可以用本地事务搞定，使用多数据库就只能通过分布式事务解决了。

常用解决方案有：基于可靠消息（MQ）的解决方案、两阶段事务提交、柔性事务等。

**（3）排序、分页、函数计算问题**

在使用 SQL 时 order by、limit 等关键字需要特殊处理，一般来说采用分片的思路：

先在每个分片上执行相应的函数，然后将各个分片的结果集进行汇总和再次计算，最终得到结果。

**（4）分布式 ID**

如果使用 Mysql 数据库在单库单表可以使用 id 自增作为主键，分库分表了之后就不行了，会出现 id 重复。

常用的分布式 ID 解决方案有：

- UUID
- 基于数据库自增单独维护一张 ID表
- 号段模式
- Redis 缓存
- 雪花算法（Snowflake）
- 百度 uid-generator
- 美团 Leaf
- 滴滴 Tinyid

**（5）多数据源**

分库分表之后可能会面临从多个数据库或多个子表中获取数据，一般的解决思路有：客户端适配和代理层适配。

业界常用的中间件有：

- shardingsphere（前身 sharding-jdbc）
- Mycat

###### 总结

如果出现数据库问题不要着急分库分表，先看一下使用常规手段是否能够解决。

分库分表会给系统带来巨大的复杂性，不是万不得已建议不要提前使用。作为系统架构师可以让系统灵活性和可扩展性强，但是不要过度设计和超前设计。在这一点上，架构师一定要有前瞻性，提前做好预判。大家学会了吗？

### MySQL索引：聚簇索引和非聚簇索引

索引存在磁盘。

聚簇索引索引和数据放在一个文件里，在Innodb里面，数据和索引全部放在ibd文件中，而myisam数据放在myd文件中，而索引放在myi文件中，索引和数据时分开的。Innodb有一个聚簇索引和多个非聚簇索引，而myisam只有非聚簇索引。

####  索引原理

MySQL索引主要使用两种数据结构，B+树和Hash索引

Innodb默认是B+树索引

Memory存储引起使用Hash索引。Memory表只存在内存中，断电会消失，适用于临时表。Memory使用hash表存储是因为他比B+树更快，但是他不能支持范围查询和排序等功能。B+树单条查询新能低于hash表，但是它支持排序和范围查询。hash表范围查询需要全量查找。

B+树作为索引的优势

hash索引不支持范围查询，也不支持like这样的模糊查询

hash索引不支持多列联合索引的最左匹配原子

Hash索引存在hash碰撞问题

### MySQL事务（ACID、锁，MVCC）

- 原子性，要不全部执行，要不全部不执行。如果执行失败，要回滚。原子性的实现原理使用的时undolog来回滚。日志有undolog、redolog、binlog，undolog。undolog和redolog不属于MySQL server 而是属于MySQL innodb存储引擎，binlog是MySQL自带的日志。不同的引擎数据存储方式不同。undolog是对成功执行的指令的反命令，如果是delete，那么就是insert，如果是update，那就update相反的，主要是增删改的操作。

  - 快照读，读取的是历史版本，例如select，不加锁的非阻塞读，快照读的实现是基于MVCC，读取的不一定是最新版本。RR是快照读，他不能读到最新数据。
  - 当前读，读取的是最新数据，如update, insert, delete, select ... lock in share mode, select ... for update，当前读是加锁读，读取期间其他食物不能修改数据。RC可以当前读

- 一致性，事务执行前后一致，包括安全检查等。这由其其他三种特性保证

- 隔离性，各个事务相互独立，不相互影响。实现方式有锁和MVCC。MySQL保证隔离性使用的是MVCC。MVCC是一种并发读写不加锁的方案。

  **锁**

  - 读读不会有数据安全问题

  - 读写：MVCC，多版本并发控制解决数据读写问题。

    **mysql 开启事务**

    ```
    set autocommit=0;
    commit;
    begin ;
    update t26 set name='123' ;
    commit ;
    ```

    **mysql删除表**

    ```
    truncate table t26 ; //清楚表的内容而不是删除整个表
    ```

  - 写写：锁

  **锁分类**

  - 按属性分

    - 共享锁：又叫读锁，共享锁主要用于并发读数据，事务为数据加上读锁以后，其他食物只能对该数据加读锁而不能加写锁，直到所有读锁释放之后其他事务才能加写锁

    - 排他锁：又叫写锁，排他锁主要目的是事务在修改数据的时候不允许其他事务修改或者读取。当事务为数据加写锁以后，其他事务不能给数据加任何锁，包括读锁或者写锁。
  - 按锁的粒度分类

    - 行锁，对表的一行或者多行加锁，事务可以访问没有加锁的数据，不能访问加锁的数据。行锁的优势是力度小，不容易冲突，比表锁支持的并发要高，但是加锁比表锁麻烦
    - 表锁，对整个表加锁，下一个事务访问这个表的时候必须等待。特点是，粒度大、加锁简单、容易冲突
    - 记录锁，记录锁是行锁的一种，他锁的是一条记录
    - 页锁，操作系统和磁盘数据交互的大小是以页为单位的，每一页一半4K，页锁就是数据页加锁，一次锁相邻数据页记录
    - 间隙锁，间隙锁属于行锁的一种，锁的是表记录的一个区间遵循左开右闭原则，只出现在可重复读的事务级别中
    - 临键锁，next-key锁，也是行锁的一种，他是Innodb默认行锁算法，他是记录锁和间隙锁的组合，next-key锁把查询出来的记录锁住，同时也会把范围查询内的所有间隙空间也锁住，再之他会把香菱的下一个区间也锁住。

  **MVCC原理**

  MVCC是解决读写冲突时的无锁并发控制，也就是为实物分配单项增长的时间戳，为每个修改保存一个版本，版本与事务时间戳关联，读操作只读该事务开始前的数据库的快照，所以MVCC为数据库解决了两个问题：1. 在并发读写数据库的时候，可以做到读操作不阻塞写操作，写操作不阻塞读操作，提高数据库并发读写能力。2. 解决脏读、幻读、不可重复读等事务隔离问题，但是不能解决更新丢失问题。

  - 隐藏字段

    隐藏字段是在创建表的时候自动创建的字段

    1. DB_TRX_ID，创建或最近修改该记录的事务ID
    2. DB_ROLL_PTR，回滚指针，记录上一个旧版本
    3. DB_ROW_ID，隐藏主键，默认6字节

  - undolog

    MVCC的undolog在添加一条新的记录时会初始化一个新数据，建立DB_ROLL_PTR=null，DB_TRX_ID指向创建他的事务；在更新事务的时候创建一条新记录为更改后的，然后DB_ROLL_PTR指向修改前的数据行的地址，DB_TRX_ID指向修改的事务。这样undolog形成一条链表

  - readview

    事务在执行快照读的时候会生成一个readview

    readview有三个属性值，trx_list表示readview生成时刻的活跃事务列表（commit的事务不是活跃事务）；up_limit_id表示列表中最小的事务ID，low_limit_id表示即将分配的下一个事务ID

    **为什么读已提交和可重复读读到的数据不一样**

    快照读是按照可见性算法来得到的读取结果

    关键在于RC和RR在生成readview的时机不同，RC每次快照读都会重新生成redview，而RR当前事务第一次进行快照读的时候生成的readview，在接下来的快照读会延用。

    **可见性算法**

    当前执行快照读的事务生成readview，当前没有执行commit的事务都放到活跃事务列表

    如果数据的上一个修改的事务DB_TRX_ID小于所有活跃事务列表的ID，那么说明他已经提交，当前事务可读取DB_TRX_ID的数值

    如果 DB_TRX_ID>=low_limit_id，。。。

    否则，判断DB_TRX_ID是否在活跃事务列表，如果在，则说明他未提交，当前事务不可见DB_TRX_ID的修改，如果不在，说明DB_TRX_ID已经修改，当前事务可见。

  **隔离级别**

  [参考](https://cloud.tencent.com/developer/article/1450773)

  读已提交和可重复读差异是因为readview生成时间不同造成的

  - 读未提交

    读未提交可能发生**脏读**、**不可重复读**、**幻读**

    读未提交是事务的快照读可以读取另外事务的修改数据，但是这个修改数据可能不是最终的数据，只是一个中间数据，那么就会发生**脏读**。

    **脏读**是事务执行过程中读取了其他事务没有提交的数据。

  - 读已提交

    读已提交可能发生**不可重复读**、**幻读**

    读已提交是读取已经提交的事务的数据。

    读已提交实现方式是每次快照读都要修改readview的三个属性值然后执行可见性算法，从而保证总是读取了已经提交的数据。

    **不可重复读**是事务两次执行快照读过程中，因为其他事务发生了对数据的修改，造成事务两次读数据不一样。解决不可重复读可以使用可重复读的MVCC协议，加行级锁。

    **幻读**是事务两次执行快照读整个表的属性时发生的因为其他食物发生了对整个表的增加或者删除导致的表的属性不一致。比如说一个事务两次读表的大小，中间发生数据增加，结果造成事务两次读表的大小不一致。解决幻读使用表级锁。

    **幻读和不可重复读区别**，幻读关注的是表的行数不一致，解决办法是表级锁；不可重复读关注的是表的行数据不一致，解决办法是行级锁。

  - 可重复读（MySQL默认隔离级别）

    可重复读可能发生**幻读**

    MySQL实现可重复读的底层原理是第一次快照读的时候生成的readview被后面的快照读服用了trx_list, up_limit_id, low_limit_id，造成后面执行序列里面提前commit的其他事务没有被更新到trx_list，从而总是被当成还未提交状态，这样总是读取的第一次快照读的数据。

  - 串行化

- 持久性，数据保存到磁盘，即使系统崩溃也不会丢失数据。持久性实现原理是redolog。redolog的二阶段提交，是为了redolog和binlog的数据一致性。binlog会一直写。WAL顺序读写随机读写，write ahead log。保证redolog和binlog一致性使用的是两阶段提交

### MySQL备份：主从复制原理

master节点上对数据库增删改操作被记录到binlog文件，之后通过一个IO thread写入到slave节点的relay log（中继日志）里面，然后slave上的一个SQL thread会把relay log重新执行一遍，从而把数据写入地盘。MySQL主从复制是一种异步复制，主机不用等待从机复制好所有的数据才返回。

1. master服务器将数据改变记录到二进制binlog日志，当master上的数据发生改变时，会将他写入二进制文件
2. slave服务器会在一定时间间隔内对master二进制日志进行探测，他是否发生改变，如果发生改变，就开始一个IO线程请求mster的二进制文件。
3. 同时master节点为每个IO线程启动一个dump线程，用于向其发送二进制时间，并保存从节点本地的中级日志中，从节点将启动SQL线程从中继日志中读取二进制日志。在本地重放，使得其数据和主节点保持一致，最后IO线程和SQL线程将进入睡眠状态，登台下一次唤醒。

### MySQL调优

#### 连接进程相关的connection

```
//max_connections
show variables like '%max_connection%' ;//显示默认MySQL的最大连接数
set max_connections=1024; //设置MySQL最大连接数，最大连接太多会造成延迟高

show processlist; //显示所有MySQL连接。
//max_user_connections; 限制每个用户请求连接个数

//back_log
show variables like '%back_log%'; // back_log参数，如果请求连接大于max_connection,请求会被放入堆里面缓存，如果缓存大于									  back_log限制，这个请求会被拒绝。这个值不能设置过大，因为那样每个客户请求会被放入堆
									 里面缓存，客户要等待连接，这对客户不友好，客户只是感觉到发送请求没响应。所以干脆给出请									 求太多等拒绝策略
//wait_timeout //关闭一个非交互连接需要等待时长
//interactive_timeout //关闭一个交互连接需要等待时长
```

#### log日志参数设置

```
log_error 错误日志名称
log_bin  二进制日志名称，记录对数据造成更改的所有语句，主从复制需要binlog，binlog默认不开启，需要手动开启。binlog执行需要写入到磁盘，所以会影响性能
```

### MySQL分库分表

当有1000万条记录，你需要分库分表，因为此时查询会很慢，把当前数据库拆分，水平拆分（按年月日拆分），垂直拆分（把相关性高的拆分），保证数据均匀分布 到不同数据库

- MySQL为什么要主从同步
  - 主从同步是实现读写分离的要求，防止请求落到一个数据库
  - 做为主机的备份，当主机访问量太大的时候启动备份服务器
  - 当业务量很大，需要对数据库分库分表，分为多个库需要主从同步

### MySQL执行计划

explain 

#### MySQL索引的设计原则

- 尽量使索引的字段占用的空间小，也就是key的大小越小越好
- 适合创建索引的列是在where字句中的列，或者连接字句中的列，或者orderby的列
- 基数少的列不适合建索引，基数少的列指的是一个列的数据很多重复的元素，比如列只有4中数字，1，2，3，4重复
- 不要给每个字段都创建索引，因为索引越多，占用磁盘空间越大，可能让你IO磁盘次数变多，反而降低效率
- 外键必须创建索引
- 更新频繁的列不能索引
- 创建索引的列不要太多，可以创建组合索引，但是组合索引的列的个数不要太多
- 大文本大对象不要建索引。

1. MySQL索引、聚集索引和非聚集索引、B树
2. 悲观锁、乐观锁、举例、CAS
3. InnoDB的页机制
4. ACID，事务如何实现，redolog很大怎么办
5. [redis](https://www.nowcoder.com/jump/super-jump/word?word=redis)的数据结构，各个使用场景，过期淘汰策略，
   1. Redis介绍
   2. 了解redis源码么
   3. 了解redis集群么
6. 数据库的主从原理，具体是怎么监听binlog日志的
7. 讲一下数据的acid
   1. 讲一下数据的acid
   2. 什么是一致性
   3. 什么是隔离性
   4. Mysql的隔离级别
   5. 每个隔离级别是如何解决
8. Mysql要加上nextkey锁，语句该怎么写
9. 数据库的索引原理 
   1. 联合索引  
   2. 非聚簇索引和聚簇索引
   3. 索引的使用注意事项
10. Mysql对联合索引有优化么？会自动调整顺序么？哪个版本开始优化
11. Redis的应用
    1. Redis的持久化的方式和原理
12. MySQL索引结构
13. Redis数据类型
14. 口述查询前十条数据的sql？
15. 左右连接的区别？

　　left join （左连接）：返回包括左表中的所有记录和右表中连接字段相等的记录。（结果条数等于左表）
　　right join （右连接）：返回包括右表中的所有记录和左表中连接字段相等的记录。（结果条数等于右表）
　　inner join （等值连接或者叫内连接）：只返回两个表中连接字段相等的行。（左连接和右连接的交集）
　　full join （全外连接）：返回左右表中所有的记录和左右表中连接字段相等的记录。（左连接和右连接的并集）

16. [union和union all的区别](https://www.cnblogs.com/xiangshu/articles/2054447.html)

    Union：对两个结果集进行并集操作，不包括重复行，同时进行默认规则的排序；

    Union All：对两个结果集进行并集操作，包括重复行，不进行排序；

    Intersect：对两个结果集进行交集操作，不包括重复行，同时进行默认规则的排序；

    Minus：对两个结果集进行差操作，不包括重复行，同时进行默认规则的排序。

    ```sql
    select employee_id,job_id from employees
    union
    select employee_id,job_id from job_history
    ```

17. mysql存储引擎，innodb用的什么数据结构存储，说说B+树和B树的区别？

18. **MySQL有哪些数据类型？**

19. 聚簇索引、唯一索引、主键索引、复合索引，重点说说主**键索引和单一索引的区别**？（想到了通过主键回表）

20. **怎么对sql调优？**

    答：只答了针对慢查询添加索引。

21. **怎么知道一个查询是慢查询？**

    答：不会，就回答了查看响应速度。

    

22. 主键索引和辅助索引的区别（1分钟）

23. 分布锁（不会）

24. Redis（不太了解）

25. Linux命令，磁盘满了，怎么找到磁盘的大文件（不会）



26. 怎么实现间隙锁 底层

27. JVM内存区域

    1. 程序计数器 ， 虚拟机栈 ，本地方法栈 ， 堆 ，方法区 ，元空间 }  // 每个区域要能介绍一下

28. Minor GC 触发条件 ： eden区剩余内存是否足够 两种情况分开分析

    FULL GC 触发条件 ： Minor GC 平均晋升空间大小 > 老年代连续剩余空间，则触发FULL GC

29. 判断对象死亡的方法 ： { 引用计数法 ， 可达分析[算法](https://www.nowcoder.com/jump/super-jump/word?word=算法) }

    深入一些,：GC root对象有哪些？为什么选择他们做GC root对象

30. 垃圾收集[算法](https://www.nowcoder.com/jump/super-jump/word?word=算法) ： { 标记清除[算法](https://www.nowcoder.com/jump/super-jump/word?word=算法) 、标记整理[算法](https://www.nowcoder.com/jump/super-jump/word?word=算法) 、 复制[算法](https://www.nowcoder.com/jump/super-jump/word?word=算法) 、 分代收集[算法](https://www.nowcoder.com/jump/super-jump/word?word=算法) }

    深入一些： 各个[算法](https://www.nowcoder.com/jump/super-jump/word?word=算法)的优点和适用场景

31. 垃圾收集器 ： { serial 、 parallel 、 CMS 、 G1  }

    CMS 、G1 重点 ， 介绍工作流程和优缺点

32. 内存泄漏

    例子： { 单例 ， 容器 等等}

    原因 ： 长生命周期持有短生命周期引用

33. 引用类型 ; { 强引用、 软引用、 弱引用 、 虚引用 }

34. 类加载过程 ： { 加载 ， 连接 ， 初始化 }

    有哪些类加载器 ， 能否自定义 Java.Object.String 的类加载器 ？

35. 双亲委派机制 介绍 & 作用

36. ArrayList 和 LinkedList 的区别

37. HashMap & ConcurrentHashMap 的比较 : 线程安全问题等等 

       深入一些 ： HashMap 为什么线程不安全？ 能否举例 = { 并发resize()触发闭环结构 ，覆盖put操作 }

38.  HashMap 的 相关问题   // HashMap系列需要通过关键源码理解，比较重要
      为什么 HashMap的size 为 2的幂次方 ？  

       HashMap resize()过程能否介绍 ？  

       HashMap效率受什么影响 (负载因子、hash数组size)？  

       HashMap中扰动函数的作用 ？

39. Hashtable 和 HashMap的区别 ： { 底层数据结构 (JDK1.8后不同)、父类不同 、扩容方法不同 、 线程上锁范围不同（重点） }

40. equals 和 == 区别

    为啥重写equals要重写hashCode()

    hash值相等，而两个对象不一定equals

41. String StringBuffer StringBuilder 区别 和各自使用场景 

    ​     深入一些 ： String 是如何实现它不可变的？ 为什么要设置String为不可变对象 ?   (字节一面这个问题给我问懵了)

42. 接口和抽象类区别

43. 重写和重载的区别

44. 深拷贝和浅拷贝区别

45. Java三大特性

46. Object的方法 ： { finalize 、 clone、 getClass 、 equals 、 hashCode }

47.  设计模式   ： {  单例模式 、 工厂模式 、 装饰者模式 、 代理模式 、 策略模式 等等} （此处我的掌握也不是很好）

48. 单例模式为什么采用双检测机制 ？ 单例为什么用Volatile修饰？ 装饰模式和代理模式区别？

49. 

50. MyISAM 和 InnoDB的区别  ： {是否支持行锁 、 是否支持事务 、 是否支持 MVCC 、 底层索引结构不同 }

51. 深入一些 ： 为什么要有一致性 ？ AID不是已经保证了一致性了吗 ？

52.  并发事务带来的问题 ： {  脏读 、 修改丢失 、 不可重复读 、 幻影读  }

53. 事务的隔离级别

54.  MVCC机制

55. 索引

    为什么索引使用B+树结构，而不是B树

    为什么索引使用B+树结构，而不是[红黑树](https://www.nowcoder.com/jump/super-jump/word?word=红黑树) ： { 磁盘预读取 、[红黑树](https://www.nowcoder.com/jump/super-jump/word?word=红黑树)高度 }

56. 聚簇索引和非聚簇索引区别？ 主键索引和二级索引了解吗？

57. 为什么不对每个列创建索引呢？

58. SQL语句优化 ，SQL题目（字节要求撸代码）

59. explain中 rows type key extra字段的含义？

60. count(1) count(*) count(列值)的区别

# 计算机网络相关

[精品 讲解计算机网络](https://zhuanlan.zhihu.com/p/404693092)

## 计算机网络实验

### 实验1-HTTP底层通信/使用网络系统调用实现网络进程通信

**实际上是HTTP协议使用TCP三次握手建立连接，四次挥手断开连接，使用read/write系统调用进行传输数据的过程的实现，这是HTTP协议底层传输数据的程**

Linux网络系统调用Socket已经实现了TCP/IP，UDP/IP协议栈，用户程序需要遵循TCP/IP协议的三次握手四次挥手规则调用系统调用建立连接和断开连接以及数据传输。HTTP使用TCP/IP协议传递数据的底层实现（使用系统调用规则）。

**网络字节序和主机字节序**

主机字节序指的是整数在内存中的保存方式，小端字节序让整数的低地址保存在内存低地址，整数高地址保存在内存高地址；大端字节序让整数低地址保存在内存高地址，整数高地址保存在内存低地址，对32整数01020304,小端保存会是(内存低地址：04 03 02 01：内存高地址)，大端会是（01 02 03 04)。网络字节序是大端字节序，对01020304 的32位整数，发送字节顺序是04 03 02 01。所以为了保证消除字节序的影响，需要将socket绑定地址的时候转换成大端字节序

**查看网络请求过程**

```
//服务端监听端口
sudo tcpdump -iany tcp port 9502

//客户端访问端口会在服务端显示请求连接过程
telnet 127.0.0.1 9502
```

**TCP三次握手和建立连接过程/TCP传送数据过程/TCP四次挥手和断开连接过程**

- TCP建立连接过程

  ![img](https://pic2.zhimg.com/80/v2-19c1a6b084bcf9aeda1aa39de684b8e5_720w.webp)

  > 我们可以通过网络抓包的查看具体的流程：
  >
  > 比如我们服务器开启9502的端口。使用tcpdump来抓包：
  >
  > **tcpdump -iany tcp port 9502**
  >
  > 然后我们使用telnet 127.0.0.1 9502开连接.:
  >
  > telnet 127.0.0.1 9502
  >
  > 14:12:45.104687 IP localhost.39870 > localhost.9502: Flags [S], seq 2927179378, win 32792, options [mss 16396,sackOK,TS val 255474104 ecr 0,nop,wscale 3], length 0**（1）**
  > 14:12:45.104701 IP localhost.9502 > localhost.39870: Flags [S.], seq 1721825043, ack 2927179379, win 32768, options [mss 16396,sackOK,TS val 255474104 ecr 255474104,nop,wscale 3], length 0 **（2）**
  > 14:12:45.104711 IP localhost.39870 > localhost.9502: Flags [.], ack 1, win 4099, options [nop,nop,TS val 255474104 ecr 255474104], length 0 **（3）**
  >
  >
  > 14:13:01.415407 IP localhost.39870 > localhost.9502: Flags [P.], seq 1:8, ack 1, win 4099, options [nop,nop,TS val 255478182 ecr 255474104], length 7
  > 14:13:01.415432 IP localhost.9502 > localhost.39870: Flags [.], ack 8, win 4096, options [nop,nop,TS val 255478182 ecr 255478182], length 0
  > 14:13:01.415747 IP localhost.9502 > localhost.39870: Flags [P.], seq 1:19, ack 8, win 4096, options [nop,nop,TS val 255478182 ecr 255478182], length 18
  > 14:13:01.415757 IP localhost.39870 > localhost.9502: Flags [.], ack 19, win 4097, options [nop,nop,TS val 255478182 ecr 255478182], length 0
  >
  > - 114:12:45.104687 时间带有精确到微妙
  > - localhost.39870 > localhost.9502 表示通信的流向，39870是客户端，9502是服务器端
  > - [S] 表示这是一个SYN请求
  > - [S.] 表示这是一个SYN+ACK确认包:
  > - [.] 表示这是一个ACT确认包， (client)SYN->(server)SYN->(client)ACT 就是3次握手过程
  > - [P] 表示这个是一个数据推送，可以是从服务器端向客户端推送，也可以从客户端向服务器端推
  > - [F] 表示这是一个FIN包，是关闭连接操作，client/server都有可能发起
  > - [R] 表示这是一个RST包，与F包作用相同，但RST表示连接关闭时，仍然有数据未被处理。可以理解为是强制切断连接
  > - win 4099 是指滑动窗口大小
  > - length 18指数据包的大小
  >
  > 我们看到 **（1）（2）（3）三步是建立tcp：**
  >
  > **第一次握手：**
  >
  > 14:12:45.104687 IP localhost.39870 > localhost.9502: Flags [S], seq 2927179378
  >
  > 客户端IP localhost.39870 (客户端的端口一般是自动分配的) 向服务器localhost.9502 发送syn包(syn=j)到服务器》
  >
  > syn包(syn=j) ： syn的seq= 2927179378 （j=2927179378）
  >
  > **第二次握手：**
  >
  > 14:12:45.104701 IP localhost.9502 > localhost.39870: Flags [S.], seq 1721825043, ack 2927179379,
  >
  > 收到请求并确认：服务器收到syn包，并必须确认客户的SYN（ack=j+1），同时自己也发送一个SYN包（syn=k），即SYN+ACK包：
  > 此时服务器主机自己的SYN：seq：y= syn seq 1721825043。
  > ACK为j+1 =（ack=j+1）=ack 2927179379
  >
  > **第三次握手：**
  >
  > 14:12:45.104711 IP localhost.39870 > localhost.9502: Flags [.], ack 1,
  >
  > 客户端收到服务器的SYN+ACK包，向服务器发送确认包ACK(ack=k+1)
  >
  > 客户端和服务器进入ESTABLISHED状态后，可以进行通信数据交互。此时和accept接口没有关系，即使没有accepte，也进行3次握手完成。
  >
  > 连接出现连接不上的问题，一般是网路出现问题或者网卡超负荷或者是连接数已经满啦。

  TCP建立连接过程：服务端使用socket系统调用创建一个监听套接字，接着创建一个网络地址变量，使用bind系统调用将这个网络地址绑定到监听套接字（（协议版本ipv4/ipv6, ip地址，端口号）三元组唯一确定网络中的一个进程），然后调用accept阻塞进程等待创建一个连接套接字，当客户端使用connect系统调用创建一个连接套接字之后，会阻塞客户端进程，同时向服务端发送SYN X的同步帧（第一次握手），服务端接收到客户端的连接请求之后，会唤醒服务器进程（信号还是端口中断？)，服务器进程唤醒之后向客户端发送一个确认帧ACK X+1和一个同步帧SYN Y（第二次握手），接着陷入阻塞等待客户端确认这个同步帧，当客户端接收到服务端发送的确认帧之后，他知道服务端已经准备好通信了，他要向服务端反映自己已经准备号通信，所以他会发送确认帧Y+1给服务器说明自己已经准备好通信（第三次握手），并且从阻塞状态返回，返回一个连接套接字，服务端接收到这个确认帧 之后知道客户端已经准备好通信了就从accept返回一个监听套接字，就此三次握手建立完成。**问题：为什么十三次握手而不是两次握手？因为TCP通信时全双工通信，在客户端接收到服务端的确认帧的时候，客户端知道服务端已经准备好通信，但是服务端并不知道客户端是否准备好通信，所以需要客户端确认服务端发送的同布帧**

- TCP发送数据过程：客户端使用write/send系统调用发送数据之后阻塞等待服务端发送确认帧，服务端调用read/recv阻塞，等待客户端发送的数据，当客户端发送的数据当来之后会检查客户端数据是否完整，如果不完整会部分确认，客户端发现服务端发送的确认不是全部确认，会重发数据（这个过程时华东窗口发送数据的过程）。服务端在接受完数据之后可能会向客户端发送数据，这个过程和上述滑动窗口发送数据的过程是一样的。

  > 紫色背景的部分：
  >
  > IP localhost.39870 > localhost.9502: Flags [P.], seq 1:8, ack 1, win 4099, options [nop,nop,TS val 255478182 ecr 255474104], length 7
  >
  > 客户端向服务器发送长度为7个字节的数据，
  >
  > IP localhost.9502 > localhost.39870: Flags [.], ack 8, win 4096, options [nop,nop,TS val 255478182 ecr 255478182], length 0
  >
  > 服务器向客户确认已经收到数据
  >
  > IP localhost.9502 > localhost.39870: Flags [P.], seq 1:19, ack 8, win 4096, options [nop,nop,TS val 255478182 ecr 255478182], length 18
  >
  > 然后服务器同时向客户端写入数据。
  >
  > IP localhost.39870 > localhost.9502: Flags [.], ack 19, win 4097, options [nop,nop,TS val 255478182 ecr 255478182], length 0
  >
  > 客户端向服务器确认已经收到数据
  >
  > 这个就是tcp可靠的连接，每次通信都需要对方来确认。

* TCP关闭过程：用户程序在传递完数据之后调用close关闭socket描述符，进入阻塞并向服务端发送一个FIN M结束帧，客户端此时处于recv数据接收阶段，他把FIN M结束帧解释为文件结束符返回给应用程序并且知道无法再从这个socket描述符接收到更多数据（此时数据发送的字符串已经全被被recv的内核缓冲区 接收了，只是可能还有全部拷贝到用户程序），服务端发送一个ACK M+1的确认帧，客户端接收到这个确认帧之后进入新的阻塞状态等待客户端发送FIN 完成帧（这个等待状态是无限等待状态，在客户端接收到这个确认帧之后客户端会关闭socket描述符，但是这只是客户端的，因为TCP时全双工的，还需要关闭服务端的socket描述符），当服务端的recv把所有缓冲数据都拷贝到应用程序用户空间之后，将会调用close系统调用来关闭连接，服务端close系统调用发送一个FIN N的完成帧给客户端，客户端接受到这个这个FIN帧之后知道服务端已经关闭了连接描述符，需要通知客户端自己知道这个事情了，所以发送一个确认ACK N+1，自己进入TIME_WAIT(2MSL)状态，当服务端接收到这个FIN帧之后知道客户端已经知道自己关闭了连接套接字，关闭过程就结束了，否则服务端等待一段时间没有接收到（信号实现）这个ACK，他会重发FIN，而TIME_WATI状态就是用来处理这个重发过程的。**问题：1. 为什么又TIME_WAIT状态？答：网路原因造成服务端无法接收到ACK，那么TIME_WAIT状态用来处理服务端重发的FIN。2. 为什么四次握手，三次握手是否可以？不可以，建立连接三次握手可以是因为没有数据拷贝到用户空间，而四次握手是因为又数据拷贝到用户空间，那么发送完成帧FIN就不能和发送ACK一起发，这里就增加了一次握手。**

  > 建立一个连接需要三次握手，而终止一个连接要经过四次握手，这是由TCP的半关闭(half-close)造成的，如图：
  >
  > ![img](https://pic1.zhimg.com/80/v2-0554854079c144d46da269740c666a50_720w.webp)
  >
  > 由于TCP连接是全双工的，因此每个方向都必须单独进行关闭。这个原则是当一方完成它的数据发送任务后就能发送一个FIN来终止这个方向的连接。收到一个 FIN只意味着这一方向上没有数据流动，一个TCP连接在收到一个FIN后仍能发送数据。首先进行关闭的一方将执行主动关闭，而另一方执行被动关闭。
  >
  > （1）客户端A发送一个FIN，用来关闭客户A到服务器B的数据传送（报文段4）。
  >
  > （2）服务器B收到这个FIN，它发回一个ACK，确认序号为收到的序号加1（报文段5）。和SYN一样，一个FIN将占用一个序号。
  >
  > （3）服务器B关闭与客户端A的连接，发送一个FIN给客户端A（报文段6）。
  >
  > （4）客户端A发回ACK报文确认，并将确认序号设置为收到序号加1（报文段7）。
  >
  > 对应函数接口如图：
  >
  > ![img](https://pic3.zhimg.com/80/v2-a59eac5deddd8b191397e6ea31ba0d72_720w.webp)
  >
  > 过程如下：
  >
  > - 某个应用进程首先调用close主动关闭连接，这时TCP发送一个FIN M；
  > - 另一端接收到FIN M之后，执行被动关闭，对这个FIN进行确认。它的接收也作为文件结束符传递给应用进程，因为FIN的接收意味着应用进程在相应的连接上再也接收不到额外数据；
  > - 一段时间之后，接收到文件结束符的应用进程调用close关闭它的socket。这导致它的TCP也发送一个FIN N；
  > - 接收到这个FIN的源发送端TCP对它进行确认。
  >
  > 这样每个方向上都有一个FIN和ACK。
  >
  > 1．为什么建立连接协议是三次握手，而关闭连接却是四次握手呢？
  >
  > 这是因为服务端的LISTEN状态下的SOCKET当收到SYN报文的建连请求后，它可以把ACK和SYN（ACK起应答作用，而SYN起同步作用）放在一个报文里来发送。但关闭连接时，当收到对方的FIN报文通知时，它仅仅表示对方没有数据发送给你了；但未必你所有的数据都全部发送给对方了，所以你可以未必会马上会关闭SOCKET,也即你可能还需要发送一些数据给对方之后，再发送FIN报文给对方来表示你同意现在可以关闭连接了，所以它这里的ACK报文和FIN报文多数情况下都是分开发送的。
  >
  > 2．为什么TIME_WAIT状态还需要等2MSL后才能返回到CLOSED状态？
  >
  > 这是因为虽然双方都同意关闭连接了，而且握手的4个报文也都协调和发送完毕，按理可以直接回到CLOSED状态（就好比从SYN_SEND状态到ESTABLISH状态那样）；但是因为我们必须要假想网络是不可靠的，你无法保证你最后发送的ACK报文会一定被对方收到，因此对方处于LAST_ACK状态下的SOCKET可能会因为超时未收到ACK报文，而重发FIN报文，所以这个TIME_WAIT状态的作用就是用来重发可能丢失的ACK报文。



**一些参考资料**

[W. Richard Stevens](http://www.kohala.com/start/)

https://zhuanlan.zhihu.com/p/180556309

http://c.biancheng.net/cpp/html/3045.html

https://www.cnblogs.com/skynet/archive/2010/12/12/1903949.html

https://cloud.tencent.com/developer/article/1722240

Socket是Linux提供的系统调用，Socket调用了TCP/IP协议栈，TCP/IP、Socket都是Linux操作系统提供的用于网络通信服务的程序。

不同的语言的库函数对Socket系统调用进行了封装，Socket的实现在Linux内核中，包括TCP/IP的实现。高级语言的库函数封装了Socket系统调用，从而可以通过使用高级语言的Socket库函数调用Socket系统调用。

同一主机上的进程通信方式有管道（有名管道和无名管道）、信号、共享内存、消息队列、信号量等；不同主机通信使用Socket套接字。Socket编程使用传输层传递的协议（TCP、UDP）+端口，网络层的IP地址这三元组唯一标记网络中的一个进程。

创建一个Socket连接会返回一个Socket描述符，这是在进程文件描述符表的一个索引，这个索引指向系统进程文件数据结构的地址。文件描述符是Linux系统中每个进程的文件描述符表的索引；文件指针式C语言的一个指向FILE数据结构的指针，FILE数据结构包括一个缓冲区和一个文件描述符。

**网络字节序和主机字节序**

字节序指的是整数保存在内存中的字节的顺序，包括小端字节序和大端字节序。小端字节序是整数的低位存放在低地址，高位存放到高地址；大端字节序是整数的高位存放在低地址，低位存放在高地址。比如一个4字节32位的int数值01020304，在文件中保存为01020304，左边是低地址，右边是高地址；在socket中保存为04030201，最低地址是04，一个字节可以保存两个十六进制数，04是一个字节的十六进制表示。

#### Socket C语言

![](https://pic1.zhimg.com/80/v2-d37fb0d929b6a8e7b68d82c2ac4f9abc_720w.jpg)

**C语言库函数中的Socket编程相关的库函数**

> **int  socket(int protofamily, int type, int protocol);//返回sockfd **
> 用于创建一个Socket描述符，他唯一标记一个Socket。protofamily表示协议族，包括AF_INET(IPV4)、AF_INET6(IPV6)等，他决定了Socket的网络地址类型；type，Socket类型，包括SOCK_TREAM、SOCK_DGRAM等；protocol，传输层协议，包括IPPROTO_TCP（TCP协议）、IIPROTO_UDP（UDP协议）等。当创建一个Socket描述符的时候，创建Socket描述符的时候返回的Socket描述符没有绑定IP和端口，可以使用bind函数绑定IP+端口，如果不使用bind绑定，在使用connect和listen等函数的时候会被自动分配IP+端口；这个机制使得服务端需要使用bind来绑定端口而客户端不用，因为客户端在使用connect和listen的时候会使用自动分配的端口。

> **int bind(int sockfd, const struct sockaddr *addr, socklen_t addrlen);**
>
> 给文件描述符绑定IP地址和端口，其中sockaddr数据结构对不同的协议族定义不一样，在IPV4中，sockaddr定义如下
>
> ```text
> struct sockaddr_in {
>  sa_family_t    sin_family; /* address family: AF_INET */
>  in_port_t      sin_port;   /* port in network byte order */
>  struct in_addr sin_addr;   /* internet address */
> };
> 
> /* Internet address. */
> struct in_addr {
>  uint32_t       s_addr;     /* address in network byte order */
> };
> ```

> ```> 
> int listen(int sockfd, int backlog);
> int connect(int sockfd, const struct sockaddr *addr, socklen_t addrlen);
> sockfd是要监听或者使用的socket描述符，backlog是服务端允许排队的最大连接个数，addrlen是地址长度,调用listen后套接字编程监听套机字
> ```

> ```text
> int accept(int sockfd, struct sockaddr *addr, socklen_t *addrlen); //返回连接connect_fd
> ```
>
> accept接收listen传递的监听套接字，转换成连接套接字

> read/write函数，进行网络IO函数
>
> ```text
> #include <unistd.h>
> #include <sys/types.h>
> #include <sys/socket.h>
> 
> ssize_t read(int fd, void *buf, size_t count);
> ssize_t write(int fd, const void *buf, size_t count);
> 
> ssize_t send(int sockfd, const void *buf, size_t len, int flags);
> ssize_t recv(int sockfd, void *buf, size_t len, int flags);
> 
> ssize_t sendto(int sockfd, const void *buf, size_t len, int flags,
> const struct sockaddr *dest_addr, socklen_t addrlen);
> 
> ssize_t recvfrom(int sockfd, void *buf, size_t len, int flags,
> struct sockaddr *src_addr, socklen_t *addrlen);
> 
> ssize_t sendmsg(int sockfd, const struct msghdr *msg, int flags);
> ssize_t recvmsg(int sockfd, struct msghdr *msg, int flags);
> ```

> ```text
> int close(int fd);
> ```
>
> 关闭套接字，这个套接字的引用计数变成0，这个套接字不能继续作为read/write函数的第一个参数

**C语言 Socket 编程实现不同主机进程通信**

https://zhuanlan.zhihu.com/p/180556309

```c
/* File Name: client.c */
#include<stdio.h>
#include<stdlib.h>
#include<string.h>
#include<errno.h>
#include<sys/types.h>
#include<sys/socket.h>
#include<netinet/in.h>
 
#define MAXLINE 4096
 
int main(int argc, char** argv){
 	int    sockfd, n,rec_len;
 	char    recvline[4096], sendline[4096] = "abcd";
 	char    buf[MAXLINE];
 	struct sockaddr_in servaddr;
 
 
 	if( argc != 2){
 		printf("usage: ./client <ipaddress>\n");
 		exit(0);
    	}
 
 
 	if( (sockfd = socket(AF_INET, SOCK_STREAM, 0)) < 0){
 		printf("create socket error: %s(errno: %d)\n", strerror(errno),errno);
 		exit(0);
    	}
 
 	memset(&servaddr, 0, sizeof(servaddr));
    	servaddr.sin_family = AF_INET;
    	servaddr.sin_port = htons(8000);
 	if( inet_pton(AF_INET, argv[1], &servaddr.sin_addr) <= 0){
 		printf("inet_pton error for %s\n",argv[1]);
 		exit(0);
    	}
 
 
 	if( connect(sockfd, (struct sockaddr*)&servaddr, sizeof(servaddr)) < 0){
 		printf("connect error: %s(errno: %d)\n",strerror(errno),errno);
 		exit(0);
    	}
 
 	printf("send msg to server: \n");
    gets(sendline, 4096, stdin);
 	if( send(sockfd, sendline, strlen(sendline), 0) < 0){
 		printf("send msg error: %s(errno: %d)\n", strerror(errno), errno);
 		exit(0);
    	}
 	if((rec_len = recv(sockfd, buf, MAXLINE,0)) == -1) {
       		perror("recv error");
 		exit(1);
    	}
    	buf[rec_len]  = '\0';
 	printf("Received : %s ",buf);
    	close(sockfd);
 	exit(0);
}

```

```c
/* File Name: server.c */
#include<stdio.h>
#include<stdlib.h>
#include<string.h>
#include<errno.h>
#include<sys/types.h>
#include<sys/socket.h>
#include<netinet/in.h>
#define DEFAULT_PORT 8000
#define MAXLINE 4096


int main(int argc, char** argv){
	int    socket_fd, connect_fd;
 	struct sockaddr_in servaddr;
 	char    buff[4096];
 	int     n;
 	//初始化Socket
 	if( (socket_fd = socket(AF_INET, SOCK_STREAM, 0)) == -1 ){
 		printf("create socket error: %s(errno: %d)\n",strerror(errno),errno);
 		exit(0);
    	}
 	//初始化
 	memset(&servaddr, 0, sizeof(servaddr));
    	servaddr.sin_family = AF_INET;
    	servaddr.sin_addr.s_addr = htonl(INADDR_ANY);//IP地址设置成INADDR_ANY,让系统自动获取本机的IP地址。
    	servaddr.sin_port = htons(DEFAULT_PORT);//设置的端口为DEFAULT_PORT
 
	//将本地地址绑定到所创建的套接字上
 	if( bind(socket_fd, (struct sockaddr*)&servaddr, sizeof(servaddr)) == -1){
 		printf("bind socket error: %s(errno: %d)\n",strerror(errno),errno);
 		exit(0);
    	}
 	//开始监听是否有客户端连接
 	if( listen(socket_fd, 10) == -1){
 		printf("listen socket error: %s(errno: %d)\n",strerror(errno),errno);
 		exit(0);
    	}
 	printf("======waiting for client's request======\n");
 	while(1){
	//阻塞直到有客户端连接，不然多浪费CPU资源。
 		if( (connect_fd = accept(socket_fd, (struct sockaddr*)NULL, NULL)) == -1){
	 		printf("accept socket error: %s(errno: %d)",strerror(errno),errno);
	 		continue;
    		}
		//接受客户端传过来的数据
	    	n = recv(connect_fd, buff, MAXLINE, 0);
		//向客户端发送回应数据
	 	if(!fork()){ /*紫禁城*/
	 		if(send(connect_fd, "Hello,you are connected!\n", 26,0) == -1)
				perror("send error");
			close(connect_fd);
	 		exit(0);
	    	}
	    	buff[n] = '\0';
	 	printf("recv msg from client: %s\n", buff);
	    	close(connect_fd);
    	}
    	close(socket_fd);
}
```

#### Socket Python

https://www.runoob.com/python/python-socket.html

```python
#!/usr/bin/python
# -*- coding: UTF-8 -*-
# 文件名：client.py
 
import socket               # 导入 socket 模块
 
s = socket.socket()         # 创建 socket 对象
host = socket.gethostname() # 获取本地主机名
port = 12345                # 设置端口号
 
s.connect((host, port))
print(s.recv(1024) )
s.close()
```

```python
#!/usr/bin/python
# -*- coding: UTF-8 -*-
# 文件名：server.py
 
import socket               # 导入 socket 模块
 
s = socket.socket()         # 创建 socket 对象
host = socket.gethostname() # 获取本地主机名
port = 12345                # 设置端口
s.bind((host, port))        # 绑定端口
 
s.listen(5)                 # 等待客户端连接
while True:
    c,addr = s.accept()     # 建立客户端连接
    print('连接地址：', addr)
    mystring = "Hello"
    c.send(mystring.encode())
    c.close()                # 关闭连接
```

#### Socket Java

https://www.liaoxuefeng.com/wiki/1252599548343744/1319099802058785

```c
//Client.java

import java.io.BufferedReader;
import java.io.BufferedWriter;
import java.io.IOException;
import java.io.InputStream;
import java.io.InputStreamReader;
import java.io.OutputStream;
import java.io.OutputStreamWriter;
import java.net.Socket;
import java.nio.charset.StandardCharsets;
import java.util.Scanner;

public class Client {
	public static void main(String[] args) throws IOException {
		Socket sock = new Socket("localhost", 6666); // 连接指定服务器和端口
		try (InputStream input = sock.getInputStream()) {
			try (OutputStream output = sock.getOutputStream()) {
				handle(input, output);
			}
		}
		sock.close();
		System.out.println("disconnected.");
	}

	private static void handle(InputStream input, OutputStream output) throws IOException {
		var writer = new BufferedWriter(new OutputStreamWriter(output, StandardCharsets.UTF_8));
		var reader = new BufferedReader(new InputStreamReader(input, StandardCharsets.UTF_8));
		Scanner scanner = new Scanner(System.in);
		System.out.println("[server] " + reader.readLine());
		for (;;) {
			System.out.print(">>> "); // 打印提示
			String s = scanner.nextLine();
			writer.write(s);
			writer.newLine();
			writer.flush();
			String resp = reader.readLine();
			System.out.println("<<< " + resp);
			if (resp.equals("bye")) {
				break;
			}
		}
	}
}

```

```java
//Server.java

import java.io.BufferedReader;
import java.io.BufferedWriter;
import java.io.IOException;
import java.io.InputStream;
import java.io.InputStreamReader;
import java.io.OutputStream;
import java.io.OutputStreamWriter;
import java.net.ServerSocket;
import java.net.Socket;
import java.nio.charset.StandardCharsets;

/**
 * Learn Java from https://www.liaoxuefeng.com/
 * 
 * @author liaoxuefeng
 */
public class Server {
	public static void main(String[] args) throws IOException {
		ServerSocket ss = new ServerSocket(6666); // 监听指定端口
		System.out.println("server is running...");
		for (;;) {
			Socket sock = ss.accept();
			System.out.println("connected from " + sock.getRemoteSocketAddress());
			Thread t = new Handler(sock);
			t.start();
		}
	}
}

class Handler extends Thread {
	Socket sock;

	public Handler(Socket sock) {
		this.sock = sock;
	}

	@Override
	public void run() {
		try (InputStream input = this.sock.getInputStream()) {
			try (OutputStream output = this.sock.getOutputStream()) {
				handle(input, output);
			}
		} catch (Exception e) {
			try {
				this.sock.close();
			} catch (IOException ioe) {
			}
			System.out.println("client disconnected.");
		}
	}

	private void handle(InputStream input, OutputStream output) throws IOException {
		var writer = new BufferedWriter(new OutputStreamWriter(output, StandardCharsets.UTF_8));
		var reader = new BufferedReader(new InputStreamReader(input, StandardCharsets.UTF_8));
		writer.write("hello\n");
		writer.flush();
		for (;;) {
			String s = reader.readLine();
			if (s.equals("bye")) {
				writer.write("bye\n");
				writer.flush();
				break;
			}
			writer.write("ok: " + s + "\n");
			writer.flush();
		}
	}
}

```

#### Socket Go

http://c.biancheng.net/view/4513.html

```go
//Client.go
package main
import (
    "log"
    "net"
    "os"
)
func main() {
    if len(os.Args) != 2 {
        log.Fatalf("Usage: %s host:port", os.Args[0])
    }
    service := os.Args[1]
    tcpAddr, err := net.ResolveTCPAddr("tcp4", service)
    if err != nil {
        log.Fatal(err)
    }
    conn, err := net.DialTCP("tcp4", nil, tcpAddr)
    if err != nil {
        log.Fatal(err)
    }
    n, err := conn.Write([]byte("HEAD / HTTP/1.1\r\n\r\n"))
    if err != nil {
        log.Fatal(err)
    }
    log.Fatal(n)
}
```

```go
//Server.go

package main
import (
    "fmt"
    "log"
    "net"
    "time"
)
func echo(conn *net.TCPConn) {
    tick := time.Tick(5 * time.Second) // 五秒的心跳间隔
    for now := range tick {
        n, err := conn.Write([]byte(now.String()))
        if err != nil {
            log.Println(err)
            conn.Close()
            return
        }
        fmt.Printf("send %d bytes to %s\n", n, conn.RemoteAddr())
    }
}
func main() {
    address := net.TCPAddr{
        IP:   net.ParseIP("127.0.0.1"), // 把字符串IP地址转换为net.IP类型
        Port: 8000,
    }
    listener, err := net.ListenTCP("tcp4", &address) // 创建TCP4服务器端监听器
    if err != nil {
        log.Fatal(err) // Println + os.Exit(1)
    }
    for {
        conn, err := listener.AcceptTCP()
        if err != nil {
            log.Fatal(err) // 错误直接退出
        }
        fmt.Println("remote address:", conn.RemoteAddr())
        go echo(conn)
    }
}
```

### 实验2-Linux网卡驱动和网络协议的实现

[(108条消息) 软考——计算机网络中的各种协议_遣隽命运的博客-CSDN博客_计算机网络协议](https://blog.csdn.net/m0_67601373/article/details/124798578)

[计算机网络协议_通信百科 (c114.com.cn)](https://baike.c114.com.cn/view.asp?id=10726-D77239EA)

[(108条消息) 计算机网络各种协议（会持续更新）_海南清补凉的博客-CSDN博客_计算机网络协议](https://blog.csdn.net/lin88556/article/details/126030642)

[(108条消息) 计算机网络协议（UDP，TCP，NAT，HTTP，HTTPS，ARP，RARP等）汇总_Mr_bugu的博客-CSDN博客_新型网络协议有哪些](https://blog.csdn.net/Mrxuanshen/article/details/117359769)

[(108条消息) 计算机网络协议总结_LiangJGo的博客-CSDN博客_计算机网络协议知识点](https://blog.csdn.net/LiangJGo/article/details/90080011)

[socket.c - net/socket.c - Linux source code (1.2.13) - Bootlin](https://elixir.bootlin.com/linux/1.2.13/source/net/socket.c)

**计算机网络协议**

网络协议的实质是计算机之间通信的规则。

![img](https://img-blog.csdnimg.cn/0583f946baf446a8bf5e8caf49050beb.jpeg)

> - 应用层
>
>   DHCP · DNS · FTP · Gopher · HTTP · IMAP4 · IRC · NNTP · XMPP · POP3 · SIP · SMTP · SNMP · SSH · TELNET · RPC · RTCP · RTSP · TLS · SDP · SOAP · GTP · STUN · NTP
>
>   - DNS域名解析协议53号端口：完成域名到IP地址的映射。使用UDP协议
>   
>     > **DNS域名解析协议工作流程**
>     >
>     > 向本地域名服务器发出查询请求前，先会查询浏览器缓存中是否有这个域名对应的ip地址，如果有，则直接返回；如果没有，会接着查询操作系统中是否有这个域名的对应的DNS解析结果，如果有，则直接返回，否则，进行以下步骤：
>     >
>     > ①先向本地域名服务器进行递归查询，如果有缓存，则直接返回
>     >
>     > ②否则，本地域名服务器采用迭代查询的方式，先向根域名服务器发起查询
>     >
>     > ③根域名服务器告诉本地域名服务器下次应该查询的顶级域名服务器的ip地址
>     >
>     > ④本地域名服务器向相应的顶级域名服务器发起查询
>     >
>     > ⑤顶级域名服务器告诉本地域名服务器下次应该查询的权威域名服务器的ip地址
>     >
>     > ⑥本地域名服务器向相应的权威域名服务器发起查询
>     >
>     > ⑦权威域名服务器告诉本地域名服务器查询的ip地址
>     >
>     > ⑧本地域名服务器返回查询ip地址并且缓存该映射
>     > ![img](https://img-blog.csdnimg.cn/7daa338434514c99bfac5121b2361a13.png)
>   
>   - HTTP超文本传输协议，默认端口80，使用TCP/IP
>   
>     > **HTTP的特点**
>     >
>     > - 支持客户/服务器模式
>     >
>     > - 无状态：协议对客户端没有状态存储，比如访问一个网站需要反复进行登录操作
>     >
>     > - 无连接：HTTP/1.1之前，限制每次连接只处理一个请求。服务器处理完客户的请求，并收到客户的应答后，即断开连接。采用这种方式可以节省传输时间。
>     >
>     > - 基于请求和响应：由客户端发起请求，服务端数据响应简单快速、灵活
>     >
>     > - 通信使用明文，请求和响应不会对通信方进行确认、无法保护数据的完整性与安全性
>     >
>     > **HTTP请求和响应**
>     >
>     > - 请求
>     >
>     >   > GET http://www.baidu.com?username=lx&password=qwe HTTP/1.1  
>     >   > Accept: image/gif, image/x-xbitmap, image/jpeg, image/pjpeg, application/vnd.ms-excel, -silverlight, application/x-shockwave-flash, */*  
>     >   > Referer: <a href="http://www.google.cn/">http://www.google.cn/</a>  
>     >   > Accept-Language: zh-cn  
>     >   > Content-Length: 28
>     >   > Accept-Encoding: gzip, deflate  
>     >   > User-Agent: Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; .NET CLR 2.0.50727; TheWorld)  
>     >   > Host: <a href="http://www.google.cn">www.google.cn</a>  
>     >   > Connection: Keep-Alive  
>     >   > Cookie: PREF=ID=80a06da87be9ae3c:U=f7167333e2c3b714:NW=1:TM=1261551909:LM=1261551917:S=ybYcq2wpfefs4V9g;
>     >   >
>     >   > username=lx&password=qwe 
>     >
>     >   首行: [方法] + [url] + [版本]
>     >   Header: 请求的属性, 冒号分割的键值对;每组属性之间使用\n分隔;遇到空行表示Header部分结束
>     >   Body: 空行后面的内容都是Body. Body允许为空字符串. 如果Body存在, 则在Header中会有一个ContentLength属性来标识Body的长度;
>     >
>     > - 响应
>     >
>     >   > HTTP/1.1 200 OK 
>     >   > Accept: image/gif, image/x-xbitmap, image/jpeg, image/pjpeg, application/vnd.ms-excel, application/vnd.ms-powerpoint, 
>     >   > application/msword, application/x-silverlight, application/x-shockwave-flash, */*  
>     >   > Referer: <a href="http://www.google.cn/">http://www.google.cn/</a>  
>     >   > Accept-Language: zh-cn  
>     >   > Content-Length： 36
>     >   > Accept-Encoding: gzip, deflate  
>     >   > User-Agent: Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; .NET CLR 2.0.50727; TheWorld)  
>     >   > Host: <a href="http://www.google.cn">www.google.cn</a>  
>     >   > Connection: Keep-Alive  
>     >   > Cookie: PREF=ID=80a06da87be9ae3c:U=f7167333e2c3b714:NW=1:TM=1261551909:LM=1261551917:S=ybYcq2wpfefs4V9g; 
>     >   > NID=31=ojj8d-IygaEtSxLgaJmqSjVhCspkviJrB6omjamNrSm8lZhKy_yMfO2M4QMRKcH1g0iQv9u-2hfBW7bUFwVh7pGaRUb0RnHcJU37y-
>     >   > FxlRugatx63JLv7CWMD6UB_O_r  
>     >   >
>     >   > hl=zh-CN&source=hp&q=domety 
>     >
>     >   首行: [版本号] + [状态码] + [状态码解释]
>     >   Header: 请求的属性, 冒号分割的键值对;每组属性之间使用\n分隔;遇到空行表示Header部分结束
>     >   Body: 空行后面的内容都是Body. Body允许为空字符串. 如果Body存在, 则在Header中会有一个ContentLength属性来标识Body的长度; 如果服务器返回了一个html页面, 那么html页面内容就是在body中.
>     >
>     > **HTTP返回状态码**
>     >
>     > > 常见状态码
>     > >
>     > > - 1XX （接收的请求正在处理）
>     > >
>     > > - 2XX（请求正常处理完毕）
>     > >   200: 请求成功
>     > >
>     > > - 3XX（重定向状态码）
>     > >   301: （永久移动）  请求的网页已永久移动到新位置。浏览器会自动访问新的url，今后用新的url进行登录
>     > >
>     > >   302: （临时移动）  服务器从别的网页资源响应请求，但请求者应继续使用原有url
>     > >
>     > >   307: （临时重定向）  服务器目前从不同位置的网页响应请求，但请求者应继续使用原有位置来进行以后的请求。
>     > >
>     > > - 4XX（请求可能出错，妨碍了服务器的处理）
>     > >   400: 客户端请求语法错误，服务器无法理解（数据类型，数据格式，协议格式错误）
>     > >
>     > >   401: 请求要求身份验证(未登录访问敏感资源)
>     > >
>     > >   403: 服务器拒绝请求
>     > >
>     > >   404: 服务器找不到请求的网页
>     > >
>     > >   405: 客户端请求中的方法被禁止（服务端提供的请求方法不包含客户端的请求方法）
>     > >
>     > > - 5XX（服务器错误）
>     > >   500: （服务器内部错误）  服务器遇到错误，无法完成请求。
>     > >
>     > >   502: （错误网关）服务器作为网关或代理，从上游服务器收到无效响应。
>     > >
>     > >   503: （服务不可用）服务器目前无法使用（停机维护）
>     >
>     > **从浏览器地址栏键入URL，回车后会尽力的流程：**
>     >
>     > > DNS解析
>     > > TCP连接
>     > > 发送HTTP请求
>     > > 服务器处理请求，并返回HTTP报文
>     > > 浏览器解析渲染页面
>     > > 连接结束
>     >
>     > **GET请求与POST请求的区别**
>     >
>     > HTTP报文层面：GET请求信息放在URL中，POST放在报文体中
>     > 数据库层面：GET符合幂等性和安全性，POST不符合
>     > 其他层面：GET可以被缓存、储存，而POST不行
>     > **Cookie和Session的区别**
>     >
>     > > 为什么会有这两种技术？
>     > > 在使用一些需要登录的网站时，每次访问，都会需要验证个人信息，即登录。这样做比较繁琐，能否将个人的账号和密码存起来，访问的时候直接用存取来的个人信息进行验证呢？解决这个问题的就是Cookie和Session
>     > > Cookie：通过客户端（浏览器）来缓存个人信息。当用户第一次登录时，服务器会将个人信息放在了响应中， 浏览器接收到响应时候会将个人信息以Cookie的形式访问浏览器中保存起来，在下一次访问服务器的时候会带上该Cookie，Cookie中有个人信息，服务器能解析出来，所以不同再次登录验证了。（不够安全，对服务器的开销小）
>     > > Session通过服务端来缓存信息，根据请求中是否包含Session id的字段，如果不存在则创建一个，并返回给浏览器缓存起来。如果存在则通过该Session id在服务器存储中获得对应的Session信息，直接验证。（安全，服务器的开销变大）
>     >
>     > **HTTP与HTTPS的区别：**
>     >
>     > > 1、HTTPS需要到CA申请证书，HTTP不需要
>     > > 2、HTTPS密文传输、HTTP明文传输
>     > > 3、连接方式不同，HTTPS默认使用443端口，HTTP使用80端口
>     > > 4、HTTPS = HTTP + 加密+认证+完整性保护，较HTTP安全
>   
>   - HTTPS协议，SSL包装的HTTP协议，默认端口443，使用TCP/IP
>   
>     > **什么是HTTPS？**
>     >
>     > http传送数据（包括账号和密码），都是明文传送，很容易被窃取或者侦听，所以有了https，https多了一层加密解密层，在发送前加密，在收到后解密。HTTPS是身披SSL外壳的HTTP。HTTPS是一种通过计算机网络进行安全通信的传输协议，经由HTTP进行通信，利用SSL/TLS建立全信道，加密数据包。HTTPS使用的主要目的是提供对网站服务器的身份认证，同时保护交换数据的隐私与完整性。TLS是传输层加密协议，前身是SSL协议，有时候两者不区分
>     > **HTTPS的特点？**
>     > 内容加密：采用混合加密技术，中间者无法直接查看明文内容
>     > 验证身份：通过证书认证客户端访问的是自己的服务器
>     > 保护数据完整性：防止传输的内容被中间人冒充或者篡改
>     > **对称加密与非对称加密？**
>     > 对称加密：A和B对自己的数据进行加密。A和B会使用一个共享的密钥，A在发送数据之前，用这个密钥对数据加密。B在收到数据之后，用这个密钥对数据解密。因为加密解密用的是同一个密钥，所以这里的加密算法称为对称加密算法。
>     > 非对称加密：（存在中间人攻击）非对称加密使用两个密钥，一个是public key，一个是private key。通过一个特殊的数学算法，使得数据的加密和解密使用不同的密钥。因为用的是不同的密钥，所以称为非对称加密。非对称加密的好处在于，现在A可以保留private key，通过网络传递public key。这样，就算public key被C拦截了，因为没有private key，C还是没有办法完成信息的破解。既然不怕C知道public key，那现在A和B不用再见面商量密钥，直接通过网络传递public key就行。具体在使用中，A和B都各有一个public key和一个private key，这些key根据相应的算法已经生成好了。private key只保留在各自的本地，public key传给对方。A要给B发送网络数据，那么A先使用自己的private key（只有A知道）加密数据的hash值，之后再用B的public key加密数据。之后，A将加密的hash值和加密的数据再加一些其他的信息，发送给B。B收到了之后，先用自己的private key（只有B知道）解密数据，本地运算一个hash值，之后用A的public key解密hash值，对比两个hash值，以检验数据的完整性。
>     >
>     > **CA证书：**
>     >
>     > 现实中，通过CA证书来保证public key的真实性。CA也是基于非对称加密算法来工作。有了CA，B会先把自己的public key（和一些其他信息）交给CA。CA用自己的private key加密这些数据，加密完的数据称为B的数字证书。现在B要向A传递public key，B传递的是CA加密之后的数字证书。A收到以后，会通过CA发布的CA证书（包含了CA的public key），来解密B的数字证书，从而获得B的public key。
>     >
>     > 但是A怎么确保CA证书不被劫持。C完全可以把一个假的CA证书发给A，进而欺骗A。CA的大杀器就是，CA把自己的CA证书集成在了浏览器和操作系统里面。A拿到浏览器或者操作系统的时候，已经有了CA证书，没有必要通过网络获取，那自然也不存在劫持的问题。
>     >
>     > **SSL/TLS的工作过程：**
>     >
>     > 通过CA体系交换public key
>     > 通过非对称加密算法，交换用于对称加密的密钥
>     > 通过对称加密算法，加密正常的网络通信
>     > 用户向web服务器发起一个安全连接的请求
>     > 服务器返回经过CA认证的数字证书，证书里面包含了服务器的public key
>     > 用户拿到数字证书，用自己浏览器内置的CA证书解密得到服务器的public key
>     > 用户用服务器的public key加密一个用于接下来的对称加密算法的密钥，传给web服务器
>     > 因为只有服务器有private key可以解密，所以不用担心中间人拦截这个加密的密钥
>     > 服务器拿到这个加密的密钥，解密获取密钥，再使用对称加密算法，和用户完成接下来的网络通信
>
> - 传输层
>   TCP · UDP · DCCP · SCTP · RTP · RSVP · PPTP
>
>   - TCP协议：端到端的、可靠的、面向连接的、全双工的数据传输服务。TCP协议服务的应用层协议有FTP文件传输协议20/21号端口、Telnet远程登陆协议23号端口、SMTP邮件传输协议25号端口、HTTP超文本传输协议80号端口
>
>     > 1. 确认应答
>     >
>     >    发送数据时：携带数据序号
>     >
>     >    接受数据时：携带确认序号
>     >
>     >    TCP将每个字节的数据都进行了编号（序列号），每一个ACK都带有确认序号，意思是告诉发送者，我已经收到了哪些数据，下一次你应该从哪里开始发。
>     >
>     > 2. 超时重传机制
>     >    两种情况：
>     >
>     >    数据丢失
>     >    确认应答丢失（进行了超市重传，所以主机B可能收到重复的数据，可以利用序列号进行去重）
>     >    超时时间如何确定？
>     >
>     >    TCP为了保证无论在任何环境下都有较高性能的通信, 因此会动态计算这个最大超时时间.（超时以500ms为一个单位进行控制）
>     >    如果重发一次之后, 仍然得不到应答, 等待 2*500ms 后再进行重传.
>     >    如果仍然得不到应答, 等待 4*500ms 进行重传. 依次类推, 以指数形式递增.
>     >    累计到一定的重传次数, TCP认为网络或者对端主机出现异常, 强制关闭连接.
>     >
>     > 3. 连接管理机制
>     >    正常情况下, tcp需要经过三次握手建立连接, 四次挥手断开连接.
>     >
>     >    - 三次握手：
>     >
>     >      刚开始, 客户端和服务器都处于 close状态.TCP服务器启动, 时刻准备接受客户端进程的连接请求, 此时服务器就进入了 listen（监听）状态
>     >
>     >      客户端向服务器主动发出连接请求, 服务器被动接受连接请求.
>     >
>     >      TCP客户端进程向服务器发出连接请求报文，此时报文首部中的同步标志位SYN=1, 同时选择一个初始序列号 seq = x, 此时，TCP客户端进程进入了 SYN-sent（同步已发送状态）状态。TCP规定, SYN报文段（SYN=1的报文段）不能携带数据，但需要消耗掉一个序号。
>     >      TCP服务器收到请求报文后, 如果同意连接, 则发出确认报文。确认报文中的 ACK=1, SYN=1, 确认序号是 x+1, 同时也要为自己初始化一个序列号 seq = y, 此时, TCP服务器进程进入了SYN-rcvd（同步收到）状态。这个报文也不能携带数据, 但是同样要消耗一个序号。
>     >      TCP客户端进程收到确认后还,要向服务器给出确认。确认报文的ACK=1，确认序号是 y+1，自己的序列号是 x+1.
>     >      此时TCP连接建立，客户端进入established（已建立连接）状态。当服务器收到客户端的确认后也进入established状态，此后双方就可以开始通信了。
>     >
>     >    - 四次挥手：
>     >
>     >      数据传输完毕后，双方都可以释放连接.此时客户端和服务器都是处于established状态，然后客户端主动断开连接，服务器被动断开连接.
>     >
>     >      客户端进程发出连接释放报文，并且停止发送数据。释放数据报文首部，FIN=1，其序列号为seq=u（等于前面已经传送过来的数据的最后一个字节的序号加1），此时客户端进入FIN-wait1（终止等待1）状态。 TCP规定，FIN报文段即使不携带数据，也要消耗一个序号。
>     >       服务器收到连接释放报文，发出确认报文，ACK=1，确认序号为 u+1，并且带上自己的序列号seq=v，此时服务端就进入了CLOSE-wait（关闭等待）状态。TCP服务器通知高层的应用进程，客户端向服务器的方向就释放了，这时候处于半关闭状态，即客户端已经没有数据要发送了，但是服务器若发送数据，客户端依然要接受。这个状态还要持续一段时间，也就是整个CLOSE-wait状态持续的时间。
>     >       客户端收到服务器的确认请求后，此时客户端就进入FIN-wait2（终止等待2）状态，等待服务器发送连接释放报文（在这之前还需要接受服务器发送的最终数据）
>     >      服务器将最后的数据发送完毕后，就向客户端发送连接释放报文，FIN=1，由于在半关闭状态，服务器很可能又发送了一些数据，假定此时的序列号为seq=w，此时，服务器就进入了LAST-ACK（最后确认）状态，等待客户端的确认。
>     >      客户端收到服务器的连接释放报文后，必须发出确认，ACK=1，确认序号为w+1，而自己的序列号是u+1，此时，客户端就进入了TIME-wait（时间等待）状态。注意此时TCP连接还没有释放，必须经过2∗MSL（最长报文段寿命）的时间后，当客户端撤销相应的TCB后，才进入CLOSED状态。
>     >       服务器只要收到了客户端发出的确认，立即进入CLOSED状态。同样，撤销TCB后，就结束了这次的TCP连接。可以看到，服务器结束TCP连接的时间要比客户端早一些。
>     >
>     > 4. 滑动窗口
>     >    我们一次发送多条数据, 就可以大大的提高性能，滑动窗口机制就是如此；
>     >
>     >    窗口大小指的是无需等待确认应答而可以继续发送数据的最大值. 例如窗口大小是4000个字节(四个段).
>     >    发送前四个段的时候, 不需要等待任何ACK, 直接发送;
>     >    收到第一个ACK后, 滑动窗口向后移动, 继续发送第五个段的数据; 依次类推;
>     >    操作系统内核为了维护这个滑动窗口, 需要开辟发送缓冲区来记录当前还有哪些数据没有应答; 只有确认应答过的数据, 才能从缓冲区删掉;
>     >    窗口越大, 则网络的吞吐率就越高;
>     >    丢包情况：
>     >
>     >    1.数据包已经抵达, ACK被丢了.
>     >
>     >    这种情况下, 部分ACK丢了并不要紧, 因为可以通过后续的ACK进行确认;
>     >    2.数据包丢了
>     >
>     >    当某一段报文段（1-1000）丢失之后, 发送端会一直收到像1001 这样的ACK, 就像是在提醒发送端 "我想要的是 1001"一样;
>     >    如果发送端主机连续三次收到了同样一个 "1001" 这样的应答, 就会将对应的数据 1001 - 2000 重新发送;
>     >    这个时候接收端收到了 1001 之后, 再次返回的ACK就是 ，例如：7001了(因为2001 - 7000)接收端其实之前就已经收到了, 被放到了接收端操作系统内核的接收缓冲区中;
>     >    这种机制被称为 "高速重发控制"(也叫 "快重传")
>     >
>     > 5. 流量控制
>     >    接收端处理数据的速度是有限的. 如果发送端发的太快, 导致接收端的缓冲区满了, 这时如果发送端继续发送, 就会造成丢包。因此TCP支持根据接收端的处理能力, 来决定发送端的发送速度. 这个机制就叫做流量控制(Flow Control);
>     >
>     >    接收端将自己可以接收的缓冲区大小放入 TCP 首部中的 "窗口大小" 字段, 通过ACK端通知发送端;
>     >    窗口大小字段越大, 说明网络的吞吐量越高;
>     >    接收端一旦发现自己的缓冲区快满了, 就会将窗口大小设置成一个更小的值通知给发送端;
>     >    发送端接受到这个窗口之后, 就会减慢自己的发送速度;
>     >    如果接收端缓冲区满了, 就会将窗口置为0; 这时发送方不再发送数据, 但是需要定期发送一个窗口探测数据段, 使接收端把窗口大小告诉发送端.
>     >
>     > 6. 拥塞控制
>     >    此处引入一个概念程为拥塞窗口
>     >    （慢启动）发送开始的时候, 定义拥塞窗口大小为1;每次收到一个ACK应答, 拥塞窗口加1;（指数级增加）
>     >    每次发送数据包的时候, 将拥塞窗口和接收端主机反馈的窗口大小做比较, 取较小的值作为实际发送的窗口;
>     >    为了不增长的那么快, 因此不能使拥塞窗口单纯的加倍，此处引入一个叫做慢启动的阈值
>     >    当拥塞窗口超过这个阈值的时候, 不再按照指数方式增长, 而是按照线性方式增长
>     >    当TCP开始启动的时候, 慢启动阈值等于窗口最大值; 在每次超时重发的时候, 慢启动阈值会变成上次网络拥塞的一半, 同时拥塞窗口置回1;
>     >    少量的丢包, 我们仅仅是触发超时重传;
>     >
>     > 7. 延迟应答
>     >    如果接收数据的主机立刻返回ACK应答, 这时候返回的窗口可能比较小.
>     >
>     >    假设接收端缓冲区为1M. 一次收到了500K的数据; 如果立刻应答, 返回的窗口就是500K;
>     >    但实际上可能处理端处理的速度很快, 10ms之内就把500K数据从缓冲区消费掉了;
>     >    在这种情况下, 接收端处理还远没有达到自己的极限, 即使窗口再放大一些, 也能处理过来;
>     >    如果接收端稍微等一会再应答, 比如等待200ms再应答, 那么这个时候返回的窗口大小就是1M;
>     >    所有的包都可以延迟应答么? 肯定也不是;
>     >
>     >    数量限制: 每隔几（如：2）个包就应答一次;
>     >    时间限制: 超过最大延迟时间（200ms）就应答一次;
>     >
>     > 8. 捎带应答
>     >    ACK就可以搭顺风车, 和服务器回应的 "数据" 一起回给客户端
>     >
>     > 9. 面向字节流
>
>   - UDP协议：不可靠的无连接的协议。UDP协议服务的应用层协议有DNS域名解析协议53号端口、SNMP简单网络管理协议161/162端口、TFTP简单文件传输协议69号端口、DHCP动态主机排至协议67/68号端口
>
>     > 1. UDP协议格式
>     >
>     > ![img](https://img-blog.csdnimg.cn/20210528150628690.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L01yeHVhbnNoZW4=,size_16,color_FFFFFF,t_70)
>     >
>     > ​		UDP首部有8个字节，由4个字段构成，每个字段都是2个字节
>     > ​		16位UDP长度：表示整个数据报(UDP首部+UDP数据)的最大长度（最大64K）
>     > ​		16位UDP检验和：如果校验和(双方约定好的字符串)出错, 就会直接丢弃;
>     >
>     > 2. UDP的特点
>     >    无连接：知道对端的IP和端口号就可以直接进行通讯，不需要建立连接。
>     >    不可靠：没有类似TCP的安全机制（确认应答机制，超时重传机制，连接管理机制）。
>     >    面向数据报：不能够灵活的控制读写数据的次数，只能一次接受整个数据报文（系统级别操作，调用操作系统函数）。应用层交给UDP多长的报文, UDP原样发送, 既不会拆分, 也不会合并;用UDP传输100个字节的数据：如果发送端调用一次sendto, 发送100个字节, 那么接收端也必须调用对应的一次recvfrom, 接收100个字节; 而不能循环调用10次recvfrom, 每次接收10个字节;
>     >
>     > 3. UDP的缓冲区
>     >    UDP没有真正意义上的发送缓冲区
>     >    UDP有接收缓存区，如果缓冲区已满，之后到达的数据就会被丢弃。
>     >
>     > 4. UDP的注意事项
>     >    UDP协议首部中有一个16位的最大长度. 也就是说一个UDP能传输的数据最大长度是64K(包含UDP首部)。如果我们需要传输的数据超过64K, 就需要在应用层手动的分包, 多次发送, 并在接收端手动拼装。
>
> - 网络层
>   IP (IPv4 · IPv6) · ARP · RARP · ICMP · ICMPv6 · IGMP · RIP · OSPF · BGP · IS-IS · IPsec
>
>   - IP协议：将上层（TCP/UDP传输层协议）或者同层的数据（ICMP，ARP，RARP）封装到IP数据报中；对数据进行分段；寻找数据报到达目的主机的网络路径；将IP数据报传送到目的地址。
>
>   - ARP地址解析协议：将IP地址转换为物理地址（MAC地址）
>
>     如果A向B发送数据，必须构建一个数据链路层帧需要A的MAC地址和B的MAC地址，这个MAC地址的获得需要ARP协议来根据IP地址获得
>
>     - 如果B的MAC地址在A计算机的ARP表中，直接返回B的MAC地址
>     - 如果B的MAC地址在A所在的局域网内，A向局域网发送一个ARP查询分组，这个查询分组的IP数据报的源地址是A的IP地址，目的地址是B的IP地址，数据链路层帧的源MAC地址是A的地址，目的MAC地址全是F，也就是广播这个ARP查询分组。当局域网的计算机收到这个查询分组之后，检查目的IP地址是否是本IP地址，如果是就单播自己的IP地址和MAC地址给A（IP地址和MAC地址一一对应，MAC地址是网卡ROM特有的数据）
>     - 如果B不在A的局域网内，B所在局域网的路由器的MAC地址R是MAC1，B的网卡的MAC地址是MAC2，A发送一个IP报文，源IP是A的IP地址，目的IP是B的IP地址，数据链路层帧的源MAC地址是A的MAC地址，目的MAC地址是B的MAC地址。R路由器收到这个IP数据报，返回给网络层，网络层组织一个源IP是A，目的IP是B，但是源MAC地址是R的MAC1和目的MAC是B的MAC2的数据链路层帧，发送给B，B收到这个ARP查询分组之后，给A发送一个IP报文，源IP是B的IP，目的IP是A的IP，数据链路层源MAC是B的MAC，目的MAC是A的MAC。
>
>   - RARP反地址解析协议：将物理地址（MAC地址）转换为IP地址
>   - ICMP控制信息协议：用于在IP主机、路由器之间传递控制信息，定义了五种差错报文（源抑制、超时、目的不可达、重定向、要求分段）和四种信息报文（回应请求、回应应答、地址屏蔽码请求、地址屏蔽码应答）。ICMP
>
> - 网络接口层
>   802.11 · 802.16 · Wi-Fi · WiMAX · ATM · DTM · 令牌环 · 以太网 · FDDI · 帧中继 · GPRS · EVDO · HSPA · HDLC · PPP · L2TP · ISDN
>
> - 物理层
>   以太网物理层 · 调制解调器 · PLC · SONET/SDH · G.709 · 光导纤维 · 同轴电缆 · 双绞线

封装情况：

![img](https://img-blog.csdnimg.cn/f90e47f31ad24f8fb16fedf49195b23d.png)

**HTTP和HTTPS应用层协议**

[(83 封私信 / 80 条消息) 想深入了解 HTTP 协议，有哪些值得推荐的书籍？ - 知乎 (zhihu.com)](https://www.zhihu.com/question/19722062)

**Sleep函数实现原理**

[sleep实现原理 - 简书 (jianshu.com)](https://www.jianshu.com/p/74becd7ffcf6)

> 使用signal给进程SIGALRM信号注册一个处理函数，然后使用alarm定时器让内核在一定时间之后发送一个SIGALRM信号给进程，当时钟中断检查到这个信号之后会调用SIGALRM的处理函数，sleep函数是通过信号加定时实现的。
>
> ```c
> #include <stdio.h>
> #include <stdlib.h>
> #include <signal.h>
> #include <unistd.h>
> ///时钟编程 alarm()
> void wakeUp()
> {
>     printf("please wakeup!!\n");
> }
> int main(void)
> {
>     printf("you have 4 s sleep!\n");
>     signal(SIGALRM,wakeUp);
>     alarm(4);
>     //将进程挂起
>     pause();
>     printf("good morning!\n");
>     return EXIT_SUCCESS;
> }
> ```
>
> ```c
> //kernel/signal.c定义了sys_signal，他注册处理程序给对应的信号放到sigaction函数指针数组
> int sys_signal(int signum, long handler, long restorer)
> {
> 	struct sigaction tmp;
> 
> 	if (signum<1 || signum>32 || signum==SIGKILL)
> 		return -1;
> 	tmp.sa_handler = (void (*)(int)) handler;
> 	tmp.sa_mask = 0;
> 	tmp.sa_flags = SA_ONESHOT | SA_NOMASK;
> 	tmp.sa_restorer = (void (*)(void)) restorer;
> 	handler = (long) current->sigaction[signum-1].sa_handler;
> 	current->sigaction[signum-1] = tmp;
> 	return handler;
> }
> 
> 
> 
> 
> //kernel/linux/sched.c定义了sys_alarm，他将current->alarm定时器设置为jiffies+HZ*秒数，
> int sys_alarm(long seconds)
> {
> 	int old = current->alarm;
> 
> 	if (old)
> 		old = (old - jiffies) / HZ;
> 	current->alarm = (seconds>0)?(jiffies+HZ*seconds):0;
> 	return (old);
> }
> 
> 
> 
> 
> //kernel/system_call.s定义了时钟中断函数timer_interrupt，这个函数调用了do_timer函数，do_timer函数在/kernel/linux/sched.c中定义.do_timer会根据current->alarm<=jiffies发送时钟信号给进程( current->signal|= 1<<(SIGALRM-1) )。之后处理信号函数会调用信号处理函数执行信号处理。
> void do_timer(long cpl)
> {
> 	extern int beepcount;
> 	extern void sysbeepstop(void);
> 
> 	if (beepcount)
> 		if (!--beepcount)
> 			sysbeepstop();
> 
> 	if (cpl)
> 		current->utime++;
> 	else
> 		current->stime++;
> 
> 	if (next_timer) {
> 		next_timer->jiffies--;
> 		while (next_timer && next_timer->jiffies <= 0) {
> 			void (*fn)(void);
> 			
> 			fn = next_timer->fn;
> 			next_timer->fn = NULL;
> 			next_timer = next_timer->next;
> 			(fn)();
> 		}
> 	}
> 	if (current_DOR & 0xf0)
> 		do_floppy_timer();
> 	if ((--current->counter)>0) return;
> 	current->counter=0;
> 	if (!cpl) return;
> 	schedule();
> }
> ```
>
> 

## NIO和IO

**一、概念**

   NIO即New IO，这个库是在JDK1.4中才引入的。NIO和IO有相同的作用和目的，但实现方式不同，NIO主要用到的是块，所以NIO的效率要比IO高很多。在Java API中提供了两套NIO，一套是针对标准输入输出NIO，另一套就是网络编程NIO。

**二、NIO和IO的主要区别**

下表总结了Java IO和NIO之间的主要区别：

| **IO** | **NIO**  |
| ------ | -------- |
| 面向流 | 面向缓冲 |
| 阻塞IO | 非阻塞IO |
| 无     | 选择器   |

**1、面向流与面向缓冲**

   Java IO和NIO之间第一个最大的区别是，IO是面向流的，NIO是面向缓冲区的。 Java IO面向流意味着每次从流中读一个或多个字节，直至读取所有字节，它们没有被缓存在任何地方。此外，它不能前后移动流中的数据。如果需要前后移动从流中读取的数据，需要先将它缓存到一个缓冲区。 Java NIO的缓冲导向方法略有不同。数据读取到一个它稍后处理的缓冲区，需要时可在缓冲区中前后移动。这就增加了处理过程中的灵活性。但是，还需要检查是否该缓冲区中包含所有您需要处理的数据。而且，需确保当更多的数据读入缓冲区时，不要覆盖缓冲区里尚未处理的数据。

**2、阻塞与非阻塞IO**

   Java IO的各种流是阻塞的。这意味着，当一个线程调用read() 或 write()时，该线程被阻塞，直到有一些数据被读取，或数据完全写入。该线程在此期间不能再干任何事情了。Java NIO的非阻塞模式，使一个线程从某通道发送请求读取数据，但是它仅能得到目前可用的数据，如果目前没有数据可用时，就什么都不会获取，而不是保持线程阻塞，所以直至数据变的可以读取之前，该线程可以继续做其他的事情。 非阻塞写也是如此。一个线程请求写入一些数据到某通道，但不需要等待它完全写入，这个线程同时可以去做别的事情。 线程通常将非阻塞IO的空闲时间用于在其它通道上执行IO操作，所以一个单独的线程现在可以管理多个输入和输出通道（channel）。

**3、选择器（Selectors）**

   Java NIO的选择器允许一个单独的线程来监视多个输入通道，你可以注册多个通道使用一个选择器，然后使用一个单独的线程来“选择”通道：这些通道里已经有可以处理的输入，或者选择已准备写入的通道。这种选择机制，使得一个单独的线程很容易来管理多个通道。

**四、总结**

NIO可让您只使用一个（或几个）单线程管理多个通道（网络连接或文件），但付出的代价是解析数据可能会比从一个阻塞流中读取数据更复杂。

如果需要管理同时打开的成千上万个连接，这些连接每次只是发送少量的数据，例如聊天服务器，实现NIO的服务器可能是一个优势。同样，如果你需要维持许多打开的连接到其他计算机上，如P2P网络中，使用一个单独的线程来管理你所有出站连接，可能是一个优势。一个线程多个连接的设计方案如下图所示：

![img](https://images2015.cnblogs.com/blog/249993/201703/249993-20170321110623815-613575568.png)

**Java NIO: 单线程管理多个连接**

如果你有少量的连接使用非常高的带宽，一次发送大量的数据，也许典型的IO服务器实现可能非常契合。下图说明了一个典型的IO服务器设计：

![img](https://images2015.cnblogs.com/blog/249993/201703/249993-20170321110840033-1588623537.png)

**Java IO: 一个典型的IO服务器设计- 一个连接通过一个线程处理.**



## 计算机OSI模型、各层数据、各层协议图：

[![osi-model](https://github.com/AlbertoWang/java-noob/raw/master/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C.assets/osi-model.png)](https://github.com/AlbertoWang/java-noob/blob/master/计算机网络.assets/osi-model.png)

## 各层协议简述

### 网络层

#### ARP：地址解析协议 *Address Resolution Protocol*

根据IP地址获取MAC地址。

#### RARP： 反向地址转换协议 *Reverse Address Resolution Protocol*

根据MAC地址获取IP地址。

#### ICMP：控制报文协议 *Internet Control Message Protocol*

主机、路由器之间传递控制消息，由IP提供服务。

#### IGMP：组管理协议 *Internet Group Management Protocol*

主机、组播路由器之间传递分组消息，由IP提供服务。

### 传输层

#### TCP：传输控制协议 *Transmission Control Protocol*

- 面向连接，可靠通信；
- 一对一；
- 头大（20字节）；
- 有流量、拥塞控制；
- 面向字节流。

#### UDP：用户数据报协议 *User Datagram Protocol*

- 无连接，快速；
- 一对一，一对多，多对多；
- 头小（8字节）；
- 网络拥堵不影响发送速率；
- 面向报文。

### 应用层

#### HTTP：超文本传输协议 *Hypertext Transfer Protocol*

基于Client/Server模式，面向连接。

#### DNS：域名系统 *Domain Name System*

将域名与IP一一映射的数据库。

#### DHCP：动态主机配置协议 *Dynamic Host Configuration Protocol*

自动获得分配的IP与子网掩码。

## 常考试题

### 传输层

#### TCP建立连接与断开连接

#### 建立连接：三次握手

[![handshake](https://github.com/AlbertoWang/java-noob/raw/master/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C.assets/handshake.png)](https://github.com/AlbertoWang/java-noob/blob/master/计算机网络.assets/handshake.png)

1. Client发起建立连接请求`[SYN]`，序列号`seq=x`，发送完进入`SYN_SEND`状态；
2. Server收到请求后，发送对应`ack=x+1`的应答`[ACK]`与`seq=y`的建立连接请求`[SYN]`，发送完进入`SYN_RCVD`状态；
3. Client收到请求后，发送对应`ack=y+1`的应答`[ACK]`并进入`ESTABLISHED`状态；
4. Server收到请求后，进入`ESTABLISHED`状态，TCP连接建立完成。

#### 断开连接：四次挥手

[![handwave](https://github.com/AlbertoWang/java-noob/raw/master/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C.assets/handwave.png)](https://github.com/AlbertoWang/java-noob/blob/master/计算机网络.assets/handwave.png)

1. Client发送断开连接请求`[FIN]`，序列号`seq=x`，发送完进入`FIN_WAI_1T`状态；
2. Server收到请求后，发送对应`ack=x+1`的应答`[ACK]`，发送完进入`CLOSE_WAIT_1`状态，等待之前连接中传输中的数据传输完成；
3. Client收到请求后，进入`FIN_WAIT_2`状态，等待服务器发送关闭连接的请求；
4. Server传输完数据打算关闭连接时，发送断开连接请求`[FIN]`，序列号`seq=y`，发送完进入`LAST_ACK`状态等待Client的通知；
5. Client收到请求后，发送对应`ack=y+1`的应答`[ACK]`，发送完进入`TIME_WAIT`状态，等待Server可能继续发送的数据；
6. Server收到请求后，关闭连接并进入`CLOSED`状态；
7. Client在等待固定时间后，如果没收到Server的其他数据，说明Server已成功关闭连接，自己也进入`CLOSED`状态。

### 应用层

#### HTTP数据包内容

具体的header可见[这里](https://www.runoob.com/http/http-header-fields.html)，具体的状态码可见[这里](https://www.runoob.com/http/http-status-codes.html)。

#### 请求报文

1. 请求方法method：GET、POST、DELETE、UPDATE等；
2. URL；
3. 协议版本：HTTP/1.0、HTTP/1.1；
4. 头部字段header：Content-Type （请求与实体对应的MIME信息）、Authorization（HTTP授权证书）、Connection（是否保持长连接）等；
5. 请求正文：POST请求中的body部分。

#### 响应报文

1. 协议版本；
2. 状态码：200、500、404、403等；
3. 响应正文：请求的body部分。

### 浏览器收到URL到展示页面的过程

1. DNS域名解析获取IP地址；
2. 建立TCP连接；
3. 发送HTTP请求；
4. Server处理请求并返回HTTP报文；
5. 浏览器解析渲染页面。

### DNS域名解析过程

[![img](https://github.com/AlbertoWang/java-noob/raw/master/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C.assets/dns.png)](https://github.com/AlbertoWang/java-noob/blob/master/计算机网络.assets/dns.png)

左图为迭代查询（查找过程全靠本地DNS跑腿），右图为递归查询（所有服务器都要跑腿）。

#### 迭代查询

1. 查询本地DNS服务器，找到了就直接返回缓存记录；
2. 本地DNS服务器找不到，找根服务器；
3. 根服务器返回域名归属.com，本地DNS服务器继续找.com服务器；
4. .com服务器返回返回域名归属baidu.com，找baidu.com服务器；
5. baidu.com服务器返回真实IP地址给本地DNS服务器。

#### 递归查询

1. 查询本地DNS服务器，找到了就直接返回缓存记录；
2. 本地DNS服务器找不到，找根服务器；
3. 根服务器找域名归属的.com服务器；
4. .com服务器找域名归属的baidu.com服务器；
5. baidu.com服务器返回真实IP地址给.com服务器，再一级一级递归返回。

### HTTP协议与HTTPS协议

- HTTPS协议需要申请证书（由数字证书认证机构CA颁发），不能在同一IP地址上绑定多个域名；
- HTTPS工作流程：
  1. 建立TCP连接；
  2. Client验证Server的数字证书；
  3. 协商加密算法、密钥；
  4. SSL安全加密隧道协商完成；
  5. 网页以加密方式传输，对称加密保证加密，hash算法保证不被篡改数据。

|        | HTTP                       | HTTPS                                 |
| ------ | -------------------------- | ------------------------------------- |
| 安全性 | 明文传输                   | 对称加密+hash                         |
| 速度   | 快，只有TCP建立连接的3个包 | 慢，除了TCP连接包外还有SSL握手的9个包 |
| 端口   | 80                         | 443                                   |

### 反向代理 *Reverse Proxy*

- 含义

  反向代理是指使用代理服务器接受请求，并将该请求转发给内部服务器，并将内部服务器的结果返回给发起请求的客户端，代理服务器对外表现为一台服务器。

- 负载均衡

  将外部请求动态转发给内部服务器达到负载均衡的目的。

- 缺点

  代理服务器需要建立两个连接（对外客户端和对内服务器），可能会成为瓶颈。

### GET 与 POST



|          | GET                        | POST                       |
| -------- | -------------------------- | -------------------------- |
| 数据位置 | 放在HTTP协议头（URL）      | 放在HTTP包（Request Body） |
| 数据大小 | 2KB                        | 理论无限，80～100KB        |
| 数据类型 | 仅限ASCII                  | 无限制                     |
| TCP报文  | 发送一个，请求和数据在一起 | 发送两个，先请求后数据     |
| 回退情况 | 无害                       | 再次提交请求               |
|          |                            |                            |

## TCP流量控制

可变滑动窗口

## TCP拥塞控制

快重传

快恢复

慢启动

## 网络安全

**攻击方式**

- 扫描和探测：知道服务器开放的端口服务，如果知道这个服务漏洞，可以攻击
- 监听：截获发送给服务器的数据从而解析用户密码信息。有些网络通过以太网组播，这很容易被监听
- 拒绝服务：通过大量请求瘫痪服务器处理资源，从而造成服务器不能相应正常用户请求
- 恶意软件：木马、病毒、弹窗等恶意软件
- 缓冲区溢出：Linux内核读取外部设备往往（网卡、磁盘）都会使用缓冲区来缓存数据（网卡的ringbuffer，磁盘的内核缓冲区4M），这会传递给设备一个缓冲区指针，用于外部设备（网卡、磁盘）保存数据到缓冲区，而C语言是缓冲区不安全的语言，他不会自动检查数组或者指针的边界，需要用户程序自己编写检查数组边界的条件，但是这往往会被一些程序员忽略，从而造成缺乏缓冲区检查。缓冲区溢出就会造成访问超过数组边界的内存访问，这种情况发生轻者会覆盖正常的数据，重者黑客将恶意代码通过缓冲区溢出植入，并且溢出正常的代码执行位置，覆盖进程执行代码，就会造成在调度的时候执行黑客的恶意代码，如果这个恶意代码能够修改用户权限，创建了一个黑客超级用户，那么黑客可以任意访问服务器资源。

## 输入URL到显示网页的过程

1. DNS域名解析获取IP地址
2. 浏览器通过IP地址建立和对应主机的连接
3. 浏览器发送请求，后台处理请求并返回响应
4. 浏览器获取响应并渲染

1. DNS域名解析过程

## 传输层协议 TCP/UDP

[计算机网络全](http://docs.52im.net/extend/docs/book/tcpip/vol1/18/)

[TCP IP头部](http://www.51testing.com/html/66/138366-216709.html) 

[TCP IP头部](https://www.cnblogs.com/limanjihe/p/10134385.html#:~:text=IP%E6%95%B0%E6%8D%AE%E5%8C%85%E6%98%AF%E4%B8%80,%E7%9A%84%E6%9C%80%E5%A4%A7%E9%95%BF%E5%BA%A6%E4%B8%BA65535B%E3%80%82)

[IP偏移量](https://blog.csdn.net/cumirror/article/details/4869770)

[Time_wait状态](https://www.cioage.com/article/623158.html)

[Time_wait状态](https://draveness.me/whys-the-design-tcp-time-wait/)

[TCP流量控制](https://blog.csdn.net/guoweimelon/article/details/50879588#:~:text=ARQ%E5%8D%8F%E8%AE%AE%EF%BC%8C%E5%8D%B3%E8%87%AA%E5%8A%A8%E9%87%8D,%E5%AE%83%E9%80%9A%E5%B8%B8%E4%BC%9A%E9%87%8D%E6%96%B0%E5%8F%91%E9%80%81%E3%80%82)

[TCP拥塞控制](https://segmentfault.com/a/1190000040600606#:~:text=%E6%8B%A5%E5%A1%9E%E7%AA%97%E5%8F%A3%E6%98%AF%E5%86%B3%E5%AE%9A%E4%BB%BB%E4%BD%95,%E5%A4%9A%E5%B0%91%E6%8B%A5%E5%A1%9E%E6%9D%A5%E8%AE%A1%E7%AE%97%E7%9A%84%E3%80%82)

[TCP拥塞控制](https://zhuanlan.zhihu.com/p/37379780)

[HTTP/HTTPS TCP/IP协议栈](https://zhangbinalan.gitbooks.io/protocol/content/httpqi_ta.html)

[MSS MTU](https://draveness.me/whys-the-design-tcp-segment-ip-packet/)

[TCP粘包](https://draveness.me/whys-the-design-tcp-message-frame/)

[TCP粘包](https://segmentfault.com/a/1190000039691657)

1. 三次握手，四次挥手，为什么三次握手，为什么要四次挥手，四次挥手中什么是 time_wait 状态 ？ close-wait 状态?time_wait状态什么场景下过多 ， 会造成什么问题？

   1. 三次握手
      1. 客户端设置SYN=1，初始化一个序号X，发送给服务端，进入SYN_SENT状态
      2. 服务端接收到请求，从LISTEN状态进入SYN_RECEIVED状态，设置ACK=1，确认好ack=X+1，SYN=1，初始化一个序号Y，发送给i客户端
      3. 客户端接收到响应，进入ESTABLISTED状态，设置ACK=1，确认号ack=Y+1，发送给服务端
      4. 服务端接收到响应，进入ESTABLISH状态

   2. 为什么三次握手，能否使用四次握手

      使用两次握手的一个问题是，客户端发送请求和得到响应则客户端知道服务端接收和发送请求都行，但是服务端不知道客户端接收请求是否可行，因此不能使用两次握手；另外一个问题是延迟到来的连接请求可能会创建一个连接而实际上客户端已经完成了连接请求，这造成服务端连接的浪费。

      使用四次握手是在服务端发送ACK响应和SYN同步请求时分开来发，这种情况是可以的，但是合并他们可以增加效率。

      综上，使用三次握手

   3. 四次挥手

      1. 客户端设置FIN=1，初始化序号为X，发送给服务端，进入FIN_WAIT_1状态
      2. 服务端接收到请求，进入CLOSE_WAIT状态，设置ACK=1，确认号ack=X+1，发送给客户端
      3. 客户端接收到响应，进入FIN_WAIT_2状态
      4. 服务端发送完数据以后，设置FIN=1，初始化一个序号X，发送给客户端，进入LAST_ACK状态
      5. 客户端收到请求，设置ACK=1，确认好为X+1，发送给服务端，进入TIME_WAIT状态，等待2MSL之后进入CLOSED状态
      6. 服务端接收到ACK响应之后进入CLOSED状态

   4. 为什么四次挥手，为什么CLOSE_WAIT状态

      在客户端发送FIN请求之后，只能说明客户端数据发送完了，服务端不一定发送完数据，这个时候CLOSE_WAIT状态，服务端只发送对客户端请求关闭的响应，等待自己发送完数据之后再发送关闭连接FIN请求

   5. TIME_WAIT状态

      也称为2MSL状态，MSL是Maximum Segment Lifetime的缩写，代表最大段生存周期，标明IP数据包再网络中存活的最大时间，再IP数据包里可以通过TTL（Time To Live）进行设置。TIME_WAIT状态是请求关闭方才能所处的状态。TIME_WAIT状态主要有两个方面的原因：

      1. 防止过期的数据到来。在TIME_WAIT状态对于过期到来的数据会直接丢弃并返回RST
      2. 确保可靠关闭TCP连接。当服务端没有收到ACK，就会重发FIN，客户端重发ACK，从而保证可靠关闭

      为什么2被MSL（这是ACK发送到被响应得到的在网络中的最大生存时间）

   6. TIME_WAIT过多

      在高并发情况下会出现很多TIME_WAIT的端口，这样会造成很多端口处于TIME_WAIT状态，造成建立新连接失败。解决方法

      1. 对于客户端，设置HTTP的connection为keep-alive，让服务端可以复用连接
      2. 对于服务端，一个是设置小的TIME_WAIT时间，另外一个是允许处于TIME_WAIT状态的Socket被重用

2. TCP怎么保证连接的可靠性（ARQ 、 流量控制 、 拥塞控制 、 校验和），说说拥塞控制（快重传、快恢复）

   1. 校验和
   2. 确认机制，停止等待协议每个发送的数据都能收到对应的确认
   3. 超时重传机制，当一个数据丢失可以被重传
   4. 流量控制，滑动窗口协议控制发送方发送速率，防止接收方缓冲区溢出
   5. 对失序的数据进行排序
   6. 丢弃重复的数据

3. TCP和UDP的区别，他们的使用场景

   TCP是有连接的、可靠的、面向字节流的传输层协议，UDP是无连接的、不可靠的、面向数据报的传输层协议

   TCP有流量控制和拥塞控制，UDP没有

   TCP因为是面向字节流的，有产生粘包的风险，而UDP是面向数据报的，他的UDP头部有这个数据报的大小，无粘包

   TCP只能一对一连接，而UDP可以广播和多播

   TCP因为可靠性来源多种方式，而UDP只有基本的校验和

   UDP比TCP速度块

   应用场景：

   TCP用于需要可靠传输的协议，比如HTTP，HTTPS，FTP

   UDP可用于对传输速度有要求但是对数据质量无要求的场景，比如视频流、IP电话
   
4. TCP流量控制

   [停止等待协议](https://zhuanlan.zhihu.com/p/405550972)

   [回退N协议](https://zhuanlan.zhihu.com/p/405573476)

   [选择重传协议](https://zhuanlan.zhihu.com/p/405575394)

   流量控制是控制发送方流量以防止接收方缓冲区溢出，是TCP保证可靠通信的一个机制

   使用的滑动窗口协议：

   发送方和接收方都有自己的窗口，在建立通信的时候，接收方会返回自己的窗口大小字段，发送方获得这个窗口和拥塞窗口比较，从而选择出自己的发送窗口

   发送的数据都被编号，每次发送方发送多个分组，收到ACK后努力把窗口向前移动到第一个没有被确认的分组，删除已经确认的分组，发送新到来的分组，每个分组会设置一个超时计时器，如果超时没有收到确认，就会重传这个分组

   接收方将接受分组，然后发送确认。

   1. 停止等待协议

      发送方窗口为1，接收方窗口为1

      分组标号为0101，使用一位比特标号

      发送方发送一个分组之后只有等到接收到这个分组的确认之后才会发送新一个分组，超时就会重传

      接收方接收到一个分组之后发送一个ACK确认分组，如果分组有差错，那么发送一个NAK加快重传或者直接抛弃等待发送方重传

   2. 回退N协议

      使用n个比特对分组进行标号，如果为2，则分组标号为01230123

      发送窗口大小
      $$
      1<W_T \leq 2^n-1
      $$
      接收窗口大小为1

      发送窗口为1则则变成停止等待协议，发送窗口超过限制就会让接收窗口无法分辨新旧分组

      发送窗口一次发送所有分组，接收窗口按序确认，逐一确认或者累计确认

      发送窗口接收到一个确认之后会努力把窗口向前移动到没有确认的分组，并且删除已经确认的分组，发送新进入窗口的分组

      接收窗口接收到一个分组，判断是否按序到达的分组，如果是就移动，如果不是就丢弃，并且发送重复确认之前到达的分组，可以让接收方快重传，当一个分组超时之后，他会重传他后面的所有的分组。

   3. 选择重传协议

      使用n个比特对分组进行标号，如果为2，则分组标号为01230123

      发送窗口大小
      $$
      1<W_T \leq 2^{(n-1)}
      $$
      接收窗口大小
      $$
      1<W_R \leq W_T
      $$
      如果发送窗口大小超过上限，那么会导致接收窗口无法分辨新旧分组

      发送窗口发送所有分组，每个分组都有一个超时计时器，接收窗口逐一确认，不能累计确认

      发送窗口接收到一个ACK之后努力移动到没有确认的分组，删除确认的分组，发送新的分组

      接收方接收到一个数据后努力移动到没有到达的分组，提交已经到达的分组

      发送方超时重传未确认的分组

      选择重传协议比前面两个要信道利用率更高，但是有缓存开销

5. TCP拥塞控制

   拥塞控制是控制网络负载，防止发送方像网络注入过多分组

## 应用层协议 HTTP/HTTPS

### HTTP和HTTPS

1. HTTP和HTTPS区别

   1. HTTP使用端口80，HTTPS使用端口443
   2. HTTP是明文传输，HTTPS运行在SSL之上，添加了加密和认证机制，更加安全
   3. HTTPS因为加密解密会带来巨大的CPU和内存开销
   4. HTTPS通信需要整数，一般想认证机构（CA）购买

2. HTTP1，HTTP1.1，HTTP2，HTTP3 区别

   [HTTP各版本特征](https://network.51cto.com/article/628901.html)

   HTTP1.0

   - 无状态（服务器不跟踪客户单也不记录过去的连接状态）、无连接（浏览器每个请求都要重新建立TCP连接，请求完就关闭）协议
   - 短连接：每次请求都要重新建立TCP连接
   - 请求报文的请求头没有host字段
   - 不允许断点续传，不能传输对象的一部分，只能传输整个对象

   HTTP1.1

   - 长连接：在请求报文的请求头的connection域设置keep-alive可以使用长连接
   - 请求管道化
   - 增加缓存处理：请求头增加Cache-control字段
   - 请求头增加Host字段（使得一个服务器可以创建多个web站点），支持断点传输
   - 由于长连接会给服务器造成压力

   HTTP2.0

   - 使用二进制分帧
   - 压缩头部，双方各自维护一个header的索引表，通过发送key来缩减头部大小
   - 使用多路复用，使用多个stream，每个stream又分帧传输，使得一个TCP连接处理多个http请求
   - 服务器推送

   HTTP3.0

   - 传输层使用基于UDP协议的QUIC协议
   - 减少了TCP三次握手时间，TLS（SSL）握手时间
   - 解决了HTTP2.0前一个Stream丢失而阻塞后一个Stream的问题
   - 优化了重传策略，重传包编号和原包不同，降低后续重传计算的开销
   - 连接迁移，不适用TCP四元组来确定一个连接，而是用一个64位随机数确定一个连接
   - 优化流量控制

3. HTTPS加密过程

   1. 客户端发送请求，并发送自己支持的加密规则，包括对阵加密、非对称加密和摘要算法

   2. 服务端从请求中选择加密算法和Hash算法，并将自己的身份信息以证书的形式发送给客户端，证书包括网站网址、加密公匙、颁发机构等信息

   3. 客户端验证证书是否合法性，包括证书是否过期、颁发机构（CA）是否可靠、公匙能否正确认证”发行者的数字签名“、证书中的域名是否和服务器实际域名相符

      如果证书不合法，就返回警告给服务器处理

      如果证书合法，客户端初始化一个随机密匙，使用公匙进行加密；使用Hash算法对握手消息计算摘要，并使用未加密的随机密匙进行加密；之后把加密后的随机密匙和摘要发送给服务端

   4. 服务端使用私钥解密加密的随机密匙，得到对称加密的密匙，用对称加密的密匙解密摘要，并验证是否和握手消息一致，如果一致，那么使用对称加密的密匙加密握手消息发送给客户端

   5. 客户端使用对称加密密匙解密并验证摘要，如果一致，则握手结束。之后传输的数据都是用对称加密的密匙进行加密。

      整个过程非对称加密只是对随机密匙进行加密，对称加密是对真正发送的数据进行加密，Hash算法用于验证数据完整性

   - 对称加密和非对称加密区别
     - 对称机密：加密和解密使用相同的密匙，算法有DES、RC2、RC4
     - 非对称加密：加密和解密分别使用公钥和私钥，算法有RSA
     - 区别：对称加密速度快，适用于大量数据加密；非对称加密安全性高，因为不传送私钥
   - 数字签名，摘要算法
     - 数字签名：发送者用私钥进行签名，接收者用公钥进行验证，如果验证通过接收者有理由相信发送者一定是A
     - 摘要算法：MD5，SHA

4. Cookie和Session的区别

   Cookie是客户端保持状态的方案，Session是服务端保持状态的方案

   Cookie保存在客户端，每次请求会一起提交Cookie；Session保存在服务端，通过检索SessionID查看状态。保存SessionID可以采用Cookie，也可以使用URL重写机制保存会话ID到URL中

### get和post方法

1. 区别

   1. get方法参数放到URL里，而post方法参数放到请求体里
   2. get方法请求体为空，post方法请求体不为空
   3. get方法长度是有限的，2K，post方法长度不限
   4. get方法要求幂等性，也就是同样的请求具有相同的副作用，而post请求没有。这样get方法适合查询，而post方法 适合增删改
   5. get方法和post方法底层都是TCP/IP协议，只是规定不同
   6. get方法只能使用ASCII编码，而post请求没有要求
   7. get方法比post更不安全，get请求可以被浏览器缓存收藏

2. 请求内容，响应内容，响应状态码类别

   1. 请求报文

      请求行：请求方法，URL字段，协议版本

      请求头：键值对（Accept-客户端可以接受的资源类型，Accept-Language-接受资源的语言，Accept-Encoding-接受资源的编码，User-Agent-客户端

      空行

      请求体

   2. 响应报文

      状态行：协议版本，状态码和状态描述

      响应头：

      空行

      响应体

   3. 响应状态码

      1. 2xx，操作成功，200 ok
      2. 3xx，重定向，301 永久重定向
      3. 4xx，客户端错误，401 bad request，402 没授权，403 禁止，404 not found
      4. 5xx，服务端错误，500 服务端内部错误，501服务不可用

## OSI模型 TCP/IP模型

[OSI TCP/IP模型](https://www.bilibili.com/read/cv7082441/)

OSI模型

1. 应用层：是特定的应用程序，数据单位是报文，TCP/IP把上面三层合并，得到应用层，应用层协议包括HTTP、DNS、FTP、TELNET、SMTP等
2. 表示层：负责数据的加密解密和压缩等，数据单位是报文
3. 会话层：管理会话（比如何时建立连接，何时关闭连接，会话时长），数据单位是报文
4. 传输层：建立端到端的连接，数据单位是数据段，协议有TCP UDP
5. 网络层：负责寻址和路由，数据单位是报文，协议有ARP、RARP、IP、ICMP、IGMP
6. 数据链路层：控制物理层的协议，包括如何访问和共享介质、如何标识设备、如何封装成帧，单位是帧
7. 物理层：传播电气信号和数据比特，包含多种物理介质，数据单位是位

# Java程序设计

**Java书籍**

Java 标准规范：[Java SE8 ](https://docs.oracle.com/javase/specs/index.html) [JDK 8](https://docs.oracle.com/javase/specs/jls/se8/jls8.pdf)   [JVM8](https://docs.oracle.com/javase/specs/jvms/se8/jvms8.pdf)

[Java核心技术 基础知识]("C:\Users\cheng\Desktop\JavaBackend\书籍\Java\Java核心技术 卷1 基础知识 原书第9版 完整中文版 .pdf")

[深入理解Java虚拟机]("C:\Users\cheng\Desktop\JavaBackend\书籍\Java\深入理解Java虚拟机：JVM高级特性与最佳实践（第3版）周志明.pdf")

[Java并发编程实战]("C:\Users\cheng\Desktop\JavaBackend\书籍\Java\Java并发编程实战（中文版）.pdf")

## Java实验

### 实验1-Java线程怎么映射到Linux内核线程

[(108条消息) Java线程如何映射到操作系统内核线程_超人汪小建(seaboat)的博客-CSDN博客_java 线程映射](https://blog.csdn.net/wangyangzhizhou/article/details/109112339)

[Java线程与Linux内核线程的映射关系（转） - 走看看 (zoukankan.com)](http://t.zoukankan.com/gyc567-p-11030234.html)

Linux支持进程（fork系统调用创建）、线程（轻量级进程，native posix thread library(NPTL)的pthread_create（实际调用sys_clone系统调用，fork调用sys_fork系统调用，vfork掉要那个sys_vfork系统调用，这三者底层都需要调用clone函数来创建进程，这三者的区别在于共享的数据不同在调用clone的时候会使用不同的共享参数）。Linux所有并不区分进程和线程，线程也是轻量级进程，可以说Linux都是线程。用户程序的线程映射到Linux内核线程的方式有两种，一种是多对一，这依赖用户函数库来调度各个线程，多个线程被映射到一个内核线程，同一时刻只有一个内核线程执行用户线程，这种方式的好处是调度开销小，但是如果一个线程发生阻塞那么其他线程也会被阻塞；另外一种方式是一对一，用户进程的每个线程都对应Linux内核线程的一个，线程调度依赖内核线程的调度器调度schedule，因为Linux是运行在多核系统，同一时间有多个CPU运行，那么有可能同一时间一个进程的多个线程都在运行，而且发生阻塞的时候也不会阻塞整个进程的其他线程，这种映射方式依赖Linux内核调度，需要切换CPU上下文这些东西，所以开销是比用多对一映射要高的。 

Java线程依赖JVM管理，但是Java线程与内核线程是一一对应关系，在JVM调用Threada.run的时候，这个函数会调用Native Posix Thread Library的pthread_create函数创建一个新的线程。Java程序的线程的调度依赖Linux内核线程调度器的调度，但是Java程序可以控制这个调度过程，当Java程序阻塞一个线程的时候，他会调用NPTL的pthread_wait等函数来阻塞，NPTL实际上是Linux提供的C语言运行函数库，可以被应用程序链接使用。从这个层面来说，Linux通过NPTL提供的函数库可以被其他语言调用，本质上是因为其他语言编译器会把其他语言编译成同样的汇编语言和连接成同样的机器语言。而在汇编语言中，他会调用Linux内核提供的函数（如NPTL，C语言标砖函数库，系统调用）等等用来进行连接操作，这样虽然不同语言写的不同的代码被不同的编译器编译，但是他们最后新城的汇编代码和机器语言代码相同的，最后都会使用到Linux内核提供的函数或者系统调用服务。

Java程序的线程和Linux内核一一对应，这和C语言一样的，C语言也是和Linux内核线程一一对应，Java语言使用在调用Thread.run()的时候会调用NPTL的Linux函数的pthread_create，而C语言变成可以直接调用pthread_create创建线程，Java语言使用thread.wait库函数调用调用NPTL的pthread_wait函数，C语言直接调用pthread_wait函数来阻塞线程。逻辑是一样的。

Java程序在被Linux执行函数系统调用sys_execve加载到内存的时候，会释放元进程分配的页面和清空原进程的页表并设置为p位位空，同时修改进程PCB中的ldt表的基地址和限长，复位信号，复位打开文件表，重置可执行程序i节点，然后在设置内核栈中返回系统调用的cs:ip指向程序执行点，设置用户空间ss:esp为压入了参数和环境变量的用户栈底部，最后发挥sys_execve系统调用，这个时候会返回到我们重新设置的可执行程序的入口地址（这个入口地址保存在可执行程序头的a_entry里面，这是一个相对代码段的逻辑偏移，是一个逻辑地址）。通过这个过程先加载JVM java虚拟机程序，他会把java文件重新编译为可执行文件的机器码，然后重新调用sys_execve系统调用装载这个可执行程序进行执行。

在虚拟机执行Java程序的时候，首先创建的进程是fork创建的，这个进程会代码段数据段堆段栈段给进程，会打开文件，保存信号，保存根目录i节点和工作目录等等。当JVM调用到thread.run创建并执行一个线程的时候，汇编代码底层实际调用的是pthread.create函数来创建一个新的Linux内核线程，使用pthread_create函数创建的内核线程和fork创建的线程的不同在于他会设置代码段数据段堆段的页面共享，同时共享打开文件，信号，根目录和工作目录等等。这样我们就可以实现Java子线程和Linxu内核线程的映射了。同时我们使用fork创建的线程会被当成主线程，这个主线程会创建一写守护线程，守护线程的调度依赖Linxu内核线程调度，守护线程也是一个Linux内核线程，守护线程需要等所有的进程的非守护线程结束之后才能结束，所以我们可以用一个信号来标明一个守护线程，在Java程序中使用一个函数setDeamon来触发一个Linxu信号设置系统调用，他会设置守护进程的信号。当发生时钟中断的时候会检查所有进程的信号，这个时候我们看到一个进程信号是守护进程，那么我们进入守护进程信号处理函数，他检查所有进程，如果发现这个进程的父进程和自己的父进程一样（pthread_create创建的线程共享pid也就是进程号）并且他不是守护进程并且他处于僵死状态，或者没有找到与自己父进程号pid一样的进程，那么守护进程就知道他的任务的其他程序都执行完毕并且关闭了，所以他会调用sys_exit系统调用来关闭自己。

Java的内存管理部分是针对堆内存的，java共享的内存有代码段数据段和堆段，但是前两个部分数据基本不会发生内存容量的变化，而只有堆段会发生内存容量的变化，同时堆上的数据会被Java程序的主线程进行管理。Java线程的栈是私有的，不会被管理，但是堆是公有的，会被释放内存（因为jJava没有释放内存的函数的概念，这在C语言中是存在delete函数调用free_page的系统调用，将传递的用户空间中的堆内存进行释放操作，恢复被释放的内存的页表为空从而实现这个页可以再次被分配堆数据，但是这个方式依赖用户程序主动释放内存，有时候用户忘了释放内存就会引发内存泄漏，让一个没有被使用的变量长期占用堆区的页表而这个页表不能被用来重新分配内存，所以引入了自动内存管理的概念，而JVM就是实现了一个自动内存管理的守护进程，他会定期检查内存堆区的变量，查看他们是否有被引用，如果没有引用就会回收这个内存（调用free_page系统调用函数，对变量表中的共享变量进行回收操作）。

上诉的这些推断都是我基于Linxu内核提供的服务进行的推断，具体怎么执行的我还要通过Java虚拟机实现来查看。上诉的推断涉及到Java多线程、JVM内存回收自动内存管理等操作，我实际上还差Linux进程同步相关的讨论（除了信号、信号量、共享内存），但是消息队列和管道的处理，此外还有CAS原子操作的认识。

## Java web/Spring

> # Web 开发
>
> ## JavaBean
>
> 是一个对数据进行封装的Java类，方便数据的传输。里面对实例变量设置了读写属性（getter和setter方法）
>
> ```java
> public class person{
> 	private String name ;
> 	
> 	public String getName(){
> 		return name ;
> 	}//读属性
> 	public void setName(String name){
> 		this.name = name ;
> 	}//写属性
> }
> ```
>
> 
>
> ## BS架构
>
> ### HTTP请求
>
> HTTP请求和响应都由HTTP Header和HTTP Body构成，其中HTTP Header每行都以`\r\n`结束。如果遇到两个连续的`\r\n`，那么后面就是HTTP Body。浏览器读取HTTP Body，并根据Header信息中指示的`Content-Type`、`Content-Encoding`等解压后显示网页、图像或其他内容。
>
> 通常浏览器获取的第一个资源是HTML网页，在网页中，如果嵌入了JavaScript、CSS、图片、视频等其他资源，浏览器会根据资源的URL再次向服务器请求对应的资源。
>
> 1. HTML是用来定义网页的文本，HTTP是在网络上传输HTML的协议，用于浏览器和服务器的通信
>
> 2. Browser请求页面流程
>
>    1. 与服务器简历TCP连接
>    2. 发送HTTP请求
>    3. 收取HTTP响应，把网页在浏览器中显示出来
>
> 3. HTTP请求头
>
>    ```
>    客户端请求HTTP头
>    
>    GET /home.html HTTP/1.1
>    Host: developer.mozilla.org
>    	Host表示浏览器正在请求的域名
>    User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:50.0) Gecko/20100101 Firefox/50.0  
>    	标识客户端本身
>    Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
>    	表示浏览器能接收的资源类型
>    Accept-Language: en-US,en;q=0.5
>    	表示浏览器偏好的语言
>    Accept-Encoding: gzip, deflate, br
>    	表示浏览器可以支持的压缩类型
>    Referer: https://developer.mozilla.org/testpage.html
>    Connection: keep-alive
>    Upgrade-Insecure-Requests: 1
>    If-Modified-Since: Mon, 18 Jul 2016 02:36:04 GMT
>    If-None-Match: "c561c68d0ba92bbeb8b0fff2a9199f722e3a621a"
>    Cache-Control: max-age=0
>    ```
>
>    ```
>    服务器响应HTTP头
>    
>    HTTP/1.1 200 OK
>    Content-Type: text/html
>    	表示该响应内容的类型
>    Content-Length: 21932
>    	表示该响应内容的长度（字节数）
>    Content-Encoding: gzip
>    	表示该响应压缩算法
>    Cache-Control: max-age=300
>    	指示客户端应如何缓存
>    
>    <html>...网页数据...
>    ```
>
>    ```
>    响应代码
>    
>    200 OK：表示成功；
>    301 Moved Permanently：表示该URL已经永久重定向；
>    302 Found：表示该URL需要临时重定向；
>    304 Not Modified：表示该资源没有修改，客户端可以使用本地缓存的版本；
>    400 Bad Request：表示客户端发送了一个错误的请求，例如参数无效；
>    401 Unauthorized：表示客户端因为身份未验证而不允许访问该URL；
>    403 Forbidden：表示服务器因为权限问题拒绝了客户端的请求；
>    404 Not Found：表示客户端请求了一个不存在的资源；
>    500 Internal Server Error：表示服务器处理时内部出错，例如因为无法连接数据库；
>    503 Service Unavailable：表示服务器此刻暂时无法处理请求。
>    ```
>
> 4. HTTP协议基于TCP协议，可以通过实现TCP的Socket编程实现HTTP协议，实现服务器端框架
>
>    ```java
>    //使用TCP的Socket编程实现HTTP协议
>    
>    package myPackage;
>    
>    import java.io.BufferedReader;
>    import java.io.BufferedWriter;
>    import java.io.IOException;
>    import java.io.InputStream;
>    import java.io.InputStreamReader;
>    import java.io.OutputStream;
>    import java.io.OutputStreamWriter;
>    import java.net.ServerSocket;
>    import java.net.Socket;
>    import java.nio.charset.StandardCharsets;
>    
>    public class Server {
>    	public static void main(String[] args) throws IOException{
>    		try (ServerSocket ss = new ServerSocket(8081)) {
>    			System.out.println("Server running");
>    			for(;;) {
>    				Socket sock = ss.accept() ;
>    				
>    				System.out.println("connect from " + sock.getRemoteSocketAddress() ) ;
>    				Thread t = new Handler(sock) ;
>    				t.start();
>    			}
>    		}
>    		
>    	}
>    }
>    class Handler extends Thread{
>    	Socket sock ;
>    	
>    	public Handler(Socket sock) {
>    		this.sock = sock ;
>    	}
>    	
>    	public void run() {
>    		try(InputStream input = this.sock.getInputStream() ){
>    			try( OutputStream output = this.sock.getOutputStream() ){
>    				handle(input, output ) ;
>    			}
>    		} catch (IOException e) {
>    			// TODO Auto-generated catch block
>    			e.printStackTrace();
>    		}
>    		System.out.println("client disconnect") ;
>    	}
>    	
>    	private void handle(InputStream input, OutputStream output)throws IOException{
>    		System.out.println("process new http request") ;
>    		var reader = new BufferedReader(new InputStreamReader(input, StandardCharsets.UTF_8)) ;
>    		var writer = new BufferedWriter(new OutputStreamWriter(output, StandardCharsets.UTF_8)) ;
>    		
>    		boolean requestOk = false ;
>    		
>    		String first = reader.readLine() ;
>    		if( first.startsWith("GET / HTTP/1.")) {
>    			requestOk = true ;
>    		}
>    		for(;;) {
>    			String header = reader.readLine() ;
>    			if( header.isEmpty() ) {
>    				break ;
>    			}
>    			System.out.println(header) ;
>    		}
>    		
>    		System.out.println(requestOk? "Ok":"Error") ;
>    		if( !requestOk) {
>    
>    			writer.write("HTTP/1.0 404 Not Found\r\n") ;
>    			writer.write("Content-Length: 0 \r\n") ;
>    			writer.write("\r\n") ;
>    			writer.flush() ;
>    		}else {
>    			String data = "<html><body><h1>Hello, world</h1></body></html>" ;
>    			int length = data.getBytes(StandardCharsets.UTF_8).length ;
>    			writer.write("HTTP/1.0 200 OK\r\n") ;
>    			writer.write("Connection: close\r\n") ;
>    			writer.write("content-Type: text/html\r\n") ;
>    			writer.write("Content-Length: "+ length + "\r\n") ;
>    			writer.write("\r\n") ;
>    			writer.write(data) ;
>    			writer.flush() ;
>    		}
>    	}
>    }
>    
>    ```
>
> 5. Web服务器（Tomcat）处理HTTP协议的解析，减少了开发人员处理HTTP协议解析的底层代码，更加关注于HTTP请求本身。我们实现Servlet API接口，来实现逻辑
>
>    Servlet容器运行的Servlet的特点：
>
>    1. 只能通过Servlet容器创建Servlet实例
>    2. Servlet容器只会给每个Servlet类创建唯一一个实例
>    3. Servlet容器使用多线程执行doGet()或者doPost()方法
>
>    Servlet的注意事项
>
>    1. Servlet的实例变量会被多线程访问，要注意线程安全
>
>    2. HttpServletRequest和HttpServletResponse实例是由Sevlet容器传入的局部变量，他只能被当前线程访问，不存在多线程访问的问题
>
>    3. 在doGet()或doPost()方法中，如果使用了ThreadLocal但是没有清理，那么他的状态可能影响下次的某个请求，因为Servlet容器很可能使用线程池实现线程复用
>
>    4. 一个Webapp完全可以有多个Servlet，分别映射不同的路径，通过注解标注路径。浏览器发出的HTTP请求总是由Web Server先接收，然后，根据Servlet配置的映射，不同的路径转发到不同的Servlet。这种根据路径转发的功能我们一般称为Dispatch。映射到`/`的`IndexServlet`比较特殊，它实际上会接收所有未匹配的路径，相当于`/*`。路径映射代码如下
>
>       ```java
>       String path = ...
>       if (path.equals("/hello")) {
>           dispatchTo(helloServlet);
>       } else if (path.equals("/signin")) {
>           dispatchTo(signinServlet);
>       } else {
>           // 所有未匹配的路径均转发到"/"
>           dispatchTo(indexServlet);
>       }
>       ```
>
> ### HttpServletRequest
>
> HttpServletRequest封装了一个HTTP请求，它实际上是从ServletRequest继承而来。HttpServletRequest提供的接口方法可以拿到HTTP请求的几乎全部信息，常用的方法
>
> ```
> getMethod()：返回请求方法，例如，"GET"，"POST"；
> getRequestURI()：返回请求路径，但不包括请求参数，例如，"/hello"；
> getQueryString()：返回请求参数，例如，"name=Bob&a=1&b=2"；
> getParameter(name)：返回请求参数，GET请求从URL读取参数，POST请求从Body中读取参数；
> getContentType()：获取请求Body的类型，例如，"application/x-www-form-urlencoded"；
> getContextPath()：获取当前Webapp挂载的路径，对于ROOT来说，总是返回空字符串""；
> getCookies()：返回请求携带的所有Cookie；
> getHeader(name)：获取指定的Header，对Header名称不区分大小写；
> getHeaderNames()：返回所有Header名称；
> getInputStream()：如果该请求带有HTTP Body，该方法将打开一个输入流用于读取Body；
> getReader()：和getInputStream()类似，但打开的是Reader；
> getRemoteAddr()：返回客户端的IP地址；
> getScheme()：返回协议类型，例如，"http"，"https"；
> ```
>
> ### HttpServletResponse
>
> HttpServletResponse封装了一个HTTP响应，由于HTTP响应必须先发送Header，再发送Body，所以，操作`HttpServletResponse`对象时，必须先调用设置Header的方法，最后调用发送Body的方法。
>
> ```
> setStatus(sc)：设置响应代码，默认是200；
> setContentType(type)：设置Body的类型，例如，"text/html"；
> setCharacterEncoding(charset)：设置字符编码，例如，"UTF-8"；
> setHeader(name, value)：设置一个Header的值；
> addCookie(cookie)：给响应添加一个Cookie；
> addHeader(name, value)：给响应添加一个Header，因为HTTP协议允许有多个相同的Header；
> ```
>
> 但是，写入完毕后调用`flush()`却是必须的，因为大部分Web服务器都基于HTTP/1.1协议，会复用TCP连接。如果没有调用`flush()`，将导致缓冲区的内容无法及时发送到客户端。此外，写入完毕后千万不要调用`close()`，原因同样是因为会复用TCP连接，如果关闭写入流，将关闭TCP连接，使得Web服务器无法复用此TCP连接。
>
> **有了`HttpServletRequest`和`HttpServletResponse`这两个高级接口，我们就不需要直接处理HTTP协议。注意到具体的实现类是由各服务器提供的，而我们编写的Web应用程序只关心接口方法，并不需要关心具体实现的子类。**
>
> ### 转发和重定向
>
> **重定向**是一种web服务器升级之后地址发生改变，让浏览器可以重新获取改变之后的地址访问的一种机制。浏览器发送Get /hi请求，会流向重定向的Servlet，他将返回一个
>
> ```
> HTTP/1.1 302 Found
> Location: /hello
> ```
>
> 的响应，浏览器收到302响应之后重新发送Get /hello请求从而获得改变的资源。观察浏览器可以发现浏览器发送了两次Get请求
>
> **转发**是服务器处理逻辑发生变化，地址发生改变，当一个Get /hi 的请求到达，处理这个请求的Servlet会将处理的参数转发给另外一个Servlet处理之后返回给浏览器。
>
> 转发和重定向的区别在于转发是在服务器内部完成的，服务器只发送了一个请求。
>
> ### Session 和Cookie
>
> Session是一种基于唯一ID识别用户身份的机制。每个用户第一次访问服务器之后，会自动获得一个Session ID，并以Cookie的方式发送给浏览器，浏览器在后续访问中总是附带此Cookie，这样服务器就可以识别用户身份。如果用户在一段时间内没有访问服务器，那么Session会自动失效。
>
> 在Servlet中第一次调用`**req.getSession()**`时，Servlet容器自动创建一个Session ID，然后通过一个名为`JSESSIONID`的Cookie发送给浏览器
>
> ![](https://www.liaoxuefeng.com/files/attachments/1328781362987073/l)
>
> JSESSIONID注意事项
>
> 1. JSESSIONID`是由Servlet容器自动创建的，目的是维护一个浏览器会话，它和我们的登录逻辑没有关系；
>
> 2. 登录和登出的业务逻辑是我们自己根据`HttpSession`是否存在一个`"user"`的Key判断的，登出后，Session ID并不会改变；
>
> 3. 即使没有登录功能，仍然可以使用`HttpSession`追踪用户，例如，放入一些用户配置信息等。
>
> 使用Session的问题
>
> 1. 由于服务器把Session放在内存，在内存不足时，就会把部分不活动的Session序列化到磁盘上，这样大大降低了服务器的运行效率，因此放入Session的对象要尽可能小
>
> 2. 通常在构建服务器集群的时候，我们会使用反向代理作为网站的入口。在使用轮询进行请求分配的时候，一个在Server 1运行的Session不在Server 2 上，造成轮询分配到Session 2时用户登录状态会变成未登录。
>
>    解决这种登录状态变化的方式由两种
>
>    1. 在所有Web Server之间进行Session复制，但是这样严重消耗网络带宽，并且每个Web Server的内存均存储所有用的Session，内存使用率很低
>    2. 粘滞会话：反向代理服务器维护一个JSESSION和Web Server的映射，将请求发送到对应的Web Server上
>
>    无论采用什么机制，使用Session机制的服务器集群很难扩展，因此Session适用于中小型Web 应用
>
> 
>
> Servlet提供的HttpSession本质上是通过一个名为JSESSIONID的Cookie来跟踪用户会话的，除了这个名称以外，其他名称的Cookie我们可以任意使用
>
> 创建一个新的Cookie时，除了指定名称和值意外，通常要设置setPath("/")，浏览器根据此前缀决定是否发送Cookie，比如设置setPath("/user")，之后用户访问带有user的地址的时候浏览器才会发送Cookie。如果浏览器发送的时Https请求，服务器返回的Cookie还要设置SetSecure(true)，否则浏览器不会发送Cookie
>
> 浏览器发送请求时是否发送Cookie，取决于Cookie中是否有下面的要求：
>
> 1. URL前缀设置发送Cookie的地址
> 2. Cookie的有效期内
> 3. Cookie设置了secure时必须以https访问
>
> ## MVC架构
>
> 把Servlet看作控制器负责逻辑处理，Jsp看作视图，JavaBean看作模型的架构。这样的好处是Controller专注于业务处理，他的处理结果时Model，Model可以是一个JavaBean，也可以是一个包含多个对象的Map，Controller只负责把Model传递给View，View只负责把Model渲染出来，这样，三者职责明确，且开发更简单。基于Servlet和Jsp的MVC架构广泛应用，但是还不够灵活，还有Spring MVC开发。
>
> ## Filter过滤器
>
> Filter可以有针对性地拦截或者放行HTTP请求。
>
> Filter是一种对HTTP请求进行预处理的组件，它可以构成一个处理链，使得公共处理代码能集中到一起；
>
> Filter适用于日志、登录检查、全局设置等；
>
> 设计合理的URL映射可以让Filter链更清晰。
>
> Filter实现缓存，让重复请求不会重复计算
>
> ## Listenner监听器
>
> 任何标注为`@WebListener`，且实现了特定接口的类会被Web服务器自动初始化。上述`AppListener`实现了`ServletContextListener`接口，它会在整个Web应用程序初始化完成后，以及Web应用程序关闭后获得回调通知。我们可以把初始化数据库连接池等工作放到`contextInitialized()`回调方法中，把清理资源的工作放到`contextDestroyed()`回调方法中，因为Web服务器保证在`contextInitialized()`执行后，才会接受用户的HTTP请求。
>
> 很多第三方Web框架都会通过一个`ServletContextListener`接口初始化自己。
>
> 除了`ServletContextListener`外，还有几种Listener：
>
> - HttpSessionListener：监听HttpSession的创建和销毁事件；
> - ServletRequestListener：监听ServletRequest请求的创建和销毁事件；
> - ServletRequestAttributeListener：监听ServletRequest请求的属性变化事件（即调用`ServletRequest.setAttribute()`方法）；
> - ServletContextAttributeListener：监听ServletContext的属性变化事件（即调用`ServletContext.setAttribute()`方法）；
>
> ## Nginx反向代理Tomcat集群
>
> 反向代理是服务端代理，对客户端透明，客户端访问服务端，先经过反向代理服务器，由反向代理服务器分发请求
>
> 正向代理是客户端代理，对服务器透明，服务端访问客户端，先经过代理服务器处理。
>
> 反向代理作用：缓存，负载均衡，访问控制。
>
> 
>
> # Spring开发
>
> **Spring解决循环依赖**
>
> 到这里，Spring整个解决循环依赖问题的实现思路已经比较清楚了。对于整体过程，读者朋友只要理解两点：
>
> - Spring是通过递归的方式获取目标bean及其所依赖的bean的；
> - Spring实例化一个bean的时候，是分两步进行的，首先实例化目标bean，然后为其注入属性。
>
> 结合这两点，也就是说，Spring在实例化一个bean的时候，是首先递归的实例化其所依赖的所有bean，直到某个bean没有依赖其他bean，此时就会将该实例返回，然后反递归的将获取到的bean设置为各个上层bean的属性的。
>
> ![img](https://pic1.zhimg.com/80/v2-abe8d96f198a33fcfd51bb2108b00004_720w.jpg)
>
> ```java
> Class<A> 表示A类类类型
> Class<?> 表示任意类的类类型
> ```
>
> 
>
> Spring Framework包含下面几个模块
>
> - 支持IoC和AOP的容器；
> - 支持JDBC和ORM的数据访问模块；
> - 支持声明式事务的模块；
> - 支持基于Servlet的MVC开发；
> - 支持基于Reactive的Web开发；
> - 以及集成JMS、JavaMail、JMX、缓存等其他模块。
>
> ## 概念
>
> 容器：一种为某种特定组件的运行提供必要支持的软件环境。容器除了提供一个组件运行环境外，还提供了许多底层服务，比如Servlet容器提供了TCP连接，解析HTTP协议等复杂的服务。
>
> Spring的核心就是提供了一个IoC容器，他可以管理所有轻量级的JavaBean组件，提供的地层服务包括组件的生命周期管理、配置和组装服务、AOP支持，以及建立在AOP基础上的声明式事务服务等。
>
> **IoC控制反转**：传统的应用程序，创建一个新实例的控制权在程序本身，同时，创建一个新实例的依赖也需要开发人员维护（比如创建一个数据库连接的实例，必须要先创建数据库连接配置的实例，传递给数据库连接实例）。这样程序的组件的创建由开发人员控制，而且开发人员还要知道创建这些组件的依赖，增加开发难度，同时应用程序本身控制组件创建会造成多次创建的开销（比如两个访问数据库的类，他们都要自己创建一个数据库连接组件，这样就要创建两个，而实际上这可以创建一个进行复用）。控制反转IoC就是把创建组件的控制权从应用程序反转到IoC容器，所有组件的创建和配置不由应用程序控制，而是由IoC容器负责，这样应用程序只需要直接使用已经配置好了和创建好了的组件。组件管理交给了IoC容器，那么怎么返回给需要使用的类，就需要**依赖注入**DI，比如通过setDataSource()方法去注入一个数据库连接实例。这样，通过控制反转和依赖注入，一个类不用new一个创建一个实例，只需要通过IoC容器注入一个实例
>
> **控制反转和依赖注入的好处：**将组件的创建和配置 与组件的使用分离，并且IoC容器负责管理组件的生命周期
>
> 1. 使得类不必关心如何创建一个实例，从而减少对实例的依赖的关心
> 2. 依赖注入可以让一个实例得以共享
> 3. 测试一个组件的时候，可以更加容易
>
> **IoC控制反转的核心问题：**
>
> 	1. 谁负责创建组件
> 	1. 谁负责根据依赖关系组装组件
> 	1. 销毁时如何根据依赖顺序正确销毁
>
> **依赖注入方式**：
>
> Spring依赖注入支持两种注入方式：构造方法注入和属性setInstance注入
>
> **无侵入注入**
>
> Spring依赖注入是一种无侵入注入，指的是应用程序组件不用实现Spring的特定的接口，这样设计的好处是
>
> 1. 应用程序既可以在Spring的IoC容器中运行，也可以让开发人员自己组装配置进行注入
> 2. 测试的时候不依赖于Spring容器，可以进行单独测试，提高开发效率。
>
> ## Bean的创建和定制(IoC和DI)
>
> ### Bean的创建和注入
>
> **通过XML配置文件创建和管理创建组件和各个组件的依赖关系**
>
> Spring通过读入XML文件使用反射完成组件的创建
>
> ```xml
> <beans>
>     <bean id="dataSource" class="HikariDataSource" />
>     	<property name = "username" value = "root"/>
>     	<property name = "password" value = "passwword"
> 	</beans>
>     <bean id="bookService" class="BookService">
>         <property name="dataSource" ref="dataSource" />
>     </bean>
>     <bean id="userService" class="UserService">
>         <property name="dataSource" ref="dataSource" />
>     </bean>
> </beans>
> ```
>
> 上面的配置文件创建了三个JavaBean组件，id为dataSource的组件被通过setDataSource注入到bookService组件，同样，被注入到userService组件的dataSource方法。注入boolean、int、String等数据类型，使用value
>
> 上面XML配置的Java代码如下
>
> ```java
> HikariDataSource dataSource = new HikariDataSource() ;
> BookService bookService = new BookService( dataSouce ) ;
> ```
>
> 配置好上面的XML之后，使用下面的语句来创建Spring IoC容器，加载配置文件
>
> ```java
> ApplicationContext context = new ClassPathXmlApplicationContext("application.xml");
> ```
>
> 从容器中获得实例的方式通过以下的语句
>
> ```java
> UserService userService = context.getBean(UserService.class);
> ```
>
> 完整的main方法
>
> ```java
> public class Main {
>     public static void main(String[] args) {
>         ApplicationContext context = new ClassPathXmlApplicationContext("application.xml");
>         UserService userService = context.getBean(UserService.class);
>         User user = userService.login("bob@example.com", "password");
>         System.out.println(user.getName());
>     }
> }
> ```
>
> 上面我们使用了Spring的一种IoC容器ApplicationContext，他是一个接口，由很多实现，我们这里使用的是ClassPathXmlApplicationContext实现。同时Spring还有一种IoC容器BeanFactory，和Application不同在于他是在请求一个Bean实例的时候才创建那个Bean，而ApplicationContext是一次性创建所有的Bean。实际上ApplicationContext是继承了BeanFactory的接口，提供了一些额外的功能，比如国际化支持、事件和通知机制等，我们一般使用的是ApplicationContext
>
> **通过注解创建和管理创建组件和各个组件的依赖关系**
>
> 使用XML配置文件比较繁琐，一种方式时使用注解
>
> - 每个Bean被标注为`@Component`并正确使用`@Autowired`注入；
> - 配置类被标注为`@Configuration`和`@ComponentScan`；
> - 所有Bean均在指定包以及子包内。
>
> ```java
> @Component
> public class MailService {
>     ...
> }
> 
> @Component
> public class UserService {
>     @Autowired
>     MailService mailService;
> 
>     ...
> }
> 
> 
> @Configuration
> @ComponentScan
> public class AppConfig {
>     public static void main(String[] args) {
>         ApplicationContext context = new AnnotationConfigApplicationContext(AppConfig.class);
>         UserService userService = context.getBean(UserService.class);
>         User user = userService.login("bob@example.com", "password");
>         System.out.println(user.getName());
>     }
> }
> ```
>
> @Configuration，在使用注解创建IoC容器时（AnnotationConfigApplication）必须要这个注解标记一个配置类，
>
> @ComponentScan，告诉容器自动搜索当前类所在的包以及子包，把所有标注为@Component的Bean自动创建出来，并根据@Autowired进行装配
>
> @Component，被扫描到的类被创建一个Bean，Bean的id时首字母小写的类名
>
> @Autowired，可以用来修饰构造方法，字段等，把指定类型的Bean装配到类里面
>
> ### Bean的定制
>
> **Scope.Prototype原型Bean**
>
> @Bean创建的是一个单例，这个单例在容器初始化时创建，在容器销毁时销毁。而Prototype原型Bean是一种在需要添加时才创建的Bean。需要在@Component 下注解@Scope(ConfigurableBeanFactory.SCOPE_PROTOTYPE)
>
> ```java
> @Component
> @Scope(ConfigurableBeanFactory.SCOPE_PROTOTYPE)
> public class MainlSession{
> 	...
> }
> ```
>
> **注入List并标记注入顺序**
>
> 有时候需要注入一组继承了同一接口的Bean，这时候使用List<Validator> 类型来告诉Spring容器把所有Validator实现注入进来，可以使用@Order指定注入顺序
>
> ```java
> public interface Validator {
>     void validate(String email, String password, String name);
> }
> 
> @Component
> @Order(1)
> public class EmailValidator implements Validator {
>     public void validate(String email, String password, String name) {
>         if (!email.matches("^[a-z0-9]+\\@[a-z0-9]+\\.[a-z]{2,10}$")) {
>             throw new IllegalArgumentException("invalid email: " + email);
>         }
>     }
> }
> 
> @Component
> @Order(2)
> public class PasswordValidator implements Validator {
>     public void validate(String email, String password, String name) {
>         if (!password.matches("^.{6,20}$")) {
>             throw new IllegalArgumentException("invalid password");
>         }
>     }
> }
> 
> @Component
> @Order(3)
> public class NameValidator implements Validator {
>     public void validate(String email, String password, String name) {
>         if (name == null || name.isBlank() || name.length() > 20) {
>             throw new IllegalArgumentException("invalid name: " + name);
>         }
>     }
> }
> 
> 
> 
> @Component
> public class Validators {
>     @Autowired
>     List<Validator> validators; //注入一组Validator类型的Bean
> 
>     public void validate(String email, String password, String name) {
>         for (var validator : this.validators) {
>             validator.validate(email, password, name);
>         }
>     }
> }
> ```
>
> **可选注入**
>
> 一般情况下当我们标记了一个@Autowired后，如果Spring没有找到对应类型的Bean，就会抛出一个NoSuchBeanDefinitionException异常，可以给Autowired添加一个required=false参数，告诉Spring如果找不到那个Bean就忽略。这种方法适用于有定义就是用定义，没有定义就使用默认值
>
> ```java
> @Component
> public class MailService {
>     @Autowired(required = false)
>     ZoneId zoneId = ZoneId.systemDefault();
>     ...
> }
> ```
>
> **创建第三方Bean**
>
> IoC会在配置文件和他的子包中寻找@Component注解的类创建Bean，但是如果一个类不在这个包下面，那么可以使用@Bean在配置文件里面创建一个Bean。这种创建的Bean依然是单例的
>
> ```
> @Configuration
> @ComponentScan
> public class AppConfig{
> 	@Bean
> 	ZoneId createZoneId(){
> 		return ZoneId.of("Z") ;
> 	}
> }
> ```
>
> **初始化和销毁**
>
> 一个Bean在注入必要的以来以后，需要进行初始化（监听消息等），在容器关闭以后，需要清理资源（关闭连接池等）
>
> ```java
> //添加init()和shutdown()方法注解依赖
> <dependency>
>     <groupId>javax.annotation</groupId>
>     <artifactId>javax.annotation-api</artifactId>
>     <version>1.3.2</version>
> </dependency>
> 
> 
> @Component
> public class MailService {
>     @Autowired(required = false)
>     ZoneId zoneId = ZoneId.systemDefault();
> 
>     @PostConstruct
>     public void init() {  //初始化Bean
>         System.out.println("Init mail service with zoneId = " + this.zoneId);
>     }
> 
>     @PreDestroy
>     public void shutdown() { //销毁Bean
>         System.out.println("Shutdown mail service");
>     }
> }
> ```
>
> Spring容器会对上面的Bean进行下面的初始化流程
>
> 1. 调用构造方法创建MailService
> 2. 根据Autowired注入
> 3. 调用标记有PostConstruct的init()方法初始化
>
> Spring容器在销毁时，会先调用@Predestroy注解的shutdown方法
>
> **使用别名**
>
> 默认情况下容器内一个类型只有一个实例，但是有时候我们需要多个实例（比如连接多个数据库），我们可以使用@Bean("name")或者@Bean@Qualifier("name") 标记名字的方式来创建，在注入的时候添加@Qualifier("name")的方式来注入
>
> ```
> //创建多个同类型Bean使用@Qualifier("name")标记名字
> @Configuration
> @ComponentScan
> public class AppConfig {
>     @Bean
>     @Primary // 指定为主要Bean
>     @Qualifier("z")
>     ZoneId createZoneOfZ() {
>         return ZoneId.of("Z");
>     }
> 
>     @Bean
>     @Qualifier("utc8")
>     ZoneId createZoneOfUTC8() {
>         return ZoneId.of("UTC+08:00");
>     }
> }
> 
> //注入Bean的时候使用@Qualifier("name")的方式注入特定名字的Bean
> @Component
> public class MailService {
> 	@Autowired(required = false)
> 	@Qualifier("z") // 指定注入名称为"z"的ZoneId
> 	ZoneId zoneId = ZoneId.systemDefault();
>     ...
> }
> ```
>
> **使用FactoryBean创建Bean**
>
> 使用工厂模式创建对象，可以实现调用方面向抽象编程，可以实现缓存复用
>
> ```java
> @Component
> public class ZoneIdFactoryBean implements FactoryBean<ZoneId> {
> 
>     String zone = "Z";
> 
>     @Override
>     public ZoneId getObject() throws Exception {
>         return ZoneId.of(zone);
>     }
> 
>     @Override
>     public Class<?> getObjectType() {
>         return ZoneId.class;
>     }
> }
> ```
>
> 当一个Bean实现了`FactoryBean`接口后，Spring会先实例化这个工厂，然后调用`getObject()`创建真正的Bean。`getObjectType()`可以指定创建的Bean的类型，因为指定类型不一定与实际类型一致，可以是接口或抽象类。
>
> ### 使用Resource
>
> 在Java程序中，我们经常会读取配置文件、资源文件等，我们也可以用注入的方式来打开文件的inputStream，读取文件
>
> Spring提供了一个org.springframework.core.io.Resource（注意不是javax.annotation.Resource），它可以像String、int等一样使用Value注入
>
> ```java
> @Component
> public class AppService {
>     @Value("classpath:/logo.txt")
>     private Resource resource;
> 
>     private String logo;
> 
>     @PostConstruct
>     public void init() throws IOException {
>         try (var reader = new BufferedReader(
>                 new InputStreamReader(resource.getInputStream(), StandardCharsets.UTF_8))) {
>             this.logo = reader.lines().collect(Collectors.joining("\n"));
>         }
>     }
> }
> ```
>
> 注入Resource最常用的方式是通过classpath，类似于**classpath:/log.txt**表示在classpath中搜索log.txt文件，当然也可以直接给出绝对地址。这里的classpath指的是Maven结构中保存数据文件的地址。
>
> ### 注入配置
>
> Java程序的配置总是以key=value的形式保存在.properties文件中
>
> 我们要获得配置文件，可以使用@Resource注入的方法读取，但是这样比较繁琐，Spring提供了@PropertySource注解来自动读取配置文件，我们只需要在配置类上添加@PropertySource("app.properties")来自动读取配置文件
>
> 1. 通过@PropertySource注入
>
> ```java
> @Configuration
> @ComponentScan
> @PropertySource("app.properties") // 表示读取classpath的app.properties
> public class AppConfig {
>     @Value("${app.zone:Z}")
>     String zoneId;
> 
>     @Bean
>     ZoneId createZoneId() {
>         return ZoneId.of(zoneId);
>     }
> }
> ```
>
> Spring读取到@PropertySource注解之后，就会自动读取这个文件，然后我们使用@Value("${app.zone:z}") 来注入，其中如果app.zone不存在 ，那么会使用默认值z注入
>
> 2. 使用一个独立的JavaBean持有所有属性，然后在其他Bean中以#{bean.property}注入
>
> ```java
> @Component
> public class SmtpConfig {
>     @Value("${smtp.host}")
>     private String host;
> 
>     @Value("${smtp.port:25}")
>     private int port;
> 
>     public String getHost() {
>         return host;
>     }
> 
>     public int getPort() {
>         return port;
>     }
> }
> 
> @Component
> public class MailService {
>     @Value("#{smtpConfig.host}")
>     private String smtpHost;
> 
>     @Value("#{smtpConfig.port}")
>     private int smtpPort;
> }
> ```
>
> 其中#{smtpConfig.host}表示从smtpConfig的Bean中读取host属性，也就是调用getHost()方法
>
> ### 使用条件装配
>
> #### 使用环境进行条件装配
>
> Spring为应用程序准备了Profile这一概念，用来表示不同的环境，例如我们可以用native、test、production分别定义开发、测试、生产三个环境
>
> ```java
> @Configuration
> @ComponentScan
> public class AppConfig {
>     @Bean
>     @Profile("!test") // Profile({ "test", "master" }) 
>     ZoneId createZoneId() {
>         return ZoneId.systemDefault();
>     }
> 
>     @Bean
>     @Profile("test")
>     ZoneId createZoneIdForTest() {
>         return ZoneId.of("America/New_York");
>     }
> }
> ```
>
> 上面如果环境为test就装配createZoneId()，否则使用createZoneIdForTest
>
> 配置profile环境，只需要在运行时添加如下参数
>
> ```
> -Dspring.profiles.active=test,master
> ```
>
> #### 使用Conditional
>
> ```java
> @Component
> @Conditional(OnSmtpEnvCondition.class)
> public class SmtpMailService implements MailService {
>     ...
> }
> 
> 
> public class OnSmtpEnvCondition implements Condition {
>     public boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata) {
>         return "true".equalsIgnoreCase(System.getenv("smtp"));
>     }
> }
> ```
>
> Spring只提供了@Conditional注解，具体判断逻辑还是需要我们自己实现
>
> Spring Boot提供了更多简单的条件注解
>
> 1. 如果配置文件中存在app.stmp=true就创建
>
>    ```java
>    @Component
>    @ConditionalOnProperty(name="app.smtp", havingValue="true")
>    public class MailService {
>        ...
>    }
>    ```
>
> 2. 如果当前classpath中存在类javax.mail.Transport就创建
>
>    ```java
>    @Component
>    @ConditionalOnClass(name = "javax.mail.Transport")
>    public class MailService {
>        ...
>    }
>    ```
>
> ## AOP面向切面编程
>
> 面向对象编程OOP把系统看成时多个对象的交互，实现数据封装、继承、多态，而AOP把系统分解为不同的关注点（切面）。
>
> 在OOP中，要实现一个类，除了业务逻辑，还需要安全检查、日志记录、事务处理等，如果按照OOP，一个BookService类可能是下面
>
> ```java
> public class BookService {
>     public void createBook(Book book) {
>         securityCheck();
>         Transaction tx = startTransaction();
>         try {
>             // 核心业务逻辑
>             tx.commit();
>         } catch (RuntimeException e) {
>             tx.rollback();
>             throw e;
>         }
>         log("created book: " + book);
>     }
> }
> ```
>
> 这样的类，不仅关注业务逻辑，还关注事务检查、安全管理和日志记录，而后面三个功能总是重复的，在很多类都是重复的，使用OOP难以将这些重复的代码进行模块化。
>
> 一种解决办法时使用代理模式，也就是为类接口添加事务检查、安全管理和日志记录，但是这种模式需要抽取接口，比较麻烦
>
> ### **AOP原理**
>
> AOP实际上也是一种代理，他拦截业务代码实现安全检查、事务管理和日志记录等。Java实现AOP有三种方式
>
> 1. 编译期：通过扩展编译器，在编译器将切面调用编译进字节码，这种需要使用关键字来扩展编译器，AspectJ扩展了Java编译器，使用aspect来实现切面织入
> 2. 类加载器：在目标类被装载到JVM时，通过一个特殊的类加载器，对目标类的字节码重新增强
> 3. 运行期：目标对象和切面都是普通的类，通过JVM的动态代理功能或者第三方库实现运行期动态织入
>
> **Spring AOP动态代理的两种方式**
>
> JDK动态代理：利用反射机制生成一个实现代理接口的匿名类，在调用具体方法前调用InvokeHandler来处理。
> CGlib动态代理：利用ASM（开源的Java字节码编辑库，操作字节码）开源包，将代理对象类的class文件加载进来，通过修改其字节码生成子类来处理。
>
> 区别：JDK代理只能对实现接口的类生成代理；CGlib是针对类实现代理，对指定的类生成一个子类，并覆盖其中的方法，这种通过继承类的实现方式，不能代理final修饰的类。
>
> 总结：1.JDK代理使用的是反射机制实现aop的动态代理，CGLIB代理使用字节码处理框架asm，通过修改字节码生成子类。所以jdk动态代理的方式创建代理对象效率较高，执行效率较低，cglib创建效率较低，执行效率高；2.JDK动态代理机制是委托机制，具体说动态实现接口类，在动态生成的实现类里面委托hanlder去调用原始实现类方法，CGLIB则使用的继承机制，具体说被代理类和代理类是继承关系，所以代理类是可以赋值给被代理类的，如果被代理类有接口，那么代理类也可以赋值给接口。
>
>
> Spring的AOP实现是基于JVM的动态代理。
>
> AOP优缺点：AOP对于解决特定的问题，比如事务管理非常有用，这是因为分散在各处的事务代码基本相同，而且他们的参数固定。而另外一些特定问题，比如日志记录，就不容器，因为打印日志，需要捕获局部i变量，而使用AOP我们只能打印出固定格式的日志。
>
> ### **Spring的实现装配AOP**  
>
> #### 使用execution(* xxx.Xyz.*(..) ) 装配AOP
>
> ```java
> @Aspect
> @Component
> public class LoggingAspect {
>     // 在执行UserService的每个方法前执行:
>     @Before("execution(public * com.itranswarp.learnjava.service.UserService.*(..))")
>     public void doAccessCheck() {
>         System.err.println("[Before] do access check...");
>     }
> 
>     // 在执行MailService的每个方法前后执行:
>     @Around("execution(public * com.itranswarp.learnjava.service.MailService.*(..))")
>     public Object doLogging(ProceedingJoinPoint pjp) throws Throwable {
>         System.err.println("[Around] start " + pjp.getSignature());
>         Object retVal = pjp.proceed();
>         System.err.println("[Around] done " + pjp.getSignature());
>         return retVal;
>     }
> }
> 
> @Configuration
> @ComponentScan
> @EnableAspectJAutoProxy
> public class AppConfig {
>     ...
> }
> ```
>
> Spring实现AOP装载需要三步
>
> 1. 定义执行方法，并在方法上通过AspectJ的注解告诉Spring应该在何处调用此方法；
> 2. 标记`@Component`和`@Aspect`；
> 3. 在`@Configuration`类上标注`@EnableAspectJAutoProxy`。
>
> **Spring实现AOP的具体方式**
>
> Spring在实现在普通类UserService的方法执行前进行权限检查的AOP的注入的具体方式是，Spring使用CGLIB代码生成包 动态创建UserService的子类，他持有UserService和Aspect的实例，创建了UserServiceAopProxy的Bean，实际获取的UserService是UserServiceAopProxy。UserServiceAopProxy创建的代码
>
> ```java
> public UserServiceAopProxy extends UserService {
>     private UserService target;
>     private LoggingAspect aspect;
> 
>     public UserServiceAopProxy(UserService target, LoggingAspect aspect) {
>         this.target = target;
>         this.aspect = aspect;
>     }
> 
>     public User login(String email, String password) {
>         // 先执行Aspect的代码:
>         aspect.doAccessCheck();
>         // 再执行UserService的逻辑:
>         return target.login(email, password);
>     }
> 
>     public User register(String email, String password, String name) {
>         aspect.doAccessCheck();
>         return target.register(email, password, name);
>     }
> 
>     ...
> }
> ```
>
> Spring对接口类型使用JDK动态代理，对普通类使用CGLIB创建子类，如果一个类是final类型，那么SPring无法为他创建子类。
>
> **Spring的AOP拦截器类型**
>
> - @Before：这种拦截器先执行拦截代码，再执行目标代码。如果拦截器抛异常，那么目标代码就不执行了；
> - @After：这种拦截器先执行目标代码，再执行拦截器代码。无论目标代码是否抛异常，拦截器代码都会执行；
> - @AfterReturning：和@After不同的是，只有当目标代码正常返回时，才执行拦截器代码；
> - @AfterThrowing：和@After不同的是，只有当目标代码抛出了异常时，才执行拦截器代码；
> - @Around：能完全控制目标代码是否执行，并可以在执行前后、抛异常后执行任意拦截代码，可以说是包含了上面所有功能。
>
> #### 使用注解装配AOP
>
> 上面装配AOP的方法容易在不需要AOP注解的地方进行注解，因此如何确定实际需要被AOP注解的方法上进行注解，
>
> ```java
> ///定义一个注解
> @Target(METHOD)
> @Retention(RUNTIME)
> public @interface MetricTime {
>     String value();
> }
> 
> //定义一个切面，实现根据注解位置进行装配
> @Aspect
> @Component
> public class MetricAspect {
>     @Around("@annotation(metricTime)")
>     public Object metric(ProceedingJoinPoint joinPoint, MetricTime metricTime) throws Throwable {
>         String name = metricTime.value();
>         long start = System.currentTimeMillis();
>         try {
>             return joinPoint.proceed();
>         } finally {
>             long t = System.currentTimeMillis() - start;
>             // 写入日志或发送至JMX:
>             System.err.println("[Metrics] " + name + ": " + t + "ms");
>         }
>     }
> }
> 
> //定义需要被装配的普通类
> @Component
> public class UserService {
>     // 监控register()方法性能:
>     @MetricTime("register")
>     public User register(String email, String password, String name) {
>         ...
>     }
>     ...
> }
> ```
>
> ### Spring使用AOP的注意事项
>
> 1. 访问被注入的Bean时，总是调用方法而非直接访问字段
> 2. 编写Bean时，如果可能被代理，不要写public final方法。
>
> 这是因为Spring使用AOP会调用CGLIB创建普通类的子类，而这个创建不是Java编译器正常的过程，会直接生成字节码，CGLIB创建的字节码没有初始化函数（而Java编译器过程会自动补全初始化函数），这造成了CGLIB生成的子类继承的父类的字段不会得到初始化，所以访问这些字段会NPE。但是CGLIB创建的子类因为包含了父类的实例，可以通过父类的实例调用方法得到需要的字段，那个地方时父类初始化的。而CGLIB继承的final方法因为不能被子类重写覆盖，造成他依然会访问子类继承到的字段，这些字段因为没有被 初始化，所以一定会是NPE。因此注入AOP一定时要普通方法。
>
> ## Spring连接数据库
>
> ###  **操纵数据库的各种方法**
>
> #### **使用DriverManager**
>
> 使用DriverManager直接创建一个Connection，再从Connection使用PreparedStatement执行SQL语句
>
> 缺点是创建数据库连接是一件很消耗资源的事情，没有实现连接复用（连接池），效率低
>
> ```java
> //使用DriverManager直接创建一个Connection，再从Connection使用PrepareStatement执行SQL语句
> try (Connection conn = DriverManager.getConnection(JDBC_URL, JDBC_USER, JDBC_PASSWORD)) {
>     try (PreparedStatement ps = conn.prepareStatement("SELECT id, grade, name, gender FROM students WHERE gender=? AND grade=?")) {
>         ps.setObject(1, "M"); // 注意：索引从1开始
>         ps.setObject(2, 3);
>         try (ResultSet rs = ps.executeQuery()) {
>             while (rs.next()) {
>                 long id = rs.getLong("id");
>                 long grade = rs.getLong("grade");
>                 String name = rs.getString("name");
>                 String gender = rs.getString("gender");
>             }
>         }
>     }
> }
> ```
>
> #### 使用连接池HikariCP 的DataSource
>
> **使用连接池创建Connection，从连接池获得一个空闲Connection，之后获得PreparedStatement执行SQL语句**
>
> JDBC连接池有一个标准接口javax.sql.DataSouce，这个接口的实现有很多，常用的由HikariCP
>
> 使用连接池的好处在于复用数据库连接
>
> ```java
> //创建数据库连接池DataSource
> HikariConfig config = new HikariConfig();
> config.setJdbcUrl("jdbc:mysql://localhost:3306/test");
> config.setUsername("root");
> config.setPassword("password");
> config.addDataSourceProperty("connectionTimeout", "1000"); // 连接超时：1秒
> config.addDataSourceProperty("idleTimeout", "60000"); // 空闲超时：60秒
> config.addDataSourceProperty("maximumPoolSize", "10"); // 最大连接数：10
> DataSource ds = new HikariDataSource(config);
> 
> 
> //从连接池中获得一个连接Connection，再获得他的prepareStatement执行SQL语句
> try (Connection conn = ds.getConnection()) { // 在此获取连接
> 	try (PreparedStatement ps = conn
> 			.prepareStatement("SELECT * FROM students WHERE grade = ? AND score >= ?")) {
> 		ps.setInt(1, 3); // 第一个参数grade=?
> 		ps.setInt(2, 90); // 第二个参数score=?
> 		try (ResultSet rs = ps.executeQuery()) {
> 			while (rs.next()) {
> 				students.add(extractRow(rs));
> 			}
> 		}
> 	}
> } // 在此“释放”连接
> ```
>
> #### **使用JDBCTemplate**
>
> Spring提供了JDBCTemplate供我们操纵数据库，他包含一个DataSource的实例，可以使用JDBCTemplate获取Connection等操纵数据库。
>
> JDBCTemplate是一个简单的ORM（关系对象映射框架）
>
> ```java
> //创建JDBCTemplate的JavaBean
> @Value("${jdbc.url}")
> String jdbcUrl;
> 
> @Value("${jdbc.username}")
> String jdbcUsername;
> 
> @Value("${jdbc.password}")
> String jdbcPassword;
> 
> @Bean
> JdbcTemplate createJdbcTemplate(@Autowired DataSource dataSource) {
>     return new JdbcTemplate(dataSource);
> }
> 
> @Bean
> DataSource createDataSource() {
>     HikariConfig config = new HikariConfig();
>     config.setJdbcUrl(jdbcUrl);
>     config.setUsername(jdbcUsername);
>     config.setPassword(jdbcPassword);
>     config.addDataSourceProperty("autoCommit", "true");
>     config.addDataSourceProperty("connectionTimeout", "5");
>     config.addDataSourceProperty("idleTimeout", "60");
>     return new HikariDataSource(config);
> }
> 
> 
> //使用JDBCTemplate增删改查
> //查
> public User getUserById(long id) {
>     return jdbcTemplate.execute((Connection conn) -> {
>         try (var ps = conn.prepareStatement("SELECT * FROM users WHERE id = ?")) {
>             ps.setObject(1, id);
>             try (var rs = ps.executeQuery()) {
>                 if (rs.next()) {
>                     return new User( // new User object:
>                         rs.getLong("id"), // id
>                         rs.getString("email"), // email
>                         rs.getString("password"), // password
>                         rs.getString("name")); // name
>                 }
>                 throw new RuntimeException("user not found by id.");
>             }
>         }
>     });
> }
> 
> //增
> public User register(String email, String password, String name) {
>     KeyHolder holder = new GeneratedKeyHolder();
>     if (1 != jdbcTemplate.update((conn) -> {
>         var ps = conn.prepareStatement("INSERT INTO users(email,password,name) VALUES(?,?,?)",
>                                        Statement.RETURN_GENERATED_KEYS);
>         ps.setObject(1, email);
>         ps.setObject(2, password);
>         ps.setObject(3, name);
>         return ps;
>     }, holder)) {
>         throw new RuntimeException("Insert failed.");
>     }
>     return new User(holder.getKey().longValue(), email, password, name);
> }
> 
> //改
> public void updateUser(User user) {
>     if (1 != jdbcTemplate.update("UPDATE user SET name = ? WHERE id=?", user.getName(), user.getId())) {
>         throw new RuntimeException("User not found by id");
>     }
> }
> ```
>
> #### **使用DAO**
>
> 传统多层应用程序，Web层调用业务层，业务层调用数据访问层，数据访问层负责数据增删改查，实现数据访问层的就是用JDBCTemplate实现的对数据库的操作
>
> 编写数据访问层的时候可以使用DAO模式（Data Access Object)，DAO提供了一个标准接口，对JDBCTemplate进行封装，可以方便数据库操作
>
> ```java
> public abstract class AbstractDao<T> extends JdbcDaoSupport {
> 
> 	@Autowired
> 	private JdbcTemplate jdbcTemplate;
> 
> 	private String table;
> 	private Class<T> entityClass;
> 	private RowMapper<T> rowMapper;
> 
> 	public AbstractDao() {
> 		this.entityClass = getParameterizedType();
> 		this.table = this.entityClass.getSimpleName().toLowerCase() + "s";
> 		this.rowMapper = new BeanPropertyRowMapper<>(entityClass);
> 	}
> 
> 	@PostConstruct
> 	public void init() {
> 		super.setJdbcTemplate(jdbcTemplate);
> 	}
> 
> 	public T getById(long id) {
> 		return getJdbcTemplate().queryForObject("SELECT * FROM " + table + " WHERE id = ?", this.rowMapper, id);
> 	}
> 
> 	public List<T> getAll(int pageIndex) {
> 		int limit = 100;
> 		int offset = limit * (pageIndex - 1);
> 		return getJdbcTemplate().query("SELECT * FROM " + table + " LIMIT ? OFFSET ?", new Object[] { limit, offset },
> 				this.rowMapper);
> 	}
> 
> 	public void deleteById(long id) {
> 		getJdbcTemplate().update("DELETE FROM " + table + " WHERE id = ?", id);
> 	}
> 
> 	public RowMapper<T> getRowMapper() {
> 		return this.rowMapper;
> 	}
> 
> 	@SuppressWarnings("unchecked")
> 	private Class<T> getParameterizedType() {
> 		Type type = getClass().getGenericSuperclass();
> 		if (!(type instanceof ParameterizedType)) {
> 			throw new IllegalArgumentException("Class " + getClass().getName() + " does not have parameterized type.");
> 		}
> 		ParameterizedType pt = (ParameterizedType) type;
> 		Type[] types = pt.getActualTypeArguments();
> 		if (types.length != 1) {
> 			throw new IllegalArgumentException(
> 					"Class " + getClass().getName() + " has more than 1 parameterized types.");
> 		}
> 		Type r = types[0];
> 		if (!(r instanceof Class<?>)) {
> 			throw new IllegalArgumentException(
> 					"Class " + getClass().getName() + " does not have parameterized type of class.");
> 		}
> 		return (Class<T>) r;
> 	}
> }
> 
> 
> @Component
> @Transactional
> public class UserDao extends AbstractDao<User> {
> 
> 	public User fetchUserByEmail(String email) {
> 		List<User> users = getJdbcTemplate().query("SELECT * FROM users WHERE email = ?", new Object[] { email },
> 				(ResultSet rs, int rowNum) -> {
> 					return new User( // new User object:
> 							rs.getLong("id"), // id
> 							rs.getString("email"), // email
> 							rs.getString("password"), // password
> 							rs.getString("name")); // name
> 				});
> 		return users.isEmpty() ? null : users.get(0);
> 	}
> 
> 	public User getUserByEmail(String email) {
> 		return getJdbcTemplate().queryForObject("SELECT * FROM users WHERE email = ?", new Object[] { email },
> 				(ResultSet rs, int rowNum) -> {
> 					return new User( // new User object:
> 							rs.getLong("id"), // id
> 							rs.getString("email"), // email
> 							rs.getString("password"), // password
> 							rs.getString("name")); // name
> 				});
> 	}
> 
> 	public User login(String email, String password) {
> 		User user = getUserByEmail(email);
> 		if (user.getPassword().equals(password)) {
> 			return user;
> 		}
> 		throw new RuntimeException("login failed.");
> 	}
> 
> 	public User createUser(String email, String password, String name) {
> 		KeyHolder holder = new GeneratedKeyHolder();
> 		if (1 != getJdbcTemplate().update((conn) -> {
> 			var ps = conn.prepareStatement("INSERT INTO users(email, password, name) VALUES(?,?,?)",
> 					Statement.RETURN_GENERATED_KEYS);
> 			ps.setObject(1, email);
> 			ps.setObject(2, password);
> 			ps.setObject(3, name);
> 			return ps;
> 		}, holder)) {
> 			throw new RuntimeException("Insert failed.");
> 		}
> 		if ("root".equalsIgnoreCase(name)) {
> 			throw new RuntimeException("Invalid name, will rollback...");
> 		}
> 		return new User(holder.getKey().longValue(), email, password, name);
> 	}
> 
> 	public void updateUser(User user) {
> 		if (1 != getJdbcTemplate().update("UPDATE user SET name = ? WHERE id=?", user.getName(), user.getId())) {
> 			throw new RuntimeException("User not found by id");
> 		}
> 	}
> }
> ```
>
> #### 使用Hibernate
>
> #### 使用JPA
>
> #### 使用Mybatis
>
> #### 各种数据库操作的区别
>
> | JDBC       | Hibernate      | JPA                  | MyBatis           |
> | :--------- | :------------- | :------------------- | :---------------- |
> | DataSource | SessionFactory | EntityManagerFactory | SqlSessionFactory |
> | Connection | Session        | EntityManager        | SqlSession        |
>
> ### 使用事务（声明式事务）
>
> Spring事务使用的是AOP代理CGLIB生成的子类创建的Bean
>
> ```java
> //原始的类
> public UserService{
>     public User register(String email, String password, String name){
>         
>     }
> }
> 
> //Spring 使用CGLIB生成的AOP子类
> public class UserService$$EnhancerBySpringCGLIB extends UserService {
>     UserService target = ...
>     PlatformTransactionManager txManager = ...
> 
>     public User register(String email, String password, String name) {
>         TransactionStatus tx = null;
>         try {
>             tx = txManager.getTransaction(new DefaultTransactionDefinition());
>             target.register(email, password, name);
>             txManager.commit(tx);
>         } catch (RuntimeException e) {
>             txManager.rollback(tx);
>             throw e;
>         }
>     }
>     ...
> }
> ```
>
> Spring配置事务方法
>
> ```java
> //配置类，使用EnableTransactionManagerMent启动声明式事务
> @Configuration
> @ComponentScan
> @EnableTransactionManagement // 启用声明式
> @PropertySource("jdbc.properties")
> public class AppConfig {
>     ...
> }
> 
> 
> //使用@Transactional添加事务支持
> @Component
> public class UserService {
>     // 此public方法自动具有事务支持:
>     @Transactional
>     public User register(String email, String password, String name) {
>        ...
>     }
> }
> 
> ```
>
> #### 事务边界
>
> 事务边界在于被注解的函数的范围，但是对于一个被事务注解的函数调用了另外一个被事务注解的函数，那么怎么界定事务的边界。无疑，我们希望被调用的函数的事务应该融合进调用函数的事务，整个只有一个事务。这涉及到事务传播
>
> #### 事务传播
>
> 如果一个被事务注解的方法调用了另外一个被事务注解的方法，我们想把后一个方法的事务融合到前一个方法的事务中去。
>
> Spring为事务传播提供了几个级别，默认级别是REQUIRED，这个级别的意思是，如果当前没有事务，就创建一个新事务，如果当前有事务，就加入到当前事务中执行。
>
> **Spring提供的其他事务传播级别：**
>
> `SUPPORTS`：表示如果有事务，就加入到当前事务，如果没有，那也不开启事务执行。这种传播级别可用于查询方法，因为SELECT语句既可以在事务内执行，也可以不需要事务；
>
> `MANDATORY`：表示必须要存在当前事务并加入执行，否则将抛出异常。这种传播级别可用于核心更新逻辑，比如用户余额变更，它总是被其他事务方法调用，不能直接由非事务方法调用；
>
> `REQUIRES_NEW`：表示不管当前有没有事务，都必须开启一个新的事务执行。如果当前已经有事务，那么当前事务会挂起，等新事务完成后，再恢复执行；
>
> `NOT_SUPPORTED`：表示不支持事务，如果当前有事务，那么当前事务会挂起，等这个方法执行完成后，再恢复执行；
>
> `NEVER`：和`NOT_SUPPORTED`相比，它不但不支持事务，而且在监测到当前有事务时，会抛出异常拒绝执行；
>
> `NESTED`：表示如果当前有事务，则开启一个嵌套级别事务，如果当前没有事务，则开启一个新事务。
>
> 上面这么多种事务的传播级别，其实默认的`REQUIRED`已经满足绝大部分需求，`SUPPORTS`和`REQUIRES_NEW`在少数情况下会用到，其他基本不会用到，因为把事务搞得越复杂，不仅逻辑跟着复杂，而且速度也会越慢。
>
> **设计事务传播级别：**
>
> ```java
> @Transactional(propagation = Propagation.REQUIRES_NEW)
> public Product createProduct() {
>     ...
> }
> ```
>
> **Spring事务传播实现**
>
> spring使用ThreadLocal来发现当前线程是否存在事务，如果不存在事务，就创建事务，如果存在，就使用当前事务的数据和TransactionStaturs
>
> 特别注意的是，事务的传播必须是在同一个线程内，如果被调用的事务函数被开启了一个新的线程，那么被调用的事务函数的线程无法检测到调用他的事务函数开启的事务TransactionStatus，那么就会开启两个事务。
>
> ```java
> Connection conn = openConnection();
> try {
>     // 关闭自动提交:
>     conn.setAutoCommit(false);
>     // 执行多条SQL语句:
>     insert(); update(); delete();
>     // 提交事务:
>     conn.commit();
> } catch (SQLException e) {
>     // 回滚事务:
>     conn.rollback();
> } finally {
>     conn.setAutoCommit(true);
>     conn.close();
> }
> ```
>
> 对于JDBC事务，这个线程开启的时候，Spring总是把JDBC相关的Connction和TransactionStatus实例绑定到ThreadLocal，当执行到insert、update、delete等事务方法时，他会检测到线程的事务，所以不会开启新的事务；同时他获得Connection实例，这是一个上下文，是几个方法通用的结构。ThreadLocal可以用来传递上下文，也可以用来控制事务传播级别。
>
> ### DAO
>
> Spring提供了一个DAO支持，DAO时Data Access Object的缩写，它实际上是封装了JDBCTemplate的类，负责操纵数据库。当然可以不用DAO，直接在代码里面编写访问数据库的代码，就像自己使用JDBCTemplate一样
>
> ```java
> //封装JDBCTemplate的接口
> public abstract class JdbcDaoSupport extends DaoSupport {
>     private JdbcTemplate jdbcTemplate;
> 
>     public final void setJdbcTemplate(JdbcTemplate jdbcTemplate) {
>         this.jdbcTemplate = jdbcTemplate;
>         initTemplateConfig();
>     }
> 
>     public final JdbcTemplate getJdbcTemplate() {
>         return this.jdbcTemplate;
>     }
> 
>     ...
> }
> 
> 
> //使用泛型
> public abstract class AbstractDao<T> extends JdbcDaoSupport {
>     private String table;
>     private Class<T> entityClass;
>     private RowMapper<T> rowMapper;
> 
>     public AbstractDao() {
>         // 获取当前类型的泛型类型:
>         this.entityClass = getParameterizedType();
>         this.table = this.entityClass.getSimpleName().toLowerCase() + "s";
>         this.rowMapper = new BeanPropertyRowMapper<>(entityClass);
>     }
> 
>     public T getById(long id) {
>         return getJdbcTemplate().queryForObject("SELECT * FROM " + table + " WHERE id = ?", this.rowMapper, id);
>     }
> 
>     public List<T> getAll(int pageIndex) {
>         int limit = 100;
>         int offset = limit * (pageIndex - 1);
>         return getJdbcTemplate().query("SELECT * FROM " + table + " LIMIT ? OFFSET ?",
>                 new Object[] { limit, offset },
>                 this.rowMapper);
>     }
> 
>     public void deleteById(long id) {
>         getJdbcTemplate().update("DELETE FROM " + table + " WHERE id = ?", id);
>     }
>     ...
> }
> 
> 
> @Component
> @Transactional
> public class UserDao extends AbstractDao<User> {
>     // 已经有了:
>     // User getById(long)
>     // List<User> getAll(int)
>     // void deleteById(long)
> }
> 
> @Component
> @Transactional
> public class BookDao extends AbstractDao<Book> {
>     // 已经有了:
>     // Book getById(long)
>     // List<Book> getAll(int)
>     // void deleteById(long)
> }
> ```
>
> ### 集成Hibernate（ORM框架）
>
> 使用JDBCTemplate的时候，我们用的最多的方法是List<T> query(String sql, Object[] args, RowMapper rowMapper)。这个RowMapper的作用是把ResultSet的一行记录映射成一个JavaBean。这种把关系数据库中的表映射成Java对象的过程就是ORM（Object-Relational Mapping）。ORM既可以把记录转换成Java对象，也可以把Java对象转换成记录。使用JDBCTemplate加上RowMaper可以看成是最原始的ORM（关系-对象映射框架）。成熟的ORM框架还有Hibernate
>
> #### 创建HibernateTemplate
>
> ```java
> @Bean
> DataSource createDataSource(
>     // JDBC URL:
>     @Value("${jdbc.url}") String jdbcUrl,
>     // JDBC username:
>     @Value("${jdbc.username}") String jdbcUsername,
>     // JDBC password:
>     @Value("${jdbc.password}") String jdbcPassword) {
>     HikariConfig config = new HikariConfig();
>     config.setJdbcUrl(jdbcUrl);
>     config.setUsername(jdbcUsername);
>     config.setPassword(jdbcPassword);
>     config.addDataSourceProperty("autoCommit", "false");
>     config.addDataSourceProperty("connectionTimeout", "5");
>     config.addDataSourceProperty("idleTimeout", "60");
>     return new HikariDataSource(config);
> } //创建DataSource线程池
> 
> @Bean
> LocalSessionFactoryBean createSessionFactory(@Autowired DataSource dataSource) {
>     var props = new Properties();
>     props.setProperty("hibernate.hbm2ddl.auto", "update"); // 生产环境不要使用
>     props.setProperty("hibernate.dialect", "org.hibernate.dialect.HSQLDialect");
>     props.setProperty("hibernate.show_sql", "true");
>     var sessionFactoryBean = new LocalSessionFactoryBean();
>     sessionFactoryBean.setDataSource(dataSource);
>     // 扫描指定的package获取所有entity class:
>     sessionFactoryBean.setPackagesToScan(AbstractEntity.class.getPackageName());
>     sessionFactoryBean.setHibernateProperties(props);
>     return sessionFactoryBean;
> }//创建SessionFactory
> 
> @Bean
> HibernateTemplate createHibernateTemplate(@Autowired SessionFactory sessionFactory) {
>     return new HibernateTemplate(sessionFactory);
> }//创建HibernateTemplate
> ```
>
> LocalSessionFactoryBean是一个FactoryBean，他自动创建一个SessionFactory，在Hibernate中，一个Session封装了一个JDBC实例，而SessionFactory封装了JDC的DataSource实例，也就是SessionFactory持有连接池，每次操作数据库的时候，SeesionFactory创建一个新的Session，相当于从连接池DataSource里面取得一个新的Connection。
>
> #### Hibernate指定的Java对象（Entity class）
>
> ```java
> @Entity
> public class User {
>     @Id
>     @GeneratedValue(strategy = GenerationType.IDENTITY)
>     @Column(nullable = false, updatable = false)
>     public Long getId() { ... }
> 
>     @Column(nullable = false, unique = true, length = 100)
>     public String getEmail() { ... }
> 
>     @Column(nullable = false, length = 100)
>     public String getPassword() { ... }
> 
>     @Column(nullable = false, length = 100)
>     public String getName() { ... }
> 
>     @Column(nullable = false, updatable = false)
>     public Long getCreatedAt() { ... }
> }
> ```
>
> 如果一个JavaBean被用于映射成关系，就要用Entity进行注解，默认的表名是JavaBean类名首字母小写，可以收用@Table(name="users") 命名表名
>
> @Column() 用于标记用于映射到数据库的属性，nullable表示这个属性是否可以为NULL，updatable表明这个属性是否可以被用于update语句，length表明String类型的属性的长度，如果没有指定，默认String长度是255.
>
> @Id 用于注解主键，自增主键需要用@GeneratedValue(strategy = GenerationType.IDENTITY)进行标记
>
> 注意Hibernate的JavaBean的属性类型必须是包装类，如果使用基本数据类型，因为基本数据类型有默认值，那么实际上插入的时候会使用默认值进行插入。Hibernate在插入的时候，如果遇到属性是NULL，那么他会请求数据库获得一个自增属性，使用这个自增的属性进行插入。
>
> ```java
> @MappedSuperclass
> public abstract class AbstractEntity {
> 
>     private Long id;
>     private Long createdAt;
> 
>     @Id
>     @GeneratedValue(strategy = GenerationType.IDENTITY)
>     @Column(nullable = false, updatable = false)
>     public Long getId() { ... }
> 
>     @Column(nullable = false, updatable = false)
>     public Long getCreatedAt() { ... }
> 
>     @Transient
>     public ZonedDateTime getCreatedDateTime() {
>         return Instant.ofEpochMilli(this.createdAt).atZone(ZoneId.systemDefault());
>     }
> 
>     @PrePersist
>     public void preInsert() {
>         setCreatedAt(System.currentTimeMillis());
>     }
> }
> 
> 
> @Entity
> public class User extends AbstractEntity {
> 
>     @Column(nullable = false, unique = true, length = 100)
>     public String getEmail() { ... }
> 
>     @Column(nullable = false, length = 100)
>     public String getPassword() { ... }
> 
>     @Column(nullable = false, length = 100)
>     public String getName() { ... }
> }
> ```
>
> @Transient表示一个虚拟属性，因为这是一个计算出来的属性，必须用这个来标记，如果没有这个标记，Hibernate会直接查询createedDataTime这个字段，然后报错。
>
> @PrePersist标识的方法，他表示将一个JavaBean持久化数据库之前，Hibernate先执行这个方法，这样我们可以设置好createdAt这个属性。
>
> #### Hibernate 操作
>
> 1. Insert操作
>
>    ```java
>    public User register(String email, String password, String name) {
>        // 创建一个User对象:
>        User user = new User();
>        // 设置好各个属性:
>        user.setEmail(email);
>        user.setPassword(password);
>        user.setName(name);
>        // 不要设置id，因为使用了自增主键
>        // 保存到数据库:
>        hibernateTemplate.save(user);
>        // 现在已经自动获得了id:
>        System.out.println(user.getId());
>        return user;
>    }
>    ```
>
> 2. Delete操作
>
>    ```java
>    public boolean deleteUser(Long id) {
>        User user = hibernateTemplate.get(User.class, id);
>        if (user != null) {
>            hibernateTemplate.delete(user);
>            return true;
>        }
>        return false;
>    }
>    ```
>
> 3. Update操作
>
>    ```java
>    public void updateUser(Long id, String name) {
>        User user = hibernateTemplate.load(User.class, id);
>        user.setName(name);
>        hibernateTemplate.update(user);
>    }
>    ```
>
> 4. Query操作
>
>    1. 使用Example查询
>
>       ```java
>       public User login(String email, String password) {
>           User example = new User();
>           example.setEmail(email);
>           example.setPassword(password);
>           List<User> list = hibernateTemplate.findByExample(example);
>           return list.isEmpty() ? null : list.get(0);
>       }
>       ```
>
>    2. 使用Criterial查询
>
>       ```java
>       public User login(String email, String password) {
>           DetachedCriteria criteria = DetachedCriteria.forClass(User.class);
>           criteria.add(Restrictions.eq("email", email))
>                   .add(Restrictions.eq("password", password));
>           List<User> list = (List<User>) hibernateTemplate.findByCriteria(criteria);
>           return list.isEmpty() ? null : list.get(0);
>       }
>       ```
>
>       使用Criterial比使用Example更好的地方在于它可以更灵活组织查询语句，而Example没办法
>
>       ```
>       DetachedCriteria criteria = DetachedCriteria.forClass(User.class);
>       criteria.add(
>           Restrictions.and(
>               Restrictions.or(
>                   Restrictions.eq("email", email),
>                   Restrictions.eq("name", email)
>               ),
>       		Restrictions.eq("password", password)
>           )
>       );
>       ```
>
>    3. 使用HQL查询
>
>       直接写HQL
>
>       ```java
>       List<User> list = (List<User>) hibernateTemplate.find("FROM User WHERE email=? AND password=?", email, password);
>       ```
>
>       使用NamedQuery
>
>       ```java
>       @NamedQueries(
>           @NamedQuery(
>               // 查询名称:
>               name = "login",
>               // 查询语句:
>               query = "SELECT u FROM User u WHERE u.email=?0 AND u.password=?1"
>           )
>       )
>       @Entity
>       public class User extends AbstractEntity {
>           ...
>       }
>       
>       
>       public User login(String email, String password) {
>           List<User> list = (List<User>) hibernateTemplate.findByNamedQuery("login", email, password);
>           return list.isEmpty() ? null : list.get(0);
>       }
>       ```
>    
>       直接写HQL和使用`NamedQuery`各有优劣。前者可以在代码中直观地看到查询语句，后者可以在`User`类统一管理所有相关查询。
>
> #### 使用Hibernate原生接口
>
> ```java
> void operation() {
>     Session session = null;
>     boolean isNew = false;
>     // 获取当前Session或者打开新的Session:
>     try {
>         session = this.sessionFactory.getCurrentSession();
>     } catch (HibernateException e) {
>         session = this.sessionFactory.openSession();
>         isNew = true;
>     }
>     // 操作Session:
>     try {
>         User user = session.load(User.class, 123L);
>     }
>     finally {
>         // 关闭新打开的Session:
>         if (isNew) {
>             session.close();
>         }
>     }
> }
> ```
>
> ### 集成JPA
>
> JPA就是JavaEE的一个ORM标准，它的实现其实和Hibernate没啥本质区别，但是用户如果使用JPA，那么引用的就是`javax.persistence`这个“标准”包，而不是`org.hibernate`这样的第三方包。因为JPA只是接口，所以，还需要选择一个实现产品，跟JDBC接口和MySQL驱动一个道理。
>
> 我们使用JPA时也完全可以选择Hibernate作为底层实现，但也可以选择其它的JPA提供方，比如[EclipseLink](https://www.eclipse.org/eclipselink/)。Spring内置了JPA的集成，并支持选择Hibernate或EclipseLink作为实现。这里我们仍然以主流的Hibernate作为JPA实现为例子，演示JPA的基本用法。
>
> #### JDBC Hibernate JPA关系
>
> | JDBC       | Hibernate      | JPA                  |
> | :--------- | :------------- | :------------------- |
> | DataSource | SessionFactory | EntityManagerFactory |
> | Connection | Session        | EntityManager        |
>
> `SessionFactory`和`EntityManagerFactory`相当于`DataSource`，`Session`和`EntityManager`相当于`Connection`。每次需要访问数据库的时候，需要获取新的`Session`和`EntityManager`，用完后再关闭。
>
> 但是，注意到`UserService`注入的不是`EntityManagerFactory`，而是`EntityManager`，并且标注了`@PersistenceContext`。难道使用JPA可以允许多线程操作同一个`EntityManager`？
>
> 实际上这里注入的并不是真正的`EntityManager`，而是一个`EntityManager`的代理类，相当于：
>
> ```java
> public class EntityManagerProxy implements EntityManager {
>     private EntityManagerFactory emf;
> }
> ```
>
> Spring遇到标注了`@PersistenceContext`的`EntityManager`会自动注入代理，该代理会在必要的时候自动打开`EntityManager`。换句话说，多线程引用的`EntityManager`虽然是同一个代理类，但该代理类内部针对不同线程会创建不同的`EntityManager`实例。
>
> 简单总结一下，标注了`@PersistenceContext`的`EntityManager`可以被多线程安全地共享。
>
> ### 集成Mybatis
>
> **全自动ORM框架**
>
> Hibernate、JPA等框架操作数据库的时候，主要工作是将ResultSet的每一行变成Java Bean实现查询，或者将Java Bean自动填充到INSERT、UPDATE或DELETE等语句的参数中实现增删改等操作。
>
> Hibernate是如何跟踪Java Bean的修改，从而在UPDATE中更新必要的属性?Hibernate实现更新，首先会使用主键查询得到对应的USER的Java Bean，此时USER Bean是瞬时状态，他失去了Session连接，当对这个User Bean修改之后，User Proxy对应的\_isXXChanged会发生变化，从而在修改的时候根据这个修改的属性更新数据库。Hibernate跟踪Java Bean状态使用的是代理类，对于一个User类，他创建了他的代理类，添加了\_session，和对应属性的\_isxxChanged。
>
> ```java
> public class UserProxy extends User{
>     Session _session;
>     boolen _isNameChanged;
>     
>     public void setName(String name){
>         super.setName(name) ;
>         _isNameChanged = true ;
>     }
> }
> ```
>
> Hibernate 和JPA使用特定的HQL或JPQL，经过一道转换变成特定数据库的SQL，理论上可以实现无缝切换数据库
>
> Hibernate提供了缓存
>
> **半自动ORM框架**
>
> 非自动化ORM框架JDBCTemplate和ORM框架相比，主要有两点区别
>
> 1. 查询之后需要手动提供Mapper实例把ResultSet的 每一行变成Java对象
> 2. 增删改操作的参数列表，需要手动传入，即把User实例变成[user.id, user.name, user.email]这样的列表，比较麻烦
>
> 但是JDBCTemplate的优势在于他的确定性，也就是每次读取操作一定是数据库操作而不是缓存，所执行的SQL是确定的，缺点就是比较麻烦。
>
> 介于全自动化框架和完全手动的JDBCTemplate之间的一种ORM是Mybatis，他负责把查询得到的ResultSet映射到Java Bean，或者把Java Bean的参数自动填充到增删改的SQL语句中
>
> **Mybatis的使用**
>
> 使用Mybatis，必须编写一个Mapper实现Java Bean属性和数据库记录列名的映射。
>
> ```java
> public interface UserMapper {
> 	//查询的返回结果会被自动转化为User Bean，转换规则是列名和属性对应
> 	@Select("SELECT * FROM users WHERE id = #{id}")
> 	User getById(@Param("id") long id);
> 
> 	@Select("SELECT * FROM users WHERE email = #{email}")
> 	User getByEmail(@Param("email") String email);
> 
> 	@Select("SELECT * FROM users LIMIT #{offset}, #{maxResults}")
> 	List<User> getAll(@Param("offset") int offset, @Param("maxResults") int maxResults);
> 
>     //Mybatis自动使用User去填充占位符。Options标明自增主键
> 	@Options(useGeneratedKeys = true, keyProperty = "id", keyColumn = "id")
> 	@Insert("INSERT INTO users (email, password, name, createdAt) VALUES (#{user.email}, #{user.password}, #{user.name}, #{user.createdAt})")
> 	void insert(@Param("user") User user);
> 
> 	@Update("UPDATE users SET name = #{user.name}, createdAt = #{user.createdAt} WHERE id = #{user.id}")
> 	void update(@Param("user") User user);
> 
> 	@Delete("DELETE FROM users WHERE id = #{id}")
> 	void deleteById(@Param("id") long id);
> }
> 
> ```
>
> 配置类AppConfig添加了@MapperScan后Mybatis会自动扫描指定包下面的所有Mapper并创建实现类。
>
> ## Spring MVC开发
>
> 在Web应用中启动Spring容器有很多种方法，可以通过Listener启动，也可以通过Servlet启动，可以使用XML配置，也可以使用注解配置
>
> Spring MVC文件结构
>
> ```ascii
> spring-web-mvc
> ├── pom.xml
> └── src
>     └── main
>         ├── java
>         │   └── com
>         │       └── itranswarp
>         │           └── learnjava
>         │               ├── AppConfig.java
>         │               ├── DatabaseInitializer.java
>         │               ├── entity
>         │               │   └── User.java
>         │               ├── service
>         │               │   └── UserService.java
>         │               └── web
>         │                   └── UserController.java
>         ├── resources
>         │   ├── jdbc.properties
>         │   └── logback.xml
>         └── webapp
>             ├── WEB-INF
>             │   ├── templates
>             │   │   ├── _base.html
>             │   │   ├── index.html
>             │   │   ├── profile.html
>             │   │   ├── register.html
>             │   │   └── signin.html
>             │   └── web.xml
>             └── static
>                 ├── css
>                 │   └── bootstrap.css
>                 └── js
>                     └── jquery.js
> ```
>
> 
>
> # Spring Boot开发
>
> Spring Boot文件结构
>
> ```ascii
> src/main/java
> └── com
>     └── itranswarp
>         └── learnjava
>             ├── Application.java
>             ├── entity
>             │   └── User.java
>             ├── service
>             │   └── UserService.java
>             └── web
>                 └── UserController.java
> ```
>
> Spring Boot相较于Spring MVC添加了许多自动装配功能。Spring Boot自动装配功能是通过自动扫描+条件装配实现的，这一套机制在默认情况下工作得很好，但是，如果我们要手动控制某个Bean的创建，就需要详细地了解Spring Boot自动创建的原理，很多时候还要跟踪`XxxAutoConfiguration`，以便设定条件使得某个Bean不会被自动创建。
>
> ### 集成第三方组件
>
> #### 集成Open API
>
> Open API可以自动生成描述REST服务API的文档
>
> #### 集成Redis
>
> Redis是一个key-valu存储系统，是跨平台的非关系型数据库。
>
> Redis是一个开源的使用ANSI C语言编写的、遵守BSD协议、支持网络、可基于内存、分布式、可选持久性的键值对（key-value）存储数据库。
>
> Redis常被称为数据结构服务器，因为他的valuekeyishi字符串（String）、哈希（Hash）、列表（List）、集合（Sets）和有序集合（sorted sets）
>
> **Redis为什么那么快**
>
> （1）完全基于内存，数据存在内存中，绝大部分请求是纯粹的内存操作，非常快速，跟传统的磁盘文件数据存储相比，避免了通过磁盘IO读取到内存这部分的开销。
>
> （2）数据结构简单，对数据操作也简单。Redis中的数据结构是专门进行设计的，每种数据结构都有一种或多种数据结构来支持。Redis正是依赖这些灵活的数据结构，来提升读取和写入的性能。
>
> （3）采用单线程，省去了很多上下文切换的时间以及CPU消耗，不存在竞争条件，不用去考虑各种锁的问题，不存在加锁释放锁操作，也不会出现死锁而导致的性能消耗。
>
> （4）使用基于IO多路复用机制的线程模型，可以处理并发的链接。
> 多个 Socket 可能会产生不同的操作，每个操作对应不同的文件事件，但是IO多路复用程序会监听多个Socket，将Socket产生的事件放入队列中排队，事件分派器每次从队列中取出一个事件，把该事件交给对应的事件处理器进行处理。
>
> Redis客户端对服务端的每次调用都经历了发送命令，执行命令，返回结果三个过程。其中执行命令阶段，由于Redis是单线程来处理命令的，所有每一条到达服务端的命令不会立刻执行，所有的命令都会进入一个队列中，然后逐个被执行。并且多个客户端发送的命令的执行顺序是不确定的。但是可以确定的是不会有两条命令被同时执行，不会产生并发问题，这就是Redis的单线程基本模型。
> （5）Redis直接自己构建了VM 机制 ，避免调用系统函数的时候，浪费时间去移动和请求
>
> **为什么Redis是单线程**
>
> 这里的单线程指的是Redis处理所有命令请求使用单线程，其他模块，比如解析网络请求和输出到socket依然使用的是多线程。为什么使用单线程，因为CPU不是Redis新能瓶颈，单线程实现比较简单好维护
>
> **多线程模式下，是否存在线程并发安全问题？**
>
> Redis的多线程，是网络IO多线程，而执行命令和访问内存等依然是是哦呢的单线程，没有并发安全的问题
>
> ![img](https://img-blog.csdnimg.cn/20210201030222228.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2E3NDUyMzM3MDA=,size_16,color_FFFFFF,t_70)
>
> 
>
> **Redis 过期策略和内存淘汰机制**
>
> Redis的用途非常广泛。作为一个高性能的内存数据库，它经常被用于缓存的业务场景。
>
> 所谓缓存，即在第一次获取到数据的时候，把它暂存在内存中。这样下次需要这个数据的时候，就直接从内存中取，不用再去查询数据库或调用远程接口，这样可以极大地提高应用程序的性能。
>
> 如果缓存中的数据永久存在，那占用的内存就会变得越来越大。而内存是有限的，所以缓存系统需要在需要的时候删除一些不必要的缓存数据以节约内存空间。
>
> Redis提供了两种机制配合来达到上述目的：**过期策略**和**内存淘汰机制**。
>
> 1. Redis是使用**定期删除**+**惰性删除**两者配合的过期策略。
>
>    **定期删除**
>
>    使用过Redis的同学应该知道，我们在设置一个key之后，可以指定这个key的过期时间。那么这个key到了过期时间就会立即被删除吗？Redis是如何删除这些过期key的呢？定期删除指的是Redis默认每隔100ms就**随机抽取**一些设置了过期时间的key，检测这些key是否过期，如果过期了就将其删掉。因为key太多，如果全盘扫描所有的key会非常耗性能，所以是随机抽取一些key来删除。这样就有可能删除不完，需要惰性删除配合。
>
>    **惰性删除**
>
>    惰性删除不再是Redis去主动删除，而是在客户端要获取某个key的时候，Redis会先去检测一下这个key是否已经过期，如果没有过期则返回给客户端，如果已经过期了，那么Redis会删除这个key，不会返回给客户端。
>
>    所以惰性删除可以解决一些过期了，但没被定期删除随机抽取到的key。但有些过期的key既没有被随机抽取，也没有被客户端访问，就会一直保留在数据库，占用内存，长期下去可能会导致内存耗尽。所以Redis提供了内存淘汰机制来解决这个问题。
>
>    **为什么不适用定时删除策略**
>
>    为什么不使用定时删除？所谓定时删除，指的是用一个定时器来负责监视key，当这个key过期就自动删除，虽然内存及时释放，但是十分消耗CPU资源，因此一般不推荐采用这一策略。
>
> 2. 内存淘汰策略
>
>    Redis在使用内存达到某个阈值（通过maxmemory配置)的时候，就会触发内存淘汰机制，选取一些key来删除。内存淘汰有许多策略，下面分别介绍这几种不同的策略。
>
>    noeviction：当内存不足以容纳新写入数据时，新写入操作会报错。**默认策略**
>
>    allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key。
>
>    allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个key。
>
>    volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的key。
>
>    volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个key。
>
>    volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的key优先移除。
>
>    **如何选取合适的策略？比较推荐的是两种lru策略**。根据自己的业务需求。如果你使用Redis只是作为缓存，不作为DB持久化，那推荐选择allkeys-lru；如果你使用Redis同时用于缓存和数据持久化，那推荐选择volatile-lru。
>
> **Redis持久化策略**
>
> ​		前面的文章里面介绍了Redis的两种持久化策略：RDB和AOF。在持久化和数据恢复阶段，对过期key也有一些特殊的处理。
>
> ​		**RDB**
>
> ​		从内存数据库持久化数据到RDB文件：持久化key之前，会检查是否过期，过期的key不进入RDB文件 从RDB文件恢复数据到内存数		据	库：数据载入数据库之前，会对key先进行过期检查，如果过期，不导入数据库（主库情况）。
>
> ​		**AOF**
>
> ​		从内存数据库持久化数据到AOF文件：当key过期后，还没有被删除，此时进行执行持久化操作（该key是不会进入aof文件的，因为		没有发生修改命令） 当key过期后，在发生删除操作时，程序会向aof文件追加一条del命令（在将来的以aof文件恢复数据的时候该		过期的键就会被删掉） AOF重写：重写时，会先判断key是否过期，已过期的key不会重写到aof文件
>
> Redis Rehash
>
> [hash table](http://blog.nosqlfan.com/tags/hash-table)是一种高效的[数据结构](https://so.csdn.net/so/search?q=数据结构&spm=1001.2101.3001.7020)，被广泛的用在key-value存储中，[Redis](http://blog.nosqlfan.com/tags/redis)的dict其实就是一个典型的[hash](http://blog.nosqlfan.com/tags/hash) table实现。
>
> [rehash](http://blog.nosqlfan.com/tags/rehash)是在[hash](https://so.csdn.net/so/search?q=hash&spm=1001.2101.3001.7020) table的大小不能满足需求，造成过多hash碰撞后需要进行的扩容hash table的操作，其实通常的做法确实是建立一个额外的hash table，将原来的hash table中的数据在新的数据中进行重新输入，从而生成新的hash表。
>
> redis的 rehash包括了[lazy rehash](http://blog.nosqlfan.com/tags/lazy-rehash)ing和[active rehash](http://blog.nosqlfan.com/tags/active-rehash)ing两种方式
>
> - lazy rehashing：在每次对dict进行操作的时候执行一个slot的rehash
>
> - active rehashing：每100ms里面使用1ms时间进行rehash。
>
>   
>
> **6.讲一下redits的持久化机制** 
>
> > 持久化就是把内存的数据写到磁盘中去，防止服务宕机了内存数据丢失
> >
> > Redis 提供两种持久化机制 RDB（默认） 和 AOF 机制:  
> >
> > （1）RDB：是Redis DataBase缩写快照  
> >
> > RDB是Redis默认的持久化方式。按照一定的时间将内存的数据以快照的形式保存到硬盘中，对应产生的数据文件为dump.rdb。通过配置文件中的save参数来定义快照的周期。  
> >
> > （2）AOF：持久化  
> >
> > AOF持久化(即Append Only File持久化)，则是将Redis执行的每次写命令记录到单独的日志文件中，当重启Redis会重新将持久化的日志中文件恢复数据。  
> >
> > 当两种方式同时开启时，数据恢复Redis会优先选择AOF恢复。  
> >
> > Redis 4.0 对于持久化机制的优化  
> >
> > Redis 4.0 开始支持 RDB 和 AOF 的混合持久化 （默认关闭，可以通过配置项 aof-use-rdb-preamble 开启）。  
> >
> > 如果把混合持久化打开，AOF 重写的时候就直接把 RDB 的内容写到 AOF 文件开头。这样做的好处是可以结合 RDB 和 AOF 的优点, 快速加载同时避免丢失过多的数据。当然缺点也是有的， AOF 里面的 RDB 部分是压缩格式不再是 AOF 格式，可读性较差。
>
> **缓存穿透、击穿、雪崩，选一个讲一下** 
>
> >   缓存雪崩是指缓存同一时间大面积的失效，所以，后面的请求都会落到数据库上，造成数据库短时间内承受大量请求而崩掉。  
> >
> >   解决方案  
> >
> >   1.  缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生。 
> >   2.  一般并发量不是特别多的时候，使用最多的解决方案是加锁排队。 
> >   3.  给每一个缓存数据增加相应的缓存标记，记录缓存的是否失效，如果缓存标记失效，则更新数据缓存。 
> >
> >   
> >
> >
> >    缓存穿透说简单点就是大量请求的 key 根本不存在于缓存中，导致请求直接到了数据库上，根本没有经过缓存这一层。举个例子：某个黑客故意制造我们缓存中不存在的 key 发起大量请求，导致大量请求落到数据库。  
> >
> >    解决方案  
> >
> >   -  接口层增加校验，如用户鉴权校验，id做基础校验，id<=0的直接拦截； 
> >   -  从缓存取不到的数据，在数据库中也没有取到，这时也可以将key-value对写为key-null，缓存有效时间可以设置短点，如30秒（设置太长会导致正常情况也没法使用）。这样可以防止攻击用户反复用同一个id暴力攻击 
> >   -  采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的 bitmap 中，一个一定不存在的数据会被这个 bitmap 拦截掉，从而避免了对底层存储系统的查询压力 
> >
> >   ​    
> >
> >
> >   缓存击穿是指缓存中没有但数据库中有的数据（一般是缓存时间到期），这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大，造成过大压力。和缓存雪崩不同的是，缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，很多数据都查不到从而查数据库。  
> >   解决方案  
> >
> >   -  设置热点数据永远不过期。 
> >   -  加互斥锁，互斥锁
>
> #### 集成JMS（ActiveMQ Artemis）
>
> JMS，Java Message Service， 是JavaEE的消息服务接口。
>
> 消息服务，就是两个进程之间，通过消息服务器通信
>
> ```ascii
> ┌────────┐    ┌──────────────┐    ┌────────┐
> │Producer│───>│Message Server│───>│Consumer│
> └────────┘    └──────────────┘    └────────┘
> ```
>
> 使用消息服务进行通信而不是调用对方的API，好处是
>
> 1. 双方各自无需知晓对方的存在，消息可以异步处理，消息可以在Consumer离线的时候缓存
> 2. 如果Producer发送的消息频率高于Consumer的处理能力，消息可以积压在消息服务器，不至于压垮Consumer
> 3. 通过一个消息服务器，可以连接多个Producer和多个Consumer
>
> JMS是JavaEE定义的消息服务接口，他的一种实现是ActiveMQ Artemis
>
> JMS消息服务模型
>
> 1. Queue
>
>    ```ascii
>    ┌────────┐    ┌────────┐    ┌────────┐
>    │Producer│───>│ Queue  │───>│Consumer│
>    └────────┘    └────────┘    └────────┘
>    ```
>
> 2. Topic
>
>    一种是Topic：
>
>    ```ascii
>                                ┌────────┐
>                             ┌─>│Consumer│
>                             │  └────────┘
>    ┌────────┐    ┌────────┐ │  ┌────────┐
>    │Producer│───>│ Topic  │─┼─>│Consumer│
>    └────────┘    └────────┘ │  └────────┘
>                             │  ┌────────┐
>                             └─>│Consumer│
>                                └────────┘
>    ```
>
> Spring 消息服务
>
> 1. 生产者
>
>    ```java
>    try {
>        Connection connection = null;
>        try {
>            // 创建连接:
>            connection = connectionFactory.createConnection();
>            // 创建会话:
>            Session session = connection.createSession(false,Session.AUTO_ACKNOWLEDGE);
>            // 创建一个Producer并关联到某个Queue:
>            MessageProducer messageProducer = session.createProducer(queue);
>            // 创建一个文本消息:
>            TextMessage textMessage = session.createTextMessage(text);
>            // 发送消息:
>            messageProducer.send(textMessage);
>        } finally {
>            // 关闭连接:
>            if (connection != null) {
>                connection.close();
>            }
>        }
>    } catch (JMSException ex) {
>        // 处理JMS异常
>    }
>    ```
>
> 2. 消费者
>
>    ```java
>    // 创建JMS连接:
>    Connection connection = connectionFactory.createConnection();
>    // 创建会话:
>    Session session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE);
>    // 创建一个Consumer:
>    MessageConsumer consumer = session.createConsumer(queue);
>    // 为Consumer指定一个消息处理器:
>    consumer.setMessageListener(new MessageListener() { 
>        public void onMessage(Message message) {
>            // 在此处理消息... 
>        }
>    });
>    // 启动接收消息的循环:
>    connection.start();
>    ```
>
> 用消息服务对发送Email进行改造的好处是，发送Email的能力通常是有限的，通过JMS消息服务，如果短时间内需要给大量用户发送Email，可以先把消息堆积在JMS服务器上慢慢发送，对于批量发送邮件、短信等尤其有用。
>
> #### 集成RabbitMQ
>
> AcitveMQ Artemis消息服务，实现了JMS消息服务协议，JMS消息服务协议是JAVAEE定义的标准消息服务接口，如果JAVA和其他语言编写的程序进行消息服务通信，就不太适合。
>
> AMQP是一种独立于语言的高级消息队列协议，它定义了一种二进制格式的消息流，任何语言都可以实现这个协议。使用最广泛的还是Erlang编写的RabbitMQ
>
> **AMQP和JMS的比较**
>
> JMS定义了两种类型的消息通道，点对点的Queue和一对多的Topic。而AMQP定义了Exchange和Queue的概念，他的消息模型是
>
> ```ascii
>                                       ┌───────┐
>                                  ┌───>│Queue-1│
>                   ┌──────────┐   │    └───────┘
>               ┌──>│Exchange-1│───┤
> ┌──────────┐  │   └──────────┘   │    ┌───────┐
> │Producer-1│──┤                  ├───>│Queue-2│
> └──────────┘  │   ┌──────────┐   │    └───────┘
>               └──>│Exchange-2│───┤
>                   └──────────┘   │    ┌───────┐
>                                  └───>│Queue-3│
>                                       └───────┘
> ```
>
> 他的producer发送的消息给exchange，由exchange负责转发给不同的queue，consumer可以订阅不同的queue获得消息。
>
> RabbitMQ比JMS的好处在于更加灵活，它可以自定义路由。如果一个exchange连接一个queue，那么这就是JMS的queue，如果连接多个queue，就像JMS的Topic
>

## JVM相关

[![这里写图片描述](https://github.com/AlbertoWang/java-noob/raw/master/%E5%B8%B8%E8%80%83%E9%A2%98.assets/jvm-model.png)](https://github.com/AlbertoWang/java-noob/blob/master/常考题.assets/jvm-model.png)

### 栈的种类

- JVM栈

  包括了**操作数栈**、局部变量表、指向当前方法所属类的运行时常量池的**引用**、方法**返回地址**；

- 本地方法栈

  非Java语言实现的方法。

### 堆中都有什么

线程共享的内存区域，所有实例化的对象保存在堆中，是垃圾回收GC的执行空间

### GC过程

[![307536-20190604201603492-1400932049](https://github.com/AlbertoWang/java-noob/raw/master/%E5%B8%B8%E8%80%83%E9%A2%98.assets/gc-model.png)](https://github.com/AlbertoWang/java-noob/blob/master/常考题.assets/gc-model.png)

### 判断对象是否需要被回收

- 引用计数：有地方引用该对象，计数器++，引用失效，计数器--，有循环引用的问题；
- 可达性分析：根据引用的关系构造引用链（有向图），在图中不可达的对象就是要被回收的。

### 可以作为GC Root的对象

1. 虚拟机栈中引用的对象；
2. 方法区中的静态变量；
3. 常量对象；
4. Native方法引用的对象；
5. 被`synchronized`修饰的对象等。

## JAVA

### JVM 内存结构

《深入理解Java虚拟机（第2版）》中的描述是下面这个样子的：

![img](https://pic4.zhimg.com/80/v2-abefb713de46f1e6dd241246c0afe263_720w.jpg)

JVM的内存结构大概分为：

- 堆（Heap）：线程共享。所有的对象实例以及数组都要在堆上分配。回收器主要管理的对象。
- 方法区（Method Area）：线程共享。存储类信息、常量、静态变量、即时编译器编译后的代码。
- 方法栈（JVM Stack）：线程私有。存储局部变量表、操作栈、动态链接、方法出口，对象指针。
- 本地方法栈（Native Method Stack）：线程私有。为虚拟机使用到的Native 方法服务。如Java使用c或者c++编写的接口服务时，代码在此区运行。
- 程序计数器（Program Counter Register）：线程私有。有些文章也翻译成PC寄存器（PC Register），同一个东西。它可以看作是当前线程所执行的字节码的行号指示器。指向下一条要执行的指令。

为什么元空间替换永久代？，方法去保存再元空间

表面上看是为了避免OOM异常。因为通常使用PermSize和MaxPermSize设置永久代的大小就决定了永久代的上限，但是不是总能知道应该设置为多大合适, 如果使用默认值很容易遇到OOM错误。

当使用元空间时，可以加载多少类的元数据就不再由MaxPermSize控制, 而由系统的实际可用空间来控制。

更深层的原因还是要合并HotSpot和JRockit的代码，JRockit从来没有所谓的永久代，也不需要开发运维人员设置永久代的大小，但是运行良好。同时也不用担心运行性能问题了,在覆盖到的测试中, 程序启动和运行速度降低不超过1%，但是这点性能损失换来了更大的安全保障。



先看一张图，这张图能很清晰的说明JVM内存结构的布局和相应的控制参数：

![img](https://pic4.zhimg.com/80/v2-8845236d1ab9f22fcc658375967d53fb_720w.jpg)

（图片来源于网络）

#### 堆

堆的作用是存放对象实例和数组。从结构上来分，可以分为新生代和老年代。而新生代又可以分为Eden 空间、From Survivor 空间（s0）、To Survivor 空间（s1）。 所有新生成的对象首先都是放在新生代的。需要注意，Survivor的两个区是对称的，没先后关系，所以同一个区中可能同时存在从Eden复制过来的对象，和从前一个Survivor复制过来的对象，而复制到老年代的只有从第一个Survivor区过来的对象。而且，Survivor区总有一个是空的。



- 控制参数

-Xms设置堆的最小空间大小。-Xmx设置堆的最大空间大小。-XX:NewSize设置新生代最小空间大小。-XX:MaxNewSize设置新生代最小空间大小。



- 垃圾回收

此区域是垃圾回收的主要操作区域。



- 异常情况

如果在堆中没有内存完成实例分配，并且堆也无法再扩展时，将会抛出OutOfMemoryError 异常

#### 方法区

方法区（Method Area）与Java 堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。虽然Java 虚拟机规范把方法区描述为堆的一个逻辑部分，但是它却有一个别名叫做Non-Heap（非堆），目的应该是与Java 堆区分开来。



很多人愿意把方法区称为“永久代”（Permanent Generation），本质上两者并不等价，仅仅是因为HotSpot虚拟机的设计团队选择把GC 分代收集扩展至方法区，或者说使用永久代来实现方法区而已。对于其他虚拟机（如BEA JRockit、IBM J9 等）来说是不存在永久代的概念的。在Java8中永生代彻底消失了。



- 控制参数

-XX:PermSize 设置最小空间 -XX:MaxPermSize 设置最大空间。



- 垃圾回收

对此区域会涉及但是很少进行垃圾回收。这个区域的内存回收目标主要是针对常量池的回收和对类型的卸载，一般来说这个区域的回收“成绩”比较难以令人满意。



- 异常情况

根据Java 虚拟机规范的规定， 当方法区无法满足内存分配需求时，将抛出OutOfMemoryError。

#### 方法栈

每个线程会有一个私有的栈。每个线程中方法的调用又会在本栈中创建一个栈帧。在方法栈中会存放编译期可知的各种基本数据类型（boolean、byte、char、short、int、float、long、double）、对象引用（reference 类型，它不等同于对象本身。局部变量表所需的内存空间在编译期间完成分配，当进入一个方法时，这个方法需要在帧中分配多大的局部变量空间是完全确定的，在方法运行期间不会改变局部变量表的大小。



- 控制参数

-Xss控制每个线程栈的大小。



- 异常情况

在Java 虚拟机规范中，对这个区域规定了两种异常状况：

\- StackOverflowError： 异常线程请求的栈深度大于虚拟机所允许的深度时抛出；

\- OutOfMemoryError 异常： 虚拟机栈可以动态扩展，当扩展时无法申请到足够的内存时会抛出。

#### 本地方法栈

本地方法栈（Native Method Stacks）与虚拟机栈所发挥的作用是非常相似的，其

区别不过是虚拟机栈为虚拟机执行Java 方法（也就是字节码）服务，而本地方法栈则

是为虚拟机使用到的Native 方法服务。



- 控制参数

在Sun JDK中本地方法栈和方法栈是同一个，因此也可以用-Xss控制每个线程的大小。



- 异常情况

与虚拟机栈一样，本地方法栈区域也会抛出StackOverflowError 和OutOfMemoryError

异常。

#### 程序计数器

它的作用可以看做是当前线程所执行的字节码的行号指示器。



- 异常情况

此内存区域是唯一一个在Java 虚拟机规范中没有规定任何OutOfMemoryError 情况的区域。

### JAVA内存模型（JMM）

Java Memory Model (JAVA 内存模型）是描述线程之间如何通过内存(memory)来进行交互。 具体说来， JVM中存在一个主存区（Main Memory或Java Heap Memory），对于所有线程进行共享，而每个线程又有自己的工作内存（Working Memory），工作内存中保存的是主存中某些变量的拷贝，线程对所有变量的操作并非发生在主存区，而是发生在工作内存中，而线程之间是不能直接相互访问，变量在程序中的传递，是依赖主存来完成的。

Java内存模型的抽象示意图如下： 

![img](https://imgs.developpaper.com/imgs/2019619101457047.jpg)

从上图来看，线程A与线程B之间如要通信的话，必须要经历下面2个步骤：

1、线程A把本地内存A中更新过的共享变量刷新到主内存中去。

 2、线程B到主内存中去读取线程A之前已更新过的共享变量。

### 内存可见性

一个线程改变了共享变量之后需要通知其他线程这种改变

### 线程同步（保证内存可见性方案）

1. synchronized关键字

   同步锁方案缺点：**会带来性能问题，效率特别低，造成线程阻塞**。

2. volatile关键字

   当一个线程改变内存，会利用CPU总线监听机制来通知这种改变

   **Volatile保证部分类型的原子性**

   我们说Voloatile不能保证原子性，有一点局限： 因为在32位（4字节）处理器中，Java中读取long类型变量不是原子的，需要分成两步，如果一个线程正在修改该long变量的值，另一个线程可能只能看到该值的一半（前32位）。但是对一个volatile型的long或double变量的读写时原子的

3. 原子操作CAS

   CAS，Compare and Swap，是一种针对多处理器设计的一种特殊命令，用于管理对共享数据的并发访问

   CAS是一种无锁的非阻塞算法实现，是硬件对并发操作的支持，保证了数据变量的原子性

   CAS包含三个操作数：内存值V，预估值A，更新值B，当且仅当V==A时，V=B，否则不会执行任何操作

![preview](https://pic1.zhimg.com/v2-d25bfd180fd5d1fc16090af61d813bb4_r.jpg)

​	CAS算法包含三个操作数，内存V，本地内存预期值A，本地内存想要修改的值B。T1和T2线程运行时，读取内存值V到本地内存预期值A，当T1将值B修改后，他检查内存值和预期值相等，就把修改值B更新到主存，否则，他发现内存值V！=预期值B，他进入自旋，不断读取新的V值并处理之后和A比较。这是一种乐观锁的思路，也就是他相信在他修改之前，内存没有得到修改。

**CAS算法问题**

1. ABA问题，一个线程把A变成B，另一个线程把B又变成A，这样第三个线程无法感知这个变量的这种变化

![img](https://pic4.zhimg.com/80/v2-9e9a59d57847f7fe01c1e4fe95769723_720w.jpg)

​		ABA问题解决方案，在变量前面添加版本号，每次更新后版本号加一

2. 自旋消耗CPU性能
3. 只能保证一个共享变量的原子操作。

可以用CAS在无锁的情况下实现原子操作，但要明确应用场合，非常简单的操作且又不想引入锁可以考虑使用CAS操作，当想要非阻塞地完成某一操作也可以考虑CAS。不推荐在复杂操作中引入CAS，会使程序可读性变差，且难以测试，同时会出现问题。

### JAVA 垃圾收集算法GC

Java中Stop-The-World机制简称**STW**，是在执行垃圾收集算法时，[Java](http://www.jb51.net/list/list_207_1.htm)应用程序的其他所有线程都被[挂起](https://so.csdn.net/so/search?q=挂起&spm=1001.2101.3001.7020)（除了垃圾收集帮助器之外）。Java中一种全局暂停现象，全局停顿，所有Java代码停止，native代码可以执行，但不能与JVM交互；这些现象多半是由于gc引起。

#### CMS收集器

CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器，它非常符合那些集中在互联网站或者B/S系统的服务端上的Java应用，这些应用都非常重视服务的响应速度。从名字上（“Mark Sweep”）就可以看出它是基于“标记-清除”算法实现的。

CMS收集器工作的整个流程分为以下4个步骤：

- 初始标记（CMS initial mark）：仅仅只是标记一下GC Roots能直接关联到的对象，速度很快，需要“Stop The World”。
- 并发标记（CMS concurrent mark）：进行GC Roots Tracing的过程，在整个过程中耗时最长。
- 重新标记（CMS remark）：为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段稍长一些，但远比并发标记的时间短。此阶段也需要“Stop The World”。
- 并发清除（CMS concurrent sweep）

由于整个过程中耗时最长的并发标记和并发清除过程收集器线程都可以与用户线程一起工作。

所以，从总体上来说，CMS收集器的内存回收过程是与用户线程一起并发执行的。通过下图可以比较清楚地看到CMS收集器的运作步骤中并发和需要停顿的时间：

![img](https://ask.qcloudimg.com/http-save/yehe-1346475/sdxh11irpl.jpeg?imageView2/2/w/1620)

优点

CMS是一款优秀的收集器，它的主要优点在名字上已经体现出来了：并发收集、低停顿，因此CMS收集器也被称为并发低停顿收集器（Concurrent Low Pause Collector）。

缺点

- 对CPU资源非常敏感 其实，面向并发设计的程序都对CPU资源比较敏感。在并发阶段，它虽然不会导致用户线程停顿，但会因为占用了一部分线程（或者说CPU资源）而导致应用程序变慢，总吞吐量会降低。
- CMS默认启动的回收线程数是（CPU数量+3）/4，也就是当CPU在4个以上时，并发回收时垃圾收集线程不少于25%的CPU资源，并且随着CPU数量的增加而下降。但是当CPU不足4个时（比如2个），CMS对用户程序的影响就可能变得很大，如果本来CPU负载就比较大，还要分出一半的运算能力去执行收集器线程，就可能导致用户程序的执行速度忽然降低了50%，其实也让人无法接受。
- 无法处理浮动垃圾（Floating Garbage） 可能出现“Concurrent Mode Failure”失败而导致另一次Full GC的产生。
- 由于CMS并发清理阶段用户线程还在运行着，伴随程序运行自然就还会有新的垃圾不断产生。这一部分垃圾出现在标记过程之后，CMS无法再当次收集中处理掉它们，只好留待下一次GC时再清理掉。
- 这一部分垃圾就被称为“浮动垃圾”。也是由于在垃圾收集阶段用户线程还需要运行，那也就还需要预留有足够的内存空间给用户线程使用，因此CMS收集器不能像其他收集器那样等到老年代几乎完全被填满了再进行收集，需要预留一部分空间提供并发收集时的程序运作使用。
- 标记-清除算法导致的空间碎片 CMS是一款基于“标记-清除”算法实现的收集器，这意味着收集结束时会有大量空间碎片产生。
- 空间碎片过多时，将会给大对象分配带来很大麻烦，往往出现老年代空间剩余，但无法找到足够大连续空间来分配当前对象。

#### G1收集器

G1（Garbage-First）收集器是当今收集器技术发展最前沿的成果之一，它是一款面向服务端应用的垃圾收集器，HotSpot开发团队赋予它的使命是（在比较长期的）未来可以替换掉JDK 1.5中发布的CMS收集器。与其他GC收集器相比，G1具备如下特点：

- 并行与并发 G1 能充分利用多CPU、多核环境下的硬件优势，使用多个CPU来缩短“Stop The World”停顿时间，部分其他收集器原本需要停顿Java线程执行的GC动作，G1收集器仍然可以通过并发的方式让Java程序继续执行。
- 分代收集 与其他收集器一样，分代概念在G1中依然得以保留。虽然G1可以不需要其他收集器配合就能独立管理整个GC堆，但它能够采用不同方式去处理新创建的对象和已存活一段时间、熬过多次GC的旧对象来获取更好的收集效果。
- 空间整合 G1从整体来看是基于“标记-整理”算法实现的收集器，从局部（两个Region之间）上来看是基于“复制”算法实现的。这意味着G1运行期间不会产生内存空间碎片，收集后能提供规整的可用内存。此特性有利于程序长时间运行，分配大对象时不会因为无法找到连续内存空间而提前触发下一次GC。
- 可预测的停顿 这是G1相对CMS的一大优势，降低停顿时间是G1和CMS共同的关注点，但G1除了降低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为M毫秒的时间片段内，消耗在GC上的时间不得超过N毫秒，这几乎已经是实时Java（RTSJ）的垃圾收集器的特征了。

![img](https://ask.qcloudimg.com/http-save/yehe-1346475/0nj852xmok.jpeg?imageView2/2/w/1620)

## 线程同步相关

### `synchronized`底层实现

同步代码块使用了底层原语的monitorenter和monitorexit，同步方法使用ACC_SYNCHRONIZED。

每个对象拥有一个monitor，monitor只能被一个线程拥有（monitor的进入数为0则可进，进入后变为1，monitor进入数为1则不允许其他线程进入），是可重入的；其他线程申请进入monitor只能等待进入数变为0；

拥有monitor的线程才可以执行monitorexit，进入数会-1，降到0时释放monitor（以上过程与[AQS](https://zhuanlan.zhihu.com/p/86072774)类似）

### `synchronized`锁升级

JDK1.6之后对`synchronized`进行了优化，锁可以逐步升级（无锁 -> 偏向锁 -> 轻量级锁 -> 重量级锁）：

- 偏向锁：适用于单线程，如果发生抢占则持有锁的线程被挂起，并升级为轻量级锁；
- 轻量级锁：不会阻塞，执行速度快，但得不到锁单线程进行自旋耗费CPU，CAS过程；
- 重量级锁：阻塞，执行时间长，但不会消耗CPU，AQS过程。

### `synchronized`与`static synchronized`

`synchronized`（对象锁）管理的是某个类的一个对象，同一个类的两个对象没办法管理，作用域是`this.synchronized`；

`static synchronized`（类锁）管理的是某个类所有的对象，作用域是`clazz.synchronized`。



###  HashMap`、`ConcurrentHashMap`与`Hashtable

#### 基本数据结构

- 底层数据结构：`HashMap`与`ConcurrentHashMap`底层数据结构相似（数组+链表+红黑树），`Hashtable`没有红黑树；
- 线程安全：`Hashtable`的`synchronized`修饰在方法，是对象级的加锁，同一时间只有一个线程能对数据进行操作，`ConcurrentHashMap`使用了修饰具体对象的`synchronized`（锁一个桶）和CAS机制，实现了更细粒度的锁；
- 地址计算：`HashMap`使用`key.hashCode() ^ (key.hashCode() >>> 16)`、`Hashtable`使用`(key.hashCode() & 0x7fffffff) % tab.length()`、`ConcurrentHashMap`使用`(key.hashCode() ^ (key.hashCode() >>> 16)) & 0x7fffffff`。

#### key类的重写`equals()`和`hashCode()`方法

只重写了其中之一，会造成相等的key对象存在两个的问题：

- 重写了`hashCode()`但没重写`equals()`方法：`equals()`比较两个对象的地址，只要不是同一个对象必为`false`，因此相等的两个key发生哈希碰撞后不会覆盖，而是存在两个相等的key；
- 重写了`equals()`但没重写`hashCode()`方法：两个相等的对象可能算出来的哈希值不同，因此被安放在了两个不同的桶中，造成相等对象存在两个的问题。

## `ThreadLocal`相关

### `ThreadLocal`造成内存泄漏

`ThreadLocalMap`的key为**弱引用**（有用但非必需，下一次GC会被回收），value为**强引用**（GC过程不会被回收），有可能造成key被GC，value没被GC，`ThreadLocalMap`中出现`null`为key的`Entry`，产生内存泄漏（软引用：有用但非必需，内存溢出之前被回收）；

解决方式：调用`set()`、`get()`和`remove()`方法时，会清理掉key为`null`的记录，使用`ThreadLocal`方法后手动`remove()`。

## 线程

先来看看什么是进程和线程？

进程是资源（CPU、内存等）分配的基本单位，它是程序执行时的一个实例。程序运行时系统就会创建一个进程，并为它分配资源，然后把该进程放入进程就绪队列，进程调度器选中它的时候就会为它分配CPU时间，程序开始真正运行。就比如说，我们开发的一个单体项目，运行它，就会产生一个进程。

线程是程序执行时的最小单位，它是进程的一个执行流，是CPU调度和分派的基本单位，一个进程可以由很多个线程组成，线程间共享进程的所有资源，每个线程有自己的堆栈和局部变量。线程由CPU独立调度执行，在多CPU环境下就允许多个线程同时运行。同样多线程也可以实现并发操作，每个请求分配一个线程来处理。在这里强调一点就是：计算机中的线程和应用程序中的线程不是同一个概念。

总之一句话描述就是：进程是资源分配的最小单位，线程是程序执行的最小单位。

### 什么是线程安全

并发多线程访问同一个对象的执行结果和串行执行他们的一样，这个并发访问就是线程安全的。

什么是线程安全呢？什么样的情况会造成线程安全问题呢？怎么解决线程安全呢？这些问题都是在下文中所要讲述的。

**线程安全：**当多个线程访问一个对象时，如果不用考虑这些线程在运行时环境下的调度和交替执行，也不需要进行额外的同步，或者在调用方进行任何其他的协调操作，调用这个对象的行为都可以获得正确的结果，那这个对象就是线程安全的。

那什么时候会造成线程安全问题呢？当多个线程同时去访问一个对象时，就可能会出现线程安全问题。那么怎么解决呢？请往下看！

### 解决线程安全

在这里提供4种方法来解决线程安全问题，也是最常用的4种方法。前提是项目在一个服务器中，如果是分布式项目可能就会用到分布锁了，这个就放到后面文章来详谈了。

讲4种方法前，还是先来了解一下悲观锁和乐观锁吧！

悲观锁，顾名思义它是悲观的。讲得通俗点就是，认为自己在使用数据的时候，一定有别的线程来修改数据，因此在获取数据的时候先加锁，确保数据不会被线程修改。形象理解就是总觉得有刁民想害朕。

而乐观锁就比较乐观了，认为在使用数据时，不会有别的线程来修改数据，就不会加锁，只是在更新数据的时候去判断之前有没有别的线程来更新了数据。具体用法在下面讲解。

现在来看有那4种方法吧！

- 方法一：使用synchronized关键字，一个表现为原生语法层面的互斥锁，它是一种悲观锁，使用它的时候我们一般需要一个监听对象 并且监听对象必须是唯一的，通常就是当前类的字节码对象。它是JVM级别的，不会造成死锁的情况。使用synchronized可以拿来修饰类，静态方法，普通方法和代码块。比如：Hashtable类就是使用synchronized来修饰方法的。put方法部分源码：

  ```java
   public synchronized V put(K key, V value) {
          // Make sure the value is not null
          if (value == null) {
              throw new NullPointerException();
          } 
  
   
  ```

  而ConcurrentHashMap类中就是使用synchronized来锁代码块的。putVal方法部分源码：

  ```java
   else {
                  V oldVal = null;
                  synchronized (f) {
                      if (tabAt(tab, i) == f) {
                          if (fh >= 0) {
                              binCount = 1;
  ```

  synchronized关键字底层实现主要是通过monitorenter 与monitorexit计数 ，如果计数器不为0，说明资源被占用，其他线程就不能访问了，但是可重入的除外。说到这，就来讲讲什么是可重入的。这里其实就是指的可重入锁：指的是同一线程外层函数获得锁之后，内层递归函数仍然有获取该锁的代码，但不受影响，执行对象中所有同步方法不用再次获得锁。避免了频繁的持有释放操作，这样既提升了效率，又避免了死锁。

  其实在使用synchronized时，存在一个锁升级原理。它是指在锁对象的对象头里面有一个 threadid 字段，在第一次访问的时候 threadid 为空，jvm 让其持有偏向锁，并将 threadid 设置为其线程 id，再次进入的时候会先判断 threadid 是否与其线程 id 一致，如果一致则可以直接使用此对象，如果不一致，则升级偏向锁为轻量级锁，通过自旋循环一定次数来获取锁，执行一定次数之后，如果还没有正常获取到要使用的对象，此时就会把锁从轻量级升级为重量级锁，此过程就构成了 synchronized 锁的升级。锁升级的目的是为了减低了锁带来的性能消耗。在 Java 6 之后优化 synchronized 的实现方式，使用了偏向锁升级为轻量级锁再升级到重量级锁的方式，从而减低了锁带来的性能消耗。可能你又会问什么是偏向锁？什么是轻量级锁？什么是重量级锁？这里就简单描述一下吧，能够帮你更好的理解synchronized。

  偏向锁（无锁）：大多数情况下锁不仅不存在多线程竞争，而且总是由同一线程多次获得。偏向锁的目的是在某个线程获得锁之后（线程的id会记录在对象的Mark Word中），消除这个线程锁重入（CAS）的开销，看起来让这个线程得到了偏护。

  轻量级锁（CAS）：就是由偏向锁升级来的，偏向锁运行在一个线程进入同步块的情况下，当第二个线程加入锁争用的时候，偏向锁就会升级为轻量级锁；轻量级锁的意图是在没有多线程竞争的情况下，通过CAS操作尝试将MarkWord更新为指向LockRecord的指针，减少了使用重量级锁的系统互斥量产生的性能消耗。

  重量级锁：虚拟机使用CAS操作尝试将MarkWord更新为指向LockRecord的指针，如果更新成功表示线程就拥有该对象的锁；如果失败，会检查MarkWord是否指向当前线程的栈帧，如果是，表示当前线程已经拥有这个锁；如果不是，说明这个锁被其他线程抢占，此时膨胀为重量级锁。

- 方法二：使用Lock接口下的实现类。Lock是juc（java.util.concurrent）包下面的一个接口。常用的实现类就是ReentrantLock 类，它其实也是一种悲观锁。一种表现为 API 层面的互斥锁。通过lock() 和 unlock() 方法配合使用。因此也可以说是一种手动锁，使用比较灵活。但是使用这个锁时一定要注意要释放锁，不然就会造成死锁。一般配合try/finally 语句块来完成。比如：

  ```java
  public class TicketThreadSafe extends Thread{
        private static int num = 5000;
        ReentrantLock lock = new ReentrantLock();
        @Override
        public void run() {
          while(num>0){
               try {
                 lock.lock();
                 if(num>0){
                   System.out.println(Thread.currentThread().getName()+"你的票号是"+num--);
                 }
                } catch (Exception e) {
                   e.printStackTrace();
                }finally {
                   lock.unlock();
                }
              }
        }
  }
  
    
  ```

  相比 synchronized，ReentrantLock 增加了一些高级功能，主要有以下 3 项：等待可中断、可实现公平锁，以及锁可以绑定多个条件。

  等待可中断是指：当持有锁的线程长期不释放锁的时候，正在等待的线程可以选择放弃等待，改为处理其他事情，可中断特性对处理执行时间非常长的同步块很有帮助。

  公平锁是指：多个线程在等待同一个锁时，必须按照申请锁的时间顺序来依次获得锁；而非公平锁则不保证这一点，在锁被释放时，任何一个等待锁的线程都有机会获得锁。synchronized 中的锁是非公平的，ReentrantLock 默认情况下也是非公平的，但可以通过带布尔值的构造函数要求使用公平锁。

  ```java
  public ReentrantLock(boolean fair) {
          sync = fair ? new FairSync() : new NonfairSync();
      }
  ```

  锁绑定多个条件是指：一个 ReentrantLock 对象可以同时绑定多个 Condition 对象，而在 synchronized 中，锁对象的 wait() 和 notify() 或 notifyAll() 方法可以实现一个隐含的条件，如果要和多于一个的条件关联的时候，就不得不额外地添加一个锁，而 ReentrantLock 则无须这样做，只需要多次调用 newCondition() 方法即可。

  ```java
  final ConditionObject newCondition() { //ConditionObject是Condition的实现类
              return new ConditionObject();
      } 
  
    
  ```

- 方法三：使用线程本地存储ThreadLocal。当多个线程操作同一个变量且互不干扰的场景下，可以使用ThreadLocal来解决。它会在每个线程中对该变量创建一个副本，即每个线程内部都会有一个该变量，且在线程内部任何地方都可以使用，线程之间互不影响，这样一来就不存在线程安全问题，也不会严重影响程序执行性能。在很多情况下，ThreadLocal比直接使用synchronized同步机制解决线程安全问题更简单，更方便，且结果程序拥有更高的并发性。通过set(T value)方法给线程的局部变量设置值；get()获取线程局部变量中的值。当给线程绑定一个 Object 内容后，只要线程不变,就可以随时取出；改变线程,就无法取出内容.。这里提供一个用法示例：

  ```java
  public class ThreadLocalTest {
        private static int a = 500;
        public static void main(String[] args) {
              new Thread(()->{
                    ThreadLocal<Integer> local = new ThreadLocal<Integer>();
                    while(true){
                          local.set(++a);   //子线程对a的操作不会影响主线程中的a
                          try {
                                Thread.sleep(1000);
                          } catch (InterruptedException e) {
                                e.printStackTrace();
                          }
                          System.out.println("子线程："+local.get());
                    }
              }).start();
              a = 22;
              ThreadLocal<Integer> local = new ThreadLocal<Integer>();
              local.set(a);
              while(true){
                    try {
                          Thread.sleep(1000);
                    } catch (InterruptedException e) {
                          e.printStackTrace();
                    }
                    System.out.println("主线程："+local.get());
              }
        }
  } 
  
   
  ```

  ThreadLocal线程容器保存变量时，底层其实是通过ThreadLocalMap来实现的。它是以当前ThreadLocal变量为key ，要存的变量为value。获取的时候就是以当前ThreadLocal变量去找到对应的key，然后获取到对应的值。源码参考如下：

  ```java
   public void set(T value) {
          Thread t = Thread.currentThread();
          ThreadLocalMap map = getMap(t);
          if (map != null)
              map.set(this, value);
          else
              createMap(t, value);
      }
       ThreadLocalMap getMap(Thread t) {
          return t.threadLocals; //ThreadLocal.ThreadLocalMap threadLocals = null;Thread类中声明的
      }
      void createMap(Thread t, T firstValue) {
          t.threadLocals = new ThreadLocalMap(this, firstValue);
      }
  ```

  观察源码就会发现，其实每个线程Thread内部有一个ThreadLocal.ThreadLocalMap类型的成员变量threadLocals，这个threadLocals就是用来存储实际的变量副本的，键值为当前ThreadLocal变量，value为变量副本（即T类型的变量）。

  初始时，在Thread里面，threadLocals为空，当通过ThreadLocal变量调用get()方法或者set()方法，就会对Thread类中的threadLocals进行初始化，并且以当前ThreadLocal变量为键值，以ThreadLocal要保存的副本变量为value，存到threadLocals。

  然后在当前线程里面，如果要使用副本变量，就可以通过get方法在threadLocals里面查找即可。

- 方法四：使用乐观锁机制。前面已经讲述了什么是乐观锁。这里就来描述哈在java开发中怎么使用的。

  其实在表设计的时候，我们通常就需要往表里加一个version字段。每次查询时，查出带有version的数据记录，更新数据时，判断数据库里对应id的记录的version是否和查出的version相同。若相同，则更新数据并把版本号+1；若不同，则说明，该数据发生了并发，被别的线程使用了，进行递归操作，再次执行递归方法，直到成功更新数据为止。

## 使用wait和notify用于协调多线程

用于协调多线程

`wait`和`notify`用于多线程协调运行：

- 在`synchronized`内部可以调用`wait()`使线程进入等待状态；
- 必须在已获得的锁对象上调用`wait()`方法；
- 在`synchronized`内部可以调用`notify()`或`notifyAll()`唤醒其他等待线程；
- 必须在已获得的锁对象上调用`notify()`或`notifyAll()`方法；
- 已唤醒的线程还需要重新获得锁后才能继续执行。

```java
class TaskQueue {
    Queue<String> queue = new LinkedList<>();

    public synchronized void addTask(String s) {
        this.queue.add(s);
        this.notifyAll();
    }

    public synchronized String getTask() throws InterruptedException {
        while (queue.isEmpty()) {
            this.wait();
        }
        return queue.remove();
    }
}
```

addTask执行的时候需要获得this的锁，而getTask执行的时候也要获得this的锁，这造成如果哦queue为空的时候，实际上会造成while循环不出来，线程不协调

多线程协调运行的原则就是：当条件不满足时，线程进入等待状态；当条件满足时，线程被唤醒，继续执行任务。

## 使用ReentrantLock（一种比Synchronied更安全的锁）

我们知道Java语言直接提供了`synchronized`关键字用于加锁，但这种锁一是很重，二是获取时必须一直等待，没有额外的尝试机制。

`java.util.concurrent.locks`包提供的`ReentrantLock`用于替代`synchronized`加锁，我们来看一下传统的`synchronized`代码：

```java
public class Counter {
    private int count;

    public void add(int n) {
        synchronized(this) {
            count += n;
        }
    }
}
```

如果用`ReentrantLock`替代，可以把代码改造为：

```java
public class Counter {
    private final Lock lock = new ReentrantLock();
    private int count;

    public void add(int n) {
        lock.lock();
        try {
            count += n;
        } finally {
            lock.unlock();
        }
    }
}
```

因为`synchronized`是Java语言层面提供的语法，所以我们不需要考虑异常，而`ReentrantLock`是Java代码实现的锁，我们就必须先获取锁，然后在`finally`中正确释放锁。

顾名思义，`ReentrantLock`是可重入锁，它和`synchronized`一样，一个线程可以多次获取同一个锁。

和`synchronized`不同的是，`ReentrantLock`可以尝试获取锁：

```java
if (lock.tryLock(1, TimeUnit.SECONDS)) {
    try {
        ...
    } finally {
        lock.unlock();
    }
}
```

上述代码在尝试获取锁的时候，最多等待1秒。如果1秒后仍未获取到锁，`tryLock()`返回`false`，程序就可以做一些额外处理，而不是无限等待下去。

所以，使用`ReentrantLock`比直接使用`synchronized`更安全，线程在`tryLock()`失败的时候不会导致死锁。

### 小结

`ReentrantLock`可以替代`synchronized`进行同步；

`ReentrantLock`获取锁更安全；

必须先获取到锁，再进入`try {...}`代码块，最后使用`finally`保证释放锁；

可以使用`tryLock()`尝试获取锁。

## 使用Condition（ReentrantLock）

使用`ReentrantLock`比直接使用`synchronized`更安全，可以替代`synchronized`进行线程同步

但是，`synchronized`可以配合`wait`和`notify`实现线程在条件不满足时等待，条件满足时唤醒，用`ReentrantLock`我们怎么编写`wait`和`notify`的功能呢？

答案是使用`Condition`对象来实现`wait`和`notify`的功能。

```java
class TaskQueue {
    private final Lock lock = new ReentrantLock();
    private final Condition condition = lock.newCondition();
    private Queue<String> queue = new LinkedList<>();

    public void addTask(String s) {
        lock.lock();
        try {
            queue.add(s);
            condition.signalAll();
        } finally {
            lock.unlock();
        }
    }

    public String getTask() {
        lock.lock();
        try {
            while (queue.isEmpty()) {
                condition.await();
            }
            return queue.remove();
        } finally {
            lock.unlock();
        }
    }
}
```

可见，使用`Condition`时，引用的`Condition`对象必须从`Lock`实例的`newCondition()`返回，这样才能获得一个绑定了`Lock`实例的`Condition`实例。

`Condition`提供的`await()`、`signal()`、`signalAll()`原理和`synchronized`锁对象的`wait()`、`notify()`、`notifyAll()`是一致的，并且其行为也是一样的：

- `await()`会释放当前锁，进入等待状态；
- `signal()`会唤醒某个等待线程；
- `signalAll()`会唤醒所有等待线程；
- 唤醒线程从`await()`返回后需要重新获得锁。

此外，和`tryLock()`类似，`await()`可以在等待指定时间后，如果还没有被其他线程通过`signal()`或`signalAll()`唤醒，可以自己醒来：

```java
if (condition.await(1, TimeUnit.SECOND)) {
    // 被其他线程唤醒
} else {
    // 指定时间内没有被其他线程唤醒
}
```

可见，使用`Condition`配合`Lock`，我们可以实现更灵活的线程同步。

### 小结

`Condition`可以替代`wait`和`notify`；

`Condition`对象必须从`Lock`对象获取。

## 使用ReadWriteLock（读写锁，增加读效率，使用读多写少条件）

使用synchronized+wait, notify, notifyall 和使用reentrantlock+ await, signal, signalall 加锁，都是很重的锁，他让一个资源在一个时刻只能有一个线程读或者写，而实际上我们可以让一个资源被重复读，写的时候不可重复写，这样我们可以使用读写锁，readwritelock

际上我们想要的是：允许多个线程同时读，但只要有一个线程在写，其他线程就必须等待：

|      | 读     | 写     |
| :--- | :----- | :----- |
| 读   | 允许   | 不允许 |
| 写   | 不允许 | 不允许 |

使用`ReadWriteLock`可以解决这个问题，它保证：

- 只允许一个线程写入（其他线程既不能写入也不能读取）；
- 没有写入时，多个线程允许同时读（提高性能）。

用`ReadWriteLock`实现这个功能十分容易。我们需要创建一个`ReadWriteLock`实例，然后分别获取读锁和写锁：

```java
public class Counter {
    private final ReadWriteLock rwlock = new ReentrantReadWriteLock();
    private final Lock rlock = rwlock.readLock();
    private final Lock wlock = rwlock.writeLock();
    private int[] counts = new int[10];

    public void inc(int index) {
        wlock.lock(); // 加写锁
        try {
            counts[index] += 1;
        } finally {
            wlock.unlock(); // 释放写锁
        }
    }

    public int[] get() {
        rlock.lock(); // 加读锁
        try {
            return Arrays.copyOf(counts, counts.length);
        } finally {
            rlock.unlock(); // 释放读锁
        }
    }
}
```

把读写操作分别用读锁和写锁来加锁，在读取时，多个线程可以同时获得读锁，这样就大大提高了并发读的执行效率。

使用`ReadWriteLock`时，适用条件是同一个数据，有大量线程读取，但仅有少数线程修改。

例如，一个论坛的帖子，回复可以看做写入操作，它是不频繁的，但是，浏览可以看做读取操作，是非常频繁的，这种情况就可以使用`ReadWriteLock`。

### 小结

使用`ReadWriteLock`可以提高读取效率：

- `ReadWriteLock`只允许一个线程写入；
- `ReadWriteLock`允许多个线程在没有写入时同时读取；
- `ReadWriteLock`适合读多写少的场景。

## 使用StampedLock（一种读写锁）

前面介绍的`ReadWriteLock`可以解决多线程同时读，但只有一个线程能写的问题。

如果我们深入分析`ReadWriteLock`，会发现它有个潜在的问题：如果有线程正在读，写线程需要等待读线程释放锁后才能获取写锁，即读的过程中不允许写，这是一种**悲观的读锁**。

要进一步提升并发执行效率，Java 8引入了新的读写锁：`StampedLock`。

`StampedLock`和`ReadWriteLock`相比，改进之处在于：读的过程中也允许获取写锁后写入！这样一来，我们读的数据就可能不一致，所以，需要一点额外的代码来判断读的过程中是否有写入，这种读锁是一种**乐观锁**。

乐观锁的意思就是乐观地估计读的过程中大概率不会有写入，因此被称为乐观锁。反过来，悲观锁则是读的过程中拒绝有写入，也就是写入必须等待。显然乐观锁的并发效率更高，但一旦有小概率的写入导致读取的数据不一致，需要能检测出来，再读一遍就行。

**乐观锁**：乐观的认为读的时候不会有写入，当然发生写入的时候要能检测到有写入并且重新读一遍

**悲观锁**：读的时候拒绝写入，也就是写入必须等待。

```java
public class Point {
    private final StampedLock stampedLock = new StampedLock();

    private double x;
    private double y;

    public void move(double deltaX, double deltaY) {
        long stamp = stampedLock.writeLock(); // 获取写锁
        try {
            x += deltaX;
            y += deltaY;
        } finally {
            stampedLock.unlockWrite(stamp); // 释放写锁
        }
    }

    public double distanceFromOrigin() {
        long stamp = stampedLock.tryOptimisticRead(); // 获得一个乐观读锁
        // 注意下面两行代码不是原子操作
        // 假设x,y = (100,200)
        double currentX = x;
        // 此处已读取到x=100，但x,y可能被写线程修改为(300,400)
        double currentY = y;
        // 此处已读取到y，如果没有写入，读取是正确的(100,200)
        // 如果有写入，读取是错误的(100,400)
        if (!stampedLock.validate(stamp)) { // 检查乐观读锁后是否有其他写锁发生
            stamp = stampedLock.readLock(); // 获取一个悲观读锁
            try {
                currentX = x;
                currentY = y;
            } finally {
                stampedLock.unlockRead(stamp); // 释放悲观读锁
            }
        }
        return Math.sqrt(currentX * currentX + currentY * currentY);
    }
}
```

和`ReadWriteLock`相比，写入的加锁是完全一样的，不同的是读取。注意到首先我们通过`tryOptimisticRead()`获取一个乐观读锁，并返回版本号。接着进行读取，读取完成后，我们通过`validate()`去验证版本号，如果在读取过程中没有写入，版本号不变，验证成功，我们就可以放心地继续后续操作。如果在读取过程中有写入，版本号会发生变化，验证将失败。在失败的时候，我们再通过获取悲观读锁再次读取。由于写入的概率不高，程序在绝大部分情况下可以通过乐观读锁获取数据，极少数情况下使用悲观读锁获取数据。

可见，`StampedLock`把读锁细分为乐观读和悲观读，能进一步提升并发效率。但这也是有代价的：一是代码更加复杂，二是`StampedLock`是不可重入锁，不能在一个线程中反复获取同一个锁。

`StampedLock`还提供了更复杂的将悲观读锁升级为写锁的功能，它主要使用在if-then-update的场景：即先读，如果读的数据满足条件，就返回，如果读的数据不满足条件，再尝试写。

### 小结

`StampedLock`提供了乐观读锁，可取代`ReadWriteLock`以进一步提升并发性能；

`StampedLock`是不可重入锁。

## Concurrent集合类

### ArrayList是线程不安全的

对于ArrayList，相信大家并不陌生。这个类是我们平时接触得最多的一个列表集合类。

面试时相信面试官首先就会问到关于它的知识。一个经常被问到的问题就是：ArrayList是否是线程安全的？

答案当然很简单，无论是背来的还是自己看过源码，我们都知道它是线程不安全的。那么它为什么是线程不安全的呢？它线程不安全的具体体现又是怎样的呢？我们从源码的角度来看下。

二.源码分析
首先看看这个类所拥有的部分属性字段：

```java
public class ArrayList<E> extends AbstractList<E>
        implements List<E>, RandomAccess, Cloneable, java.io.Serializable
{
    /**
     * 列表元素集合数组
     * 如果新建ArrayList对象时没有指定大小，那么会将EMPTY_ELEMENTDATA赋值给elementData，
     * 并在第一次添加元素时，将列表容量设置为DEFAULT_CAPACITY 
     */
    transient Object[] elementData; 

    /**
     * 列表大小，elementData中存储的元素个数
     */
    private int size;
}

```

所以通过这两个字段我们可以看出，ArrayList的实现主要就是用了一个Object的数组，用来保存所有的元素，以及一个size变量用来保存当前数组中已经添加了多少元素。

接着我们看下最重要的add操作时的源代码：

```java
public boolean add(E e) {

    /**
     * 添加一个元素时，做了如下两步操作
     * 1.判断列表的capacity容量是否足够，是否需要扩容
     * 2.真正将元素放在列表的元素数组里面
     */
    ensureCapacityInternal(size + 1);  // Increments modCount!!
    elementData[size++] = e;
    return true;
}
```

ensureCapacityInternal()这个方法的详细代码我们可以暂时不看，它的作用就是判断如果将当前的新元素加到列表后面，列表的elementData数组的大小是否满足，如果size + 1的这个需求长度大于了elementData这个数组的长度，那么就要对这个数组进行扩容。

由此看到add元素时，实际做了两个大的步骤：

1. 判断elementData数组容量是否满足需求
2. 在elementData对应位置上设置值

这样也就出现了第一个导致线程不安全的隐患，在多个线程进行add操作时可能会导致elementData数组越界。具体逻辑如下：

1. 列表大小为9，即size=9
2. 线程A开始进入add方法，这时它获取到size的值为9，调用ensureCapacityInternal方法进行容量判断。
3. 线程B此时也进入add方法，它获取到size的值也为9，也开始调用ensureCapacityInternal方法。
4. 线程A发现需求大小为10，而elementData的大小就为10，可以容纳。于是它不再扩容，返回。
5. 线程B也发现需求大小为10，也可以容纳，返回。
6. 线程A开始进行设置值操作， elementData[size++] = e 操作。此时size变为10。
7. 线程B也开始进行设置值操作，它尝试设置elementData[10] = e，而elementData没有进行过扩容，它的下标最大为9。于是此时会报出一个数组越界的异常ArrayIndexOutOfBoundsException.

另外第二步 elementData[size++] = e 设置值的操作同样会导致线程不安全。从这儿可以看出，这步操作也不是一个原子操作，它由如下两步操作构成：

1. elementData[size] = e;
2. size = size + 1;

在单线程执行这两条代码时没有任何问题，但是当多线程环境下执行时，可能就会发生一个线程的值覆盖另一个线程添加的值，具体逻辑如下：

1. 列表大小为0，即size=0
2. 线程A开始添加一个元素，值为A。此时它执行第一条操作，将A放在了elementData下标为0的位置上。
3. 接着线程B刚好也要开始添加一个值为B的元素，且走到了第一步操作。此时线程B获取到size的值依然为0，于是它将B也放在了elementData下标为0的位置上。
4. 线程A开始将size的值增加为1
5. 线程B开始将size的值增加为2

这样线程AB执行完毕后，理想中情况为size为2，elementData下标0的位置为A，下标1的位置为B。而实际情况变成了size为2，elementData下标为0的位置变成了B，下标1的位置上什么都没有。并且后续除非使用set方法修改此位置的值，否则将一直为null，因为size为2，添加元素时会从下标为2的位置上开始。

### Concurrent集合类实现线程安全的数据结构

我们在前面已经通过`ReentrantLock`和`Condition`实现了一个`BlockingQueue`：

```
public class TaskQueue {
    private final Lock lock = new ReentrantLock();
    private final Condition condition = lock.newCondition();
    private Queue<String> queue = new LinkedList<>();

    public void addTask(String s) {
        lock.lock();
        try {
            queue.add(s);
            condition.signalAll();
        } finally {
            lock.unlock();
        }
    }

    public String getTask() {
        lock.lock();
        try {
            while (queue.isEmpty()) {
                condition.await();
            }
            return queue.remove();
        } finally {
            lock.unlock();
        }
    }
}
```

`BlockingQueue`的意思就是说，当一个线程调用这个`TaskQueue`的`getTask()`方法时，该方法内部可能会让线程变成等待状态，直到队列条件满足不为空，线程被唤醒后，`getTask()`方法才会返回。

因为`BlockingQueue`非常有用，所以我们不必自己编写，可以直接使用Java标准库的`java.util.concurrent`包提供的线程安全的集合：`ArrayBlockingQueue`。

除了`BlockingQueue`外，针对`List`、`Map`、`Set`、`Deque`等，`java.util.concurrent`包也提供了对应的并发集合类。我们归纳一下：

| interface | non-thread-safe         | thread-safe                              |
| :-------- | :---------------------- | :--------------------------------------- |
| List      | ArrayList               | CopyOnWriteArrayList                     |
| Map       | HashMap                 | ConcurrentHashMap                        |
| Set       | HashSet / TreeSet       | CopyOnWriteArraySet                      |
| Queue     | ArrayDeque / LinkedList | ArrayBlockingQueue / LinkedBlockingQueue |
| Deque     | ArrayDeque / LinkedList | LinkedBlockingDeque                      |

使用这些并发集合与使用非线程安全的集合类完全相同。我们以`ConcurrentHashMap`为例：

```
Map<String, String> map = new ConcurrentHashMap<>();
// 在不同的线程读写:
map.put("A", "1");
map.put("B", "2");
map.get("A", "1");
```

因为所有的同步和加锁的逻辑都在集合内部实现，对外部调用者来说，只需要正常按接口引用，其他代码和原来的非线程安全代码完全一样。即当我们需要多线程访问时，把：

```
Map<String, String> map = new HashMap<>();
```

改为：

```
Map<String, String> map = new ConcurrentHashMap<>();
```

就可以了。

`java.util.Collections`工具类还提供了一个旧的线程安全集合转换器，可以这么用：

```
Map unsafeMap = new HashMap();
Map threadSafeMap = Collections.synchronizedMap(unsafeMap);
```

但是它实际上是用一个包装类包装了非线程安全的`Map`，然后对所有读写方法都用`synchronized`加锁，这样获得的线程安全集合的性能比`java.util.concurrent`集合要低很多，所以不推荐使用。

#### 小结

使用`java.util.concurrent`包提供的线程安全的并发集合可以大大简化多线程编程：

多线程同时读写并发集合是安全的；

尽量使用Java标准库提供的并发集合，避免自己编写同步代码。

### Concurrent原子类型 Atomic

Java的`java.util.concurrent`包除了提供底层锁、并发集合外，还提供了一组原子操作的封装类，它们位于`java.util.concurrent.atomic`包。

我们以`AtomicInteger`为例，它提供的主要操作有：

- 增加值并返回新值：`int addAndGet(int delta)`
- 加1后返回新值：`int incrementAndGet()`
- 获取当前值：`int get()`
- 用CAS方式设置：`int compareAndSet(int expect, int update)`

Atomic类是通过无锁（lock-free）的方式实现的线程安全（thread-safe）访问。它的主要原理是利用了CAS：Compare and Set。

如果我们自己通过CAS编写`incrementAndGet()`，它大概长这样：

```
public int incrementAndGet(AtomicInteger var) {
    int prev, next;
    do {
        prev = var.get();
        next = prev + 1;
    } while ( ! var.compareAndSet(prev, next));
    return next;
}
```

CAS是指，在这个操作中，如果`AtomicInteger`的当前值是`prev`，那么就更新为`next`，返回`true`。如果`AtomicInteger`的当前值不是`prev`，就什么也不干，返回`false`。通过CAS操作并配合`do ... while`循环，即使其他线程修改了`AtomicInteger`的值，最终的结果也是正确的。

我们利用`AtomicLong`可以编写一个多线程安全的全局唯一ID生成器：

```
class IdGenerator {
    AtomicLong var = new AtomicLong(0);

    public long getNextId() {
        return var.incrementAndGet();
    }
}
```

通常情况下，我们并不需要直接用`do ... while`循环调用`compareAndSet`实现复杂的并发操作，而是用`incrementAndGet()`这样的封装好的方法，因此，使用起来非常简单。

在高度竞争的情况下，还可以使用Java 8提供的`LongAdder`和`LongAccumulator`。

#### 小结

使用`java.util.concurrent.atomic`提供的原子操作可以简化多线程编程：

- 原子操作实现了无锁的线程安全；
- 适用于计数器，累加器等。

## 线程池使用

### 实现Runnable接口创建线程池

**把很多小任务让一组线程来执行，而不是一个任务对应一个新线程。这种能接收大量小任务并进行分发处理的就是线程池。**

简单地说，线程池内部维护了若干个线程，没有任务的时候，这些线程都处于等待状态。如果有新任务，就分配一个空闲线程执行。如果所有线程都处于忙碌状态，新任务要么放入队列等待，要么增加一个新线程进行处理。

Java标准库提供了`ExecutorService`接口表示线程池，它的典型用法如下：

```
// 创建固定大小的线程池:
ExecutorService executor = Executors.newFixedThreadPool(3);
// 提交任务:
executor.submit(task1);
executor.submit(task2);
executor.submit(task3);
executor.submit(task4);
executor.submit(task5);
```

因为`ExecutorService`只是接口，Java标准库提供的几个常用实现类有：

- FixedThreadPool：线程数固定的线程池；
- CachedThreadPool：线程数根据任务动态调整的线程池；
- SingleThreadExecutor：仅单线程执行的线程池。

创建这些线程池的方法都被封装到`Executors`这个类中。我们以`FixedThreadPool`为例，看看线程池的执行逻辑：

```java
import java.util.concurrent.*;

public class Main {
    public static void main(String[] args) {
        // 创建一个固定大小的线程池:
        ExecutorService es = Executors.newFixedThreadPool(4);
        for (int i = 0; i < 6; i++) {
            es.submit(new Task("" + i));
        }
        // 关闭线程池:
        es.shutdown();
    }
}

class Task implements Runnable {
    private final String name;

    public Task(String name) {
        this.name = name;
    }

    @Override
    public void run() {
        System.out.println("start task " + name);
        try {
            Thread.sleep(1000);
        } catch (InterruptedException e) {
        }
        System.out.println("end task " + name);
    }
}
```

我们观察执行结果，一次性放入6个任务，由于线程池只有固定的4个线程，因此，前4个任务会同时执行，等到有线程空闲后，才会执行后面的两个任务。

线程池在程序结束的时候要关闭。使用`shutdown()`方法关闭线程池的时候，它会等待正在执行的任务先完成，然后再关闭。`shutdownNow()`会立刻停止正在执行的任务，`awaitTermination()`则会等待指定的时间让线程池关闭。

如果我们把线程池改为`CachedThreadPool`，由于这个线程池的实现会根据任务数量动态调整线程池的大小，所以6个任务可一次性全部同时执行。

如果我们想把线程池的大小限制在4～10个之间动态调整怎么办？我们查看`Executors.newCachedThreadPool()`方法的源码：

```
public static ExecutorService newCachedThreadPool() {
    return new ThreadPoolExecutor(0, Integer.MAX_VALUE,
                                    60L, TimeUnit.SECONDS,
                                    new SynchronousQueue<Runnable>());
}
```

因此，想创建指定动态范围的线程池，可以这么写：

```
int min = 4;
int max = 10;
ExecutorService es = new ThreadPoolExecutor(min, max,
        60L, TimeUnit.SECONDS, new SynchronousQueue<Runnable>());
```

#### ScheduledThreadPool

还有一种任务，需要定期反复执行，例如，每秒刷新证券价格。这种任务本身固定，需要反复执行的，可以使用`ScheduledThreadPool`。放入`ScheduledThreadPool`的任务可以定期反复执行。

创建一个`ScheduledThreadPool`仍然是通过`Executors`类：

```
ScheduledExecutorService ses = Executors.newScheduledThreadPool(4);
```

我们可以提交一次性任务，它会在指定延迟后只执行一次：

```
// 1秒后执行一次性任务:
ses.schedule(new Task("one-time"), 1, TimeUnit.SECONDS);
```

如果任务以固定的每3秒执行，我们可以这样写：

```
// 2秒后开始执行定时任务，每3秒执行:
ses.scheduleAtFixedRate(new Task("fixed-rate"), 2, 3, TimeUnit.SECONDS);
```

如果任务以固定的3秒为间隔执行，我们可以这样写：

```
// 2秒后开始执行定时任务，以3秒为间隔执行:
ses.scheduleWithFixedDelay(new Task("fixed-delay"), 2, 3, TimeUnit.SECONDS);
```

注意FixedRate和FixedDelay的区别。FixedRate是指任务总是以固定时间间隔触发，不管任务执行多长时间：

```ascii
│░░░░   │░░░░░░ │░░░    │░░░░░  │░░░  
├───────┼───────┼───────┼───────┼────>
│<─────>│<─────>│<─────>│<─────>│
```

而FixedDelay是指，上一次任务执行完毕后，等待固定的时间间隔，再执行下一次任务：

```ascii
│░░░│       │░░░░░│       │░░│       │░
└───┼───────┼─────┼───────┼──┼───────┼──>
    │<─────>│     │<─────>│  │<─────>│
```

因此，使用`ScheduledThreadPool`时，我们要根据需要选择执行一次、FixedRate执行还是FixedDelay执行。

细心的童鞋还可以思考下面的问题：

- 在FixedRate模式下，假设每秒触发，如果某次任务执行时间超过1秒，后续任务会不会并发执行？
- 如果任务抛出了异常，后续任务是否继续执行？

Java标准库还提供了一个`java.util.Timer`类，这个类也可以定期执行任务，但是，一个`Timer`会对应一个`Thread`，所以，一个`Timer`只能定期执行一个任务，多个定时任务必须启动多个`Timer`，而一个`ScheduledThreadPool`就可以调度多个定时任务，所以，我们完全可以用`ScheduledThreadPool`取代旧的`Timer`。

### 实现Callable方法创建线程池

Callable方法比Runnable方法要好的地方在于可以获得一个返回的对象

在执行多个任务的时候，使用Java标准库提供的线程池是非常方便的。我们提交的任务只需要实现`Runnable`接口，就可以让线程池去执行：

```
class Task implements Runnable {
    public String result;

    public void run() {
        this.result = longTimeCalculation(); 
    }
}
```

`Runnable`接口有个问题，它的方法没有返回值。如果任务需要一个返回结果，那么只能保存到变量，还要提供额外的方法读取，非常不便。所以，Java标准库还提供了一个`Callable`接口，和`Runnable`接口比，它多了一个返回值：

```
class Task implements Callable<String> {
    public String call() throws Exception {
        return longTimeCalculation(); 
    }
}
```

并且`Callable`接口是一个泛型接口，可以返回指定类型的结果。

现在的问题是，如何获得异步执行的结果？

如果仔细看`ExecutorService.submit()`方法，可以看到，它返回了一个`Future`类型，一个`Future`类型的实例代表一个未来能获取结果的对象：

```
ExecutorService executor = Executors.newFixedThreadPool(4); 
// 定义任务:
Callable<String> task = new Task();
// 提交任务并获得Future:
Future<String> future = executor.submit(task);
// 从Future获取异步执行返回的结果:
String result = future.get(); // 可能阻塞
```

当我们提交一个`Callable`任务后，我们会同时获得一个`Future`对象，然后，我们在主线程某个时刻调用`Future`对象的`get()`方法，就可以获得异步执行的结果。在调用`get()`时，如果异步任务已经完成，我们就直接获得结果。如果异步任务还没有完成，那么`get()`会阻塞，直到任务完成后才返回结果。

一个`Future<V>`接口表示一个未来可能会返回的结果，它定义的方法有：

- `get()`：获取结果（可能会等待）
- `get(long timeout, TimeUnit unit)`：获取结果，但只等待指定的时间；
- `cancel(boolean mayInterruptIfRunning)`：取消当前任务；
- `isDone()`：判断任务是否已完成。

### 使用CompletableFuture

使用`Future`获得异步执行结果时，要么调用阻塞方法`get()`，要么轮询看`isDone()`是否为`true`，这两种方法都不是很好，因为主线程也会被迫等待。

从Java 8开始引入了`CompletableFuture`，它针对`Future`做了改进，可以传入回调对象，当异步任务完成或者发生异常时，自动调用回调对象的回调方法。

我们以获取股票价格为例，看看如何使用`CompletableFuture`：

```
// CompletableFuture
import java.util.concurrent.CompletableFuture;
```

创建一个`CompletableFuture`是通过`CompletableFuture.supplyAsync()`实现的，它需要一个实现了`Supplier`接口的对象：

```
public interface Supplier<T> {
    T get();
}
```

这里我们用lambda语法简化了一下，直接传入`Main::fetchPrice`，因为`Main.fetchPrice()`静态方法的签名符合`Supplier`接口的定义（除了方法名外）。

紧接着，`CompletableFuture`已经被提交给默认的线程池执行了，我们需要定义的是`CompletableFuture`完成时和异常时需要回调的实例。完成时，`CompletableFuture`会调用`Consumer`对象：

```
public interface Consumer<T> {
    void accept(T t);
}
```

异常时，`CompletableFuture`会调用`Function`对象：

```
public interface Function<T, R> {
    R apply(T t);
}
```

这里我们都用lambda语法简化了代码。

可见`CompletableFuture`的优点是：

- 异步任务结束时，会自动回调某个对象的方法；
- 异步任务出错时，会自动回调某个对象的方法；
- 主线程设置好回调后，不再关心异步任务的执行。

如果只是实现了异步回调机制，我们还看不出`CompletableFuture`相比`Future`的优势。`CompletableFuture`更强大的功能是，多个`CompletableFuture`可以串行执行，例如，定义两个`CompletableFuture`，第一个`CompletableFuture`根据证券名称查询证券代码，第二个`CompletableFuture`根据证券代码查询证券价格，这两个`CompletableFuture`实现串行操作如下：

```
// CompletableFuture
import java.util.concurrent.CompletableFuture;
```

除了串行执行外，多个`CompletableFuture`还可以并行执行。例如，我们考虑这样的场景：

同时从新浪和网易查询证券代码，只要任意一个返回结果，就进行下一步查询价格，查询价格也同时从新浪和网易查询，只要任意一个返回结果，就完成操作：

```
// CompletableFuture
import java.util.concurrent.CompletableFuture;
```

上述逻辑实现的异步查询规则实际上是：

```ascii
┌─────────────┐ ┌─────────────┐
│ Query Code  │ │ Query Code  │
│  from sina  │ │  from 163   │
└─────────────┘ └─────────────┘
       │               │
       └───────┬───────┘
               ▼
        ┌─────────────┐
        │    anyOf    │
        └─────────────┘
               │
       ┌───────┴────────┐
       ▼                ▼
┌─────────────┐  ┌─────────────┐
│ Query Price │  │ Query Price │
│  from sina  │  │  from 163   │
└─────────────┘  └─────────────┘
       │                │
       └────────┬───────┘
                ▼
         ┌─────────────┐
         │    anyOf    │
         └─────────────┘
                │
                ▼
         ┌─────────────┐
         │Display Price│
         └─────────────┘
```

除了`anyOf()`可以实现“任意个`CompletableFuture`只要一个成功”，`allOf()`可以实现“所有`CompletableFuture`都必须成功”，这些组合操作可以实现非常复杂的异步流程控制。

最后我们注意`CompletableFuture`的命名规则：

- `xxx()`：表示该方法将继续在已有的线程中执行；
- `xxxAsync()`：表示将异步在线程池中执行。

### ForkJoin线程池

ForkJoin线程池判断任务是否很大，如果很大就划分任务为小任务，然后再小任务上执行完成之后将小任务的结果组合起来得到结果，典型应用就是很多数求和

Java 7开始引入了一种新的Fork/Join线程池，它可以执行一种特殊的任务：把一个大任务拆成多个小任务并行执行。

我们举个例子：如果要计算一个超大数组的和，最简单的做法是用一个循环在一个线程内完成：

```ascii
┌─┬─┬─┬─┬─┬─┬─┬─┬─┬─┬─┬─┬─┬─┬─┬─┬─┬─┬─┬─┬─┬─┬─┬─┐
└─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┘
```

还有一种方法，可以把数组拆成两部分，分别计算，最后加起来就是最终结果，这样可以用两个线程并行执行：

```ascii
┌─┬─┬─┬─┬─┬─┬─┬─┬─┬─┬─┬─┐
└─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┘
┌─┬─┬─┬─┬─┬─┬─┬─┬─┬─┬─┬─┐
└─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┘
```

如果拆成两部分还是很大，我们还可以继续拆，用4个线程并行执行：

```ascii
┌─┬─┬─┬─┬─┬─┐
└─┴─┴─┴─┴─┴─┘
┌─┬─┬─┬─┬─┬─┐
└─┴─┴─┴─┴─┴─┘
┌─┬─┬─┬─┬─┬─┐
└─┴─┴─┴─┴─┴─┘
┌─┬─┬─┬─┬─┬─┐
└─┴─┴─┴─┴─┴─┘
```

这就是Fork/Join任务的原理：判断一个任务是否足够小，如果是，直接计算，否则，就分拆成几个小任务分别计算。这个过程可以反复“裂变”成一系列小任务。

我们来看如何使用Fork/Join对大数据进行并行求和：

```
import java.util.Random;
import java.util.concurrent.*;
```

观察上述代码的执行过程，一个大的计算任务0~2000首先分裂为两个小任务0~1000和1000~2000，这两个小任务仍然太大，继续分裂为更小的0~500，500~1000，1000~1500，1500~2000，最后，计算结果被依次合并，得到最终结果。

因此，核心代码`SumTask`继承自`RecursiveTask`，在`compute()`方法中，关键是如何“分裂”出子任务并且提交子任务：

```
class SumTask extends RecursiveTask<Long> {
    protected Long compute() {
        // “分裂”子任务:
        SumTask subtask1 = new SumTask(...);
        SumTask subtask2 = new SumTask(...);
        // invokeAll会并行运行两个子任务:
        invokeAll(subtask1, subtask2);
        // 获得子任务的结果:
        Long subresult1 = subtask1.join();
        Long subresult2 = subtask2.join();
        // 汇总结果:
        return subresult1 + subresult2;
    }
}
```

Fork/Join线程池在Java标准库中就有应用。Java标准库提供的`java.util.Arrays.parallelSort(array)`可以进行并行排序，它的原理就是内部通过Fork/Join对大数组分拆进行并行排序，在多核CPU上就可以大大提高排序的速度。

## 线程池细节

### 目的

- 利用多线程压榨CPU算力；
- 降低创建、销毁线程过程的CPU开销与GC压力；
- 提高任务响应速度，无需等待线程创建；
- 限制线程数量并可以进行统一的分配、调优和监控。

### 使用流程

<details class="details-reset details-overlay details-overlay-dark" style="box-sizing: border-box; display: block; margin-top: 0px; margin-bottom: 16px;"><summary class="btn-sm btn position-absolute js-full-screen-render render-expand" aria-haspopup="dialog" role="button" style="box-sizing: border-box; display: inline-block; cursor: pointer; position: absolute !important; padding: 3px 12px; font-size: 12px; font-weight: 500; line-height: 20px; white-space: nowrap; vertical-align: middle; user-select: none; border-width: 1px; border-style: solid; border-color: var(--color-btn-border); border-image: initial; border-radius: 6px; appearance: none; color: var(--color-btn-text); background-color: var(--color-btn-bg); box-shadow: var(--color-btn-shadow),var(--color-btn-inset-shadow); transition: color 0.2s cubic-bezier(0.3, 0, 0.5, 1) 0s, background-color, border-color; list-style: none; top: 2px; right: 2px;"><svg width="16" height="16" viewBox="0 0 16 16" fill="currentColor" class="octicon" style="display:inline-block;vertical-align:text-bottom"><path fill-rule="evenodd" d="M3.72 3.72a.75.75 0 011.06 1.06L2.56 7h10.88l-2.22-2.22a.75.75 0 011.06-1.06l3.5 3.5a.75.75 0 010 1.06l-3.5 3.5a.75.75 0 11-1.06-1.06l2.22-2.22H2.56l2.22 2.22a.75.75 0 11-1.06 1.06l-3.5-3.5a.75.75 0 010-1.06l3.5-3.5z"></path></svg></summary></details>

<iframe class="render-viewer" sandbox="allow-scripts allow-same-origin allow-top-navigation" src="https://viewscreen.githubusercontent.com/markdown/mermaid?color_mode=light#66d955df-dae3-4f25-8510-a7227844c0c5" name="66d955df-dae3-4f25-8510-a7227844c0c5" data-content="{&quot;data&quot;:&quot;graph LR\nstart[提交任务] --&amp;gt; condition1{核心线程池已满}\ncondition1 -- Y --&amp;gt; condition2{队列已满}\ncondition2 -- Y --&amp;gt; condition3{线程池已满}\ncondition3 -- Y --&amp;gt; end3[按策略处理无法执行的任务]\ncondition3 -- N --&amp;gt; end4[创建线程并执行任务]\ncondition2 -- N --&amp;gt; end2[任务进队列]\ncondition1{核心线程池是否已满} -- N --&amp;gt; end1[创建线程并执行任务]\n&quot;}" style="box-sizing: border-box; display: block; width: 1012px; height: 304.594px; border: 0px;"></iframe>

[![thread-pool](https://github.com/AlbertoWang/java-noob/raw/master/%E5%B8%B8%E8%80%83%E9%A2%98.assets/thread-pool.png)](https://github.com/AlbertoWang/java-noob/blob/master/常考题.assets/thread-pool.png)

其中`corePool`是核心线程池（保活线程），`maximumPool`是总线程池（保活线程+工作线程），`blockQueue`是等待任务队列，`rejectedExecutionHandler`是拒绝策略：

1. 未达到corePoolSize时，核心线程池会开辟新线程运行任务，任务结束后线程不销毁；
2. 任务队列未满时，新任务提交到等待队列；
3. 未达到最大线程数时，新建工作线程执行任务，线程空闲时间超过keepAliveTime时被销毁；
4. 超过最大线程数时，按拒绝策略处理，包括：抛出异常、使用调用者线程运行任务、丢弃新任务、丢弃队列头任务等。

### 相关参数及设置

#### 可选参数

- `corePoolSize`：当使用了`LinkedBlockingQueue = new LinkedBlockQueue`的时候，队列长度默认无限长，会导致线程数量永远等于`corePoolSize`，任务激增时任务响应时间也激增；
- `maxPoolSize`：线程池中线程个数，增加线程的公式：$(任务数-queueCapacity) \times (原线程数 \div 原任务数)$；
- `keepAliveTime`：线程最大（空闲）存活时间；
- `rejectedExecutionHandler`：线程被拒绝的解决方案，可以自己重写。

#### 参数选择

在参数选择上，通过判断IO密集型还是计算密集型来进行参数设置：

- IO密集型：$(等待时间+计算时间)/计算时间*CPU核心数$；
- 计算密集型：线程数为CPU核心数。

### `Executors`包内实现的`ExecutorService`

- `newFixedThreadPool`：使用`LinkedBlockingQueue`，线程池长度通过参数固定，没达到指定数量前会继续创建线程，**队列不限长度**，`maxpoolsize`与`keepalive`参数无效，线程空闲时按**FIFO调度**，不空闲时进入队列；
- `newSingleThreadExecutor`：同样使用`LinkedBlockingQueue`，**线程池中只有一个线程**，队列不限长度，线程空闲时按FIFO调度，不空闲时进入队列；
- `newCachedThreadPool`：使用`SynchronousQueue`，**核心线程池长度为0**，**队列需要插入元素前必须有另一个线程从这个队列消耗元素**；
- `newScheduledThreadPool`：使用`DelayQueue`，**提交的任务按时间为优先级进入阻塞队列**，线程只能从队列获取任务。

##  ThreadLocal

多线程是Java实现多任务的基础，`Thread`对象代表一个线程，我们可以在代码中调用`Thread.currentThread()`获取当前线程。例如，打印日志时，可以同时打印出当前线程的名字：

```
// Thread
```

 Run

对于多任务，Java标准库提供的线程池可以方便地执行这些任务，同时复用线程。Web应用程序就是典型的多任务应用，每个用户请求页面时，我们都会创建一个任务，类似：

```
public void process(User user) {
    checkPermission();
    doWork();
    saveStatus();
    sendResponse();
}
```

然后，通过线程池去执行这些任务。

观察`process()`方法，它内部需要调用若干其他方法，同时，我们遇到一个问题：如何在一个线程内传递状态？

`process()`方法需要传递的状态就是`User`实例。有的童鞋会想，简单地传入`User`就可以了：

```
public void process(User user) {
    checkPermission(user);
    doWork(user);
    saveStatus(user);
    sendResponse(user);
}
```

但是往往一个方法又会调用其他很多方法，这样会导致`User`传递到所有地方：

```
void doWork(User user) {
    queryStatus(user);
    checkStatus();
    setNewStatus(user);
    log();
}
```

这种在一个线程中，横跨若干方法调用，需要传递的对象，我们通常称之为上下文（Context），它是一种状态，可以是用户身份、任务信息等。

给每个方法增加一个context参数非常麻烦，而且有些时候，如果调用链有无法修改源码的第三方库，`User`对象就传不进去了。

Java标准库提供了一个特殊的`ThreadLocal`，它可以在一个线程中传递同一个对象。

`ThreadLocal`实例通常总是以静态字段初始化如下：

```
static ThreadLocal<User> threadLocalUser = new ThreadLocal<>();
```

它的典型使用方式如下：

```
void processUser(user) {
    try {
        threadLocalUser.set(user);
        step1();
        step2();
    } finally {
        threadLocalUser.remove();
    }
}
```

通过设置一个`User`实例关联到`ThreadLocal`中，在移除之前，所有方法都可以随时获取到该`User`实例：

```
void step1() {
    User u = threadLocalUser.get();
    log();
    printUser();
}

void log() {
    User u = threadLocalUser.get();
    println(u.name);
}

void step2() {
    User u = threadLocalUser.get();
    checkUser(u.id);
}
```

注意到普通的方法调用一定是同一个线程执行的，所以，`step1()`、`step2()`以及`log()`方法内，`threadLocalUser.get()`获取的`User`对象是同一个实例。

实际上，可以把`ThreadLocal`看成一个全局`Map<Thread, Object>`：每个线程获取`ThreadLocal`变量时，总是使用`Thread`自身作为key：

```
Object threadLocalValue = threadLocalMap.get(Thread.currentThread());
```

因此，`ThreadLocal`相当于给每个线程都开辟了一个独立的存储空间，各个线程的`ThreadLocal`关联的实例互不干扰。

最后，特别注意`ThreadLocal`一定要在`finally`中清除：

```
try {
    threadLocalUser.set(user);
    ...
} finally {
    threadLocalUser.remove();
}
```

这是因为当前线程执行完相关代码后，很可能会被重新放入线程池中，如果`ThreadLocal`没有被清除，该线程执行其他代码时，会把上一次的状态带进去。

为了保证能释放`ThreadLocal`关联的实例，我们可以通过`AutoCloseable`接口配合`try (resource) {...}`结构，让编译器自动为我们关闭。例如，一个保存了当前用户名的`ThreadLocal`可以封装为一个`UserContext`对象：

```
public class UserContext implements AutoCloseable {

    static final ThreadLocal<String> ctx = new ThreadLocal<>();

    public UserContext(String user) {
        ctx.set(user);
    }

    public static String currentUser() {
        return ctx.get();
    }

    @Override
    public void close() {
        ctx.remove();
    }
}
```

使用的时候，我们借助`try (resource) {...}`结构，可以这么写：

```
try (var ctx = new UserContext("Bob")) {
    // 可任意调用UserContext.currentUser():
    String currentUser = UserContext.currentUser();
} // 在此自动调用UserContext.close()方法释放ThreadLocal关联对象
```

这样就在`UserContext`中完全封装了`ThreadLocal`，外部代码在`try (resource) {...}`内部可以随时调用`UserContext.currentUser()`获取当前线程绑定的用户名。

## Java线程是可重入锁

对同一个线程，能否在获取到锁以后继续获取同一个锁？

同一个线程，在获取到同一个锁之后可以获取同一个锁

答案是肯定的。JVM允许同一个线程重复获取同一个锁，这种能被同一个线程反复获取的锁，就叫做可重入锁。

由于Java的线程锁是可重入锁，所以，获取锁的时候，不但要判断是否是第一次获取，还要记录这是第几次获取。每获取一次锁，记录+1，每退出`synchronized`块，记录-1，减到0的时候，才会真正释放锁。

### 死锁

两个线程各自持有不同的锁，然后各自试图获取对方手里的锁，造成了双方无限等待下去，这就是死锁。

死锁发生后，没有任何机制能解除死锁，只能强制结束JVM进程。

### 死锁四个必要条件

互斥：某种资源一次只允许一个进程访问，即该资源一旦分配给某个进程，其他进程就不能再访问，直到该进程访问结束。
占有且等待：一个进程本身占有资源（一种或多种），同时还有资源未得到满足，正在等待其他进程释放该资源。
不可抢占：别人已经占有了某项资源，你不能因为自己也需要该资源，就去把别人的资源抢过来。
循环等待：存在一个进程链，使得每个进程都占有下一个进程所需的至少一种资源。

### 死锁预防

我们可以通过破坏死锁产生的4个必要条件来 预防死锁，由于资源互斥是资源使用的固有特性是无法改变的。

破坏“占有且等待”条件

方法1：所有的进程在开始运行之前，必须一次性地申请其在整个运行过程中所需要的全部资源。
         优点：简单易实施且安全。
         缺点：因为某项资源不满足，进程无法启动，而其他已经满足了的资源也不会得到利用，严重降低了资源的利用率，造成资源浪费。
                  使进程经常发生饥饿现象。

方法2：该方法是对第一种方法的改进，允许进程只获得运行初期需要的资源，便开始运行，在运行过程中逐步释放掉分配到的已经使用完毕的资源，然后再去请求新的资源。这样的话，资源的利用率会得到提高，也会减少进程的饥饿问题。

破坏“不可抢占”条件

当一个已经持有了一些资源的进程在提出新的资源请求没有得到满足时，它必须释放已经保持的所有资源，待以后需要使用的时候再重新申请。这就意味着进程已占有的资源会被短暂地释放或者说是被抢占了。

该种方法实现起来比较复杂，且代价也比较大。释放已经保持的资源很有可能会导致进程之前的工作实效等，反复的申请和释放资源会导致进程的执行被无限的推迟，这不仅会延长进程的周转周期，还会影响系统的吞吐量。

破坏“循环等待”条件

采用资源有序分配其基本思想是将系统中的所有资源顺序编号，将紧缺的，稀少的采用较大的编号，在申请资源时必须按照编号的顺序进行（从小往大申请），一个进程只有获得较小编号的进程才能申请较大编号的进程。

 

### 死锁的避免

死锁避免：在使用前进行判断，只允许不会产生死锁的进程申请资源；

死锁避免是利用额外的检验信息，在分配资源时判断是否会出现死锁，只在不会出现死锁的情况下才分配资源。
两种避免办法：
    1、如果一个进程的请求会导致死锁，则不启动该进程
    2、如果一个进程的增加资源请求会导致死锁 ，则拒绝该申请。
避免死锁的具体实现通常利用银行家算法
    银行家算法
a、银行家算法的相关数据结构
    可利用资源向量Available：用于表示系统里边各种资源剩余的数目。由于系统里边拥有的资源通常都是有很多种（假设有m种），所以，我们用一个有m个元素的数组来表示各种资源。数组元素的初始值为系统里边所配置的该类全部可用资源的数目，其数值随着该类资源的分配与回收动态地改变。
    最大需求矩阵Max：用于表示各个进程对各种资源的额最大需求量。进程可能会有很多个（假设为n个），那么，我们就可以用一个nxm的矩阵来表示各个进程多各种资源的最大需求量
    分配矩阵Allocation：顾名思义，就是用于表示已经分配给各个进程的各种资源的数目。也是一个nxm的矩阵。
    需求矩阵Need：用于表示进程仍然需要的资源数目，用一个nxm的矩阵表示。系统可能没法一下就满足了某个进程的最大需求（通常进程对资源的最大需求也是只它在整个运行周期中需要的资源数目，并不是每一个时刻都需要这么多），于是，为了进程的执行能够向前推进，通常，系统会先分配个进程一部分资源保证进程能够执行起来。那么，进程的最大需求减去已经分配给进程的数目，就得到了进程仍然需要的资源数目了。

银行家算法通过对进程需求、占有和系统拥有资源的实时统计，确保系统在分配给进程资源不会造成死锁才会给与分配。
死锁避免的优点：不需要死锁预防中的抢占和重新运行进程，并且比死锁预防的限制要少。
死锁避免的限制：
    必须事先声明每个进程请求的最大资源量
    考虑的进程必须无关的，也就是说，它们执行的顺序必须没有任何同步要求的限制
    分配的资源数目必须是固定的。
    在占有资源时，进程不能退出

## Java多线程\**实现的方式有四种**

1. 1.继承Thread类，重写run**方法**
2. 2.实现Runnable接口，重写run**方法**，实现Runnable接口的实现类的实例对象作为Thread构造函数的target.
3. 3.通过Callable和FutureTask创建**线程**
4. 4.通过**线程**池创建**线程**

## 页面置换算法

在地址映射过程中，若在页面中发现所要访问的页面不在内存中，则产生**缺页中断**。当发生缺页中断时，如果操作系统内存中没有空闲页面，则操作系统必须在内存选择一个页面将其移出内存，以便为即将调入的页面让出空间。而用来选择淘汰哪一页的规则叫做**页面置换算法**。

### 抖动和***Belady*** 异常

抖动指频繁缺页造成频繁调入调出内存

Belady异常是FIFO产生的分配给进程的页面数越多反而缺页频率越高的现象。

1. FIFO，先进先出
2. LRU，最近最少使用
3. OPT，最远不使用。主要是前两种，第三种无法预测未来请求

### 内存分配碎片

内碎片：系统多分给进程的进程没有使用的内存

外碎片：因为内存太小而系统无法分给任何进程的内存



## 进程与线程

### 进程与线程的区别

进程是资源分配的最小单位，线程是任务调度与执行的最小单位。

- 进程维护成本高，彼此之间独立，安全性高；
- 线程有独立堆栈空间，但共享数据段，开销小。

### 进程与线程的资源

- 共享资源：

  堆、全局变量、静态变量、文件等公共资源、进程代码段、进程当前所在目录等信息；

- 独享资源：

  栈、线程ID、寄存器组的值、错误返回码、信号屏蔽码

### 进程与线程的选择

- 频繁创建、销毁、切换（并行）的情况下，使用线程；
- 需要稳定安全的情况下，使用进程。

### Linux常用命令

- 搜索进程ID：`ps -ef | grep <进程名>`，`-e`相当于`-a`是全部列出，`-f`是显示UID等（也可以用`ps -aux | grep <进程名>`）；
- 查询文件位置：`find <查询路径> -name <文件名>`
- 任务管理器：`top`，具体查看某个进程的情况：`top -p <pid>`；
- 内存使用情况：`free -m`；
- 统计：`wc`，统计单词个数使用`grep <单词> <文件路径> ｜ wc -o`；
- 修改用户权限：`chmod`；
- 设置进程优先级：`nice -n <优先级，越小优先级越高> bash`（开新bash运行），`renice -n <优先级> -p <进程ID> -u <用户>`（修改进程优先级）；



## ThreadLocal

ThreadLocal用于对线程内多个函数调用传递上下文，上下文是多个函数共同使用的对象、数据模型、用户信息等。为什么用ThreadLocal而不用在函数中直接传递参数，一种情况是给函数添加上下文麻烦，一种是有些第三方库无法修改他的源码添加传递对象。

ThreadLocal总是以静态字段初始化

```java
static ThreadLocal<User> threadLocalUser = new ThrreadLocal<>() ;
```

ThreadLocal的使用方式是

```java
void processUser(user) {
    try {
        threadLocalUser.set(user);
        step1();
        step2();
    } finally {
        threadLocalUser.remove();
    }
}
```

ThreadLocal实际上相当于一个全局Map<Thread, Object>，在同一个线程的方法总是通过Thread.currentThead()作为Key区获得ThreadLocal中的数据，各个不同的线程的数据互不影响。

注意在使用完ThreadLocal之后要使用thread.remove()去消除当前Thread关联的Object，因为在线程池条件下，一个Thread可能被复用，而就的Thread所关联的状态可能会造成影响。

为了关闭ThreadLocal关联的对象，可以向上面一样在finally里面关闭，同时也可以通过实现AutoCloseable接口配合try(resource){...}这样的结构让编译器自动为我们关闭。

```java
package com.itranswarp.learnjava;

import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.concurrent.TimeUnit;

/**
 * Learn Java from https://www.liaoxuefeng.com/
 * 
 * @author liaoxuefeng
 */
public class Main {
	public static void main(String[] args) throws Exception {
		ExecutorService es = Executors.newFixedThreadPool(3);
		String[] users = new String[] { "Bob", "Alice", "Tim", "Mike", "Lily", "Jack", "Bush" };
		for (String user : users) {
			es.submit(new Task(user));
		}
		es.awaitTermination(3, TimeUnit.SECONDS);
		es.shutdown();
	}
}

class UserContext implements AutoCloseable {
	private static final ThreadLocal<String> userThreadLocal = new ThreadLocal<>();

	public UserContext(String name) {
		userThreadLocal.set(name);
		System.out.printf("[%s] init user %s...\n", Thread.currentThread().getName(), UserContext.getCurrentUser());
	}

	public static String getCurrentUser() {
		return userThreadLocal.get();
	}

	@Override
	public void close() {
		System.out.printf("[%s] cleanup for user %s...\n", Thread.currentThread().getName(),
				UserContext.getCurrentUser());
		userThreadLocal.remove();
	}
}

class Task implements Runnable {

	final String username;

	public Task(String username) {
		this.username = username;
	}

	@Override
	public void run() {
		try (var ctx = new UserContext(this.username)) {
			new Task1().process();
			new Task2().process();
			new Task3().process();
		}
	}
}

class Task1 {
	public void process() {
		try {
			Thread.sleep(100);
		} catch (InterruptedException e) {
		}
		System.out.printf("[%s] check user %s...\n", Thread.currentThread().getName(), UserContext.getCurrentUser());
	}
}

class Task2 {
	public void process() {
		try {
			Thread.sleep(100);
		} catch (InterruptedException e) {
		}
		System.out.printf("[%s] %s registered ok.\n", Thread.currentThread().getName(), UserContext.getCurrentUser());
	}
}

class Task3 {
	public void process() {
		try {
			Thread.sleep(100);
		} catch (InterruptedException e) {
		}
		System.out.printf("[%s] work of %s has done.\n", Thread.currentThread().getName(),
				UserContext.getCurrentUser());
	}
}

```



## 运算优先级

单目（+- !）

乘除（* /）

位（^ << >> ）

关系（> < = != ）

逻辑（&& || ）

三目（A? B:C）

后赋值（A=B）

## 查找树

### AVL平衡二叉树

[参考](https://blog.csdn.net/code_peak/article/details/120610047)

```java

class AVLTree{
	private class AVLTreeNode{
		public int val ;
		public int height ;
		public AVLTreeNode left, right ;
		
		AVLTreeNode(int v, int h, AVLTreeNode left, AVLTreeNode right){
			this.val = v ;
			this.height = h ;
			this.left = left ;
			this.right = right ;
		}
	}
	
	private AVLTreeNode root = null ;
	
	private int getHeight(AVLTreeNode node) {
		return node == null? 0 : node.height ;
	}
	
//	LLRotation(pRoot)
//	传入最小的失衡的系节点pRoot
//	对pRoot右旋
	private AVLTreeNode LLRotation(AVLTreeNode node) {
		AVLTreeNode nodeLeft = node.left ;
		node.left = nodeLeft.right ;
		nodeLeft.right = node ;
		
		node.height = Math.max( getHeight(node.left), getHeight(node.right ) ) + 1 ;
		nodeLeft.height = Math.max( getHeight(nodeLeft.left), getHeight(nodeLeft.right) ) + 1 ;
		return nodeLeft ;
	}
//	RRRotation(pRoot)
//	传入最小失衡节点pRoot
//	对pRoot进行一次左旋
	private AVLTreeNode RRRotation(AVLTreeNode node) {
		AVLTreeNode nodeRight = node.right ;
		node.right = nodeRight.left ;
		nodeRight.left = node ;
		
		node.height = Math.max(getHeight(node.left),  getHeight(node.right) ) + 1 ;
		nodeRight.height = Math.max( getHeight(nodeRight.left), getHeight(nodeRight.right ) ) + 1 ;
		return nodeRight ;
	}
//	LRRotation(pRoot)
//	传入最小失衡的节点pRoot
//	先对pRoot.left左旋
//	再对pRoot右旋
	private AVLTreeNode LRRotation(AVLTreeNode node) {
		AVLTreeNode nodeLeft = node.left ;
		nodeLeft = this.RRRotation(nodeLeft) ;
		node.left = nodeLeft ;
		
		return this.LLRotation(node) ;
	}
	private AVLTreeNode RLRotation(AVLTreeNode node) {
		AVLTreeNode nodeRight = node.right ;
		nodeRight = this.LLRotation(nodeRight) ;
		node.right = nodeRight ;
		
		return this.RRRotation(node) ;
	}
	
//	最大值节点
	public AVLTreeNode maxNode(AVLTreeNode root) {
		while(root.right != null)
			root = root.right ;
		return root ;
	}
//	最小值节点
	public AVLTreeNode minNode(AVLTreeNode root) {
		while( root.left != null)
			root = root.left ;
		return root ;
	}
	
	//查找元素
	//返回根节点
	public boolean search(int key) {
		if( search(root, key) != null)
			return true ;
		return false ;
	}
	private AVLTreeNode search(AVLTreeNode root, int key) {
		if( root == null || root.val == key)
			return root ;
		if( key<root.val )
			return search( root.left, key) ;
		else
			return search( root.right, key ) ;
	}
	
	//增加元素，返回根节点
	public void add(int key) {
		root = add(root, key) ;
	}
	private AVLTreeNode add( AVLTreeNode root, int key) {
		if( root == null ) 
			return new AVLTreeNode(key, 1, null, null) ;
		if( key < root.val ) {
			root.left = add(root.left, key) ;
			if( this.getHeight(root.left)- this.getHeight(root.right) == 2 ) {
				if( key<root.left.val )
					root = this.LLRotation(root) ;
				else
					root = this.LRRotation(root) ;
			}
		}else if( key> root.val) {
			root.right = add( root.right, key) ;
			if( this.getHeight(root.right) - this.getHeight(root.left) == 2) {
				if( key> root.right.val )
					root = this.RRRotation(root) ;
				else
					root = this.RLRotation(root) ;
			}
		}else {
			System.out.println("allready in: "+ key) ;
		}
		root.height = Math.max( this.getHeight(root.left), this.getHeight(root.right ) ) + 1 ;
		return root ;
	}
	
	//删除元素，返回根节点
	public boolean remove(int key) {
		AVLTreeNode ret = this.search(root, key) ;
		if( ret == null) {
			System.out.println(key + " not in AVL") ;
			return false ;
		}
		root = this.remove(root, ret ) ;
		return true ;
	}
	private AVLTreeNode remove( AVLTreeNode root, AVLTreeNode key) {
		if( key.val< root.val) {
			root.left = this.remove(root.left, key) ;
			if( this.getHeight(root.right) - this.getHeight(root.left) == 2 ) {
				AVLTreeNode right = root.right ;
				if( this.getHeight(right.left) > this.getHeight(right.right) ) {
					//LR型
					root = this.LRRotation(root) ;
				}else {
					root = this.RRRotation(root) ;
				}
			}
		}else if( key.val> root.val) {
			root.right = this.remove( root.right, key) ;
			if( this.getHeight(root.left) - this.getHeight(root.right) == 2) {
				AVLTreeNode left = root.left ;
				if( this.getHeight(left.left) > this.getHeight(left.right) ) {
					root = this.LLRotation(root) ;
				}else {
					root = this.LRRotation(root) ;
				}
			}
		}else {
			if( root.left == null && root.right == null) {
				return null ;
			}
			if( this.getHeight(root.left) >= this.getHeight(root.right )) {
				AVLTreeNode leftMax = this.maxNode(root.left) ;
				root.val = leftMax.val ;
				root.left = this.remove( root.left, leftMax) ;
			}else {
				AVLTreeNode rightMin = this.minNode(root.right) ;
				root.val = rightMin.val ;
				root.right = this.remove( root.right, rightMin) ;
			}
		}
		root.height = Math.max(this.getHeight(root.left), this.getHeight(root.right)) + 1 ;
		return root ;
	}
	
	
	public void show() {
		show(root) ;
		System.out.println();
	}
	private void show(AVLTreeNode root) {
//		System.out.println(root.val) ;
		if( root == null || (root.left == null && root.right == null))
			return ;
		System.out.println(root.val) ;
		
		if( root.left != null) {
			System.out.println( root.val+ " " + root.height + " L " + root.left.val) ;
		}
		if( root.right != null) {
			System.out.println( root.val + " " + root.height + " R " + root.right.val ) ;
		}
		
		show( root.left) ;
		show( root.right) ;
	}
}

public class Main { 
	
	public static void main(String[] args) throws Throwable { 
		AVLTree tree = new AVLTree() ;
		tree.add(1) ;
		tree.add(2) ;
		
//		tree.show();
		
		tree.add(3) ;
		tree.add(-1);
		tree.add(10);
		tree.add(3);
		
		tree.show() ;
		
		tree.remove(2) ;
		tree.show();
		
//		tree.add(-1);
//		tree.add(5);
//		
//		tree.add(-2);
		
//		tree.show();
//		System.out.println(tree.search(-1)) ;
	}
}
```

#### AVL树讨论

AVL树任意节点的两个子树的高度差不超过1

### 红黑树

[参考1](https://blog.51cto.com/u_15197573/5164593?b=totalstatistic)

[参考2](https://blog.csdn.net/weixin_42786274/article/details/86557922)

[参考代码](https://www.jianshu.com/p/eb6e3fa41c66)

```java
class RedBlackTree{
	
	private static final int Red = 1 ;
	private static final int Black = 0 ;
	private class RedBlackTreeNode{
		public RedBlackTreeNode parent, left, right ;
		public int val , color ;
		public RedBlackTreeNode(RedBlackTreeNode p, RedBlackTreeNode l, RedBlackTreeNode r, int v, int c) {
			this.parent = p ;
			this.left = l ;
			this.right = r ;
			this.val = v ;
			this.color = c ;
		}
	}
	
	private RedBlackTreeNode root = null ;
	
	//左旋
	private void leftRotation(RedBlackTreeNode node) {
		RedBlackTreeNode right = node.right ;
		node.right = right.left ;
		right.left = node ;
		
		right.parent = node.parent ;
		node.parent = right ;
		
		if( node.right != null)
			node.right.parent = node ;
		if( right.parent != null) {
			if(right.parent.left == node) {
				right.parent.left = right ;
			}else {
				right.parent.right = right ;
			}
		}else {
			this.root = right ;
		}
	}
	//右旋
	private void rightRotation(RedBlackTreeNode node) {
		//类似AVL的右旋
		RedBlackTreeNode left = node.left ;
		node.left = left.right ;
		left.right = node ;
		
		//设置left节点父节点为node节点父节点，设置node节点父节点为left节点
		left.parent = node.parent ;
		node.parent = left ;
		
		//设置原left节点的右子节点的父节点为node节点
		if(node.right != null)
			node.right.parent = node ;
		//设置left节点的父节点的子节点
		if( left.parent != null) {
			if( left.parent.left == node) {
				left.parent.left = left ;
			}else {
				left.parent.right = left ;
			}
		}else {
			//如果left节点父节点为null，说明left节点是root节点，那么设置root节点
			this.root = left ;
		}
	}
	
//	add(key)
//	找到add的parent节点，添加node节点到parent节点
//	然后调整节点
//	设置node节点的color为红色
//	如果node节点的父节点是黑色，不做任何改变
//	while node节点不为空&&node节点不为root节点&&node节点的父节点的color是红色：
//		if node节点的父节点是祖父节点的左子节点
//			if 父节点的兄弟节点存在并且是红色，
//				那么修改父节点和父节点兄弟节点为黑色，修改祖父节点为红色，让node=祖父节点继续调整
//			else node节点的父节点的兄弟节点不存在
//				if node节点是父节点的右子节点,形成LR型结构，要转换成LL型结构
//					根据node节点的父节点左旋，并且令node节点=父节点
//				对LL型结构，设置父节点为黑色，祖父节点为红色，根据祖父节点进行进行右旋，调整结束
//		else node节点的父节点是祖父节点的右子节点
//		    if 父节点的兄弟节点存在并且为红色
//		        那么修改父节点和父节点的兄弟节点为黑色，修改祖父节点为红色，让node=祖父节点继续向上调整
//		    else 父节点的兄弟节点不存在
//		        if node节点是父节点的左子节点，形成RL型结构，要转成RR型结构
//		            根据node节点的父节点右旋，并且令node节点=父节点
//		        对RR型结构，设置父节点为黑色，祖父节点为红色，根据祖父节点进行左旋，调整结束
	public void add(int key) {
		//添加root节点
		if(root == null) {
			root = new RedBlackTreeNode(null, null, null, key, Black) ;
			return ;
		}
		
		//查找到添加位置的父节点parent
		RedBlackTreeNode tmp = root, parent = null ;
		while( tmp!=null ) {
			parent = tmp ;
			if( key<tmp.val )
				tmp = tmp.left ;
			else if( key>tmp.val)
				tmp = tmp.right ;
			else {
				System.out.println(key + " 已经存在") ;
				return ;
			}
		}
		
		RedBlackTreeNode node = new RedBlackTreeNode(parent, null, null, key, Red) ;
		if( key<node.parent.val ) {
			node.parent.left = node ;
		}else {
			node.parent.right = node ;
		}
		
		fixTree(node ) ;
	}
	private void fixTree(RedBlackTreeNode node) {
		//设置新节点颜色为Red
		node.color = Red ;
		//如果node不为空，node不是root节点，node父节点颜色是Red
		while( node!= null && node!= root && node.parent.color == Red) {
//			如果node父节点是祖父节点的左子节点
			//因为root节点为Black，当node.parent为Red时，一定存在node的祖父节点
			if( node.parent == node.parent.parent.left ) {
				//如果父节点兄弟节点存在
				//修改父节点和兄弟节点颜色为黑色，祖父节点颜色为红色，node节点=祖父节点，继续向上调整
				if( node.parent.parent.right != null && node.parent.parent.right.color == Red) {
					node.parent.color = Black ;
					node.parent.parent.right.color = Black ;
					node.parent.parent.color = Red ;
					node = node.parent.parent ;
				}else {
					//如果父节点兄弟节点不存在，
					//1. 如果是LR型结构，转成LL型结构，node=node.parent, 对node左旋
					//2. 设置node父节点黑色，祖父节点红色，祖父节点右旋
					//完成调整
					if( node == node.parent.right ) {
						node = node.parent ;
						this.leftRotation(node);
					}
					node.parent.color = Black ;
					node.parent.parent.color = Red ;
					this.rightRotation(node.parent.parent);
				}
			}else {
				if( node.parent.parent.left != null) {
					node.parent.color = Black; 
					node.parent.parent.left.color = Black ;
					node.parent.parent.color = Red ;
					node = node.parent.parent ;
				}else {
					if( node == node.parent.left ) {
						node = node.parent ;
						this.rightRotation(node);
					}
					node.parent.color = Black ;
					node.parent.parent.color = Red ;
					this.leftRotation(node.parent.parent);
				}
			}
		}
		this.root.color = Black ;
	}
	
	public void show() {
		show(this.root) ;
	}
	private void show( RedBlackTreeNode node ) {
		if( node == null  )
			return ;
		
		if( ( node.left == null && node.right == null ) ) {
			System.out.println( node.val +" "+ (node.color==1? "Red":"Black") ) ;
		}
		if( node.left != null) {
			System.out.println( node.val +" "+ (node.color==1? "Red":"Black") + "  L "+ node.left.val ) ;
		}
		if( node.right != null) {
			System.out.println( node.val +" "+ (node.color==1? "Red":"Black") + "  R "+ node.right.val ) ;
		}
		
		show(node.left ) ;
		show(node.right ) ;
	}
}

public class Main { 
	
	public static void main(String[] args) throws Throwable { 
		RedBlackTree tree = new RedBlackTree() ;
		
//		tree.add(2);
		tree.add(3);
		tree.add(5);
		tree.add(1);
		tree.add(6);
//		tree.add(-1);
		tree.add(10);
		
		
		tree.show();
	}
}
```

#### AVL树讨论

AVL树是一个平衡二叉树，它满足四条性质

1. 节点要不是红要不是黑
2. 根节点是黑
3. 红节点的两个子节点必为黑
4. Null节点为黑
5. 从根节点到叶节点的任意路径的黑节点数目相同

其中第五条性质保证了最长路径不大于最短路径的2倍，因为最长路径是红黑相间的路径，而最短的路径是全为黑色的路径，这样可以看到最长路径的长度不大于最短路径的2倍，所以是近似平衡的

### B树

[参考代码](https://blog.csdn.net/u011983531/article/details/78377026)

[参考代码](https://github.com/tclxspy/Articles/blob/master/algorithm/MD/%E7%AE%97%E6%B3%95%2316--B%E6%A0%91%E5%AE%8C%E6%95%B4%E4%BB%A3%E7%A0%81Java%E5%AE%9E%E7%8E%B0.md)

[参考](https://www.cnblogs.com/dfyz/p/5029797.html)

```java
class BTree{
	static int t = 2 ;
	static final int M = 2*t ;
	static final Boolean Leaf = true ;
	static final Boolean NonLeaf = false ;
	
	class Node{
		public Boolean leaf ;
		public int size ;
		public Entry[] entry = new Entry[M] ;
		public Node() {
			size = 1 ;
			entry[0] = new Entry(-1, null) ;
		}
	}
	class Entry{
		int key ;
		Node next ;
		Entry(int k, Node node) {
			this.key = k ;
			this.next = node ;
		}
	}
	
	Node root = null;
	BTree(){
		root = new Node() ;
		root.leaf = true ;
	}
	//增加元素
	//如果root节点满，那么分离root节点
	//如果root节点不满，调用insertNonNull(root, key)
	public void insert(int key) {
		System.out.println(key) ;
		if( root.size == M) {
			//分离root节点，
			//令旧root节点为oldRoot
			//取中间Entry e，创建一个新的root节点newRoot，将节点e放到newRoot的数组
			//新建Node z，将oldRoot节点的e Entry的后面的Entry复制到z的数组，修改z的size
			//将e.next = z; newRoot.entry[0].next = oldRoot
			//令root = newRoot 
			Entry e = root.entry[ M/2 ] ;
			root.size = M/2 ;
			
			Node z = new Node() ;
			z.leaf = root.leaf ;
			for(int i=M/2+1;i<M;i++) {
				z.entry[ z.size++ ] = root.entry[i] ;
			}
			
			Node newRoot = new Node() ;
			e.next = z ;
			newRoot.entry[ newRoot.size++ ] = e ;
			newRoot.leaf = false ;
			newRoot.entry[0].next = root ;
			
			root = newRoot ;
		}
		insertNonNull(root, key) ;
	}
	private void insertNonNull( Node root, int key) {
		//如果root是叶子节点，直接插入key
		//如果root不是叶子节点，
		//   首先找到key插入的Entry节点e，检查e.next指向的子节点是不是满
		//   如果满，就调用splitNode分离子节点，分离之后再调用insertNonNull(root,key)
		//   如果不满，那就调用insertNonNull(e.next, key)
		System.out.println("in insertNonNull: " + key) ;
		int i = 1 ;
		while(i<root.size && key > root.entry[i].key ) {
			i++ ;
		}
		System.out.println( "i : "+ i) ;
		if( root.leaf == true) {
			
			if( i==root.size ) {
				root.entry[root.size] = new Entry(key, null) ;
			}else {
				for(int j=root.size-1;j>=i;j--) {
					root.entry[j+1] = root.entry[j] ;
				}
				root.entry[i] = new Entry(key, null) ;
			}
			root.size ++ ;
			
			showNode( root ) ;
		}else {
			//获得key节点插入的子节点
			Entry e = root.entry[i-1] ;
			System.out.println("Show root") ;
			showNode(root) ;
			//判断这个子节点是否是满节点
			if( e.next.size == M) {
				//满节点，就分离
				splitNode(root, i-1) ;
				showNode(root) ;
				insertNonNull(root, key) ;
			}else {
				insertNonNull(e.next, key) ;
			}
		}
	}
	private void splitNode(Node root, int i) {
		//获得root.entry[i]的子节点next, 获取e=next.entry[ M/2]
		//将e放到root.entry[i+1]的位置
		//创建z节点复制next节点的一半的entry
		//z.entry[0].next = e.next ;
		//e.next = z ;
		
		Node next = root.entry[i].next ;
		Entry e = next.entry[ M/2 ] ;
		next.size = M/2 ;
//		System.out.println(e.key) ;
		
		Node z = new Node() ;
		for(int j=M/2+1;j<M;j++) {
			z.entry[z.size++] = next.entry[j] ;
		}
		z.leaf = next.leaf ;
		
		z.entry[0].next = e.next ;
		e.next = z ;
		for(int j=root.size-1;j>=i+1;j--) {
			root.entry[j+1] = root.entry[j] ;
		}
		root.entry[i+1] = e ;
		root.size++ ;
	}
	
	private void showNode(Node root) {
		System.out.println("Node: "+root) ;
		for(int i=0;i<root.size;i++) {
			System.out.println(root.entry[i].key + " : "+ root.entry[i].next ) ;
		}
		System.out.println("===========") ;
	}
	public void show() {
		show(root) ;
	}
	private void show( Node root) {
		if( root == null)
			return ;
		
		System.out.println(root) ;
		for(int i=0;i<root.size; i++) {
			System.out.println(root.entry[i].key + " : "+ root.entry[i].next ) ;
		}
		System.out.println("===========") ;
		
		for(int i=0;i<root.size;i++) {
			show(root.entry[i].next ) ;
		}
	}
}

public class Main { 
	
	public static void main(String[] args) throws Throwable { 
		BTree tree = new BTree() ;
		for(int i=6;i>=1;i--) {
			tree.insert(i);
		}
		
		System.out.println() ;
		tree.show();
	}
}
```

#### B树讨论

B树节点包括key数组和子节点数组，数组大小是M，M是阶数，也是最小读书t的两倍，n表示key的个数，则n+1是子节点的个数，节点用leaf标记是否为叶节点

B树的高度是
$$
height = O(log_t( (n+1) \div2))
$$
B树是一种用于索引的数据结构，之所以用B树，因为B树是一个多路树，他的节点可以设计的很大，跟磁盘页一样大，从而减少树的高度，进而让索引的时候减少磁盘IO的操作。B树把自己的根节点保留再内存，插入的时候找到插入的节点位置，然后根据这个节点位置的磁盘地址从外存中读取这个页面到内存，如果对这个页面发生修改，修改完成之后写入到磁盘。为什么不用红黑树或者AVL平衡树，因为他们叶子节点都是二，树的高度太高，增加磁盘IO次数。B树的节点都是按页保存在外存。

B树查找复杂度和增加节点复杂度都是，其中t是最小度数
$$
O(tlog_t(n))
$$
B+树是B树的一种扩展，他和B树不同的点在于他的数据结构key包含前驱节点pre和后继节点next，形成一个链表；B+树在分离节点的时候，把用于分离的节点保留在了左子节点，而B树没有保存在子节点，这样B+树的所有数据都保存在叶节点，而中间节点只是索引的功能，而B树的每个节点都可以包含对数据项的引用；B+树使用链表结构使得遍历B+树有两种方法，一种是使用链表，一种是直接中序遍历B+树。

### 完全二叉树、满二叉树、二叉搜索树、平衡二叉树AVL树、红黑树、B树、B+树

[参考](https://www.cnblogs.com/fengtingxin/p/13720992.html)

完全二叉树：空树不是完全二叉树，完全二叉树的叶子节点只在最底层和次底层，并且最底层全集中在最坐标。

满二叉树：除了最底层所有节点都没有子节点，非叶节点都有两个子节点

二叉搜索树：根节点的左子节点都小于根节点，根节点的右子节点都大于等于根节点，理论增删改查复杂度log(n)，但有一种退化成链表的情况

AVL树，一种平衡二叉树，任意节点的左右子节点高度不超过1，当失衡时需要左右旋操作

红黑树：一种近似平衡二叉树，最长节点不超过最短节点2倍。红黑树相较于AVL树，不是高度平衡的，在删除节点时最多三次旋转操作，而AVL树要维护删除操作的那一条路，所以AVL维护代价更高；AVL因为高度平衡，查询性能优于红黑树；综合来说红黑树优于AVL树。

B树，多路树，所有叶子节点深度相同，用于索引结构

B+树，B+树优于B树一个是B+树的关键字只是关键字用于索引，而B树的关键字包含了数据在磁盘的位置指针，这减少了一次取页的关键字的个数，为查询数据增加了次数；其次是B+树使用链表方便区间查询。

## Java集合框架

[集合框架](https://www.geeksforgeeks.org/how-to-learn-java-collections-a-complete-guide/)

### List接口

#### ArrayList

ArrayList实现了List接口，底层实际上是动态数组

1. 增

   检查size是否超过length，如果超过，那么length增加一半，内存增加一半，再添加元素，之后size+1

2. 删

   检查删除的index是否越界，没有越界，那么将动态数组元素向前移动一个位置，size-1

3. 改

   检查index是否越界，没有越界直接再数组上修改

4. 查

   检查index是否越界，没有越界直接按index返回数据

5. 检查元素是否在数组中，循环查询，使用元素的eaquals函数比较

6. sort，默认使用merge_sort，可以添加比较方法

7. hashcode

   ```java
   int hashcode = 1 ;
   for(E e: objArr){
   	hashcode = 31*hashcode + (e==null)?0:e.hashCode() ;
   }
   ```

8. eaquals

   比较每个Element是否相等

9. ArrayList的hashcode方法和equals方法是现成安全的，它使用了modificationCounter实现了CAS机制，从而保证了hashCode方法和equals方法的线程安全性。

   ArrayList是不线程安全的，比如增加数据，两个线程同时读取了size，那么在添加数据的时候他们会发生覆盖，从而只是添加了一个元素

10. ArrayList可以初始化length，如果没有，默认为0，之后如果添加数据，设置为10；之后如果内存不够，就至少增加一半

#### Vector

Vector和ArrayList类似，区别在于Vector是在ArrayList方法之上添加了Synchronized修饰方法，从而保证了线程安全。

Vector 扩容时2倍，ArrayList扩容时1.5倍，为什么设置成2倍和1.5倍，首先采用固定增量扩容平均push_back一个元素的时间复杂度是线性的，而采用倍增的方法可以将增加元素的复杂度变成O(1)；其次，为什么不采用更高的比如3倍，因为在分配内存的时候使用2倍的话，每一次分配内存总是大于前面所有分配内存的和，这样我们在复制分配内存的时候就不能利用原来的内存，所以分配内存大小倍增应该在(1,2)之间其取值

#### Stack

Stack继承自Vector，是线程安全的。可以用双端队列ArrayDeque和LinkedList实现Stack，但是那是不线程安全的

#### LinkedList

LinkedList实现了List和Deque接口，不仅仅是链表，也是双端队列，可以用来实现栈和队列，但是这是不线程安全的。LinkedList没有实现hashCode和equals函数，因为他可以是双端队列，所以方向没办法确定。

```java
class MyLinkedList{
	class Node{
		int val ;
		Node pre ;
		Node next ;
		
		Node(Node p, int v, Node n ){
			pre = p ;
			val = v ;
			next = n ;
		}
	}
	
	Node first = null ;
	Node last = null ;
	
	int size = 0 ;
	
	private void linkLast(int v ) {
		Node l = last ;
		Node newNode = new Node(last, v, null) ;
		last = newNode ;
		if( l == null) {
			first = newNode ;
		}else {
			l.next = newNode ;
		}
		size ++ ;
	}
	
	
	
	public void add(int v) {
		linkLast( v ) ;
	}
	
	private Node nodeAt(int idx) {
		if( idx<1 || idx>size )
			throw new RuntimeException("index越界") ;
			
		Node f = first ;
		for( int i=0;i<idx-1;i++) {
			f= f.next ;
		}
		return f ;
	}
	
	public int get(int idx) {
		return nodeAt(idx).val ;
	}
	
	public void remove(int idx ) {
		Node node = nodeAt(idx ) ;
		Node pre = node.pre ;
		Node next = node.next ;
		System.out.print("node value") ;
		System.out.println( node.val ) ;
		
		if( pre == null ) {
			first = next ;
		}else {
			pre.next = next ;
		}
		
		if( next == null ) {
			last = pre ;
		}else {
			next.pre = pre ;
		}
		
		node = null ;
		size -- ;
	}
	
	public void print() {
		Node f = first ;
		for( int i=0;i<size;i++) {
			System.out.print( f.val ) ;
			System.out.print(" ");
			f = f.next ;
		}
		System.out.print("    size:");
		System.out.println( size) ;
	}
}

public class Main {

	public static void main(String[] args) {
		MyLinkedList mylst = new MyLinkedList() ;
		
		mylst.add(0);
		mylst.add(1);
		mylst.add(23);
		
		mylst.print();
		
		System.out.println( mylst.get(1) ) ;
//		System.out.println( mylst.get(5) ) ;
		
		mylst.print();
		
		mylst.remove(3);
		mylst.print();
	}

}
```

### Queue接口

#### Deque接口

##### LinkedList

实现了List和Deque接口的链表实现双端队列。使用First和Last标记指向链表第一个和最后一个节点，操作总是在First和Last位置进行操作。操作都是常数复杂度

##### ArrayDeque

底层数据结构是动态数组。使用循环队列实现双端队列，head和tail初始化指向0下标，head总是指向队列新加入的元素，tail总是为空，并且总是在队列最早加入的元素的前面。

1. 增加元素，push操作使用addFirst实现，head先减1，然后加入增加的元素，

   在增加元素的时候判断队列（动态数组）是否为满：当增加元素的时候head==tail，那么说明队列为满，就扩容

   ArrayDeque扩容是至少增加一半容量jump，也可以增加指定的容量needed，但是needed>jump。获得扩容的newCapacity之后，新申请一个newCapacity的数组，使用System.arrayCopy(oldes, 0, newes,0, oldLength)复制到新数组；之后调整head和tail的位置，这需要tail<head或者tail==head并且es[head]!=null，首先获取newSpace = newCapacity-oldCapacity，然后使用System.arrayCopy(es, head, es,head+newSpace, oldCapacity-head)进行复制，这里获得head后面的所有元素个数使用oldCapacity-head。

   ArrayList扩容也是增加一半容量

   Vector扩容增加一个容量

2. 删除元素，pop操作使用removeFirst实现，首先获取head位置的元素e，如果e!=null，那么head加1，返回e，否则返回null，发生NoElementException

   判断删除元素后队列为空

   在删除元素的时候判断head==tail则队列为空

   removeLast实现，首先h=tail-1，e=elements[h]，如果e!=null，那么tail减1，返回e，否则返回null，发生NoElementException

   删除元素后判空，删除元素head==tail则为空

3. 判空

   因为在加入元素的时候保证了为满就增加容量，所以只有一种情况会出现head==taill，那就是为空，所以可以用head==tail判断是否为空。

4. 判满

   head==tail并且es[head] != null，因为在增加元素时发生head==tail就代表满了。

5. 元素个数

   tail-head<0 ? tail-head+es.length, tail-head ;

#### PriorityQueue

```java

class PQueue{
	private int[] que = new int[20] ;
	
	private int size = 0 ;
	
	private void siftUp(int k, int x) {
		while(k>0) {
			int parent = (k-1)>>1 ;
			int c = que[parent] ;
			if( c< x )
				break ;
			que[k] = c ;
			k = parent ;
		}
		que[k] = x ;
	}
	private void siftDown(int k, int x) {
		int half = size>>1 ;
		
		while(k<half) {
//			System.out.println(k) ;
			int pos = ((k<<1)+1) ;
			System.out.println(pos) ;
			int c = que[pos] ;
			int right = pos +1 ;
			if( right<size && que[right]<c)
				c = que[ pos= right] ;
			System.out.print(x);
			System.out.print(" ");
			System.out.println(c) ;
			if( x<c )
				break ;
			que[k] = c ;
			k = pos ;
		}
		que[k] = x ;
	}
	
	public void add(int x) {
		siftUp(size++, x ) ;
		System.out.print("        size: ");
		System.out.println(size) ;
	}
	public int peek() {
		return que[0] ;
	}
	public int pop() {
		int result = que[0] ;
		int x = que[--size] ;
		siftDown(0, x) ;
		
		System.out.println("aaaaa") ;
		return result ;
	}
	
	public void print() {
		for( int i=0;i<size;i++) {
			System.out.print(que[i]) ;
			System.out.print(" " );
		}
		System.out.println() ;
	}
}
```

1. PriorityQueue 是一个堆，底层使用动态数组实现，从0开始标号
2. 关键的点在于siftUp函数和siftDown函数
3. 当容量不够的时候至少扩充原来数组的一半。

### Set接口

#### SortedSet接口

##### NavigableSet接口

###### TreeSet

#### HashSet

#### LinkedHashSet

### Map接口

#### SortedMap接口

##### NavigableMap接口

###### TreeMap

#### HashMap

TreeSet、TreeMap使用红黑树存储

HashMap默认桶的个数是16，默认调整红黑树的节点个数是8，当initCapacity不为2的幂次，会自动转换成大于initCapacity的最小的幂次。当size个数>capacity*loadFactor就扩容，扩充桶的个数，此时桶的个数是2的幂次就有用了，h&32==0就代表节点在新桶的位置等于在旧桶的位置，如果h&32==1就代表节点在新桶的位置是旧桶的位置+16

HashMap存储结构是数组+链表，当链表长度>=8时替换链表使用红黑树存储数据

HashMap处理hash冲突使用拉链法，链表插入使用尾插法，因为要计算链表长度判断是否转换成红黑树

HashMap可以存放null:valuue的键值对，默认null的key保存在0号桶

HashMap数组大小时2的幂次好处是可以在计算桶的下表的时候可以使用位运算h&(length-1) == h%length，来计算桶的下表；其次是在扩容的时候，比如16扩容到32，可以用h&32==0 也就是判断h的第五位来判断到新桶下标等于旧桶下表，如果h&32==1，那么新桶下标是旧桶下表+16 ；

**插入**

1. 首先计算key的hash值，计算方法是key.hashCode()^key.hashCode()>>>16

2. 判断table是否为空，为空就resize分配内存给table，resize总是扩充为原桶的两倍，然后重新把旧节点放到新桶，这个时候判断一个节点的桶的位置可以用hash&32==0，就代表在原桶；hash&32==1，就代表在原桶+16的那个桶
3. 利用hash&(length-1)获得key所在的桶的下标，判断头节点p是否为空，为空就分配p节点内存保存key
4. 如果不为空，判断p是否是RBTreeNode节点，如果是，就执行RBTreeNode并且返回一个旧的保存key的节点
5. 如果p不是树节点，就遍历链表，如果遇到一个关键字与key相同的节点，返回这个节点，否则就在尾部插入key关键字的节点
6. 判断插入之后链表长度是否大于等于链表转树的阈值，如果大于等于8，就把链表转为红黑树，并且把树的根节点赋值给桶第一个节点
7. 如果e不为空，代表哈希表存在这个key，返回e的旧值

**获取key节点的数值**

计算key的hash值，找到对应的桶

判断桶的节点p是否是树节点，是树节点就查找红黑树

否则遍历链表

#### HashTable

HashMap和HashTable区别

1. HashTable使用synchronized进行同步
2. HashMap支持null的key节点
3. HashMap不保证节点顺序
4. HashMap迭代器是failfast的。

#### LinkedHashMap

LinkedHashMap继承自HashMap，他只是在HashMap的节点添加了两个指针，从而把HashMap的节点通过head和tail构建出一个在HashMap结构基础上还有关于head和tail的双向链表。当添加一个元素的时候，按照hashMap的方式添加，同时也要把他加入到tail节点后面；当访问到一个节点后，就把这个节点重新添加到tail节点；当增加元素的时候，考虑把head元素删除。

#### WeakHashMap

WeakHashMap的节点是继承自WeakReference对象的节点，其他和HashMap相同，这种结构只是利用弱引用容易被回收的特点方便JVM回收HashMap的对象

**Tomcat的concurrentCache使用了WeakHashMap**

```java
public final class ConcurrentCache<K, V> {

    private final int size;

    private final Map<K, V> eden;

    private final Map<K, V> longterm;

    public ConcurrentCache(int size) {
        this.size = size;
        this.eden = new ConcurrentHashMap<>(size);
        this.longterm = new WeakHashMap<>(size);
    }

    public V get(K k) {
        V v = this.eden.get(k);
        if (v == null) {
            v = this.longterm.get(k);
            if (v != null)
                this.eden.put(k, v);
        }
        return v;
    }

    public void put(K k, V v) {
        if (this.eden.size() >= size) {
            this.longterm.putAll(this.eden);
            this.eden.clear();
        }
        this.eden.put(k, v);
    }
}
```

ConcurrentCache把缓存划分为两个部分Eden区和Longtern区，Longtern区存放弱引用哈希表，首先被回收

- 对于get操作，首先在Eden区get，如果没有再在Longtern区get，并且把get的对象放到Eden区
- 对于put操作，如果size不够，把Eden区全部转移到Longtern区，再在Edent插入

## Java并发集合框架Java.util.Concurrent JUC

[参考-介绍并发集合框架](https://spongecaptain.cool/post/java/frameworkofjuc/#41-lock)

**浅拷贝和深拷贝**

浅拷贝只拷贝引用，引用所指向的对象没有改变

深拷贝不仅拷贝引用，还拷贝了引用所指的对象，新引用所指向的对象是新拷贝的对象。

**锁的释放**

- 正常结束：synchronized代码块执行结束，ReentrantLock在finally调用lock.unlock
- 异常结束：在synchronized代码块或者ReentrantLock的try代码块抛出异常
- return释放：在代码块调用return返回

### 顶层

#### Lock包

[参考](https://blog.csdn.net/qq_20499001/article/details/103322794)

##### ReetrantLock

底层使用AQS作为同步队列（锁池队列），使用Unsafe的CAS，初始化CAS的state变量为0，当一个执行态的线程到来时竞争state，cas(state, 0, 1)，期望值是0，如果成功设置为1，那么代表这个线程竞争到锁，它可以继续执行；如果之前一个线程已经竞争到锁，那么state就不可能是0，那么这个线程就无法设置state变量，从而不能竞争到锁，之后这个线程被放到同步阻塞队列，等待竞争锁。当进行lock.unlock()的时候，会让state-1，并且返回false；如果state减到0，那么就说明没有占用

ReetrantLock实现了Lock接口，它可以结合Condition接口实现synchronized条件等待

```java
//A 线程
synchronized(lock){
	lock.wait(); //进入等待队列，失去锁
}
//B线程
synchronized(lock){
	lock.notify(); //从等待队列
}


//A线程
lock.lock() ;
try{
    doSomething();
    Condition.await() ;//进入等待队列
    doSomething() ;
}
finally{
    lock.unlock() ;
}
//B线程
lock.lock();
try{
    doSomething() ;
    Condition.signal() ;//从等待队列获取一个线程放入阻塞队列，这是一种延迟通知，只有等这个							线程释放锁之后才会signal一个等待队列的线程
}
finally{
    lock.unlock();
}
```

#### 并发容器

##### Queue接口

###### ArrayBlockingQueue

[参考](https://juejin.cn/post/6844903796485668872#heading-0)

````java
class Producer implements Runnable{
	BlockingQueue<Integer> que ;
	
	public Producer(BlockingQueue<Integer> q) {
		que = q ;
	}
	
	public void run() {
		for( int i=0;i<10;i++) {
			try {
				que.put(i) ;
			} catch (InterruptedException e) {
				// TODO Auto-generated catch block
				e.printStackTrace();
			}
		}
	}
}
class Consumer implements Runnable{
	BlockingQueue<Integer> que ;
	public Consumer(BlockingQueue<Integer> q) {
		que = q ;
	}
	@Override
	public void run() {
		for(int i=0;i<10;i++) {
			try {
				Thread.sleep(2000);
			} catch (InterruptedException e) {
				// TODO Auto-generated catch block
				e.printStackTrace();
			}
			int a = 0;
			try {
				a = que.take();
			} catch (InterruptedException e) {
				// TODO Auto-generated catch block
				e.printStackTrace();
			}
			
			System.out.println(a) ;
		}
	}
}
public class Main { 
	
	public static void main(String[] args) throws InterruptedException {
		
		BlockingQueue<Integer> que = new ArrayBlockingQueue<Integer>(3) ;
		
		Thread producer = new Thread(new Producer(que)) ;
		producer.start();
		Thread consumer = new Thread(new Consumer(que)) ;
		consumer.start();
		
		while(producer.isAlive() || consumer.isAlive() ) {
			System.out.println( producer.getState() ) ;
			Thread.sleep(1000);
		}
	}
}
````

**ArrayBlockingQueue实现原理**

- 同一时间只有一个生产者或者消费者线程操作队列，队列使用循环队列

- 对于生产者put线程，他们互斥获得锁，操作队列，如果队列没有满，他向队列写元素，同时使用notEmpty.signal在notEmpty的条件同步队列上唤醒一个线程来读取运输；如果对了满了，那么这个生产者线程会被放到notFull.await的notFull的条件同步队列阻塞
- 对于消费者take线程，如果队列有元素，他获取元素并且使用notFull在notFull的同步队列上唤醒一个生产者线程放入元素；如果队列没有元素，他被阻塞到notFull同步队列。

##### List接口

###### CopyOnWriteArrayList

底层使用Object[] array数组来存储

增删改，使用synchronized同步，每次总是新建一个克隆数组，在克隆数组上进行增删改操作，然后把得到的新数组array=es替换到array

查操作，查操作没有锁，是在原数组array上进行查找操作。这样的好处在于实现了读写分离，读线程可以并发操作，而写线程之间必须互斥。

CopyOnWriteArrayList读写分离适合读多写少的情况，他不适合内存敏感和数据实时性敏感的情况。他的缺点

1. 因为增删改在复制数组上操作，浪费内存
2. 读取数据的时候可能发生写数据，因此读数据可能不是实时的

##### Map接口

###### ConcurrentHashMap

Java17 ConcurrentHashMap实际上就是一个HashMap，只是在增删改的时候会把对应的key的那个桶Synchronized锁起来

JDK1.7 使用segment继承ReetrantLock实现，每个segment包含HashEntry数组，以及size表示segment包含HashEntry个数，modCount表示数据结构变化次数，当要求size的时候，使用CAS来求：

- 当retries=-1，遍历所有segments求modCount的和得到last

- 当retries=0，遍历所有segments得到size的和Size，以及所有modCount的和ModCount，比较ModCount==last，如果相等就返回这个Size，认为没有进程争用

- 当retries=1，重复retries=0的操作，这样求一个size需要两次CAS操作

- 当retries=2，认为前两次都不成功，这次把所有的segments调用segment.lock()锁住，然后求size，并且返回这个size，之后记得在finally里面把所有的segment.unlock()解锁。

#### 线程池 Executer

##### Thread 类

thread.start方法执行过程：在main线程初始化时，每次new Thread()就会创建一个Thread对象，并且这个Thread对象会被加入到main线程的ThreadGroup group里，然后调用start0这个native方法啊创建线程。

#### TimeOut类

提供时间

#### 同步器

[参考资料](https://www.cnblogs.com/dolphin0520/p/3920397.html)

同步器是用来协调线程的同步的

#####  CountDownLatch

调用latch.await的main进程等待state个线程执行完latch.countDown之后执行。

**原理**

CountDownLatch初始化一个Volatile state变量，维护一个Sync extends AQS的同步队列。在每个线程里面，线程执行完成之后（某个执行完成的点调用latch.countDown将state变量-1，如果说到了一个线程让state变成0，那么就从同步队列里面唤醒一个线程到就绪队列。在主线程main里面，调用latch.await()方法，会把Thread.currentThread = main放到Sync同步队列，直到state被变成0才唤醒他。注意这里的sync同步队列和ReetrantLock里面的同步队列是不一样，ReetrantLock的同步队列是一个锁池队列，他被唤醒的进程需要去竞争锁才能进入就绪队列，而CoountDownLatch的sync同步队列不需要竞争锁，他被唤醒之后直接回到就绪队列，而且这个同步队列最多只有main线程一个线程。

CountDownLatch用来协调A线程等待state个线程BCDE等执行完成之后才开始执行，相当于线程池里面thread.join()方法，主线程调用其他线程的join方法进入无限等待状态，直到调用join的线程执行完成之后才能执行

ReetrantLock不是用来协调线程执行关系的，它主要是用来解决多进程同步访问共享变量的问题。

##### CyclicBarrier

等待N个线程执行到CyclicBarrier.await的栅栏点之后这个N个线程重新开始执行

**原理**

CyclicBarrier包含一个count记录还有多少没有到达到达栅栏点的所有线程数目，一个ReetrantLock lock用于锁池，Condition trip = lock.condition() 用于挂起和唤醒线程。

CyclicBarrier变量barrier的count=N，barrrier被初始化赋值给N个线程，每个线程执行到barrier.await到达栅栏点，开始竞争barrier.lock的ReetrantLock锁，如果竞争得到锁，count-1，判断count-1的结果是否等于0，如果为0就代表所有N个线程到达栅栏点，唤醒所有挂起的N-1个线程执行barrier之后的工作。如果cout-1!=0，就代表还有线程没到栅栏点，那么就调用trip.await()把这个线程挂起到等待队列，变成Waiting状态，等待调用trip.signalAll唤醒到阻塞队列，当线程争用到锁之后，他会从调用condition.wait的地方重新执行，这样就能统一所有的N个线程到同一个barrier。CyclicBarrir还可以重用，可以设置多个barrier

##### semaphore

CountDownLatch和CyclicBarrier都是用于协调线程运行的，CountDownLatch适合让一个线程等待其他线程执行完毕（使用join方法，使用线程池shutdown也有同样的效果），而CyclicBarrier适合多个线程相互等待到达一定的 状态后执行。此外CyclicBarrier是可以被重用的。

Semaphore是信号量，主要用于多线程对多个共享资源的访问。如果信号量的个数是1，那么就是锁机制

**信号量semaphore实现原理**

Semaphore信号量使用Unsafe类的state直接内存来保存资源个数，当一个线程使用aquir申请一个资源时，先state-1，判断剩余量是否大于0，大于0就证明能分配，线程获得信号量资源继续执行；否则就是小于0，那么就把这个线程放到Semaphore类的Sync阻塞队列，并且调用LockSupport.park的线程管理把这个线程放到等待队列（这是操作系统层面的）。当调用release的时候，会让state+1，之后把阻塞队列的中的线程谁支撑Waiting，调用LockSupport.unpark将线程唤醒。

基于Unsafe下的state变量

1. Lock类：有ReetrantLock记录锁和重用，
2. 同步器类：Semaphore记录资源数量，CountDownLatch记录还有多少个线程没有执行到latch.await命令

### 中间层

#### AQS（AbstractQueuedSynchronizer）

同步队列，底层使用双向链表实现，当线程竞争锁失败后线程被调用Unsafe.park()挂起，同时把线程状态和线程组合成Node加入同步队列保存，当线程被唤醒时从同步队列里面找到线程并且调用Unsafe.unpark()从阻塞中唤醒，并且删除这个同步队列节点。

AQS需要配合Unsafe的线程调度方法一起完成对线程的管理，相当于模拟实现了操作系统线程调度过程。

#### Automic类 原子类

### 底层

#### Volatile关键字

[参考资料](https://www.cnblogs.com/dolphin0520/p/3920373.html)

**多核计算机工作模型**

多核CPU计算机的存储器分为，寄存器、高速缓存Cache、主存（物理内存）、辅存（外存、磁盘、U盘、光盘）。

因为CPU在读写Cache的速度远大于读写主存的速度，因此，CPU工作的时候，总是先把主存的变量拷贝到Cache里面，然后对变量的操作总是在Cache里面，在某个时刻才考虑把Cache里面的数值写回到主存里面（程序执行结束，Volatile关键字变量的本地变量被修改）

这种工作模式造成的问题就是缓存一致性问题，当两个CPU共享主存变量，他们分别把主存共享变量拷贝到本地Cache，然后再本地Cache上对变量进行操作，这样可能造成他们写回到主存中的变量不是两个CPU线程执行的正确结果，也就造成了缓存一致性问题。

**CPU解决缓存一致性问题方法**

- 总线锁：CPU在使用一个共享变量的时候会使用总线锁把那个变量的总线锁住，这样其他CPU在获取那个共享变量的时候会被迫等待或者挂起，直到那个共享变量可以被使用
- 缓存一致性协议：CPU在写本地变量的时候，一方面立即写入到主存，另一方面使用总线把其他CPU的这个共享变量的缓存设置为无效，这样当其他CPU在读取Cache缓存里面的值时总是从主存里面读取更新的值覆盖缓存的值。

**Java内存模型 JMM - Java Memory Model **

Java内存模型就是为了适应多核CPU共享内存的执行情况的。Java内存模型规定所有变量保存到主存，线程有自己的工作内存，线程对数据的操作只能在自己的工作内存中，而不能在主存中，每个线程不能访问其他线程的工作内存。

**并发编程的三大特性，Java内存模型的三大特性**

- 原子性

  一组指令要么全部执行，要么都不执行

  Java内存模型只保证read苁主存中读取变量到工作内存，write把工作内存变量写到主存，lock和unlock对主存中变量加锁和释放锁等操作的原子性

  如果要实现更大范围的一组指令的原子性，可以使用synchronized或者lock包下面的锁来实现，他们使得同一时间只有一个线程或CPU执行同步代码块，保证了原子性。

- 可见性

  在多个线程访问同一变量时，一个线程修改了这个变量的值，其他线程能够立即看到这个修改的值

  Java可以使用Volatile关键字保证可见性，Volatile修饰的变量，在修改Cache工作内存的本地变量时，实现了CPU缓存一致性协议，他会把修改的值更新到主存中，同时通过CPU总线设置其他CPU的工作内存Cache的同一共享变量的本地内存为失效，这样其他CPU在操作这个本地变量时会首先从主存中读取这个更新值

  此外，可以使用synchronized和lock锁来保证可见性，synchronized和lock保证同一时间只有一个线程CPU在执行同步代码块，并且在退出同步代码块的时候会将本地变量写回主存，这样下一个CPU执行同步代码块的时候可以读取这个更新的值

- 有序性

  代码的执行顺序和代码书写的先后顺序执行

  为了提高执行效率，编译器会对指令重排序，指令重排序不影响单线程执行指令的正确性，但是会影响多线程执行指令的正确性。

  ***

  比如A线程执行a=1, b=2；B线程执行if b==2: a+1 ; 正确结果是a=3

  如果A代码发生指令重排序使得执行顺序时b=2, a=1，那么B线程先检测到b=2然后把a+1，结果就造成a的值不能预测。

  ***

  Java内存模型保证有序性可以使用Volatile关键字，Volatile关键字保证有序性是使用内存屏障实现的，在汇编代码里，我们会看到对变量操作时会产生一个内存屏障指令，这个指令保证编译器在指令重排序的时候不会把后面的代码重排序到内存屏障前面，也不会让内存屏障前面的代码被重排序到后面

  可以使用synchronized和lock保证有序性，他们同一时间只有一个CPU执行同步代码块，而一个线程执行代码块相当于顺序执行。

**Volatile关键字功能**

- 保证可见性，通过写本地变量时写到主存，并且使用CPU总线让其他CPU的本地变量失效，从而在操作共享本地变量时从主存中重新读
- 禁止指令重排序，保证一定的有序性，通过内存屏障实现，内存屏障让他前面的代码不会被重排序到他后面，他后面的代码不会被重排序到他前面

**实现原子性i+1**

volatile不能实现原子性，但是可以保证可见性

实现原子性可以使用synchronized（底层操作MarkWord），lock（ReetrantLock底层使用unsafe类的CAS机制操作直接内存），原子类型AtomicInteger（底层使用unsafe类CAS机制操作直接内存）

#### Unsafe类

Unsafe类是一个操作直接内存（堆外内存）的底层类，它可以完成所有对内存的操作，比如分配数组、分配对象、清理对象等，Unsafe类是一个单例

JUC使用了Unsafe类的两个特性

- 线程调度，unsafe可以使用park()和unpark()方法挂起或者唤醒一个线程
- 乐观锁CAS，比较替换，unsafe的CAS方法是一个原子操作，他直接使用CPU的cmpxchng原语实现变量的比较替换



## Java基础

[Java SE8 ](https://docs.oracle.com/javase/specs/index.html) [JDK 8](https://docs.oracle.com/javase/specs/jls/se8/jls8.pdf)  [JVM8](https://docs.oracle.com/javase/specs/jvms/se8/jvms8.pdf)

### Java基础

> # Basic Java
>
> Learning Material
>
> [link](https://www.youtube.com/watch?v=xk4_1vDrzzo)
>
> [link](https://www.runoob.com/java/java-collections.html)
>
> [link](https://juejin.cn/post/6844903922700648456)
>
> [命令行编译Java项目](https://blog.csdn.net/chen930724/article/details/49432051)
>
>       1. javac -d bin/ -cp lib/*.jar src/firstproject/Main.java
>    
>      -d 表示编译后.class文件存放位置
>         
>      -cp 表示编译依赖的环境（jar包），多个包可以用冒号隔开
>    
>       2. java -cp bin/ firstproject.Main
>    
>      -cp表示执行以来环境，一定要把编译时的路径加上（bin/）
>         
>      firstproject.Main要加上包和主文件名
>
> [link](https://www.liaoxuefeng.com/wiki/1252599548343744/1304048154181666)
>
> 
>
> Jvm相关（没有学）
>
> [link](https://zhuanlan.zhihu.com/p/44694290)
>
> [link](https://blog.csdn.net/weixin_43767015/article/details/105453983)
>
> Java书籍（没有下载，没有学）
>
> [link](https://www.w3cschool.cn/java/java-book.html)
>
> [一个Java博客](https://www.cnblogs.com/aishangJava/tag/)
>
> [java培训](https://wiki.jikexueyuan.com/list/java/)
>
> [重要 没学](https://wiki.jikexueyuan.com/list/java/)
>
> [泥瓦匠 没看](https://www.bysocket.com/2022-02-26/%e5%89%91%e6%8c%87%e5%a4%a7%e5%8e%82%ef%bc%9a%e5%b0%8f%e7%99%bd%e5%85%a5%e8%81%8c%e5%a4%a7%e5%8e%82%e5%ae%8c%e5%85%a8%e6%94%bb%e7%95%a5%ef%bc%8c%e5%be%88%e8%82%9d.html)
>
> [没看](https://juejin.cn/post/6844903560719646728)
>
> ## Basic concept（Java高级编程语言语法）
>
> 1. source code (.java) compiled to byte code (.class),  by JVM to machine code
>
> 2. JDK: java development kit > JRE: java runtime environment > JVM: java virtual machine
>
> 3. IDE: integrated development environment
>
> 4. Java实现一次编译，到处运行，是基于把编译和运行分开的结果。Java编译器负责把Java编译成字节码，编译成字节码可以对这个字节码进行优化，这个字节码可以发送到不同平台上被JVM（Java虚拟机进行运行）加载运行（字节码不跟平台相关），JVM还集成了一些比如垃圾回收机制等特性，JVM是平台相关的，针对不同类型的机器单独编写了JVM。C++等语言编译和执行是一起的，C++编译器把代码直接编译成平台相关的机器码，点击这个机器码得到执行，C++编译器可以将机器码进行优化。Python发送的是源码，编译和执行是一起的，一句一句的，没有代码优化的方法。
>
>    Java EE是Java企业版，实在Java SE标准版上添加了分布式处理、网页处理、数据库请求、消息服务这些特性的，Java SE和Java EE的JVM通用。Java ME是Java SE的瘦身版，是用于嵌入式编程的语言，Java ME的JVM和Java SE不通用，Java SE程序不能在Java ME上运行。Java ME没能在移动应用上火起来，而是Android代替了他。
>
>    想学习Java语法、核心开发技术和标准库，学习Java SE
>
>    想学习Web 开发、Spring框架、数据库开发、分布式架构，学习EE
>
>    想学习大数据开发，学习Had、Spark、Flink
>
>    想学习移动开发，学习Android
>
>    
>
>    JDK：Java开发套件，在JRE开发编译器和调试器等
>
>    JRE：Java运行环境，在JVM上开发运行库
>
>    JVM：Java虚拟机，负责加载执行
>
>    
>
>    JSR：Java SPecification Request，Java语言规范，定义了接口等规范
>
>    JCP：Java Community Process
>
>    RI： Reference Implementation，参考实现，定义了一个接口，他的实现的参考，这个RI不讲究效率但是要保证正确性
>
>    TCK：Technology Compatibility Kit，兼容性测试套件，提供接口和功能描述，方便开发者理解
>
>    发布JSR也就是要发布RI和TCK
>
>     
>
> 5. 参数传递：
>
>    传值：对于基本数据类型，直接传值；对于类类型和集合类以及String类，等，传递实例的引用
>
> 6. 重载和重写：
>
>    重载：方法名相同，但是参数或者返回不同
>
>    重写：类继承时子类重写父类的同名函数
>
> 7. JAVA特性
>
>    1. 跨平台性：Java程序(.java)被编译成字节码(.class)，通过JVM解释运行。Java通过JVM实现跨平台性，但是JVM不是跨平台的，不同操作系统具有不同的JVM。
>    2. Java**语法**和C++相近，但是抛弃了C++的一些特性，比如操作符重载、多继承、强制类型转换，Java不使用指针，而是引用，Java提供自动内存分配和回收机制。
>    3. JAVA支持**面向对象编程**。Java只支持类单继承，但是支持接口多继承。Java支持动态绑定，C++只对虚函数使用动态绑定
>    4. JAVA提供**网络应用编程**几口（JAVA net），RMI远程激活方法可以用于开发分布式应用
>    5. JAVA**健壮性**，强类型机制、异常处理、垃圾回收、安全检查
>    6. JAVA**安全性**，在网络环境中，提供了一个安全机制防止恶意代码攻击
>    7. JAVA**体系结构中立，可移植性**，JAVA代码被编译成字节码格式，这个格式可以在任意JVM上运行
>    8. JAVA**高性能**，运行速度在JIT编译器技术的发展下接近C++
>    9. JAVA**多线程**，支持多线程同步，有两种方法实现多线程，一种是Thread子类，一种是传递一个实现了Runnable接口的对象给Thread对象
>    10. JAVA**动态性**，JAVA运行的类可以动态载入运行环境，也可以通过网络载入运行环境，方便软件升级
>
> 8. Java代码执行顺序：
>
>    new 创建实例：静态代码块，非静态代码块，构造函数
>
>    无new的顺序：静态代码块，方法，方法中的代码块
>
> 9. JAVA关键字和修饰符
>
>    1. 访问控制修饰符：public，protected，private，default
>
>    2. 类和变量修饰符：class，extends，implements，interface
>
>       1. abstract： 用来创建抽象类和抽象方法，一个类不能同时被abstract和final修饰，抽象类的唯一目的就是对这个类进行扩充，抽象类可以包含抽象方法和非抽象方法。抽象方法是一个必须由子类实现的方法，抽象方法不能被final和static修饰。子类必须实现所有抽象方法，除非子类也是抽象类。抽象类可以不含抽象方法
>
>          ```java
>          public abstract sample() ;
>          ```
>
>          
>
>       2. static：修饰的变量只在类的所有对象中一份拷贝，存储在静态内存空间，main函数必须用static休书，否则JAVA无法执行。静态方法可以用className.methodName方式引用。static方法不能被子类重写，但是能被子类重新声明
>    
>          static字段，创建一个全部实例共享的变量
>    
>          static方法，穿凿一个与实例无关的方法，static方法内部不能使用this关键字，只能访问static字段。
>    
>       3. final: final修饰的类不能被继承，final修饰的方法不能被子类重写（防止子类修改这个方法），final修饰的变量是常量。final修饰的变量必须显示给出初始值，通常public static final 用于声明常量。
>    
>          final的作用，阻止类被继承，阻止子类被复写，组织变量被重新赋值
>    
>          final类，类不能被继承
>    
>          final方法，方法不能被重写
>    
>          final变量，变量不能重新赋值
>    
>       4. static final合用，创造一个全局实例共享但是不能被改变的变量
>    
>       5. new，native，strictfp，
>    
>       6. transient： 序列化的对象含有被transient修饰的实例变量时，JVM会跳过这个变量，这个用来预处理类和数据变量的类型，不会持久化
>    
>       7. synchronized：修饰的方法同一时间只能被一个线程访问，synchronized可以加四个访问控制符
>    
>       8. volatile： volatile修饰的局部变量在每次线程调用时都会从共享内存读取这个变量的数值，在局部变量数据发生变化的时候线程会强制写道内存空间，这样在任何时刻，两个不同的线程总是看到成员变量的同一个值。
>
>    3. 变量引用：
>
>       1. super：父类
>       2. this：本类
>
>    4. 错误处理：
>
>       1. assert：断言表达式是否为真
>       2. try，catch，finally：捕获异常
>       3. throw：抛出异常对象
>       4. throws：声明一个异常可能被抛出
>
> 10. 面向对象编程
>
>     1. 对象：一个类的实例，有状态和行为
>     2. 类：一个模板，描述一类对象的行为和状态
>     3. 方法：方法就是类的行为
>
> 11. Notes
>
>     1. 接口：对象间相互通信的协议，接口只定义派生用到的方法，方法的实现决定于派生类。接口的访问控制符只能是public
>
>     2. JAVA一个源文件只能有一个public类，可以有多个非public类。源文件名字和public类名字相同。如果源文件在包中，要把包名放到源文件首行。import语句放到package和类之间
>
>     3. String类可以用于数据比较读取（改查）等操作，要对字符串进行修改需要用（增删改查）StringBuffer或者StringBuilder，StringBuffer在字符串空间内对数据进行修改，线程安全；StringBuilder不是线程安全的，他比StringBuffer访问速度快。
>
>     4. 参数传递：值传递，引用，指针
>
>     5. finalize方法：在对象在被垃圾回收回收前调用的方法，可以用来清除对象，但是你不知道何时被调用，而且也不需要你自己完成
>
>        ```java
>        protected void finalize() ;
>        ```
>
>     6. Java所有类都是Object类的子类，如果没有指定一个父类，那么Java自动继承Object类
>
> 12. Optional类型
>
>     Optional类是一个包装器类，是一个泛型类，它可以对一个对象进行包装，检查一个类是否为空并且抛出空异常，如果为空，可以返回默认值。Optional类是对长变量方法的一种补充，比如下面的方法
>
>     ```
>     A.get().get().get().get().print()
>     ```
>
>     上面的代码如果在某个部分出现了空异常，那就是一个NuLLPointerException，这种时候我们很难确定是哪个类的get出现了这个异常。要防止这个异常，我们必须编写检查代码
>
>     ```java
>     if( A != Null){
>     	B b = A.get() ;
>     	if( b!= Null ){
>     		C c = b.get() ;
>     		...
>     	}
>     }
>     ```
>
>     1. Optional类的创建
>
>        ```java
>        Optional<T> a = Optional.of( t ) //这个t如果是一个Null，那么会返回NullPointerException
>        Optional<T> a = Optional.ofNullable(t) //这个t允许是Null
>        Optional<T> a = OPtional.empty() //返回一个包装为空的Optial类型
>        ```
>
>     2. Optinal类的内容获取
>
>        ```java
>        T t = a.orElse(new T()) //返回Optional类包装器内容，如果为Null那么久返回默认值
>        ```
>
>     3. Optional类的处理
>
>        ```java
>        a.isPresent(); //如果Optional类型为空，返回false，否则返回true
>        ```
>
>        
>
> 13. 对象序列化
>
>     Java对象序列化是Java对象持久化的一种方法，通常一般使用数据库等持久化技术，对象序列化技术没人关注。Java实现了java.io.Serializable接口的类都是可序列化类。对象序列化可以把一个对象表示为一个字节序列，这个字节序列包含对象的类型、对象的数据以及数据的类型。反序列化需要指定数据的类型。对象序列化是JVM独立的，也就是说一个平台上序列化的对象可以在另外一个平台上反序列化得到同样的对象。
>
>     如果对象的成员变量不想被序列化，那么就应该定义成瞬态（transient）或者静态（static），序列化的方法不能使用非序列化的成员变量，瞬态成员变量在反序列化之后会变成默认值。
>
>     序列化对象保存在ser文件，类似Python字典的持久化一样
>
>     ```java
>     Series series = new Series(2,3) ;
>     System.out.println(series.max()) ;
>     
>     
>     //对象序列化
>     try {
>     	FileOutputStream fileOut = new FileOutputStream("C:\\Users\\cheng\\Desktop\\trash\\Series.ser") ;
>     	ObjectOutputStream out = new ObjectOutputStream(fileOut) ;
>     	out.writeObject(series);
>     	out.close();
>     	fileOut.close() ;
>     	System.out.println("Seialized data is saved") ;
>     }catch(IOException e) {
>     	e.printStackTrace();
>     }
>     
>     
>     //对象反序列化
>     Series series1 = null ;
>     try {
>     	FileInputStream fileIn = new FileInputStream("C:\\\\Users\\\\cheng\\\\Desktop\\\\trash\\\\Series.ser") ;
>     	ObjectInputStream in = new ObjectInputStream(fileIn) ;
>     	series1 = (Series)in.readObject() ;
>     	in.close();
>     	fileIn.close();
>     }catch(IOException i) {
>     	i.printStackTrace();
>     return ;
>     }catch(ClassNotFoundException c ){
>     	c.printStackTrace();
>     return ;
>     }
>     System.out.println( series1.max() ) ;
>     ```
>
>     
>
> ## Data type（计算机组成原理，计算机体系结构）  
>
> #### primitive
>
> Wrapper class of primitive type contain more usefull methods than bare primitive variables
>
> 包装类包含了对元数据的处理方法
>
> 1. boolean: 1 bit          
> 2. byte: 1 byte，4 bits
> 3. short: 2 bytes, 8 bits
> 4. int: 4 bytes, 16 bits
> 5. long: 8 bytes, 32 bits
> 6. float: 4 bytes, 单精度浮点数32位
> 7. double: 8 bytes，双精度浮点数64位
> 8. char 2 bytes，一个16位的Unicode字节，16位
>
> #### reference
>
> 引用类型指向一个对象，在声明引用类型变量的时候就指定了他的数据类型，比如Dog类
>
> 数组和对象都是引用类型
>
> 1. String: varies
>
> #### array
>
> 1. 数组的变量是数组引用类型，数组可以作为参数传递，也可以作为返回
>
>    String[] cars ={ "abc", "bcd"} ;
>
>    String[] [] cars = new String[3] [3] ;
>
>    String: built in function
>
>      1. String s ;
>         1. C++ : string
>            	2. Python: string  ""
>      2. s.equals() ;
>      3. s.charAt(0); s[0] ;
>      4. s.toUpperCase(); s.toLowerCase() ;
>      5. s.indexOf("O") ;
>      6. s.length() ;
>      7. s.isEmpty() ;
>      8. s.trim() ;
>      9. s.replace('o', 'a') ;
>
> 2. ArrayList: a resizable array, store reference data types
>
>    1. ArrayList<String> food = new ArrayList<String>() ;
>       	1. C++: vector
>           	2. Python: list []
>    2. food.add('abc') ;
>    3. food.set(0, 'cdb') ;
>    4. food.get() ;
>    5. food.remove(2) ;
>    6. food.clear() ;
>
> ## Concepts
>
> 1. Loop : for(String i : animals)
>
> 2. Python: for i in animals
>
> 3. Overloaded methods( functions ): same method name but different parameters，重载：同一个类中方法名相同但是参数不同；重写：子类重写父类的方法
>
> 4. Formated output: System.out.printf("%,.2f", 123.423) ;
>
> 5. Name space:
>
>    1. local variable, only visible in that method（局部变量）
>
>       1. 局部变量旨在声明他的方法中可见，访问修饰符不能用于局部变量，局部变量在栈上分配，随着创建它的代码块的执行被创建，随着代码块执行完毕被销毁。
>
>    2. global variable, visible in all the parts of the class（实例变量）
>
>       1. 实例变量在类的方法之外声明，随着对象的创建创建，随着对象的销毁被销毁。实例变量至少被一个方法使用，才能从外部通过这些方法调用这些变量。实例变量可以加访问控制符，通过访问控制符，实例变量可以被直接访问。public的实例变量可以被外部直接访问，private的实例变量只能被本类访问，protected实例变量在子类可见。
>
>    3. 类变量（静态变量，static关键字声明）
>
>       1. 无论类创建了多少对象，静态变量只有一个拷贝。静态变量经常和public final使用被声明为常量。静态变量存储在静态存储区。静态变量可以通过className.variableName访问。
>
>          ```java
>          public static final String A="aaaaa" ;
>          ```
>
> ### Java数据结构（数据结构和算法）
>
> 1. 基本数据结构
>
>    1. 枚举（Enumeration），可以指向下一个元素
>    2. 位集合（BitSet），按位操作，按位与或非
>    3. 向量（vector），动态数组，和ArrayList相似，但是定义了一些ArrayList没有的方法
>    4. 栈（stack）
>    5. 字典，Dictionary。键值对映射，哈希表Hashtable实现了字典的map接口。Properties 类继承于Hashtable
>
> 2. 集合框架
>
>    ![img](https://www.runoob.com/wp-content/uploads/2014/01/2243690-9cd9c896e0d512ed.gif) 
>
>    1. **线性表List**
>
>       1. **ArrayList**
>
>          ArrayList 是一个动态修改的数组（[]），他转载的数据类型时引用类型，如果使用元数据类型，需要使用元数据类型的Wrapper类，ArrayList是一个数组队列，提供了增删改查等功能
>
>           ![img](https://www.runoob.com/wp-content/uploads/2020/06/ArrayList-1-768x406-1.png) 
>
>          1. 使用方法
>
>             ```java
>             //initiate
>             ArrayList<String> lst = new ArrayList<String>() ;
>             
>             //add elements
>             lst.add("a") ;
>             lst.add("b") ;
>             lst.add("c") ;
>             
>             //iterate by for-each
>             for(String each: lst) {
>             	System.out.println(each) ;
>             }
>             
>             //iterate by for-index
>             for(int i=0;i<lst.size();i++) {
>             	System.out.println(lst.get(i)) ;
>             }
>             
>             //iterate by iterator
>             Iterator<String> iter = lst.iterator() ;
>             while( iter.hasNext()) {
>             	System.out.println(iter.next() ) ;
>             }
>             
>             //modify
>             lst.set(0, "d") ;
>             System.out.println(lst.get(0)) ;
>             ```
>
>          2. 类似C++
>
>             1. 静态数组 int A[10] ;
>             2. 动态数组Vector<int> A ;
>
>       2. **LinkedList（链表，队列，栈）**
>
>          LinkedList不会顺序存储数据，而是在每个节点存到下一个节点的地址，可分为单向链表和双向链表。和ArrayList相比，LinkedList增加和删除效率高，查找和修改效率低。LinkedList实现了Dequeue接口，**可以作为队列使用**
>
>           ![img](https://www.runoob.com/wp-content/uploads/2020/06/linkedlist-2020-11-16.png) 
>
>          1. 使用方法
>
>             ```
>             LinkedList<String> lst = new LinkedList<String>() ;
>             lst.addLast("a");
>             lst.addFirst("b");
>                      
>             for(int i=0;i<lst.size();i++) {
>             	System.out.println(lst.get(i)) ;
>             }
>             for(String each:lst) {
>             	System.out.println(each) ;
>             }
>             Iterator<String> iter = lst.iterator() ;
>             while( iter.hasNext()) {
>             	System.out.println(iter.next() ) ;
>             }
>                      
>             lst.set(0, "c") ;
>             System.out.println(lst.get(0)) ;
>                      
>             //delete 
>             lst.removeFirst() ;
>             for(int i=0;i<lst.size();i++) {
>             	System.out.println(lst.get(i)) ;
>             }
>             ```
>
>    2. 集合Set
>
>       HashSet是基于HashMap实现的，是一个不允许有重复元素的集合，可以有null值且只有一个。HashSet是无序的。HashSet不是线程安全的，需要显示对线程进行同步。HashSet实现了Set接口
>
>        ![img](https://www.runoob.com/wp-content/uploads/2020/07/java-hashset-hierarchy.png) 
>
>       1. 使用方法
>
>          ```
>          HashSet<String> set = new HashSet<String>() ;
>          set.add("a") ;
>          set.add("b") ;
>                
>          for(String each: set) {
>          	System.out.println( each) ;
>          }
>          Iterator<String> iter=set.iterator() ;
>          while(iter.hasNext()) {
>          	System.out.println(iter.next()) ;
>          }
>                
>          set.remove("a") ;
>          for(String each: set) {
>          	System.out.println( each) ;
>          }
>          ```
>
>    3. 映射Map
>
>       HashMap是一个散列表，存储的内容是键值对的映射。HashMap实现了Map接口，根据建的HashCode存储数据，具有很快的访问速度，最多允许一条记录的建是null，不支持线程同步。HashMap是无序的
>
>        ![img](https://www.runoob.com/wp-content/uploads/2020/07/WV9wXLl.png) 
>
>       1. 使用方法
>
>          ```java
>          HashMap<Integer, String> map = new HashMap<Integer, String>() ;
>          map.put(1, "a") ;
>          map.put(2, "b") ;
>                   
>          for(Integer each: map.keySet() ) {
>          	System.out.printf("%d:%s\n", each, map.get(each) ) ;
>          }
>                   
>          map.put(1, "c") ;
>          for(Integer each: map.keySet() ) {
>          	System.out.printf("%d:%s\n", each, map.get(each) ) ;
>          }
>          ```
>
> ### Object oriented programming（面向对象编程，设计模式，软件工程)
>
> 1. object, an instance of a class
>
> 2. constructor and deconstructor
>
> 3. 类间关系：
>
>    依赖：use a，A类作为B类的方法的参数或者方法内的成员变量
>
>    聚合：has a，A类的成员变量包含B类
>
>    继承：is a，B类继承了A类的许多方法和变量
>
> 4. 内部类：内部类，匿名类，静态内部类
>
>    1. 内部类和匿名类都是差不多的内部类，只是匿名类不关心他的名字而做的。内部类和匿名类不能独立存在，必须依赖于外部类的实例存在的视厚才能获得建立这个类的实例。内部类的好处在于可以获取外部类的private变量，可以使用外部类的this关键字
>    2. 静态内部类是用static修饰的内部类，它实际上是一个独立的类，可以不依赖于外部类的实例而存在，他的好处在于可以比普通类相比可以获取外部类的private变量，静态内部类不能使用this关键字
>
> 5. 抽象类和接口
>
>    1. interface:  
>
>       	1. similar to inheritance, a template used to specify what a class must do, a class can inherit only one parent class, but a class can apply more than one interface 
>       	     	2. way: implements
>       	   	3. 接口不能被实例化，接口没有构造方法，接口的方法都是抽象方法，接口不能包含成员变量，除了static和final变量，接口不是被类继承了，而是被类实现了，接口支持多继承。一个接口只含static或final变量，以及函数。每个函数都是抽象方法，只是在实现的时候被隐藏成default
>
>    2. abstract:  abstract classes cannot be instantiated, but the can have a subclass; abstract method can be left not implemented. 抽象类和接口不能被实例化，但是可以被声明，然后指向实例化的子类。abstract修饰的方法不能和final合用，因为final目的方法不能在子类重写，而使用abstract的目的就是要重写，冲突；abstract修饰的方法不能和static合用，因为使用static目的是要实例化父类并且在所有实例化中共享一个方法或者变量的拷贝，而抽象类不能被实例化，所以用static修饰没有意义。
>
>    3. 抽象类和接口的区别
>
>           1. 抽象类中的方法可以包括非抽象方法，可以实现这个方法，而接口全都是抽象方法
>           2. 抽象类中的变量可以是各种类型，但是在接口只能是public static final 类型
>           3. 抽象类可以含有静态方法，但是接口全都是抽象方法
>
>       4. 一个类只能继承一个抽象类，但是可以实现多个接口
>
>    4. 重写接口中的方法时，需要注意下面规则
>
>           1. 类在实现接口的方法时，不能抛出强制异常，只能在接口中，或者继承接口的抽象类中抛出该强制异常
>           2. 雷灾重写方法时要保持方法名一致，并且应该保持相同或者相兼容的返回类型
>
>       3. 如果实现接口的类时抽象类，那么没有必要都实现接口方法
>
>    5. 实现接口注意规则
>
>           1. 一个类可以实现多个接口
>           2. 一个接口可以继承另外一个接口（extends）
>           3. 一个抽象类可以实现另外一个接口（implement）
>
>       4. 类的多继承不可以，但是接口的多继承可以（extends）
>
>    6. 标记接口，一个没有任何方法的接口
>
>       ```java
>       public interface MyInterface{
>       
>       }
>       ```
>
>        标记接口主要有两个目的
>           1. 建立一个公共的父接口
>
>       2. 把一个类编程接口类型，一个类继承了这个标记接口，就变成了一个接口类型。
>
>    7. 抽象类和接口的异同
>
>       相同点
>
>       1. 都不能被实例化
>       2. 继承了抽象类和实现了接口的类只有实现了所有的抽象方法才能被实例化
>
>       不同点：
>
>       1. 接口的方法只有极了default关键字才能在接口里面实现；抽象类可以实现方法
>       2. 一个类只能单继承一个抽象类，但是可以多实现多个接口
>       3. 接口强调功能实现；抽象类强调类的所属关系
>       4. 接口的字段默认时public static final并且必须在生命接口的时候赋值；抽象类的字段可以被修改，但是不能包含private、static、synchronized、native等关键字
>
> 6. encapsulation
>
>    	1. attributes of a class will be hidden or private, can be accessed by methods(getter or setter), attributes should be made private. 
>    	2. way: getter and setter
>
> 7. inheritance
>
>    1. Way: extends: the process where one class acquires the attributes and methods of another 
>
>    2. @Override: overriding,   sub class give its own implementation of a method already present in parent class
>
>    3. super: keyword refers to the superclass, similar to keyword this, but used in subclasses
>
>       	1. when override, use super to refer parent class's method, use this to refer this class
>       	    	
>       	4. access level
>
>       |  Modifier   | Class | Package | Subclass | World |
>       | :---------: | :---: | :-----: | :------: | :---: |
>       |   public    |   Y   |    Y    |    Y     |   Y   |
>       |  protected  |   Y   |    Y    |    N     |   N   |
>       | no modifier |   Y   |    Y    |    N     |   N   |
>       |   private   |   Y   |    N    |    N     |   N   |
>
>       If a class is public, classes within the package and out of the package can instantiate the class,  public method of class can be accessed everywhere, protected method can be accessed only by subclasses, private method can be accessed only by the class itself.
>
>       父类声明位public的变量，子类声明位public的变量子类也是public，父类位protected的变量，子类位public或protected，private的变量不能被子类继承
>
>       final方法，static方法，构造方法，可以继承但是不能重写，static方法可以重新声明
>
>       4. Java支持单继承，多重继承，不同类继承同一类，不支持多继承，也就是不支持
>
>          ```java
>          public class C extends A,B{
>                
>          }
>          ```
>
>      ```
>    
>      ```
>
> 8. polymorphism: the ability of an object to identify as more than one type
>
>    多态：一个父类的变量声明，在使用的时候可以具体指向子类的实例。
>
>    1. Way:
>
>       ```
>          public class Vehicle{} ;
>          public class Car extends Vehicle{} ;
>          public class Boat extends Vehicle{};
>          Vehicle vehicle ;
>          vehicle = new Car() ;
>          vehicle = new Boat() ;
>       ```
>
>       2. when using polymorphism, the subclass will degenerate to its parent class, that is to say, vehicle can only access the method it contains when it changes to Car object or Boat object 
>
>       3. 多态实现的必要条件
>
>          1. 重写
>
>          2. 继承
>
>          3. 父类指向子类对象（父类指针向下转型指向子类对象，父类指针向上转型回到子类对象）
>
>             ```
>             Vehicle vehicle = new Car() ;
>             vehicle.run() ;
>                         
>             Car car = (Car)vehicle ;
>             car.run() ;
>             ```
>
> ### Thread（操作系统）
>
> 1. JVM allows an application to have multiple threads running concurrently. Each thread executes part of your code with the main thread. Each thread has a priority, threads with high priority are executed in preference compared to that with low priority.
>
> 2. When JVM starts, it runs main thread. JVM stops when the exit method is called or all threads have died. Threads will not interrupt each other even one of them stops.
>
> 3. 检查线程状态
>
>    ```java
>    Thread.currentThread.isactive()
>    ```
>
> 4. *Daemon thread*, a low priority thread run in background to perform tasks like garbage collection.  JVM doesn't care whether daemon threads are running. JVM terminates itself when all *user threads* ( non-daemon threads ) are finished, then all the Daemon threads will be killed. Daemon thread shouldn't get access to files, cause it has to stop at any time.
>
> 5. Way: 2 ways to implement multiple threads
>
>    1. thread subclass
>
>       ```java
>       public class MyThread extends Thread{
>       	@Override
>           public void run(){
>                  
>           }
>       }
>          
>       public class Main{
>           public int main(String[] args){
>       		MyThread mythread = new MyThread() ;
>           }
>       }
>       ```
>
>    ```
>    	2. Runnable passed to Thread
>    
>       ```java
>       public class MyRunnable implements Runnable{
>       	@Override
>           public void run(){
>               
>           }
>       }
>       
>       public class Main{
>           public int main(String[] args){
>               MyRunable myrun = new MyRunnable() ;
>               Thread thread = new Thread(myrun) ;
>           }
>       }
>    ```
>
> 6. thread2 starts after thread1 is finished
>
>    ```
>    thread1.start() ;
>    thread1.join() ;
>    thread2.start() ;
>    ```
>
>    thread2 starts after thread1 executed some time
>
>       ```
>    thread1.start() ;
>    thread1.join(3000) ;
>    thread2.start()
>       ```
>
> 7. 线程状态
>
>    ![img](https://www.runoob.com/wp-content/uploads/2014/01/java-thread.jpg) 
>
>      	1. 新建状态：使用new关键字创建一个线程对象就处于新建状态
>      	2. 就绪状态：线程对象调用start()方法后，线程进入就绪状态，就绪状态的线程进入就绪队列中，等待JVM线程调度器调度
>      	3. 运行状态：就绪状态的线程被分配CPU资源，得到执行
>      	4. 阻塞状态：一个线程执行sleep、suspend等方法，失去占用的资源，线程从运行状态进入阻塞状态，在睡眠时间完成或者获得需要的资源后可以重新进入就绪队列，从而编程就绪状态。阻塞的状态有三种
>      	      	1. 等待阻塞：线程调用wait()方法进入等待阻塞
>      	           	2. 同步阻塞：线程获取synchronized同步锁失败（因为同步锁被其他线程占用）
>      	                	3. 其他阻塞：线程调用sleep或join方法发出I/O请求时，线程进入阻塞状态，当sleep结束或者join等待超时或终止的时候、或者I/O处理完毕，线程进入就绪状态
>      	          	5. 死亡状态：线程完成任务或者其他终止条件发生，线程切换到死亡状态
>
> 8. 线程优先级
>
>    每个线程都有一个优先级，有助于操作系统确定调度顺序，线程优先级是一个整数（1-10），具有较高优先级的线程会被优先分配处理资源。但是，线程优先级不能保证线程执行的顺序。
>
> 9. 创建太多线程可能导致程序效率变低，因为上下文切换的时间要考虑
>
> #### 多线程
>
> 1. 多任务可以有多进程实现，单进程多线程实现，多进程多线程实现进程是操作系统资源分配单位，线程是操作系统调度单位
>
>    **多进程优点**：稳定性比多线程高，因为一个进程崩溃不会导致其他进程崩溃，一个程序使用多进程不会因为一个进程崩溃而导致整个程序崩溃，而多线程一个线程崩溃会导致整个进程崩溃，从而导致整个程序崩溃。
>
>    **多线程缺点**：创建进程的开销比创建线程的开销大；进程间通信被线程间通信要慢，因为线程间通信只需要读写同一个变量
>
>    **Java支持多线程**，每个程序都由一个JVM进程管理，JVM使用一个主线程来执行main方法，在main方法内部，我们可以启动多个线程。同时，JVM还运行这垃圾回收机制的线程
>
> 2. 一个线程通过start方法启动一个新线程，start方法只能调用一次；可以通过thread.setPriority( 4 )设置调度优先级，但是不能保证这个程序被优先执行，执行顺序依赖操作系统调度
>
> 3. 进程的终止
>
>    ```java
>    public class Main{
>    	public static void main(String[] args) {
>    		   
>    		FirstThread firstThread = new FirstThread() ;
>    		firstThread.start();
>    		   
>    		try {
>    			Thread.sleep(2000);
>    		} catch (InterruptedException e) {
>    			// TODO Auto-generated catch block
>    			e.printStackTrace();
>    		}
>    		   
>    		firstThread.interrupt();
>    	}
>    }
>       
>    public class FirstThread extends Thread{
>    	@Override
>    	public void run() {
>    		SecondThread secondThread = new SecondThread() ; 
>    		secondThread.start();
>    		   
>    		try {
>    			secondThread.join() ;
>    		}catch(InterruptedException e) {
>    			System.out.println("Interrupted secondThread");
>    		}
>    		   
>    		secondThread.interrupt();
>    	}
>       
>    }
>       
>    public class SecondThread extends Thread {
>    	@Override
>    	public void run() {
>    		while(true) {
>    			if( ! isInterrupted() ) {
>    				System.out.println("In SecondThread") ;
>    			}
>    		}
>    	}
>    }
>       
>    ```
>
>    进程可以调用interrupt方法进行终止，在上面的实现中，我们可以看到三个进程，Main进程创建了FirstThread线程，FirstThread进程创建了SecondThread线程，当Main进程调用FirstThread的进程的interrupt方法之后，会让FirstThread进程的isInterrupted()方法的标志位变成true，同时，如果FirstThread的线程正在等待一个线程结束，那么会产生一个InterruptedException异常，在上面的代码里面我们捕获了这个异常进行处理，否则这个进程会直接终止，上面异常捕获之后，我们在下面的语句中终止了SecondThread线程。如果不终止这个线程，那么JVM不会终止，这个线程会一直运行。
>
>    4. 多线程同步访问共享变量的正确性
>
>     JVM的内存模型是，变量保存在主内存中，当线程访问变量时，他会先获取变量的一个副本，保存在自己的工作内存中，如果线程修改了一个变量的值，虚拟机会在某个时刻把修改的值写回到主内存。
>
>     为了保证共享变量的正确读写，必须保证一组指令以原子的方式执行，即某一个线程执行时，其他线程必须等待，因此必须加锁。
>
>     通过加锁，可以保证一组指令即便被中断，也不会有其他线程获取这个组的指令所获得的资源。只有线程将锁释放之后，其他线程才有机会获得这个资源。这种加锁解锁的区间，我们成为临界区，任何时刻，临界区最多只有一个线程执行。通过加锁和解锁保证一段代码的原子性。
>
>     1. synchronized对临界区代码加锁和解锁实现共享变量同步
>
>        注意加锁和解锁必须是同一个对象
>
>        synchronized在获取锁进入临界区的时候从主存中读取
>
>        添加锁的流程
>
>        1. 找到线程中修改共享变量的代码块
>        2. 选择一个共享实例作为锁
>        3. 通过synchronized(lockedObject){ ... }对代码块进行加锁和解锁
>
>        ```
>        class Variable{
>        	public static final Object lock = new Object() ;
>        	public static int count = 0 ;
>        }
>               
>        class IncVariable extends Thread{
>        	@Override
>        	public void run() {
>        		synchronized(Variable.lock ){
>        			Variable.count ++ ;
>        		}
>        	}
>        }
>               
>        class DecVariable extends Thread{
>        	@Override
>        	public void run() {
>        		synchronized(Variable.lock) {
>        			Variable.count -- ;
>        		}
>        	}
>        }
>               
>        public class Main{
>        	       
>        	public static void main(String[] args) {
>        		IncVariable inc = new IncVariable() ;
>        		DecVariable dec = new DecVariable() ;
>        		       
>        		inc.start();
>        		dec.start();
>        		       
>        		try {
>        			inc.join();
>        		} catch (InterruptedException e) {
>        			// TODO Auto-generated catch block
>        			e.printStackTrace();
>        		}
>        		try {
>        			dec.join();
>        		} catch (InterruptedException e) {
>        			// TODO Auto-generated catch block
>        			e.printStackTrace();
>        		}
>        		       
>        		System.out.println( Variable.count ) ;
>        	}
>        }
>               
>        ```
>
>        
>
>     2. volatile关键字修饰共享变量实现线程共享变量的同步
>    
>        每次访问变量时，线程总是获取主内存最新值
>    
>        每次修改变量后，线程立刻写到主内存，并且通过CPU总线嗅探机制告知其他线程主内存发生改变，需要重新从内存中读取
>    
>        **CPU总线嗅探机制**：为了实现缓存一致性，米格处理器（线程）监听总线上传播的数据（主内存）来检查自己缓存（本地缓存）中的数据是否过期，如果过期就重新读取主存。
>    
>        **指令重排序**： Volatile修饰的共享变量在保证一致性的同时，禁止了指令重排序优化（使用内存屏障实现），保证了被volatile修饰的共享变量在编译后执行的顺序于代码顺序相同。
>    
>     3. synchronized 鱼volatile的选择
>    
>        1. 选择synchronized的情况
>           - 运算结果以来了共享变量某一时刻的值
>           - 多个线程同时对共享变量进行修改（总线嗅探机制无法应对多个线程对共享变量同时修改）
>           - 需要对多个共享变量同时同步
>        2. 选择volatile的情况
>           - 尽量避免使用volatile
>           - 对共享变量的写入不依赖于某一时刻的值
>
>    4. 锁的类型
>
>     - 重量级锁、悲观锁
>    
>       Lock接口
>    
>     - 轻量级锁、自旋锁、乐观锁
>    
>       - 写时复制 copy on write, COW
>    
>         当线程执行时，会读取变量的拷贝到本地内存，在本地内存上实现对这个数据进行修改，在线程执行完成才把修改写道主内存
>    
>         实现COW的集合类：ConcurrentHashMap，ConcurrentLinkedQueue，CopyOnWriteArrayList，CopyOnWriteSet
>    
>       - 比较交换Compare and swap, CAS
>    
>         JVM地层实现使用CPU源于中的锁来保证原子性，没有使用操作系统的，所以时轻量级锁
>    
>         实现CAS的类：Atomic类
>    
>         ABA问题：初始值为A，被改为B后又改为A，对外不知道被修改过
>    
>       - 抽象队列同步器 Abstract Queued Synchronizer，AQS
>    
>     - 偏向锁
>
>       
>
>     
>
>     
>
>    6. 守护线程
>
>     用户编写的线程里面有一类为其他线程提供服务的线程，用户不关心他们什么时候结束，只要非守护线程都结束之后能结束就行，这类线程就可以设置成守护线程。守护线程的设置只需要在start()方法之前调用setDaemon方法设置就行。
>    
>     ```
>    Thread t = new MyThread() ;
>    t.setDaemon(true) ;
>    t.start() ;
>     ```
>
>     
>
> 
>
> ### 网络编程（计算机网络)
>
> 程序在多个设备上运行，通过网络链接起来
>
> 1. java.net包提供了两个钟网络协议支持
>
>    1. TCP，Transmission Control Protocol， 传输控制协议，是一种面向连接的、可靠的、基于字节流的传输层通信协议，位于IP层之上，应用层之下，保证了两个应用程序之间可靠通信
>    2. UDP，User Datagram Protocol，用户数据报协议，位于OSI模型的传输层，是一个无连接的协议提供了应用程序之间发送数据的数据报，UDP是不可靠的无连接的协议，允许数据错误丢失和重复的数据报。
>
> 2. 客户端网络编程和Web网络编程
>
>    1. Socket编程
>
>       1）服务器实例化一个ServerSocket对象，调用SeverSocked的accept()方法，一直等待，知道客户端连接到服务器上给定的端口
>
>       2）客户端实例化一个Socked对象，指定服务器名称和端口号请求连接，如果可以连接，则建立一个可以和客户端连接的Socket对象
>
>       3）服务端accept()方法返回服务器上一个新的Socket引用，连接到客户端socket。
>
>       4）连接创建以后，通过IO流进行通信，每一个socket都有一个输出流和一个输入流，客户端的输出流连接到服务端输入出流，客户端的输入流连接到服务端的输出流。
>
>       TCP是一个双向通信协议，因此数据可以在两个数据流中同时发送。
>
>       ```java
>       ///////////////////////////////////客户端/////////////////////////
>       String serverName = "localhost" ;
>       int port = 6066 ;
>             
>       try {
>       	//尝试创建套接字，连接服务器
>           System.out.println("connect to localhost:6066") ;
>           Socket client = new Socket(serverName, port) ;
>           System.out.println("remote address: "+ client.getRemoteSocketAddress() ) ;
>       	      
>           //连接到服务器后，创建传输通道进行数据传输，分为写通道
>           OutputStream outToServer = client.getOutputStream() ;
>           DataOutputStream out = new DataOutputStream(outToServer) ;
>       	//向写通道写入数据
>           out.writeUTF("Hello, this is client");
>             
>           //创建读通道
>           InputStream inFromServer = client.getInputStream();
>           DataInputStream in = new DataInputStream(inFromServer) ;
>       	//从都通道读数据
>           System.out.println("server response: "+ in.readUTF() ) ;
>             
>       	//关闭连接
>           client.close();
>             
>       }catch(IOException e ) {
>       	e.printStackTrace();
>       }
>       
>       
>       
>       
>       //////////////////////////////////////服务端/////////////////
>       //开一个服务器线程
>       public class GreetingServer extends Thread{
>       	private ServerSocket serverSocket ;
>       	    
>       	public GreetingServer(int port) throws IOException{
>       		serverSocket = new ServerSocket(port) ;
>       		serverSocket.setSoTimeout(60000);
>       	}
>       	    
>       	public void run() {
>       		while(true) {
>       			try {
>                       //创建ServerSocket并调用accept等待
>       				System.out.println("Waiting connection, port is "+serverSocket.getLocalPort() ) ;
>       				Socket server = serverSocket.accept() ;
>       				    
>                       //创建读数据通路，从客户端读数据
>       				System.out.println("Remote address: "+server.getRemoteSocketAddress() ) ;
>       				DataInputStream in = new DataInputStream(server.getInputStream() ) ;
>       				System.out.println(in.readUTF() ) ;
>       				    
>                       //创建写数据通路，向客户端写数据
>       				DataOutputStream out = new DataOutputStream(server.getOutputStream() ) ;
>       				out.writeUTF("This is server "+ server.getLocalSocketAddress() );
>       				    
>                       //关闭服务端
>       				server.close();
>       			}catch(SocketTimeoutException s) {
>       				s.printStackTrace();
>       				break ;
>       			}catch(IOException e) {
>       				e.printStackTrace();
>       				break ;
>       			}
>       		}
>       	}
>       	    
>       }
>       ```
>
>    2. Web 编程
>
>       1. WebServer(Tomcat/servlet/JSP)
>
>          ***Tomcat 是一个web容器***，负责管理servlet服务器小程序，把客户端请求映射到对应的servlet，将servlet的处理结果返回给客户请求
>
>          ***JSP引擎***，JSP引擎是一个服务器小程序，被web容器（例如Tomcat）管理。当客户端传递一个JSP文件请求的时候，web容器判断这个对JSP文件的请求，JSP引擎获取那个JSP文件，将他编译成servlet类返回给servlet引擎，servlet引擎执行这个servlet类获得一个静态html网页，将这个网页返回给客户端。（JSP创建的JSP文件对应的servlet类会保留，如果下一次继续访问这个JSP文件，那么就会修改这个servlet类，从而保证效率）
>
>          ![img](https://www.runoob.com/wp-content/uploads/2014/01/jsp-processing.jpg)
>
>          **JSP文件生命周期**： 一个JSP文件生命周期包括四个阶段
>
>          	1. 编译阶段： 一个JSP请求到来，JSP引擎判断这个JSP请求是否已经创建了他的servlet类，如果没有，则解析对应的JSP文件，将他转化成servlet类，并且编译这个servlet类。
>          	1. 初始化：由jspInit()负责
>          	1. 执行：根据一些列定义的方法执行
>          	1. 销毁：
>
>          **Servlet表单数据**
>
>          ```html
>          <!-- HelloWorldGet.html -->
>          <!-- 使用GET方法传递参数-->
>          <!-- 点击之后网址显示 http://localhost:8080/TomcatTest/HelloServlet?name=abc&url=abc -->
>          <!DOCTYPE html>
>          <html>
>          <head>
>          <meta charset="utf-8">
>          <title>菜鸟教程(runoob.com)</title>
>          </head>
>          <body>
>          <form action="HelloServlet" method="GET">
>          网址名：<input type="text" name="name">
>          <br />
>          网址：<input type="text" name="url" />
>          <input type="submit" value="提交" />
>          </form>
>          </body>
>          </html>
>                   
>          <!-- HelloWorldPost.html -->
>          <!-- 使用POST方法传递参数-->
>          <!-- 点击之后网址显示 http://localhost:8080/TomcatTest/HelloServlet -->
>          <!DOCTYPE html>
>          <html>
>          <head>
>          <meta charset="utf-8">
>          <title>菜鸟教程(runoob.com)</title>
>          </head>
>          <body>
>          <form action="HelloServlet" method="POST">
>          网址名：<input type="text" name="name">
>          <br />
>          网址：<input type="text" name="url" />
>          <input type="submit" value="提交" />
>          </form>
>          </body>
>          </html>
>          
>          
>          ```
>    
>          ```java
>          //服务器获取表单数据
>          String name =new String( request.getParameter("name") );
>          ```
>
>          
>
> ###  JDBC连接数据库（数据库设计）
>
> 关系型数据库：MySQL、Oracle、DB2、PostgreSQL
>
> 非关系型数据库：Redis、MongoDB、HBase
>
> **ORM**：object relational mapping，对象关系映射。JAVA连接数据库的标准接口是JDBC，但是使用JDBC访问数据库非常繁琐，因此产生了对JDBC进行封装的ORM框架，自动产生SQL语句访问数据库。ORM框架建立起关系数据库和对象（JAVA类）的映射，一种最简单的映射关系是每个类对应一张表，每个实例对应表的一个记录，类的每个属性对应表的每个字段。ORM框架有**MyBatis、Hibernate、SpringJDBC**等。Hibernate是一个标准的ORM框架，建立了实体类和数据库的完整的映射，基本不需要开发人员写SQL语句，内部自动生成SQL语句，这样也造成无法优化SQL语句。Mybatis是一个半自动框架，他只在实体类和SQL之间建立映射关系，并不自动生成SQL语句，因此开发人员可以自己写SQL语句，方便优化。
>
> 1. Mysql命令
>
>    ```
>    show databases ;
>    create database adatabase ;
>    use adatabase ;
>    
>    show tables ;
>    create table `atable`(
>    	`id` int not null auto_increment comment 'id' ,
>    	`name` char(20) not null comment 'name',
>    	primary key (`id`)
>    ) ;
>    
>    drop adatabase ;
>    drop atable ;
>    
>    insert into atable(name) values
>    	('a'),('b'),('c'),('d') ;
>    select * from atable ;
>    
>    delete from atable where id = 3 ;
>    select * from atable ;
>    
>    update atable set name='e' where id=3 ;
>    select * from atable ;
>    
>    select * from atable where id>=3 ;
>    ```
>
> 2. JDBC连接Mysql
>
> ```
> public class Main {
>    static final String JDBC_DRIVER = "com.mysql.cj.jdbc.Driver" ;
>    static final String DB_URL = "jdbc:mysql://localhost:3306/adatabase?useSSL=false&allowPublicKeyRetrieval=true&serverTimezone=UTC";
> 
>    static final String USER = "root" ;
>    static final String PASS = "cheng" ;
> 
>    public static void main(String[] args) {
>    	Connection conn = null ;
>    	Statement stmt = null ;
>    	
>    	try {
>    		//注册JDBC驱动
>    		Class.forName(JDBC_DRIVER) ;
>    		
>    		//连接数据库
>    		conn = DriverManager.getConnection(DB_URL, USER, PASS) ;
>    		
>    		//执行命令
>    		stmt = conn.createStatement() ;
>    		
>    		String sql ;
>    		sql = "select * from atable" ;
>    		ResultSet rs = stmt.executeQuery(sql) ;
>    		
>    		while(rs.next() ) {
>    			int id = rs.getInt("id") ;
>    			String name = rs.getString("name") ;
>    			
>    			System.out.printf("%d %s\n",id, name ) ;
>    		}
>    		
>    		rs.close();
>    		stmt.close();
>    		conn.close();
>    	}catch(SQLException se) {
>    		se.printStackTrace();
>    	}catch(Exception e) {
>    		e.printStackTrace();
>    	}finally {
>    		try {
>    			if(stmt != null) {
>    				stmt.close();
>    			}
>    		}catch(SQLException se ) {
>    			se.printStackTrace();
>    		}
>    	}
>    }
> }
> 
> ```
>
> 
>
> ### Java Optional类型
>
> Optional类是一个包装器类，是一个泛型类，它可以对一个对象进行包装，检查一个类是否为空并且抛出空异常，如果为空，可以返回默认值。Optional类是对长变量方法的一种补充，比如下面的方法
>
> ```
> A.get().get().get().get().print()
> ```
>
> 上面的代码如果在某个部分出现了空异常，那就是一个NuLLPointerException，这种时候我们很难确定是哪个类的get出现了这个异常。要防止这个异常，我们必须编写检查代码
>
> ```java
> if( A != Null){
> 	B b = A.get() ;
> 	if( b!= Null ){
> 		C c = b.get() ;
> 		...
> 	}
> }
> ```
>
> 1. Optional类的创建
>
>    ```java
>    Optional<T> a = Optional.of( t ) //这个t如果是一个Null，那么会返回NullPointerException
>    Optional<T> a = Optional.ofNullable(t) //这个t允许是Null
>    Optional<T> a = OPtional.empty() //返回一个包装为空的Optial类型
>    ```
>
> 2. Optinal类的内容获取
>
>    ```java
>    T t = a.orElse(new T()) //返回Optional类包装器内容，如果为Null那么久返回默认值
>    ```
>
> 3. Optional类的处理
>
>    ```java
>    a.isPresent(); //如果Optional类型为空，返回false，否则返回true
>    ```
>
>    
>
> ### Java对象序列化
>
> Java对象序列化是Java对象持久化的一种方法，通常一般使用数据库等持久化技术，对象序列化技术没人关注。Java实现了java.io.Serializable接口的类都是可序列化类。对象序列化可以把一个对象表示为一个字节序列，这个字节序列包含对象的类型、对象的数据以及数据的类型。反序列化需要指定数据的类型。对象序列化是JVM独立的，也就是说一个平台上序列化的对象可以在另外一个平台上反序列化得到同样的对象。
>
> 如果对象的成员变量不想被序列化，那么就应该定义成瞬态（transient）或者静态（static），序列化的方法不能使用非序列化的成员变量，瞬态成员变量在反序列化之后会变成默认值。
>
> 序列化对象保存在ser文件，类似Python字典的持久化一样
>
> ```java
> Series series = new Series(2,3) ;
> System.out.println(series.max()) ;
> 
> 
> //对象序列化
> try {
> 	FileOutputStream fileOut = new FileOutputStream("C:\\Users\\cheng\\Desktop\\trash\\Series.ser") ;
> 	ObjectOutputStream out = new ObjectOutputStream(fileOut) ;
> 	out.writeObject(series);
> 	out.close();
> 	fileOut.close() ;
> 	System.out.println("Seialized data is saved") ;
> }catch(IOException e) {
> 	e.printStackTrace();
> }
> 
> 
> //对象反序列化
> Series series1 = null ;
> try {
> 	FileInputStream fileIn = new FileInputStream("C:\\\\Users\\\\cheng\\\\Desktop\\\\trash\\\\Series.ser") ;
> 	ObjectInputStream in = new ObjectInputStream(fileIn) ;
> 	series1 = (Series)in.readObject() ;
> 	in.close();
> 	fileIn.close();
> }catch(IOException i) {
> 	i.printStackTrace();
> return ;
> }catch(ClassNotFoundException c ){
> 	c.printStackTrace();
> return ;
> }
> System.out.println( series1.max() ) ;
> ```
>
> 
>
> ### Java泛型
>
> 1. 泛型类
>
>    ```java
>    public class A<T,U>{
>    
>    }
>    ```
>
> 2. 泛型方法
>
>    ```java
>    public static<T> T A(T t ){
>    
>    }
>    ```
>
> 3. 范型变量的限定，如果泛型带有方法，需要用extends继承对应的类，下面是限定泛型的方法
>
> ```java
> //泛型方法-带泛型边界，E是一个可比较对象
> public static <E extends Comparable<E>> E max(E a, E b ) {
>     E e = a ;
>     if( b.compareTo(e)> 0 ) {
>     	e = b ;
>     }
>     return e ;
> }
> 
> //泛型上界-E是Integer或者他的子类
> public static <E extends Integer> E max(E a , E b ) {
>     E e = a ;
>     if( b.compareTo(e)>0 ) {
>         e = b ;
>     }
>     return e ;
> }
> 
> //泛型类-类似C++类模板
> public class Main <T> {
> 	T a ;
> 	public void setter(T a) {
> 		this.a = a ;
> 	}
> 	public T getter() {
> 		return this.a ;
> 	}
> 
> 	public static void main(String[] args) {
> 		Main<Integer> main = new Main<Integer>() ;
> 		main.setter(1);
> 		Integer num = main.getter() ;
> 		
> 		System.out.println(num) ;
> 	}
> }
> 
> ```
>
> 4. 泛型在JVM中的处理
>
>    1. 泛型擦除
>
>       JVM没有泛型类，所以泛型会被编译器编程限定的对象，如果没有限定泛型类型，那么泛型类型会被指定位Object
>
>       ```
>       //泛型类
>       public class A<T,U>{
>       	private T t ;
>       	private U u ;
>       }
>       
>       //编译器编译
>       public class A{
>       	private Object t ;
>       	private Object u ;
>       }
>       
>       //泛型方法
>       public static<T> T A(T t){
>       	return t ;
>       }
>       
>       //编译器编译
>       Object t; //内部类
>       public Object A(Object t){
>       	return t ;
>       }
>       ```
>
>    2. 泛型的限制
>
>       1. 泛型不能被实例化，但是可以通过函数式接口Supplier<T> 表示一个无参数且返回类型为T的方法
>
>          ```java
>          public static<T> A<T> constructA( Supplier<T> supplier){
>          	return new A<>(supplier.get() ) ;
>          }
>          ```
>
>       2. 不能构造泛型数组
>
> ### Java反射机制
>
>    一种动态获取类的信息以及动态调用对象的方法的功能。
>
>    在程序运行过程中，获取类或者对象的属性和方法信息。实际就是查看源代码里面对类的定义获得的信息。
>
>    ```
>    Car car = new Car() ;
>    Class cls = car.getClass() ;
> 
>    Method[] declaredMethods = cls.getDeclaredMethods() ;
>    for( Method method: declaredMethods) {
>    	System.out.println(method.getName() ) ;
>    }
>    ```
>
>    
>
> ### Java注解
>
> 注解的价值体现在Java反射的过程中，具体实现包括：
>
> - 文件自动生成，如bean等
> - 测试、日志、事务等代码的自动生成
> - 框架编写（比如使用JUnit4工具调用所有被特定注解@Test标注的方法）
>
> Java的一些标准注解
>
> | 注解名           | 作用位置                               | 作用                            |
> | :--------------- | -------------------------------------- | ------------------------------- |
> | Deprecated       | 全部                                   | 将被标注的东西标记为不支持的    |
> | SuppressWarnings | 除了PACKAGE与ANNOTATION_TYPE的其他位置 | 将被标注的位置的Warning信息屏蔽 |
> | Override         | Method                                 | 检查方法是否重写了              |
> | Documented       | ANNOTATION_TYPE                        | 说明这个注解被包含在javdoc中    |
> | Resource         | TYPE，FIELD                            | 标注会使用到的资源              |
> | Target           | ANNOTATION_TYPE                        | 说明注解的位置                  |
> | Retention        | ANNOTATION_TYPE                        | 说明注解的声明周期              |
> | Inherited        | ANNOTATION_TYPE                        | 声明注解可以被子类继承          |
>
> 
>
> 注解是一个无参数方法类，主要用来对类、方法、变量等进行约束，比如使用注解并且配合反射机制动态检查参数的范围。
>
> 1. 注解的分类
>
>    注解根据存在时期和使用对象分为三类，一种是编译器使用的注解，比如@Override会让编译器强制检查方法是否被重写，@SuppressWarnings会让编译器忽略代码产生的警告；第二种注解是工具处理字节码文件使用的注解，一般是底层库使用的注解，一般会改变字节码文件，比如对字节码文件进行部分优化；第三种是运行时使用的注解，这种注解可以配合反射机制动态控制类、方法、参数的行为，有些时JVM自动识别使用的，有些可以自己编写。第一种注解被编译器使用之后丢弃，不会出现在字节码中；第二种注解会被JVM加载执行当时不会出现在程序执行的内存中；第三种注解会出现在程序执行的内存里面。
>
> 2. 注解的定义
>
>    定义注解实际上时编写一个无参数方法的类，有一些注解时JVM使用的元注解，可以用来修饰注解。
>
>    1. @Target，用来修饰注解的使用位置，包括类、方法、构造方法、字段、方法参数五个类型
>    2. @Retention，用来定义注解的生命周期，包括编译器、class文件期和运行时期
>    3. @Repeatable，用来定义注解可以重复
>    4. @Inherited，定义注解是否可以被子类继承，这个注解只能用来修饰使用了@Target(Element.Type.TYPE)的注解
>
>    下面时一个注解的定义的模板，这里定义了一个在运行期的只能用来修饰类或接口、方法的注解Report
>
>    ```java
>    @Target([ElementType.TYPE, ElementType.METHOD])
>    @Retention(RententionPolicy.RUNTIME)
>    public @interface Report{
>        int type() default 0;
>        String level() default "info";
>        String value() default "";
>        int min() default 0;
>        int max() default 100;
>    }
>    ```
>
> 3. 注解的使用
>
>    运行期的注解不会被编译器有什么影响，必须利用反射机制编写获取这些注解的方法来使用这些注解，下面的方法获取注解来检查字段变量的范围。
>
>    ```java
>    public class Person{
>        @Range(max = 10)
>        public String city;
>    }
>       
>    void check(Person person) throws IllegalArgumentException, ReflectiveOperationException{
>        for(Field field: person.getClass().getFIelds() ){
>            Range range = field.getAnnotation(Range.class) ;
>            if (range != null){
>                Object value = field.get(person) ;
>                if( value instanceof String){
>                    String s = (String) value ;
>                    if( s.length()< range.min() || s.length()> range.max() ){
>                        throw new IllegalArgumentException("INvalid field: "+ field.getName() ) ;
>                    }
>                }
>            }
>        }
>    }
>    ```
>
>    
>
>    
>
> ### JAVA8 流编程
>
> 
>
> ### Exceptions(异常处理)
>
> ```
> 1. an event occurs during the execution of a program that disrupts the normal flow of the instructions
> 
> 2. Way:
> ```
>
> ```java
>  try{
>  
>  }
>  catch(Exception e){
>  	System.out.println("an error occur in ...") ;
>  }
>  finally{
>  
>  }
> ```
>
> 1. Java 异常的层次结构
>
>    ![](https://github.com/AlbertoWang/java-noob/raw/master/Java%E5%9F%BA%E7%A1%80.assets/exception_structure.png)
>
>    1. Error系列：系统内部错误，资源耗尽等
>    2. RuntimeException系列：错误的强制类型转换、数组越界(ArayIndexOutOfBoundException)、访问null错误（NullPointerException)
>    3. 非RuntimeException系列：文件读写错误（IOException)，类不存在
>
> ## 框架
>
> ### Spring
>
> 1. spring, spring mvc, spring boot, spring cloud
>
>    spring 是一个实现控制反转(IoC)和面向切片编程(AOP)的框架；spring mvc是基于spring的mvc框架，和struts2同性质；spring boot是基于spring mvc，集成了tomcat，支持REST，继承了maven/gradle简化了jar文件的下载和配置；spring cloud是基于spring boot， spring boot 是集鉴权、路由等功能于一体的单体应用，spring cloud是一个专注于一个功能的spring boot应用组成的分布式应用。
>
> ## JVM相关
>
> 1. 对象的大小包括markword（包括锁、GC分代年龄、hashcode等，8字节）、class pointer（说明指向哪个对象）、instance data（字段的大小）、pading（将整个对象大小补齐到8的整数倍）
>
> 2. Java代码执行过程：.java编译成.class，通过ClassLoader加载到JVM。类保存在方法去Method Area，类的实例保存在虚拟机堆JVM Heap，调用方法的过程会使用到虚拟机栈JVM Stacks、程序计数器Program Counter Register和本地方法区Native Method Area
>
> 3. JMM
>
>    1. 分区
>
>       线程私有：程序计数器，虚拟机栈（描述Java方法执行过程，包括局部变量、操作栈、返回地址等），本地方法去（描述Native方法过程）
>
>       线程共享：方法区（存储类的信息、常量、静态变量、常量池等），虚拟机堆（创建的对象都在这里，GC主要区域）
>
>    2. 引用类型：
>
>       - 强引用：常用引用方式，不会被GC
>       - 软引用：内存不足会被GC
>       - 弱引用：优先被GC
>       - 虚引用：跟踪对象GC状态
>
> ### JVM类加载
>
> #### 类加载流程
>
> 1. 加载：JVM读取.class文件到方法区，在堆中创建Class对象
> 2. 验证：验证.class文件符合JVM要求，满足安全
> 3. 准备：在方法区为类变量分配内存空间，设置初始值
> 4. 解析：将常量池堆符号引用替换为直接引用
> 5. 初始化：执行构造函数的<client>方法，限制性父类的初始化才能执行子类的初始化
>
> #### 双亲委派机制
>
> 用来保障类的安全性和唯一性。类加载时，先不加载此类，而是把类加载请求向上委派给父类完成；若父类无法加载该类，才会向下委派子类加载器来加载。
>
> 1. UserClassLoader挂载到ApplicationClassLoader
> 2. 委托给ExtensionClassLoader
> 3. 委托给BootstrapClassLoader
> 4. BootStrapClassLoader查找并加载.class文件，若不存在则交给ExtensionClassLoader
> 5. ExtensionClassLoader查找并加载.class文件，若不存在则交给ApplicationClassLoader
> 6. ApplicationClassLoader查找并加载.class文件，若不存在则交给UserClassLoader
> 7. UserClassLoader查找并加载.class文件，若不存在则抛出ClassNotFound
>
> ## Packages 
>
> 1. ***GUI: javax.swing.JOPtionPane***
>
>    ​	1. Python GUI: tkinter
>
> 2. Scanner: java.util.Scanner       
>
>    1. C++: cin, 
>    2. Python: input, with open('') as file:
>
> 3. Math: Math
>
>    1. C++: math
>    2. Python: math
>
> 4. Random: java.util.Random
>
>    1. C++: random
>    2. Python: random
>
> 5. Check file: java.io.File
>
> 6. Read file: java.io.FileReader
>
>    1. C++: ifstream cin("a.txt"); cin.close() ;
>    2. Python: with open('a.txt', 'r') as f: f.readlines()
>
> 7. Write into file: java.io.FileWriter
>
>    1. C++: ofstream cout("a.txt"); cout.close() ;
>    2. Python: with open('a.txt', 'w') as f: f.writeline()
>
> 8. Exceptions: java.io.IOExcepttion
>
> ## Notes
>
> 1. friend method: 
>
>    ```java
>    Car car1 = new Car() ; 
>    Car car2 = new Car() ;
>    car1=car2 ;
>    ```
>
>    
>
>    this variable car is a reference
>
>    car1 store the same reference of car2 
>
>    if you want to copy the variables from car2 into car1, you have to write a friend function to do the operation.
>
>    1. C++: friend method
>    2. Python: deepcopy
>
> 2. compile and run Java with command prompt 
>
>    ```shell
>    javac HelloWorld.java \\to compile
>    java HelloWorld \\to run
>    ```
>
> 3. export executable Jar file
>
> 4. 静态方法和变量不属于实例，静态方法内部不能使用this关键字。静态方法和静态变量常常用于辅助方法。接口不能定义实例变量，但是可以定义静态final变量，接口定义的变量都是public static final修饰的
>
>    
>
> ## 考试题目
>
> 1. Java中+的优先级大于==优先级，所以
>
>    ```java
>    System.out.println("a "+ "a" == "a" ) ;
>    ```
>
>    等价于
>
>    ```java
>    System.out.println("a a" == "a")
>    ```
>
>    这个输出是false
>
> 2. Java中if(expression)的expression是比较表达式，必须返回true或者false，不能是数字，所以
>
>    ```
>    if(x=1){
>    
>    }
>    ```
>
>    会产生编译错误。这跟C++不一样，Java的数字不能转成boolean类型。
>
> 3. Java 的char类型
>
>    ```java
>    char c = 65;
>    System.out.println("c = "+c);
>    ```
>
>    因为c变量位char类型，65对应的ASCII码是A
>
> 4. Java实例变量不需要显示初始化（不初始化那么在实例化对象的时候会使用默认值初始化），局部变量必须显示初始化（声明的时候可以不初始化，但是一定要在一个地方初始化）
>
>    **Java对象的创建：** 创建对象分为两个阶段，首先是声明阶段，声明阶段会在线程的栈区创建对象的引用（线程栈区保存基本类型和对象的引用），此时这个引用会被赋值为默认的null值。其次是实例化阶段，实例化阶段会在堆区创建对象的实例化，对于对象的实例变量，首先会赋值一个默认值，如果这个变量有显示赋值，那么之后用显示赋值覆盖默认值，之后调用对象的构造函数，如果构造函数对这个实例变量有赋值，那么就用这个赋值覆盖之前的默认值或者显示赋值。在堆区创建好对象的实例化之后，这个实例化的地址会被赋值给栈区的引用。如果一个对象的实例化失去了线程栈区对他的引用，那么这个对象可能之后会被Java垃圾回收机制回收。**基本数据类型和对象引用在栈上分配，实例化对象和数组在堆上分配。**
>
>    **空引用可用于访问静态变量或方法**：Java的静态成员和方法是依赖于类的，而不是实例的，所以可以用空引用访问静态成员和方法，也就是下面的代码不会报错。但是这样的方法不是调用静态变量和方法的常用方法。
>
>    ```java
>    public class Student{
>    	public static int a = 0 ;
>    	public static void main(String[] args){
>    		Student student = null ;
>               
>    		//空引用访问静态变量不会报错
>    		Sytem.out.println(student.a) ;
>    	}
>    }
>    ```
>
>    
>
> 5. Math.round()默认是四舍五入到整数
>
> 6. Java不支持goto关键字
>
> 7. 异常类的基类是Java.Lang.throwable
>
> 8. 面向对象编程意味着（根据分析问题时发现的对象设计应用程序）
>
> 9. 一个对象可能是任何事物，面向对象的思想是万物皆为对象，也就是说任何事物都能封装成对象
>
> 10. is 开头的命名方式一般用于布尔值判断 ，则isSwimmer用于boolean类型
>
> 11. Java源文件名命名规则：源文件名必须以.java结尾，如果源文件没有public类，则源文件名可以是任意的，但是如果有public类，那么源文件名必须和public类的类名相同。一个源文件有且只能有一个public类，但是可以有多个非public类。
>
> 12. Java严格数据类型，相互转换要经过强制类型转换，否则编译错误。下面会编译错误
>
>     ```java
>     int a = 6.6 ;
>     ```
>
> 13. 引用传递会创建一个新的引用变量，只是他们数值指向相同的地址，但是分别对他们数值修改不会相互影响
>
>     ```java
>     Student s1 = new Student() ;
>     Student s2 = s1 ;
>     s2 = new Student() ;
>     //此时对s2的修改并不会影响s1指向第一个创建的对象，在参数传递的时候依然一样不会影响
>     ```
>
> 14. Java的static方法只能调用static方法，Java静态方法不能调用非静态方法
>
> 15. Java不允许参数设置默认值，下面的代码报错
>
>     ```java
>     public int func(int x=0){
>     	return x ;
>     }
>     ```
>
> 16. Java 的hashcode()
>
>     如果是String对象，hashcode根据字符串内容获得，具有相同字符串的String对象hashcode相等
>
>     如果是Integer对象，hashcode就是Integer数值
>
>     如果是其他对象，hashcode是根据对象的JVM分配的内存地址获得的，如果两个引用变量不是指向同一个实例，hashcode不一样，当然，hashcode可以强行改变。
>
> 17. Java引用数据类型，比较数值使用.equals()，比较地址使用==
>
> 18. Java的String对象调用toUpperCase()的函数不会改变本地成员变量，只会返回成员变量变化的结果
>
> # Effective Java
>
> 1. 私有constructer：防止类被实例化
>
>    ```java
>    public class A{
>    	private A(){
>    		throw new AssertionError() ;
>    	}
>    }
>    ```
>
> 2. 依赖注入：类A使用另一个类B（这个类被称为依赖），类A需要在自己成员变量声明这个依赖。
>
>    依赖注入的三种方式
>
>    - Constructor注入
>    - setter注入
>    - 接口注入
>
>    ```java
>    public class A{
>    	private final B b ;
>    
>        //constructor注入
>    	pubclic A(B b1){
>    		this.b = b1 ;
>    	}
>        //setter注入
>        public void setter(B b1){
>            this.b = b1 ;
>        }
>    }
>    ```
>
> 3. 单例模式Singleton：仅会被构造一次的对象
>
>    有些类希望在整个程序过程中只有一个实例。单例模式使用的场景
>
>    - 有些类的实例化消耗资源多，但又需要频繁用到，比如一些工具类（打印机类）
>    - 频繁访问数据库或文件的对象
>
>    构建方法：这种构建方法优点是在类的加载过程就创建了类的实例，之后使用的时候只需要使用getInstance获取这个实例就可以了，避免了线程安全问题。缺点是不是Lazy Load，可能这个运行期都用不到这个实例，造成资源浪费。
>
>    ```java
>    public class Singleton{
>    	private static final Singleton INSTANCE = new Singleton() ;
>    	
>    	public Singleton(){
>    	
>    	}
>    	
>    	public static Singleton getInstance(){
>    		return INSTANCE ;
>    	}
>    }
>    ```
>
> 4. 构造者模式Builder：多参数时使用Builder进行参数传递，参数少优势不明显
>
> 5. 静态工厂模式static factory：一个对象创建他很消耗资源，不应该频繁创建和销毁，因此

### Java执行过程

1. 将Java代码编译成class字节码

   字节码格式：

   类描述信息

   access_flag：public、interface、abstract

   this.class引用在常量池中，表示类名；super.class引用在常量池中，表示继承类名

   Interface表 表示实现的接口

   常量池，保存字面值和符号引用

   字段表，保存静态变量和实例变量

   方法表，保存方法代码（包括参数，返回值；access_flag；JVM指令集代码；方法相对原代码的偏移；本地变量表）

2. JVM启动一个Main线程，加载包含Main方法的类

   将二进制字节流加载到方法区，并且创建一个Java.Lang.Class对象，作为外部访问方法去类类型的接口

   数组类型不会加载，JVM直接给他分配内存，但是数组中元素的类型需要被加载。

   **不同的类会用不同的加载Loader来加载，主要有三种**

   1. Bootstrap Loader，负责加载Java Liberary的类，在<JAVA_HOME>\lib目录下的类
   2. Extension Loader，负责加载扩充的类，在<JAVA_HOME>\lib\ext目录下的类
   3. Application Loader，负责加载用户自己写的类，在-classpath目录下的类

   **加载的双亲委派机制**

   除Bootstrap Loader以外，任何一个加载类都必须属于一个父类，这种属于是一种组合关系

   加载的时候，子类首先调用父类来加载对应的类，如果父类加载不了（加载器在他的加载目录下找不到这个类），再用子类来加载

   **双亲委派机制的好处**

   保证加载的优先顺序，这样同样一个名字的类，优先加载父类加载器可以加载的类

3. JVM的Main线程验证

   检查类信息是否符合JVM规范，保证JVM运行安全

4. JVM的Main线程准备

   准备阶段为类的静态变量分配内存并且初始化，这里的静态变量保存在方法区，实际上可能是在方法区的堆上（方法去时JVM的概念，而永久代和元空间是实现方法区的两种方式。永久代有大小限制，可以使用-Xms PermMaxSize 等设置大小，而元空间是建立在堆上，理论上的限制是内存大小，使用元空间的好处是减少产生方法区内存溢出）

5. JVM的Main线程解析

   解析阶段将符号引用替换成直接引用，直接引用是指向目标的指针、偏移量或者标记目标的句柄。直接引用是跟内存相关的，意味着在内存中分配内存存储。解析具体分为类符号应用解析、字段符号引用解析、方法符号引用解析、接口符号引用解析。如果解析成功，成功返回直接引用，那么还要进行权限检查，查看类A是否对类C的直接应用具有访问控制权限。

6. JVM的Main线程初始化

   这个初始化是对类静态变量的初始化，这个初始化时JVM按序收集父类的对静态变量的赋值语句产生clinit方法和按序收集子类的静态变量的赋值语句产生clinit方法完成的，首先执行父类的clinit方法，其次执行子类的clinit方法。这个初始化不是new实例时对实例变量的初始化，而是类加载过程中的初始化静态变量

7. JVM的Main线程加载到主类之后，建立主类Main方法的Frame，设置本地变量表、程序计数器、常量池引用。开始执行Main方法。

   ```java
   // 执行循环过程
   int i ;
   for( i=0;i<100;i++){
   
   }
   被编译成
   localVariable this(reference,1 slot),i(int 1 slot)
   code :
   	0. iconst_0 ; //将0压入操作栈
   	1. istore_1 ; //将操作栈中的数送回本地变量表，两个指令给i赋值 i=0
   	2. goto #7 ;
   	
   	3. 	iload_1 ;
   	4.	iconst_1 ;
   	5.	iadd ;
   	6.	istore_1 ; //上面四个指令执行i++
   		
   	7.	iload_1 ; //将1号int本地变量数值压入操作栈
   	8.	bipush 100; //100 压入操作栈
   	9.	ifcmplt #3 ;// 上面三个指令执行判断i<100
   	
   		
   //执行类初始化过程
   A a = new A() ;
   被编译成
   new #19 ; //创建对象A，过程是首先检查类A是否被加载，如果没有加载，就把A类交给对应的ApplicationLoader进行加载。加载过程
   		  //是加载（将二进制字节码加载到方法区，并创建一个java.lang.class对象的实例作为在方法区获得这个类）；验证（检查
   		  //类信息是否负荷JVM规范，保证JVM安全；准备（给静态字段创建内存并初始化为默认值，如果是static final直接初始化为
   		  //字面值）；解析（替换常量池的符号引用为直接引用，也就是分配内存，把内存引用赋值给对应的常量，解析完成之后会进行权		  //限检查，查看对应的字段、方法等是否可以被调用）；初始化（这里的初始化时静态字段的初始化，初始化方法是JVM获取对静		   //态字段的赋值语句建立的clinit方法，父类也有这个方法，首先初始化父类的静态字段，然后初始化子类的静态变量
   		  
   		  //上面的类加载完成之后，会在堆上分配内存，建立A的实例，这个堆上的实例保存有三个部分，A的对象头-包括A的类类型的
   		  //引用，实例的锁等；A的实例变量；A的对齐补充。这样在堆上我们建立了A的实例变量的内存。之后这个对象的引用会被返回给
   		  //a所在的方法的frame的操作栈上
   dup  ;    //将栈帧的操作栈的第一个元素duplicate
   invocateSpecial #20; //调用A方法的初始化方法进行初始化，注意这个初始化方法会调用父类的（Object类）的初始化方法进行初始化
   					 
   
   //执行函数调用
   public class A{
   	Integer a = 10 ;
   	
   	public void set(int a){
   		this.a = a ;
   	}
   	public static void main(String[] args){
   		A a = new A() ;
   		
   		a.set(10) ;
   	}
   }
   被编译成
   public void set(int a)
   describer: (int)V
   local variable: this(指向对象在堆中的引用);int a ;
   code :
   	aload_0 ;
   	iload_1 ; //加载1号int本地变量
   	invokeStatic #1 ; //调用Integer.valueOf()将int数字转换成Integer类型并且返回Integer在Integer常量池的引用
   	
   	putfield #2 ; //将在堆上的A的实例变量的a字段赋值为Integer的引用
   	return 
   public static void main(String[] args)
   describer: ([Ljava.lang.String)V
   local variable : [Ljava.lang.String ; A a ;
   code :
   	new #3 ;  //new A，创建A的实例
   	dup ; 
   	invokeSpecial #4; //执行A的初始化函数
   	astore_1 ; 保存A的实例引用到一号本地变量
   	
   	aload_1 ;
   	bipush 10 ;
   	invokeVirtual #5 ;// 调用set方法
   	
   访问静态变量，静态变量在方法区分配内存，在准备阶段就被分配内存并且初始化
   getstatic #12 ;//读取静态变量的引用
   invokevirtual #14;//调用Integer.inValue()将这个引用获取int
   
   iconst_1 ;
   invokevirtual #14; //调用Integer.valueOf()将int转换成Integer并压入引用
   putstatic #12 ;// 写入静态变量
                     
   访问实例变量，实例变量在堆上分配内存，要使用new关键字创建对象的时候才会在堆上分配内存，之后调用初始化函数初始化。
   aload_0 ;
   getfiled #12 ;
                     
   aload_0 ;
   iconst_1 ;
   putfield #12 ;
   ```

### JVM内存结构 Java内存模型

#### JVM 内存结构

1. 方法区：代码，常量池（字面值，符号引用）
2. 堆：创建对象分配内存（对象头、实例变量、对齐）、数组
3. 程序计数器PC：线程私有，指向执行代码的位置
4. 虚拟机栈：线程私有，为Java方法执行服务。一个方法建立一个Frame，一个Frame包括操作栈（用于数字运算、程序调用传递参数、赋值传递参数）、本地变量表（Compile阶段产生）、运行时常量池的引用（用于动态生成对常量池中的引用）
5. 本地方法栈：线程私有，用于执行本地方法（C++等）编写的方法

#### Java内存模型

多个线程共享主存，每个线程私有工作内存，线程主要操作的是自己的工作内存，完成之后才送到主存，线程之间不能获得内存，线程操作主存依赖一组原子操作，比如read、write

这里的内存和JVM内存结构完全不是一回事，非要对应，也是主存代表堆上的实例变量，而线程工作内存代表虚拟机栈。

Java内存模型划分主存和工作内存的原因是可以利用高速缓存加速线程的计算，而减少访问内存的操作。

在Java中，主存表示方法区的静态变量和堆区的实例变量，工作内存表示线程的虚拟机栈，主存和工作内存使用getstatic，putstatic读写方法区的静态变量，使用getfield和putfield读写实例变量，读到的实例变量数据会被放到当前栈帧的操作栈上，可以通过本地变量栈和栈帧修改数值之后putfield或者putstatic到实例变量或者静态变量。

### Java数据类型

 

|               | byte(1byte) | short(2bytes)              | int(4bytes)   | long(8bytes)   |      |
| ------------- | ----------- | -------------------------- | ------------- | -------------- | ---- |
|               |             | char(2bytes) unicode16字符 |               |                |      |
| boolean(1bit) |             |                            | float(4bytes) | double(8bytes) |      |
|               |             |                            |               |                |      |

#### 引用类型

[引用类型](https://juejin.cn/post/6884507434036133901)

引用类型保存对象在内存的首地址

**四种引用类型**

根据跟GC的关系划分4个引用类型

1. 强引用：使用new创建对象返回的是对象内存首地址，这个是强引用
2. 软引用：使用SoftReference将强引用转换成软引用，软引用对象会在内存不足时被GC
3. 弱引用：使用WeakReference将其他引用转换成弱引用，弱引用对象在下一次GC时会被回收
4. 虚引用：使用PhantonReference转换，虚引用对象不能被使用，他的意义在于对象被回收会向系统发送提示

#### 类型常量池

每个类都有对应的常量表，可以存储缓存

**Integer.valueOf(12)和new Integer(12)区别**

前者是在Ineger缓存池查看是否有12Interger的缓存，如果有，返回缓存的引用，如果没有，则创建新的Integer返回引用

后者直接在堆上常见Integer累心并返回引用

#### 字符串String不可变

[为什么字符串String不可变](https://www.programcreek.com/2013/04/why-string-is-immutable-in-java/)

String不可变底层是用final byte[]数组实现

所有的String都是final的，可以使用intern将String加入字符串常量池

1. 缓存HashCode，不可变字符串只需要在调用HashCode的时候一次计算缓存就行，计算HashCode方法是31*h+(v&0xff)

2. 字符串常量池的要求，从常量池返回一个字符串引用就设置了这个变量的字符串数值，如果这个位置可变，那么就会改变这个数值。
3. 安全性，String经常被当成参数传递，比如网络环境，设置final可以保证安全
4. 线程安全，final的对象是线程安全的

**String、StringBuilder、StringBuffer**

是否可变长：String因为final数组，是不可变的；String Builder和StringBuffer都是使用byte[]，是可变的

线程安全：StringBuffer和StringBuilder都继承了AbstractStringBuilder，只是StringBuffer使用synchronized加锁增删改方法实现同步；而String因为final数组是线程安全的

**字符串常量池**

字符串常量池是在编译时期创建的静态常量池，在加载的解析阶段分配内存创建。字面值会被保存在常量池中，并且编译时会将字面值相同的变量指向常量池中的同一个对象。

使用字符串常量池和基本类型缓存不一样，String.valueOf(byte[])不会检查常量池，而是直接创建对应的String，当然可以使用intern将这个新的String加入到常量池；而使用Integer.valueOf(123)会检查Integer的缓存，如果没有就创建新值在堆上，如果有就返回Integer缓存引用，IntegerCache是Integer的静态内部类，他在初始化准备阶段就分配好Cache的数组内存并且在初始化的时候创建了[-128,127]之间的数字的Integer对象。Integer缓存的数字范围是[-128,127]

字符串常量池在堆上分配内存，因为要保证字符串太大方法区容不下。

#### 参数传递

[参数传递](https://www.cnblogs.com/wkfvawl/p/10539084.html)

Java只有按值传递，传引用类型也是传递的一个引用类型的拷贝，只是这个拷贝指向相同对象

C++有三种参数传递方式传值、传指针、传引用

实际上传指针也是传值，因为形参是实参的拷贝，他们指向相同的内存对象

传引用要求的是将实参传递，形参和实参是同一个对象，改变形参也就改变实参

#### 关键字

##### final

final基本类型，这个变量在被初始化之后不能改变

final引用类型，这个变量在初始化指向一个对象后就不能指向其他对象，只能指向这一个对象，但是不影响修改这个对象

final方法，方法不能被重写

final类，类不能被继承

##### static

static字段，这个变量是类相关的变量，静态变量，与对象无关的变量，在加载的准备阶段分配内存初始化为默认值、在初始化阶段被JVM生成的clinit方法初始化为字面值

static方法，这个方法是静态方法，他只能访问类中的静态字段和静态方法，调用这个静态方法不需要实例，直接类名.方法名就可以调用。Main方法被设置为static，因为需要一个程序执行接口，而非static变量依赖实例，而创建实例就依赖进入接口，这是一个先有鸡还是先有蛋的问题。static方法必须是实现了的，不能是虚方法

static内部类，普通内部类的创建依赖外部类的创建，而静态内部类不需要。静态内部类只能访问外部类的静态方法和成员

static语句块，静态语句块，静态语句块只能执行一次，是在类加载阶段初始化时候被JVM联合静态变量、静态语句块收集赋值操作组成clinit方法执行初始化使用的。他只能在类加载阶段使用一次

##### super

访问父类构造函数super(1,2,3)

访问父类成员函数super().A() ;

#### 对象创建初始化

在加载类阶段对静态变量的初始化，这是JVM自动收集静态变量和静态代码块的赋值操作完成的

父类（静态变量、静态代码块）

子类（静态变量、静态代码块）

在实例化时的初始化，在compile阶段会把普通变量赋值添加到一个init初始化函数，实例化的初始化是对实例变量的创建和初始化，实际上在编译阶段会把实例变量赋值、普通代码块实例变量赋值和构造方法赋值一起创建一个构造init方法，在这个方法中，实例变量赋值和普通代码块赋值在构造方法之前

父类（实例变量赋值、普通代码块）

父类（构造方法）

子类（实例变量赋值、普通代码块）

子类（构造方法）

#### Object类方法

##### equals

equals满足等价性的五个条件

1. 自反性，自己等于自己 x.equals(x) 为true
2. 对称性，x.equals(y)和y.equals(x)结果相同
3. 传递性，x.equals(y) y.equals(z) 则x.equals(z)
4. 一致性，多次比较结果不变x.equals(y)多次执行结果不变
5. 与null比较为false，因为obj不为空

**等价的判断**

x==y比较的是引用，是内存地址是否相同，是否是同一个对象

x.equals(y)，比较的是内容是否一样

**重写equals**

判断是否同一个对象x==y，不是就false

判断为空或者不为同一个类型，false；y==null ||getClass() !=y.getClass() ;

y转型为x的类型

比较x和y的每个变量

##### hashCode

重写equals就必须重写hashCode，以保证同一个变量hash值相等

在HashSet和HashMap等依赖hashCode的集合类，必须重写equals和hashCode

如果只是重写equals，可能hashCode不一样，那么相等的对象被分到两个桶

如果只是重写hashCode不重写equals，相同对象在同一个桶中有两个实例

**重写hashCode**

result=17

result =  result*31+this.x ; (this.x只对基本数据类型，对byte需要this.x&0xff，对引用类型this.x.hashCode() )

result = result*31 + this.y ;

##### tostring

##### clone

深拷贝，重新建立一个对象和被拷贝的对象相同，并且拷贝的变量指向这个新创建的对象

浅拷贝，只拷贝引用类型的值，这样拷贝的变量和原来的应用类型变量指向同一个对象

#### 访问控制符

public protected private

#### 抽象类和接口

抽象类可以被继承，而接口只能实现

抽象类只能单继承，接口可以有多个实现

抽象类可以实现方法，接口都是抽象方法，不能实现

接口字段默认public static final，方法默认public，而抽象类没限制。

#### 重写与重载

重写是把父类的方法重写，参数、方法名相同

重载是方法名相同，但是参数或参数顺序不同

#### 反射

反射用来提供运行时类信息，包括三个类

Filed类，可以通过get和set方法动态改变字段值

Method类，可以通过invoke方法类方法

Constructor类，可以通过newInstance方法重建类对象

**反射优点**

1. 可扩展性：可以通过全限定名创建对象
2. 类浏览器和可视化开发环境，可以动态加载类的成员信息
3. 方便调试和测试

**反射缺点**

性能开销，降低性能

安全性约束，反射要运行在没有安全约束条件

内部暴力，允许访问私有成员等操作

#### 异常

异常是指令错误产生的，比如除0

中断不是CPU执行指令产生的，是系统其他部分发出的，比如IO

#### 泛型

#### 反射

## Java多线程

多线程是用来并发执行程序，加快速度的一种方案，其次是一种开展多任务的方案

### 线程状态

1. 新建，使用new Thread创建一个新线程
2. Runnable，可运行态，是线程要不再就绪，要不在执行
3. 无限期等待，线程调用没有Timeout设置的wait（等待notify或notifyall）或者join方法
4. 限期等待，线程调用有时间设置的Timeout的wait或者join方法
5. 阻塞，线程等待获取锁，或者Thread.sleep()方法
6. 死亡，线程执行结束

**线程状态**

[七状态模型](https://www.jianshu.com/p/ea9821e4cd24)

[参考](https://blog.csdn.net/weixin_43808717/article/details/115351888)

[参考](https://blog.csdn.net/pange1991/article/details/53860651)

[参考](https://blog.csdn.net/coding_1994/article/details/80634792)

[参考](https://www.jianshu.com/p/b8df805825b5?utm_campaign=maleskine&utm_content=note&utm_medium=seo_notes&utm_source=recommendation)

![img](https://images2018.cnblogs.com/blog/137084/201804/137084-20180421113325399-1759953729.jpg)

1. 新建态（New），使用new得到的
2. 就绪态（Ready），被放到就绪队列
   - 新建态调用start方法进入就绪态
   - 执行态调用Thread.yeild方法立即释放CPU进入就绪态，此过程Thread不释放锁。或者执行态时间片用完进入就绪态
   - 阻塞态的线程在锁池队列（同步队列），竞争到对象锁之后进入就绪态
   - 有限等待状态的线程Thread.sleep(10)时间结束，或者用户输入结束，或者object.join(10)执行object时间10毫秒结束，进入就绪态，进入就绪队列
   - 调用LockSupport.park处于无限等待状态的线程被LockSupport.unpark唤醒回到就就绪队列
3. 执行态（Running），线程调度执行得到。
   - 就绪态被CPU调度变成执行态，从就绪队列中获取线程
4. 计时等待（Timed_waiting)，
   - 执行态执行Thread.sleep(10)，thread.join(10)，lock.wait(10)执行用户输入等会让线程进入计时等待
5. 无限等待（Waiting）
   - 执行态执行thread.join()，调用lock.wait()，调用LockSupport.park()等方法，使用lock.wait之前一定获得锁，使用时会释放锁，使LockSupport.park可以不获得锁
6. 阻塞状态（Blocked）
   - 执行态争用锁lock失败直接进入锁池队列（同步队列），进入阻塞状态
   - 因为调用lock.wait（计时等待或者无限等待）, Condition.await()，被lock.nofify, lock.notifyAll 或者Condition.signal(), Condition.signalAll() 从等待队列里面释放进入同步队列（锁池），同时进入阻塞状态。使用lock.notify唤醒线程选择是任意的，可以自己实现定义哪种方法（FIFO，随机）
7. 死亡状态（Terminated）
   - run方法结束，main方法结束，或者发生异常终止

### 线程创建

1. 继承Thread

2. 实现Runnable接口

3. 实现Callable接口

4. 线程池

   **线程池工作流程**

   [线程池](https://www.cnblogs.com/qlqwjy/p/9470414.html)

   [线程池](https://blog.csdn.net/saibeidehuangyan/article/details/122294753)

   1. 核心线程数没有满，就创建线程获取任务执行
   2. 如果核心线程数满，尝试将任务加入工作队列
   3. 如果不能成功加入工作队列，说明工作队列满了，尝试建立新线程
   4. 如果不能成功建立新线程，那么说明达到最大线程数，执行拒绝策略

   **拒绝策略**

   1. Abort，直接抛出异常
   2. CallerRuns，返回主线程处理
   3. DiscardOldest，抛弃工作队列最久的任务
   4. Discard，抛弃当前任务

   **线程池参数**

   核心线程数, corePoolSize

   总线程最大数，maximunPoolSize

   keepAliveTime，空闲线程存活时间

   Timeunit 时间单位

   BlockingQueue，工作队列的实例

```java
//
////创建多线程的四种方式
////1. 继承Thread,继承Thread创建的多线程没有共享数据，因此不存在同步问题
//class MyThread extends Thread{
//	
//	@Override
//	public void run() {
//		for( int i=0;i<10;i++) {
//			System.out.println(Thread.currentThread().getName()+": "+i) ;
//		}
//	}
//}

//2. 实现Runnable接口
//实现Runnable接口创建线程可以共享变量，这样就需要实现同步
//2.1 线程代码相同，实现共享变量，只需要传入相同的Runnable实例到Thread实例
class MyThreadRunnable implements Runnable{
	public static int a=0 ;
	@Override
    public void run() {  
        synchronized(this) {  //synchronized需要传递一个引用来作为互斥量，这里使用类对象的this引用来作为互斥量
//             for (int i = 0; i < 5; i++) {  
//                  System.out.println(Thread.currentThread().getName() + " synchronized loop " + i);  
//             }  
        	a++ ;
        	a++ ;
        	System.out.println(Thread.currentThread().getName() + ": " + a ) ;
//        	a=a+1 ;
        }  
   }  
}

////2.2 多线程的代码不一样
//class Data{
//	int i =0 ;
//	
//	public void inc() {
//		i++ ;
//	}
//	public void dec() {
//		i-- ;
//	}
//	public int get() {
//		return i ;
//	}
//}
//class MyThreadRunnableInc implements Runnable{
//	Data data ;
//	
//	MyThreadRunnableInc(Data d){
//		this.data = d ;
//	}
//	
//	@Override
//	public void run() {
//		synchronized(data) {
//			this.data.inc();
//		}
//	}
//}
//class MyThreadRunnableDec implements Runnable{
//	Data data ;
//	MyThreadRunnableDec(Data d){
//		this.data = d ;
//	}
//	
//	@Override
//	public void run() {
//		synchronized(data) {
//			this.data.dec();
//		}
//	}
//}


class MyThread implements Runnable{
	int x ;
	public MyThread(int i) {
		this.x = i ;
	}
	
	@Override
	public void run() {
		for( int i=0;i<3;i++) {
			System.out.println(Thread.currentThread().getName() + " : "+ x+ " : "+i) ;
		}
	}
}

public class Main { 
	
	public static void main(String[] args) throws Throwable { 
		
//		int num = 3 ;
//		Thread[] t = new MyThread[num] ;
//		for( int i=0;i<num ;i++) {
//			t[i] = new MyThread() ;
//			
//			t[i].start();
//		}
		
//		String a = "123" ;
//		String b = "123" ;
		
		
		
//		MyThreadRunnable a = new MyThreadRunnable() ;
//		int num=3 ;
//		Thread[] t= new Thread[num] ;
//		for( int i=0;i<num;i++) {
//			t[i] = new Thread( a ) ;
//			t[i].start() ;
//		}
//		
//		for( int i=0;i<num;i++) {
//			t[i].join() ;
//			System.out.println("end: " + i);
//		}//使用join等待所有线程结束
//		System.out.println(a.a) ;
		
//		Data a = new Data() ;
//		int num=3 ;
//		Thread[] t= new Thread[num] ;
//		for( int i=0;i<num/2;i++) {
//			t[i] = new Thread(new MyThreadRunnableInc(a)) ;
//			t[i].start() ;
//		}
//		
//		for( int i=num/2;i<num;i++) {
//			t[i] = new Thread(new MyThreadRunnableDec(a)) ;
//			t[i].start() ;
//		}
//		
//		for( int i=0;i<num;i++) {
//			t[i].join() ;
//			System.out.println("end: " + i);
//		}//使用join等待所有线程结束
//		System.out.println(a.get()) ;		
		
        
		ExecutorService executor = new ThreadPoolExecutor(3, 5, 1, TimeUnit.SECONDS, new ArrayBlockingQueue(4) ) ;
		
		for( int i=0;i<6;i++) {
			executor.execute(new MyThread(i) ) ;
		}
		
		executor.shutdown();
	}
}
```

### 线程协作

使用wait notify，等待和唤醒线程

使用join等待另外线程结束

### 线程安全

#### 不可变

使用final让数组和对象不可变

String，BigInteger使用final实现线程安全

#### 无同步方案

线程不共享变量

一种是线程就没有共享的变量

一种是ThreadLocal，ThreadLocal使用了是在方法区的，使用了一个Map<currentThread.getName, Map>来保存各自的数据，使用ThreadLocal可以用来传递一个线程调用多个方法时传递上下文，类似于参数传递

#### 线程同步

线程共享变量保证共享变量安全性的方案

##### 阻塞同步，锁

synchronized和Reentrantlock

synchronized方法是用Acc_synchronized同步

synchronized代码块使用moniterenter和moniterexit同步

synchronized是JVM实现的同步方案，Reentrantlock是JDK实现的同步方案

##### 非阻塞同步

1. CAS compare and set

   包括内存地址V，expectedValue A和新值B，开始读取内存地址V保存到A，修改成新值B，到要写入的时候，重新读入内存地址V，和A比较，如果没有发生变化，那么就说明没有线程与他争用共享变量，之后写入B

2. AutomicInteger原子类型使用CAS来同步

### 锁优化

锁优化是对synchronized关键字进行的优化

#### 自旋锁

锁被占用，线程忙循环一段时间后获取锁而不是立即阻塞

#### 锁升级

1. 无锁，锁对象markword设置无锁

2. 偏向锁

   偏向锁让获取这个锁的线程在之后获取这个锁的时候不需要进行同步操作

   线程在获取锁对象之后，设置markword为偏向状态，并用CAS把自己的线程ID写入markword，之后线程访问锁的代码块不需要同步操作

   当另外一个线程试图获得锁时，偏向状态结束，锁对象回到无锁或者轻量级锁状态

3. 轻量级锁

   锁对象的锁状态是无锁是，线程在自己的虚拟机栈上创建一个LockRecord，并使用CAS修改锁对象的Markword为LockRecord的指针，如果CAS失败，虚拟机检查MarkWord是否已经是指向LockRecord的指针，如果是，代表线程已经获得锁，那就可以访问同步块，如果不是，那就是有线程占用了这个锁。轻量级锁不适合两个线程以上同步。

4. 重锁synchronized

   线程无法获得锁对象就阻塞等待，这种阻塞等待需要切换到操作系统线程，是非常耗时的

### Java内存模型

线程共享主内存，每个线程有自己的工作内存，线程之间不能访问工作内存，主内存和工作内存使用原子操作交互

1. read，从主内存读取变量值放到工作内存
2. load，把工作内存变量值放到本地变量副本
3. use，把工作内存变量值放到执行引擎执行
4. assign，把执行引擎返回值放到共工作内存
5. store，把工作内存变量放到主存
6. write，把主存内的变量值写入变量
7. lock和unlock对主存变量加减锁

#### Java内存模型三大特性

1. 原子性，内存模型保证read，load，use，assign，store，write，lock和unlock原子性

2. 可见性，可见性指的是线程修改变量值需要让其他线程知道这个修改。Java实现可见性是当线程修改本地变量值的时候就刷新到主存，当线程要读取本地变量的时候就从主存读取数据。

   实现可见性：

   1. volitle关键字：他保证可见性，同时禁止指令重排序（通过内存屏障防止内存屏障后面的代码被重排序到前面）。Volatile不能保证线程安全，因为他只能保证可见性，不能保证操作原子性。但是可以使用while循环检查volatile关键字变量来实现同步
   2. synchronized：在执行对变量unlock之前，把修改值写入主存
   3. final关键字：只要完成对final变量的初始化并且没有发生this逃逸（其他线程在线程初始化的时候访问了this对象，修改了final的值），那么final变量对所有线程可见

3. 有序性

   有序性是在本线程观察，所有操作都是有序的。但是这种有序在其他线程看来，可能是无序的，因为发生了指令重排序。

   要保证有序性有两种实现

   1. volatile关键字，通过内存屏障保证有序性
   2. 使用synchronized保证执行代码有序性

### 其他

#### 中断

主线程调用线程的interrupt方法可以中断线程，这种中断对线程处于阻塞、限期等待和无限等待状态，可以产生一个InterruptedException异常，从而中断线程。但是这种中断不能处理处于IO阻塞和synchronized锁阻塞的的线程。这个时候因为interrupt会修改线程状态标志Interrupted，所以可以通过使用Intterrupted方法检测是否发生了中断从而进行中断处理。

#### 守护线程

一个线程被设置为守护线程，他会在非守护线程结束之后随时结束

## Java 虚拟机

### 垃圾收集

#### 判断对象是否可以被回收

1. 引用计数

   给每个对象记录引用个数，如果引用为0就代表可以被回收

2. 可达性分析

   根据GC Root建立引用图，不在引用图上的是可以被回收的对象

   **可以被当成GC Root的对象**

   1. 虚拟机栈中本地变量表的引用
   2. 本地方法栈中JNI的引用对象
   3. 方法区中静态属性引用的对象
   4. 方法区中常量引用对象

#### 方法区的回收

主要是常量池的回收和类的卸载（避免反射和动态代理创建过多的类而造成方法区溢出）

类的卸载必须满足三个条件

1. 堆里没有类及其子类的实例
2. 加载这个类的ClassLoader被回收
3. 这个类的java.lang.Class对象没有在任何地方被引用，也就在任何地方无法通过反射访问这个类方法

### 垃圾回收算法

#### 标记清除

CMS（concurrent mark sweep）等采用标记清除

首先标记要被清除的对象，然后清除他们。回收的块会被添加到空闲链表，每次分配内存时从空闲链表获得满足对象大小的块分配内存，然后把block-size的块返回给空闲链表

不足：

- 标记和清除效率不高
- 会产生外部碎片

#### 标记整理

把所有存活的对象移动到内存一边，然后清除边界以外的对象

优点：

- 不产生外部碎片

缺点：

- 需要移动大量对象，效率低

#### 标记复制

把内存分为两个部分，一部分分配内存，一部分不用，回收时将存活的对象复制到不用的内存，然后回收用过的内存

标记复制一般用于Minor GC，回收新生代，新生代分为Eden区和两个小的Survivor区，每次分配空间总是在Eden区和一个Survivor区分配，回收时将存活对象复制到不用的Survivor区。这其中可能发生Survivor区不够情况，就需要老年区来分配这个内存，实现空间分配担保

HostSpot虚拟机默认Eden：Survivor=8：1

缺点：

- 浪费一般内存不用

### 垃圾收集器

#### 新生代 Minor GC

##### Serial

串行垃圾收集器，客户端默认新生代默认垃圾收集器（客户端关注内存大小，Serial效率能接受）

##### ParNew

Serial多线程版本，服务端默认新生代垃圾收集器，可以和CMS配合使用

##### Parallel Scavenge

多线程垃圾收集器

在达到可控制的吞吐量的目标时尽可能缩短垃圾回收时停顿时间，时吞吐量优先收集器

吞吐量是执行执行用户代码时间/(执行用户代码时间+执行垃圾回收时间)，高吞吐量可以提高CPU利用率，缩短运行时间，适合不需要交互的应用；延迟是收集器Stop the World执行的时间，延迟越短，则客户服务质量越好，适合用户交互的程序，但是会增加整个运行时间。

缩短停顿时间（延迟）是靠牺牲吞吐量和新生代内存空间实现的，小的新生代空间会触发更频繁的垃圾回收，导致吞吐量下降。

Parallel Scavenge可以自动调节新生代大小、Eden和Survivor比例、晋升到老年代年龄

#### 老年代 Major GC

##### CMS

Concurrent Mark Sweep，使用标记清除算法，哟四个流程

1. 初始标记：仅仅标记GC Root引用的对象，有停顿
2. 并发标记：根据GC Root进行可达性分析过程，和用户线程并发执行，不需要停顿
3. 重复标记：标记因为并发标记时用户线程产生的新的垃圾对象，需要停顿
4. 并发清除：和用户程序并发，清除垃圾

缺点：

- 吞吐量低，并发标记和并发清除占用CPU
- 没办法处理浮动垃圾，并发清除时用户线程在运行会产生新的垃圾，这必须等到下一次GC时才能处理
- 并发时用户线程在申请新的内存，意味着CMS不能等到老年代快满的时候收集，必须留一部分空间。而预留的空间可能不够新对象分配，造成并发失败
- 标记清除算法产生外部碎片，造成老年代还有空内存的时候因为不能给大对象分配内存而引发Full GC

##### Serial Old

Serial老年代版本，适合客户端

在服务端，主要作为CMS收集器并发失败后的后备方案

##### Parallel Old

Parallel Scavenge的老年代版本

在注重吞吐量和CPU资源的场合，可以优先考虑Parallel Scavenge+Parallel Old收集器组合

#### Mixed GC

##### G1

面向服务端的垃圾收集器，在多CPU和大内存场景有很好的性能，CMS的替代

G1将内存划分为小的内存Region，每个Region可以作为Eden、Survivor或老年代，根据经验设置每个Region回收时间和获得的内存，并维护一个优先列表，根据允许的收集时间，优先回收价值大（回收内存多）的Region，这样实现了一个停顿模型

每个Region保存一个RemenberedSet保存这个Region引用对象所在的Region，这样在做可达性分析的时候可以避免全堆扫描

特点：

- 空间整合：整体上看是基于标记整理算法实现的，但从局部看是基于复制算法实现的，意味着不会产生外部碎片
- 可控制的停顿时间：让GC时间不超过使用者设定的时间内。

##### Shenanwoah

##### ZGC

#### Full GC

在新生代和老生代都可以GC

### 内存分配策略

1. 优先在Eden区分配，当Eden区不够时发生MinorGC
2. 大对象进入老年代，比如长字符串和大数组，这样避免大对象快速沾满Eden区发生MinorGC频繁发生Eden和Survivor之间的复制
3. 长期存活对象进入老年区，增加对象年龄计数器，每熬过一次GC就加一，默认15次就复制到老年代
4. 动态对象年龄判定，如果Survivor区具有相同年龄的对象占一半内存，就把年龄大于等于这个年龄的对象复制到老年区
5. 空间分配担保，当进行MinorGC之前，检查老年代最大连续空间是否可以容纳所有新生代对象的总空间，如果时，则进行MinorGC；如果不是，检查是否可以HandlePromotionFailure=True，如果是，检查老年代最大可用空间是否大于历次Promotion的平均对象的平均大小，如果是，则进行一次冒险的MinorGC；如果不是或者HandlePromotionFailure=False，那么进行一次FullGC

### GC触发条件

#### MinorGC

当Eden区满时触发

#### MajorGC

Serial Old、Parallel Old在老年代满时

CMS在达到设定的大小时

#### FullGC

1. 调用system.gc()，并不会立即FullGC
2. 老年代空间不足，在大对象和长期存活对象进入老年代引发。可以设置Xmn调大虚拟机新生代或者调大XX：MaxTenuringThreshold调大进入老年代年龄，让对象躲在新生代存活一段时间。同时避免创建过大对象和数组
3. 空间分配担保失败，整理到Survivor的对象内存不足要移动到老年代但是老年代最大连续内存不能分配
4. JDK1.7之前永久代空间不足，那是永久代是固定内存，在反射和动态代理创建类的时候可能内存不足
5. Concurrent Mode Failure，并发失败，在CMS时并发的用户线程在创建对象使得内存不足



1. springboot自动装配

2. 为什么JAVA要进行GC

3. 怎么判断一个垃圾（垃圾回收机制）

4. 讲讲volatile，JMM，垃圾回收过程，字节码角度解释return i++，mysql的事务原理

5. Hashmap的原理，增删的情况后端数据结构如何位移
   hashmap容量为什么是2的幂次
   hashset的源码
   object类你知道的方法
   hashcode和equals
   你重写过hashcode和equals么，要注意什么
   假设现在一个学生类，有学号和姓名，我现在hashcode方法重写的时候，只将学号参与计算，会出现什么情况？
   往set里面put一个学生对象，然后将这个学生对象的学号改了，再put进去，可以放进set么？并讲出为什么

6. Java的内存模型，垃圾回收

7. Spring的aop有哪些实现方式

8. 指针和引用的区别

9. JAVA的ArrayList分配内存机制

10. volatile关键字的作用

11. java多线程实现方法

12. 5 Jvm垃圾回收， 垃圾回收算法

13. HashMap线程安全吗？如何线程安全（答了ConCurrentHashMap，后来还根据这个出了一道场景题，具体内容忘了）

14.  string和stringbuffer的区别？

15. 抽象类和接口的区别？

16. 如何遍历list？

17. 问了问spring中的AOP和IOC

18. 方法重载和重写的区别？

19. 说说Java面向对象的特征及理解？**（多态说的不好）**

20. JVM内存结构？JMM内存模型

21. 堆和栈有什么区别

22. 垃圾回收GC在哪？JVM垃圾回收过程？

23.  **怎样查看GC调用频率，或者说怎么样针对GC执行进行堆内存调优？** 

     答：（重点来了）打了打印GC日志，或者使用Java自带的Jstat内存监视工具，或者可以下载dump文件用工具查看，还有一款[阿里巴巴]()开源的堆内存调优工具不记得叫啥了。

24. **hashmap遍历？**

    答：太菜了只用过迭代器遍历所以只说了迭代器作者：旭一个

    看了网上还有：使用For-Each迭代entry，使用For-Each迭代keys或者values，迭代keys并搜索values（低效），1.8之后lambda表达式简化foreach遍历（map.forEach((k,v) -> System.out.println(k + "=" + v));）

25. static关键字？**如果子类和父类都有static变量，static修饰的代码块以及相应构造器，问加载顺序****？**

26. ==和equals？ Object类方法，hashcode，equals，hashcode实现，equals实现，会出现什么问题

27. **平常遇到哪些异常？**

28. **包的访问权限？说说public等几个修饰访问权限的区别？**

29. JVM内存分区？

    哪些地方是线程共享的？

     一个对象在内存分区中的过程？

    答：回答了栈中的对象引用，对象从eden区到sur[vivo](https://www.nowcoder.com/jump/super-jump/word?word=vivo)r到老年代的过程。

    **JVM内存调优？**

    答：说了些堆调优的参数配置，说了什么时候调大调小eden区。

30. **springMVC工作流程？**

    答：只知道请求响应。。。

    

31. JVM内存区域（1分钟）

32. 堆的内存布局（0.5分钟）

33. 垃圾回收完整过程（1分钟）

34. CMS垃圾回收过程（1分钟，记错了，失了忆，乱扯了一会）

35. NIO底层实现原理（2分钟）

36. G1垃圾回收过程（1.5分钟）

37. Spring如何解决循环依赖（3.5分钟）

38. MVCC原理（3分钟）

39. 消息中间件（不太了解）

40. 常见的设计模式（讲了单例、工厂、代理、装饰器、观察者，4分钟）

# 开发/测试/运维/中间件/套件

## 反向代理/微服务

### 服务注册与发现、服务调用

#### 相关框架

|           | Netflix（停更） | RPC（Remote Procedure Call）框架 | 消费端调用远程服务，简化http调用，内置Ribbon，不支持Spring MVC注解，基于http协议不适合高并发 |
| :-------: | :-------------: | :------------------------------: | :----------------------------------------------------------: |
| OpenFeign |     Spring      |               同上               |           Spring扩展版Feign，支持了Spring MVC注解            |
|   Dubbo   |     Alibaba     |               同上               |                 基于Netty，长连接适合高并发                  |
|  Eureka   | Netflix（停更） |                                  |                                                              |
|   Nacos   |     Alibaba     |                                  |                                                              |

### 负载均衡Load Balance

将任务分摊到不同的工作单元

#### 负载均衡策略

##### 基于随机的负载均衡

###### 完全随机

随机分配任务到一个工作单元

###### 加权随机

为不同服务器分配权重，权重大的优先分配任务

###### 改进加权随机

为服务器分配权重，生成一个随机数，便利权重，找到第一个比随机数大的分配

##### 基于轮询的负载均衡

###### 轮询Round Robin

将收到的请求循环分配到服务器，使用一个指针遍历所有服务器，收到一个请求将把指针加一

这个策略简单有效，但是因为每个机器性能不一，可能是性能差的超载

###### 加权轮询Weighted Round Robin

给每个机器分配权重，轮询分配如果超权重那么就移动到下一个

###### 平滑加权轮询

![](https://github.com/AlbertoWang/java-noob/raw/master/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91%E7%9B%B8%E5%85%B3%E7%BB%84%E4%BB%B6.assets/smoothed-weighted-round-robin.png)

##### 基于连接数的负载均衡

###### 最小连接数

连接数最小分配请求

###### 加权最小连接

加权连接说最小

###### 源IP哈希/一致性哈希

来自同一个客户端的请求分配到同一个服务器

##### 不同框架的负载均衡

1. RIbbon

   ```
   NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRule # 随机
   NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RoundRobinRule # 轮询（默认）
   NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RetryRule # 重试
   NFLoadBalancerRuleClassName: com.netflix.loadbalancer.WeightedResponseTimeRule # 加权响应时间
   NFLoadBalancerRuleClassName: com.netflix.loadbalancer.BestAvailableRule # 最小连接
   ```

2. Nacos

   ![](https://github.com/AlbertoWang/java-noob/raw/master/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91%E7%9B%B8%E5%85%B3%E7%BB%84%E4%BB%B6.assets/nacos-register-and-discovery.png)

#### 服务注册与发现

##### 工作流程

微服务将自身注册到nacos服务注册列表，里面包含了微服务ID、微服务host、微服务port，心跳机制使用`@EnableScheduling`实现；有服务需要调用其他微服务时，使用OpenFeign的`@FeignClient`进行服务发现，使用Ribbon的`@LoadBalancer`进行负载均衡

## 消息队列

### 消息队列概念

#### 业务问题模型

无消息队列的方案：假设某个业务涉及到了支付、短信通知、邮件通知三个子业务，如果不使用消息队列，需要等待$(100+200+300)ms$；如果需要增加子业务，这个时间还会更长并且需要修改整体业务代码

[![img](https://github.com/AlbertoWang/java-noob/raw/master/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91%E7%9B%B8%E5%85%B3%E7%BB%84%E4%BB%B6.assets/purchase-without-message-queue.png)](https://github.com/AlbertoWang/java-noob/blob/master/后端开发相关组件.assets/purchase-without-message-queue.png)

使用消息队列：主业务完成后，不着急的任务可以放在消息队列之后慢慢处理，全部业务完成虽然仍需$(100+200+300)ms$，但在这个过程中下单业务完成后用户可以进行其他操作（后续操作就成了异步操作），如果需要增加子业务可以增加到消息队列之后成为子项目（业务解耦），最耗时或浪费资源的任务可以后面慢慢处理（高并发情况下系统不崩，削峰）

[![purchase-with-message-queue](https://github.com/AlbertoWang/java-noob/raw/master/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91%E7%9B%B8%E5%85%B3%E7%BB%84%E4%BB%B6.assets/purchase-with-message-queue.png)](https://github.com/AlbertoWang/java-noob/blob/master/后端开发相关组件.assets/purchase-with-message-queue.png)

### 消息队列好处

- 异步
- 解耦
- 削峰

### Kafka

分布式的基于发布/订阅模式的消息队列。

### 

### RabbitMQ

#### 使用docker安装

1. 新建*docker-compose.yml*文件并写入以下内容

   ```
   rabbitmq:
     image: rabbitmq:management
     ports:
       - "5672:5672"
       - "15672:15672"
   ```

2. 在同级目录下的terminal中运行命令`docker-compose up`

3. 在本地terminal中运行命令`docker exec -it <imageId> bash`进入RabbitMQ的terminal

4. 添加用户命令：`rabbitmqctl add_user <username> <password>`（默认用户账号名与密码为*guest*）

5. 添加管理员权限：`rabbitmqctl set_user_tags <username> administrator`

6. 浏览器URL：[http://localhost:15672，查看RabbitMQ相关情况](http://localhost:15672，查看RabbitMQ相关情况/)

[![rabbitmq-setup](https://github.com/AlbertoWang/java-noob/raw/master/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91%E7%9B%B8%E5%85%B3%E7%BB%84%E4%BB%B6.assets/rabbitmq-setup.png)](https://github.com/AlbertoWang/java-noob/blob/master/后端开发相关组件.assets/rabbitmq-setup.png)

#### AMQP模型 *Advanced Message Queue Protocol*

[![img](https://github.com/AlbertoWang/java-noob/raw/master/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91%E7%9B%B8%E5%85%B3%E7%BB%84%E4%BB%B6.assets/amqp.png)](https://github.com/AlbertoWang/java-noob/blob/master/后端开发相关组件.assets/amqp.png)

1. Publisher：消息生产者；
2. Exchange：交换器，接受生产者的消息并路由到服务器的队列中（类似于路由器）；
3. Binding：将消息队列和交换器关联起来的操作，基于路由规则绑定（类似于路由表）；
4. Queue：消息队列本体，保存消息到发送给消费者；
5. Connection：网络连接，如TCP连接；
6. Channel：信道，多路复用连接中的双向通道，建立在TCP上的虚拟连接；
7. Consumer：消息消费者；
8. Virtual Host：虚拟主机，表示一批交换器和消息队列（类似于文件夹，存放了交换器和消息队列文件）；
9. Broker：消息队列服务器实体（由多个文件夹构成的文件系统）。

#### Exchange的类型

1. direct 单播模式（默认模式）

   生产者提供的消息包含`routing-key`，Exchange根据`routing-key`将消息发送到对应相同`binding-key`的队列；如果没有对应的`binding-key`，消息将丢失；

   [![exchange delivering messages to  queues based on routing key](https://github.com/AlbertoWang/java-noob/raw/master/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91%E7%9B%B8%E5%85%B3%E7%BB%84%E4%BB%B6.assets/exchange-direct.png)](https://github.com/AlbertoWang/java-noob/blob/master/后端开发相关组件.assets/exchange-direct.png)

2. fanout 多播模式

   将消息发送到所有绑定的队列中，不涉及到`routing-key`所以很快；如果后加入的队列，收不到前面发送过的消息；

   [![exchange delivering messages to three queues](https://github.com/AlbertoWang/java-noob/raw/master/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91%E7%9B%B8%E5%85%B3%E7%BB%84%E4%BB%B6.assets/exchange-fanout.png)](https://github.com/AlbertoWang/java-noob/blob/master/后端开发相关组件.assets/exchange-fanout.png)

3. topic 订阅模式

   Exchange根据`routing-key`将消息发送到满足`binding-key`的队列；匹配规则：在绑定队列时，`binding-key`的值格式为`aa.bb.cc...`，则`aa.*`只能匹配到`aa.xx`（仅仅下一级）；`aa.#`可以匹配到`aa`、`aa.xx`或`aa.xx.yy`等（下面多级）。

#### 事务管理

##### 生产者端

RabbitMQ中的事务是在Channel中的，通过`channel.txSelect()`开启事务，并需要使用`channel.txCommit()`提交，在错误处理中调用`channel.txRollback()`进行回滚并`channel.close()`释放内存。

##### 消费者端

## 设计模式

### Java单例模式

**private构造函数的作用**

https://wenku.baidu.com/view/c1ba14df971ea76e58fafab069dc5022aaea463b.html

private构造函数作用是防止private构造函数的类被其他类实例化，也就是private构造函数的类不能被其他类实例化。private构造函数的类的成员函数只能是静态函数，因为他不能被实例化，那么他的方法都是类相关的方法而不是跟实例相关的方法。private构造函数的类不能被外部函数创建但是可以被内部函数创建。

**Java单例模式实现方法**

- 饱汉模式（静态方法）

  ```java
  public class Singleton{
  	private static Singleton INSTANCE = null ;				  //因为单例模式不能被实例化，那么必须使用static
  	private Singleton() { }									  //private构造函数的类不能被外部类实例化，但是可以																 //被内部函数实例化
  	public synchronized static final Singleton getInstance() {//synchronized保证线程安全，因为不能被实例化所以															   //方法使用static，final可有可无，final方法防止类															  //被继承时改写方法
  		if( INSTANCE == null )
  			INSTANCE = new Singleton() ;
  		return INSTANCE ;
  	}
  	
  	public static void main(String[] args) {
  		Singleton s1 = Singleton.getInstance() ;
  		Singleton s2 = Singleton.getInstance() ;
  		
  		System.out.println( System.identityHashCode(s1) ) ;
  		System.out.println( System.identityHashCode(s2) );
  	}
  }
  ```

- 饱汉模式（静态代码块）

  ```java
  public class Singleton{
  	private static Singleton INSTANCE = null ;				  //因为单例模式不能被实例化，那么必须使用static
  	private Singleton() { }									  //private构造函数的类不能被外部类实例化，但是可以																 //被内部函数实例化
  	public static final Singleton getInstance() {//synchronized保证线程安全，因为不能被实例化所以															   //方法使用static，final可有可无，final方法防止类															  //被继承时改写方法
  		if( INSTANCE == null ) {
  			synchronized( Singleton.class ) {
  				INSTANCE = new Singleton() ;
  			}
  		}
  		return INSTANCE ;
  	}
  	
  	public static void main(String[] args) {
  		Singleton s1 = Singleton.getInstance() ;
  		Singleton s2 = Singleton.getInstance() ;
  		
  		System.out.println( System.identityHashCode(s1) ) ;
  		System.out.println( System.identityHashCode(s2) );
  	}
  }
  ```

- 饱汉模式（静态内部类）

  https://blog.csdn.net/czh500/article/details/83876425

  **Java静态类一定是静态内部类，他和普通内部类的区别在于**

  - 静态内部类可以创建静态和非静态成员（函数或变量），而普通内部类不能创建静态成员（函数或者变量）

  - 静态内部类只能访问外部类的静态成员（函数或变量），而普通内部类可以访问任意城公园（函数或变量）

  - 静态内部类可以单独使用 **new 外部类.内部类()**的方式创建，而创建内部类实例必须先实例化外部类，在实例化内部类

    ```
    outer = new Outer() ;
    inner = outer.Inner() ;
    ```

  **静态内部类实现饱汉模式单例模式**

  ```java
  public class Singleton{
  	private Singleton() {} ;
  	
  	public static Singleton getInstance() {
  		return SingletonOnce.INSTANCE ;
  	}
  	private static class SingletonOnce{
  		private static final Singleton INSTANCE = new Singleton() ;//外部类可以访问内部类的私有成员，
  																   //内部类也可以访问外部类的私有成员
  	}
  	
  	public static void main(String[] args) {
  		Singleton s1 = Singleton.getInstance() ;
  		Singleton s2 = Singleton.getInstance() ;
  		
  		System.out.println( System.identityHashCode(s1) ) ;		   //使用identityHashCode打印内存地址
  		System.out.println( System.identityHashCode(s2) );
  	}
  }
  ```

  

- 饿汉模式（静态变量类加载时实例化）

  ```java
  public class Singleton{
  	private static Singleton INSTANCE = new Singleton() ; 		//类加载时初始化
  	private Singleton() {} ;
  	public static Singleton getInstance() {
  		return INSTANCE ;
  	}
  	
  	public static void main(String[] args) {
  		Singleton s1 = Singleton.getInstance() ;
  		Singleton s2 = Singleton.getInstance() ;
  		
  		System.out.println( System.identityHashCode(s1) ) ;
  		System.out.println( System.identityHashCode(s2) );
  	}
  }
  ```

## 微服务架构

### 微服务监控服务性能指标

Redis缓存一般监控占用内存值、网络流量；数据库监控连接数、磁盘空间；业务服务监控并发数、响应延迟、错误率等

### 微服务框架

#### 什么是微服务

首先微服务并没有一个官方的定义，想要直接描述微服务比较困难，我们可以通过对比传统WEB应用，来理解什么是微服务。

[![1.jpg](http://dockone.io/uploads/article/20190626/cdf6b85e3128aece77f99babcfd4db7d.jpg)](http://dockone.io/uploads/article/20190626/cdf6b85e3128aece77f99babcfd4db7d.jpg)


传统的WEB应用核心分为业务逻辑、适配器以及API或通过UI访问的WEB界面。业务逻辑定义业务流程、业务规则以及领域实体。适配器包括数据库访问组件、消息组件以及访问接口等。一个打车软件的架构图如下：

尽管也是遵循模块化开发，但最终它们会打包并部署为单体式应用。例如Java应用程序会被打包成WAR，部署在Tomcat或者Jetty上。

这种单体应用比较适合于小项目，优点是：

- 开发简单直接，集中式管理
- 基本不会重复开发
- 功能都在本地，没有分布式的管理开销和调用开销


当然它的缺点也十分明显，特别对于互联网公司来说：

- 开发效率低：所有的开发在一个项目改代码，递交代码相互等待，代码冲突不断
- 代码维护难：代码功能耦合在一起，新人不知道何从下手
- 部署不灵活：构建时间长，任何小修改必须重新构建整个项目，这个过程往往很长
- 稳定性不高：一个微不足道的小问题，可以导致整个应用挂掉
- 扩展性不够：无法满足高并发情况下的业务需求


所以，现在主流的设计一般会采用微服务架构。其思路不是开发一个巨大的单体式应用，而是将应用分解为小的、互相连接的微服务。一个微服务完成某个特定功能，比如乘客管理和下单管理等。每个微服务都有自己的业务逻辑和适配器。一些微服务还会提供API接口给其他微服务和应用客户端使用。** 如果你想和更多微服务技术专家交流，可以加我微信liyingjiese，备注『加群』。群里每周都有全球各大公司的最佳实践以及行业最新动态**。

比如，前面描述的系统可被分解为：

[![2.jpg](http://dockone.io/uploads/article/20190626/18080f8527c8690ddf6dde040b34f5a0.jpg)](http://dockone.io/uploads/article/20190626/18080f8527c8690ddf6dde040b34f5a0.jpg)


每个业务逻辑都被分解为一个微服务，微服务之间通过REST API通信。一些微服务也会向终端用户或客户端开发API接口。但通常情况下，这些客户端并不能直接访问后台微服务，而是通过API Gateway来传递请求。API Gateway一般负责服务路由、负载均衡、缓存、访问控制和鉴权等任务。

#### 微服务架构的优点

微服务架构有很多重要的优点。首先，它解决了复杂性问题。它将单体应用分解为一组服务。虽然功能总量不变，但应用程序已被分解为可管理的模块或服务。这些服务定义了明确的RPC或消息驱动的API边界。微服务架构强化了应用模块化的水平，而这通过单体代码库很难实现。因此，微服务开发的速度要快很多，更容易理解和维护。

其次，这种体系结构使得每个服务都可以由专注于此服务的团队独立开发。只要符合服务API契约，开发人员可以自由选择开发技术。这就意味着开发人员可以采用新技术编写或重构服务，由于服务相对较小，所以这并不会对整体应用造成太大影响。





第三，微服务架构可以使每个微服务独立部署。开发人员无需协调对服务升级或更改的部署。这些更改可以在测试通过后立即部署。所以微服务架构也使得CI／CD成为可能。

最后，微服务架构使得每个服务都可独立扩展。我们只需定义满足服务部署要求的配置、容量、实例数量等约束条件即可。比如我们可以在EC2计算优化实例上部署CPU密集型服务，在EC2内存优化实例上部署内存数据库服务。

#### 微服务架构的缺点和挑战

实际上并不存在silver bullets，微服务架构也会给我们带来新的问题和挑战。其中一个就和它的名字类似，微服务强调了服务大小，但实际上这并没有一个统一的标准。业务逻辑应该按照什么规则划分为微服务，这本身就是一个经验工程。有些开发者主张10-100行代码就应该建立一个微服务。虽然建立小型服务是微服务架构崇尚的，但要记住，微服务是达到目的的手段，而不是目标。微服务的目标是充分分解应用程序，以促进敏捷开发和持续集成部署。

微服务的另一个主要缺点是微服务的分布式特点带来的复杂性。开发人员需要基于RPC或者消息实现微服务之间的调用和通信，而这就使得服务之间的发现、服务调用链的跟踪和质量问题变得的相当棘手。





微服务的另一个挑战是分区的数据库体系和分布式事务。更新多个业务实体的业务交易相当普遍。这些类型的事务在单体应用中实现非常简单，因为单体应用往往只存在一个数据库。但在微服务架构下，不同服务可能拥有不同的数据库。CAP原理的约束，使得我们不得不放弃传统的强一致性，而转而追求最终一致性，这个对开发人员来说是一个挑战。

微服务架构对测试也带来了很大的挑战。传统的单体WEB应用只需测试单一的REST API即可，而对微服务进行测试，需要启动它依赖的所有其他服务。这种复杂性不可低估。

微服务的另一大挑战是跨多个服务的更改。比如在传统单体应用中，若有A、B、C三个服务需要更改，A依赖B，B依赖C。我们只需更改相应的模块，然后一次性部署即可。但是在微服务架构中，我们需要仔细规划和协调每个服务的变更部署。我们需要先更新C，然后更新B，最后更新A。





部署基于微服务的应用也要复杂得多。单体应用可以简单的部署在一组相同的服务器上，然后前端使用负载均衡即可。每个应用都有相同的基础服务地址，例如数据库和消息队列。而微服务由不同的大量服务构成。每种服务可能拥有自己的配置、应用实例数量以及基础服务地址。这里就需要不同的配置、部署、扩展和监控组件。此外，我们还需要服务发现机制，以便服务可以发现与其通信的其他服务的地址。因此，成功部署微服务应用需要开发人员有更好地部署策略和高度自动化的水平。

以上问题和挑战可大体概括为：

- API Gateway
- 服务间调用
- 服务发现
- 服务容错
- 服务部署
- 数据调用



[![3.png](http://dockone.io/uploads/article/20190626/e664885b9b03a5fbbc9d366e84a2221d.png)](http://dockone.io/uploads/article/20190626/e664885b9b03a5fbbc9d366e84a2221d.png)


幸运的是，出现了很多微服务框架，可以解决以上问题。

#### 第一代微服务框架

##### Spring Cloud

Spring Cloud为开发者提供了快速构建分布式系统的通用模型的工具（包括配置管理、服务发现、熔断器、智能路由、微代理、控制总线、一次性令牌、全局锁、领导选举、分布式会话、集群状态等）。 主要项目包括：

- Spring Cloud Config：由Git存储库支持的集中式外部配置管理。配置资源直接映射到Spring Environment，但是如果需要可以被非Spring应用程序使用。
- Spring Cloud Netflix：与各种Netflix OSS组件（Eureka，Hystrix，Zuul，Archaius等）集成。
- Spring Cloud Bus：用于将服务和服务实例与分布式消息传递联系起来的事件总线。用于在集群中传播状态更改（例如配置更改事件）。
- Spring Cloud for Cloudfoundry：将您的应用程序与Pivotal Cloudfoundry集成。提供服务发现实现，还可以轻松实现通过SSO和OAuth 2保护资源，还可以创建Cloudfoundry服务代理。
- Spring Cloud - Cloud Foundry Service Broker：提供构建管理一个Cloud Foundry中服务的服务代理的起点。
- Spring Cloud Cluster：领导选举和通用状态模型（基于ZooKeeper，Redis，Hazelcast，Consul的抽象和实现）。
- Spring Cloud Consul：结合Hashicorp Consul的服务发现和配置管理
- Spring Cloud Security：在Zuul代理中为负载平衡的OAuth 2休眠客户端和认证头中继提供支持。
- Spring Cloud Sleuth：适用于Spring Cloud应用程序的分布式跟踪，与Zipkin，HTrace和基于日志（例如ELK）跟踪兼容。
- Spring Cloud Data Flow：针对现代运行时的可组合微服务应用程序的云本地编排服务。易于使用的DSL，拖放式GUI和REST-API一起简化了基于微服务的数据管道的整体编排。
- Spring Cloud Stream：轻量级事件驱动的微服务框架，可快速构建可连接到外部系统的应用程序。使用Apache Kafka或RabbitMQ在Spring Boot应用程序之间发送和接收消息的简单声明式模型。
- Spring Cloud Stream Application Starters：Spring Cloud任务应用程序启动器是Spring Boot应用程序，可能是任何进程，包括不会永远运行的Spring Batch作业，并且它们在有限时间的数据处理之后结束/停止。
- Spring Cloud ZooKeeper：ZooKeeper的服务发现和配置管理。
- Spring Cloud for Amazon Web Services：轻松集成托管的Amazon的Web Services服务。它通过使用Spring的idioms和APIs便捷集成AWS服务，例如缓存或消息API。开发人员可以围绕托管服务，不必关心基础架构来构建应用。
- Spring Cloud Connectors：使PaaS应用程序在各种平台上轻松连接到后端服务，如数据库和消息代理（以前称为“Spring Cloud”的项目）。
- Spring Cloud Starters：作为基于Spring Boot的启动项目，降低依赖管理（在Angel.SR2后，不在作为独立项目）。
- Spring Cloud CLI：插件支持基于Groovy预言快速创建Spring Cloud的组件应用。



##### Dubbo

Dubbo是一个阿里巴巴开源出来的一个分布式服务框架，致力于提供高性能和透明化的RPC远程服务调用方案，以及SOA服务治理方案。其核心部分包含：

- 远程通讯： 提供对多种基于长连接的NIO框架抽象封装，包括多种线程模型，序列化，以及“请求-响应”模式的信息交换方式。
- 集群容错：提供基于接口方法的透明远程过程调用，包括多协议支持，以及软负载均衡，失败容错，地址路由，动态配置等集群支持。
- 自动发现：基于注册中心目录服务，使服务消费方能动态的查找服务提供方，使地址透明，使服务提供方可以平滑增加或减少机器。



[![4.jpg](http://dockone.io/uploads/article/20190626/88adbc1cdde8241d80e5e0db9d747795.jpg)](http://dockone.io/uploads/article/20190626/88adbc1cdde8241d80e5e0db9d747795.jpg)


但是显而易见，无论是Dubbo还是Spring Cloud都只适用于特定的应用场景和开发环境，它们的设计目的并不是为了支持通用性和多语言性。并且它们只是Dev层的框架，缺少DevOps的整体解决方案（这正是微服务架构需要关注的）。而随之而来的便是Service Mesh的兴起。

#### 下一代微服务：Service Mesh？

##### Service Mesh

Service Mesh又译作“服务网格”，作为服务间通信的基础设施层。如果用一句话来解释什么是Service Mesh，可以将它比作是应用程序或者说微服务间的TCP/IP，负责服务之间的网络调用、限流、熔断和监控。对于编写应用程序来说一般无须关心TCP/IP这一层（比如通过 HTTP 协议的 RESTful 应用），同样使用Service Mesh也就无须关系服务之间的那些原来是通过应用程序或者其他框架实现的事情，比如Spring Cloud、OSS，现在只要交给Service Mesh就可以了。

Service Mesh有如下几个特点：

- 应用程序间通讯的中间层
- 轻量级网络代理
- 应用程序无感知
- 解耦应用程序的重试/超时、监控、追踪和服务发现


Service Mesh的架构如下图所示：

[![5.png](http://dockone.io/uploads/article/20190626/b7999b4fd674ce3f19f77981e09ad60f.png)](http://dockone.io/uploads/article/20190626/b7999b4fd674ce3f19f77981e09ad60f.png)


Service Mesh作为Sidebar运行，对应用程序来说是透明，所有应用程序间的流量都会通过它，所以对应用程序流量的控制都可以在Service Mesh中实现。

目前流行的Service Mesh开源软件有Linkerd、Envoy和Istio，而最近Buoyant（开源Linkerd的公司）又发布了基于Kubernetes的Service Mesh开源项目Conduit。

###### Linkerd

Linkerd是开源网络代理，设计为以服务网格部署：用于管理，控制和监控应用程序内的服务与服务间通讯的专用层。

Linkerd旨在解决Twitter、Yahoo、Google和Microsoft等公司运营大型生产系统时发现的问题。根据经验，最复杂，令人惊奇和紧急行为的来源通常不是服务本身，而是服务之间的通讯。Linkerd解决了这些问题，不仅仅是控制通讯机制，而是在其上提供一个抽象层。

[![6.jpg](http://dockone.io/uploads/article/20190626/55a04e6b902a8adf1849adb6d0781ca9.jpg)](http://dockone.io/uploads/article/20190626/55a04e6b902a8adf1849adb6d0781ca9.jpg)


它的主要特性有：

- 负载平衡：Linkerd提供了多种负载均衡算法，它们使用实时性能指标来分配负载并减少整个应用程序的尾部延迟。
- 熔断：Linkerd包含自动熔断，将停止将流量发送到被认为不健康的实例，从而使他们有机会恢复并避免连锁反应故障。
- 服务发现：Linkerd 与各种服务发现后端集成，通过删除特定的(ad-hoc)服务发现实现来帮助您降低代码的复杂性。
- 动态请求路由：Linkerd 启用动态请求路由和重新路由，允许您使用最少量的配置来设置分段服务（staging service），金丝雀（canaries），蓝绿部署（blue-green deploy），跨DC故障切换和黑暗流量（dark traffic）。
- 重试次数和截止日期：Linkerd可以在某些故障时自动重试请求，并且可以在指定的时间段之后让请求超时。
- TLS：Linkerd可以配置为使用TLS发送和接收请求，您可以使用它来加密跨主机边界的通信，而不用修改现有的应用程序代码。
- HTTP代理集成：Linkerd可以作为HTTP代理，几乎所有现代HTTP客户端都广泛支持，使其易于集成到现有应用程序中。
- 透明代理：您可以在主机上使用iptables规则，设置通过Linkerd的透明代理。
- gRPC：Linkerd支持HTTP/2和TLS，允许它路由gRPC请求，支持高级RPC机制，如双向流，流程控制和结构化数据负载。
- 分布式跟踪：Linkerd支持分布式跟踪和度量仪器，可以提供跨越所有服务的统一的可观察性。
- 仪器仪表：Linkerd支持分布式跟踪和度量仪器，可以提供跨越所有服务的统一的可观察性。



###### Envoy

Envoy是一个面向服务架构的L7代理和通信总线而设计的，这个项目诞生是出于以下目标：

对于应用程序而言，网络应该是透明的，当发生网络和应用程序故障时，能够很容易定位出问题的根源。

Envoy可提供以下特性：

- 外置进程架构：可与任何语言开发的应用一起工作；可快速升级。
- 基于新C++11编码：能够提供高效的性能。
- L3/L4过滤器：核心是一个L3/L4网络代理，能够作为一个可编程过滤器实现不同TCP代理任务，插入到主服务当中。通过编写过滤器来支持各种任务，如原始TCP代理、HTTP代理、TLS客户端证书身份验证等。
- HTTP L7过滤器：支持一个额外的HTTP L7过滤层。HTTP过滤器作为一个插件，插入到HTTP链接管理子系统中，从而执行不同的任务，如缓冲，速率限制，路由/转发，嗅探Amazon的DynamoDB等等。
- 支持HTTP/2：在HTTP模式下，支持HTTP/1.1、HTTP/2，并且支持HTTP/1.1、HTTP/2双向代理。这意味着HTTP/1.1和HTTP/2，在客户机和目标服务器的任何组合都可以桥接。
- HTTP L7路由：在HTTP模式下运行时，支持根据content type、runtime values等，基于path的路由和重定向。可用于服务的前端／边缘代理。
- 支持gRPC：gRPC是一个来自谷歌的RPC框架，使用HTTP/2作为底层的多路传输。HTTP/2承载的gRPC请求和应答，都可以使用Envoy的路由和LB能力。
- 支持MongoDB L7：支持获取统计和连接记录等信息。
- 支持DynamoDB L7：支持获取统计和连接等信息。
- 服务发现：支持多种服务发现方法，包括异步DNS解析和通过REST请求服务发现服务。
- 健康检查：含有一个健康检查子系统，可以对上游服务集群进行主动的健康检查。也支持被动健康检查。
- 高级LB：包括自动重试、断路器，全局限速，阻隔请求，异常检测。未来还计划支持请求速率控制。
- 前端代理：可作为前端代理，包括TLS、HTTP/1.1、HTTP/2，以及HTTP L7路由。
- 极好的可观察性：对所有子系统，提供了可靠的统计能力。目前支持statsd以及兼容的统计库。还可以通过管理端口查看统计信息，还支持 第三方的分布式跟踪机制。
- 动态配置：提供分层的动态配置API，用户可以使用这些API构建复杂的集中管理部署。



###### Istio

Istio是一个用来连接、管理和保护微服务的开放平台。Istio提供一种简单的方式来建立已部署服务网络，具备负载均衡、服务间认证、监控等功能，而不需要改动任何服务代码。想要为服务增加对Istio的支持，您只需要在环境中部署一个特殊的边车（sidecar），使用Istio控制面板功能配置和管理代理，拦截微服务之间的所有网络通信。

Istio目前仅支持在Kubernetes上的服务部署，但未来版本中将支持其他环境。

Istio提供了一个完整的解决方案，通过为整个服务网格提供行为洞察和操作控制来满足微服务应用程序的多样化需求。它在服务网络中统一提供了许多关键功能：

- 流量管理：控制服务之间的流量和API调用的流向，使得调用更可靠，并使网络在恶劣情况下更加健壮。
- 可观察性：了解服务之间的依赖关系，以及它们之间流量的本质和流向，从而提供快速识别问题的能力。
- 策略执行：将组织策略应用于服务之间的互动，确保访问策略得以执行，资源在消费者之间良好分配。策略的更改是通过配置网格而不是修改应用程序代码。
- 服务身份和安全：为网格中的服务提供可验证身份，并提供保护服务流量的能力，使其可以在不同可信度的网络上流转。


Istio服务网格逻辑上分为数据面板和控制面板：

- 数据面板由一组智能代理（Envoy）组成，
- 代理部署为边车，调解和控制微服务之间所有的网络通信。
- 控制面板负责管理和配置代理来路由流量，以及在运行时执行策略。


下图显示了构成每个面板的不同组件：

[![7.jpg](http://dockone.io/uploads/article/20190626/39199c13751c3cd996c1b490aa9cac60.jpg)](http://dockone.io/uploads/article/20190626/39199c13751c3cd996c1b490aa9cac60.jpg)



###### Conduit

Conduit是为Kubernetes设计的一个超轻型服务网格服务，它可透明地管理在Kubernetes上运行的服务的运行时通信，使得它们更安全可靠。Conduit提供了可见性、可靠性和安全性的功能，而无需更改代码。

Conduit service mesh也是由数据面板和控制面板组成。数据面板承载应用实际的网络流量。控制面板驱动数据面板，并对外提供北向接口。

###### 对比

Linkerd和Envoy比较相似，都是一种面向服务通信的网络代理，均可实现诸如服务发现、请求路由、负载均衡等功能。它们的设计目标就是为了解决服务之间的通信问题，使得应用对服务通信无感知，这也是Service Mesh的核心理念。Linkerd和Envoy像是分布式的Sidebar，多个类似Linkerd和Envoy的proxy互相连接，就组成了service mesh。

而Istio则是站在了一个更高的角度，它将Service Mesh分为了Data Plane和Control Plane。Data Plane负责微服务间的所有网络通信，而Control Plane负责管理Data Plane Proxy：

[![8.jpg](http://dockone.io/uploads/article/20190626/3b1c60d24e0a667adab2e9cc04a75450.jpg)](http://dockone.io/uploads/article/20190626/3b1c60d24e0a667adab2e9cc04a75450.jpg)


并且Istio天生的支持Kubernetes，这也弥合了应用调度框架与Service Mesh之间的空隙。

关于Conduit的资料较少，从官方介绍看它的定位和功能与Istio类似。

###### Kubernetes + Service Mesh = 完整的微服务框架

Kubernetes已经成为了容器调度编排的事实标准，而容器正好可以作为微服务的最小工作单元，从而发挥微服务架构的最大优势。所以我认为未来微服务架构会围绕Kubernetes展开。而Istio和Conduit这类Service Mesh天生就是为了Kubernetes设计，它们的出现补足了Kubernetes在微服务间服务通讯上的短板。虽然Dubbo、Spring Cloud等都是成熟的微服务框架，但是它们或多或少都会和具体语言或应用场景绑定，并只解决了微服务Dev层面的问题。若想解决Ops问题，它们还需和诸如Cloud Foundry、Mesos、Docker Swarm或Kubernetes这类资源调度框架做结合：

[![9.png](http://dockone.io/uploads/article/20190626/f4b0ed3fd02c1218d11513ef2aa8b68e.png)](http://dockone.io/uploads/article/20190626/f4b0ed3fd02c1218d11513ef2aa8b68e.png)


但是这种结合又由于初始设计和生态，有很多适用性问题需要解决。

Kubernetes则不同，它本身就是一个和开发语言无关的、通用的容器管理平台，它可以支持运行云原生和传统的容器化应用。并且它覆盖了微服务的Dev和Ops阶段，结合Service Mesh，它可以为用户提供完整端到端的微服务体验。

所以我认为，未来的微服务架构和技术栈可能是如下形式：

[![10.jpg](http://dockone.io/uploads/article/20190626/c2bc51de0e8bd32f7ed23e6eca9e8a5b.jpg)](http://dockone.io/uploads/article/20190626/c2bc51de0e8bd32f7ed23e6eca9e8a5b.jpg)


多云平台为微服务提供了资源能力（计算、存储和网络等），容器作为最小工作单元被Kubernetes调度和编排，Service Mesh管理微服务的服务通信，最后通过API Gateway向外暴露微服务的业务接口。

我相信未来随着以Kubernetes和Service Mesh为标准的微服务框架的盛行，将大大降低微服务实施的成本，最终为微服务落地以及大规模使用提供坚实的基础和保障。

### 微服务架构详解
https://www.zhihu.com/question/65502802/answer/802678798

本文将介绍微服务架构和相关的组件，介绍他们是什么以及为什么要使用微服务架构和这些组件。本文侧重于简明地表达微服务架构的全局图景，因此不会涉及具体如何使用组件等细节。

要理解微服务，首先要先理解不是微服务的那些。通常跟微服务相对的是单体应用，即将所有功能都打包成在一个独立单元的应用程序。从单体应用到微服务并不是一蹴而就的，这是一个逐渐演变的过程。本文将以一个网上超市应用为例来说明这一过程。

#### **最初的需求**

几年前，小明和小皮一起创业做网上超市。小明负责程序开发，小皮负责其他事宜。当时互联网还不发达，网上超市还是蓝海。只要功能实现了就能随便赚钱。所以他们的需求很简单，只需要一个网站挂在公网，用户能够在这个网站上浏览商品、购买商品；另外还需一个管理后台，可以管理商品、用户、以及订单数据。

我们整理一下功能清单：

网站：

- - 用户注册、登录功能
  - 商品展示
  - 下单

管理后台：

- - 用户管理
  - 商品管理
  - 订单管理

由于需求简单，小明左手右手一个慢动作，网站就做好了。管理后台出于安全考虑，不和网站做在一起，小明右手左手慢动作重播，管理网站也做好了。总体架构图如下：

![img](https://pica.zhimg.com/50/v2-72023eb73961d33d560cd4419f803103_720w.jpg?source=1940ef5c)![](https://pica.zhimg.com/80/v2-72023eb73961d33d560cd4419f803103_720w.jpg?source=1940ef5c)

小明挥一挥手，找了家云服务部署上去，网站就上线了。上线后好评如潮，深受各类肥宅喜爱。小明小皮美滋滋地开始躺着收钱。

#### **随着业务发展……**

好景不长，没过几天，各类网上超市紧跟着拔地而起，对小明小皮造成了强烈的冲击。

在竞争的压力下，小明小皮决定开展一些营销手段：

- 开展促销活动。比如元旦全场打折，春节买二送一，情人节狗粮优惠券等等。
- 拓展渠道，新增移动端营销。除了网站外，还需要开发移动端APP，微信小程序等。
- 精准营销。利用历史数据对用户进行分析，提供个性化服务。
- ……

这些活动都需要程序开发的支持。小明拉了同学小红加入团队。小红负责数据分析以及移动端相关开发。小明负责促销活动相关功能的开发。

因为开发任务比较紧迫，小明小红没有好好规划整个系统的架构，随便拍了拍脑袋，决定把促销管理和数据分析放在管理后台里，微信和移动端APP另外搭建。通宵了几天后，新功能和新应用基本完工。这时架构图如下：

![img](https://pic1.zhimg.com/50/v2-1292f5a391142ac8da195787e28291bf_720w.jpg?source=1940ef5c)![img](https://pic1.zhimg.com/80/v2-1292f5a391142ac8da195787e28291bf_720w.jpg?source=1940ef5c)

这一阶段存在很多不合理的地方：

- 网站和移动端应用有很多相同业务逻辑的重复代码。
- 数据有时候通过数据库共享，有时候通过接口调用传输。接口调用关系杂乱。
- 单个应用为了给其他应用提供接口，渐渐地越改越大，包含了很多本来就不属于它的逻辑。应用边界模糊，功能归属混乱。
- 管理后台在一开始的设计中保障级别较低。加入数据分析和促销管理相关功能后出现性能瓶颈，影响了其他应用。
- [数据库表结构](https://www.zhihu.com/search?q=数据库表结构&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A802678798})被多个应用依赖，无法重构和优化。
- 所有应用都在一个数据库上操作，数据库出现性能瓶颈。特别是数据分析跑起来的时候，数据库性能急剧下降。
- 开发、测试、部署、维护愈发困难。即使只改动一个小功能，也需要整个应用一起发布。有时候发布会不小心带上了一些未经测试的代码，或者修改了一个功能后，另一个意想不到的地方出错了。为了减轻发布可能产生的问题的影响和线上业务停顿的影响，所有应用都要在凌晨三四点执行发布。发布后为了验证应用正常运行，还得盯到第二天白天的用户高峰期……
- 团队出现推诿扯皮现象。关于一些公用的功能应该建设在哪个应用上的问题常常要争论很久，最后要么干脆各做各的，或者随便放个地方但是都不维护。

尽管有着诸多问题，但也不能否认这一阶段的成果：快速地根据业务变化建设了系统。不过**紧迫且繁重的任务容易使人陷入局部、短浅的思维方式，从而做出妥协式的决策**。在这种架构中，每个人都只关注在自己的一亩三分地，缺乏全局的、长远的设计。长此以往，系统建设将会越来越困难，甚至陷入不断推翻、重建的循环。

#### **是时候做出改变了**

幸好小明和小红是有追求有理想的好青年。意识到问题后，小明和小红从琐碎的业务需求中腾出了一部分精力，开始梳理整体架构，针对问题准备着手改造。

> *要做改造，首先你需要有足够的精力和资源。如果你的需求方（业务人员、项目经理、上司等）很强势地一心追求需求进度，以致于你无法挪出额外的精力和资源的话，那么你可能无法做任何事……*

在编程的世界中，最重要的便是**抽象能力**。微服务改造的过程实际上也是个抽象的过程。小明和小红整理了网上超市的业务逻辑，抽象出公用的业务能力，做成几个公共服务：

- 用户服务
- 商品服务
- 促销服务
- 订单服务
- 数据分析服务

各个应用后台只需从这些服务获取所需的数据，从而删去了大量冗余的代码，就剩个轻薄的控制层和前端。这一阶段的架构如下：

![img](https://pic1.zhimg.com/50/v2-0882bc64f3f20939876d3433e51fad72_720w.jpg?source=1940ef5c)![img](https://pic1.zhimg.com/80/v2-0882bc64f3f20939876d3433e51fad72_720w.jpg?source=1940ef5c)

这个阶段只是将服务分开了，数据库依然是共用的，所以一些[烟囱式系统](https://www.zhihu.com/search?q=烟囱式系统&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A802678798})的缺点仍然存在：

1. 数据库成为性能瓶颈，并且有单点故障的风险。
2. 数据管理趋向混乱。即使一开始有良好的模块化设计，随着时间推移，总会有一个服务直接从数据库取另一个服务的数据的现象。
3. 数据库表结构可能被多个服务依赖，牵一发而动全身，很难调整。

如果一直保持共用数据库的模式，则整个架构会越来越僵化，失去了微服务架构的意义。因此小明和小红一鼓作气，把数据库也拆分了。所有持久化层相互隔离，由各个服务自己负责。另外，为了提高系统的实时性，加入了[消息队列机制](https://www.zhihu.com/search?q=消息队列机制&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A802678798})。架构如下：

![img](https://pic3.zhimg.com/50/v2-90388920d31fe35b791c6a92f758db18_720w.jpg?source=1940ef5c)![img](https://pic3.zhimg.com/80/v2-90388920d31fe35b791c6a92f758db18_720w.jpg?source=1940ef5c)

完全拆分后各个服务可以采用异构的技术。比如数据分析服务可以使用数据仓库作为持久化层，以便于高效地做一些统计计算；商品服务和促销服务访问频率比较大，因此加入了缓存机制等。

> *还有一种抽象出公共逻辑的方法是把这些公共逻辑做成公共的框架库。这种方法可以减少服务调用的性能损耗。但是这种方法的管理成本非常高昂，很难保证所有应用版本的一致性。*
> *数据库拆分也有一些问题和挑战：比如说跨库级联的需求，通过服务查询数据颗粒度的粗细问题等。但是这些问题可以通过合理的设计来解决。总体来说，数据库拆分是一个利大于弊的。*

微服务架构还有一个技术外的好处，它使整个系统的分工更加明确，责任更加清晰，每个人专心负责为其他人提供更好的服务。在单体应用的时代，公共的业务功能经常没有明确的归属。最后要么各做各的，每个人都重新实现了一遍；要么是随机一个人（一般是能力比较强或者比较热心的人）做到他负责的应用里面。在后者的情况下，这个人在负责自己应用之外，还要额外负责给别人提供这些公共的功能——而这个功能本来是无人负责的，仅仅因为他能力较强/比较热心，就莫名地背锅（这种情况还被美其名曰能者多劳）。结果最后大家都不愿意提供公共的功能。长此以往，团队里的人渐渐变得各自为政，不再关心全局的架构设计。

从这个角度上看，使用微服务架构同时也需要组织结构做相应的调整。所以说做微服务改造需要管理者的支持。

改造完成后，小明和小红分清楚各自的锅。两人十分满意，一切就像是[麦克斯韦方程组](https://www.zhihu.com/search?q=麦克斯韦方程组&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A802678798})一样漂亮完美。

然而……

#### **没有银弹**

春天来了，万物复苏，又到了一年一度的购物狂欢节。眼看着日订单数量蹭蹭地上涨，小皮小明小红喜笑颜开。可惜好景不长，乐极生悲，突然嘣的一下，系统挂了。

以往单体应用，排查问题通常是看一下日志，研究错误信息和调用堆栈。而**微服务架构整个应用分散成多个服务，定位故障点非常困难**。小明一个台机器一台机器地查看日志，一个服务一个服务地手工调用。经过十几分钟的查找，小明终于定位到故障点：促销服务由于接收的请求量太大而停止响应了。其他服务都直接或间接地会调用促销服务，于是也跟着宕机了。**在微服务架构中，一个服务故障可能会产生[雪崩效用](https://www.zhihu.com/search?q=雪崩效用&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A802678798})，导致整个系统故障**。其实在节前，小明和小红是有做过请求量评估的。按照预计，服务器资源是足以支持节日的请求量的，所以肯定是哪里出了问题。不过形势紧急，随着每一分每一秒流逝的都是白花花的银子，因此小明也没时间排查问题，当机立断在云上新建了几台虚拟机，然后一台一台地部署新的促销服务节点。几分钟的操作后，系统总算是勉强恢复正常了。整个故障时间内估计损失了几十万的销售额，三人的心在滴血……

事后，小明简单写了个日志分析工具（量太大了，文本编辑器几乎打不开，打开了肉眼也看不过来），统计了促销服务的访问日志，发现在故障期间，商品服务由于代码问题，在某些场景下会对促销服务发起大量请求。这个问题并不复杂，小明手指抖一抖，修复了这个价值几十万的Bug。

问题是解决了，但谁也无法保证不会再发生类似的其他问题。微服务架构虽然逻辑设计上看是完美的，但就像积木搭建的华丽宫殿一样，经不起风吹草动。微服务架构虽然解决了旧问题，也引入了新的问题：

- 微服务架构整个应用分散成多个服务，定位故障点非常困难。
- 稳定性下降。服务数量变多导致其中一个服务出现故障的概率增大，并且一个服务故障可能导致整个系统挂掉。事实上，在大[访问量](https://www.zhihu.com/search?q=访问量&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A802678798})的生产场景下，故障总是会出现的。
- 服务数量非常多，部署、管理的工作量很大。
- 开发方面：如何保证各个服务在持续开发的情况下仍然保持协同合作。
- 测试方面：服务拆分后，几乎所有功能都会涉及多个服务。原本单个程序的测试变为服务间调用的测试。测试变得更加复杂。

小明小红痛定思痛，决心好好解决这些问题。对故障的处理一般从两方面入手，一方面尽量减少故障发生的概率，另一方面降低故障造成的影响。

![img](https://pic3.zhimg.com/50/v2-9e24974c29f3a57ef1bdc5ea47c59566_720w.jpg?source=1940ef5c)![img](https://pic3.zhimg.com/80/v2-9e24974c29f3a57ef1bdc5ea47c59566_720w.jpg?source=1940ef5c)

#### **监控 - 监控服务性能指标**

在高并发分布式的场景下，故障经常是突然间就雪崩式爆发。所以必须建立完善的监控体系，尽可能发现故障的征兆。

微服务架构中组件繁多，各个组件所需要监控的指标不同。比如Redis缓存一般监控占用内存值、网络流量，数据库监控连接数、磁盘空间，业务服务监控并发数、响应延迟、错误率等。因此如果做一个大而全的监控系统来监控各个组件是不大现实的，而且扩展性会很差。一般的做法是让各个组件提供报告自己当前状态的接口（[metrics接口](https://www.zhihu.com/search?q=metrics接口&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A802678798})），这个接口输出的数据格式应该是一致的。然后部署一个指标采集器组件，定时从这些接口获取并保持组件状态，同时提供查询服务。最后还需要一个UI，从指标采集器查询各项指标，绘制监控界面或者根据阈值发出告警。

大部分组件都不需要自己动手开发，网络上有开源组件。小明下载了RedisExporter和MySQLExporter，这两个组件分别提供了Redis缓存和MySQL数据库的指标接口。微服务则根据各个服务的业务逻辑实现自定义的指标接口。然后小明采用Prometheus作为指标采集器，Grafana配置监控界面和邮件告警。这样一套微服务监控系统就搭建起来了：

![img](https://pica.zhimg.com/50/v2-ab2479317923472e06d5f3e0b8943944_720w.jpg?source=1940ef5c)![img](https://pica.zhimg.com/80/v2-ab2479317923472e06d5f3e0b8943944_720w.jpg?source=1940ef5c)

#### **定位问题 - 链路跟踪**-请求故障跟踪错误

在微服务架构下，一个用户的请求往往涉及多个内部服务调用。为了方便定位问题，需要能够记录每个用户请求时，微服务内部产生了多少服务调用，及其调用关系。这个叫做链路跟踪。

我们用一个Istio文档里的链路跟踪例子来看看效果：

![img](https://pic3.zhimg.com/50/v2-c1e791200de645b39ed670f9b86109e8_720w.jpg?source=1940ef5c)![img](https://pic3.zhimg.com/80/v2-c1e791200de645b39ed670f9b86109e8_720w.jpg?source=1940ef5c)

> *图片来自[Istio文档](https://link.zhihu.com/?target=https%3A//istio.io/zh/docs/tasks/telemetry/distributed-tracing/zipkin/)*

从图中可以看到，这是一个用户访问productpage页面的请求。在请求过程中，productpage服务顺序调用了details和reviews服务的接口。而reviews服务在响应过程中又调用了ratings的接口。整个链路跟踪的记录是一棵树：

![img](https://pic2.zhimg.com/50/v2-da001bd5ae83cd8fbcca1dec0db8dc24_720w.jpg?source=1940ef5c)![img](https://pic2.zhimg.com/80/v2-da001bd5ae83cd8fbcca1dec0db8dc24_720w.jpg?source=1940ef5c)

要实现链路跟踪，每次服务调用会在HTTP的HEADERS中记录至少记录四项数据：

- traceId：traceId标识一个用户请求的调用链路。具有相同traceId的调用属于同一条链路。
- spanId：标识一次服务调用的ID，即链路跟踪的节点ID。
- parentId：父节点的spanId。
- requestTime & responseTime：请求时间和响应时间。

另外，还需要调用日志收集与存储的组件，以及展示链路调用的UI组件。

![img](https://pic2.zhimg.com/50/v2-c1ac0f0772b5ddedafa44636e75b3ded_720w.jpg?source=1940ef5c)![img](https://pic2.zhimg.com/80/v2-c1ac0f0772b5ddedafa44636e75b3ded_720w.jpg?source=1940ef5c)

以上只是一个极简的说明，关于链路跟踪的理论依据可详见Google的[Dapper](https://link.zhihu.com/?target=http%3A//bigbully.github.io/Dapper-translation/)

了解了理论基础后，小明选用了Dapper的一个开源实现Zipkin。然后手指一抖，写了个HTTP请求的拦截器，在每次HTTP请求时生成这些数据注入到HEADERS，同时异步发送调用日志到Zipkin的日志收集器中。这里额外提一下，HTTP请求的拦截器，可以在微服务的代码中实现，也可以使用一个网络代理组件来实现（不过这样子每个微服务都需要加一层代理）。

链路跟踪只能定位到哪个服务出现问题，不能提供具体的错误信息。查找具体的错误信息的能力则需要由日志分析组件来提供。

#### **分析问题 - 日志分析**-（定位哪个服务故障之后分析故障服务的日志文件定位问题）

日志分析组件应该在微服务兴起之前就被广泛使用了。即使单体应用架构，当访问数变大、或服务器规模增多时，[日志文件](https://www.zhihu.com/search?q=日志文件&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A802678798})的大小会膨胀到难以用文本编辑器进行访问，更糟的是它们分散在多台服务器上面。排查一个问题，需要登录到各台服务器去获取日志文件，一个一个地查找（而且打开、查找都很慢）想要的日志信息。

因此，在应用规模变大时，我们需要一个日志的“**搜索引擎**”。以便于能准确的找到想要的日志。另外，数据源一侧还需要收集日志的组件和展示结果的UI组件：

![img](https://pic2.zhimg.com/50/v2-b721b26bd974169cffd107ba4eec54f0_720w.jpg?source=1940ef5c)![img](https://pic2.zhimg.com/80/v2-b721b26bd974169cffd107ba4eec54f0_720w.jpg?source=1940ef5c)

小明调查了一下，使用了大名鼎鼎地ELK日志分析组件。ELK是Elasticsearch、Logstash和Kibana三个组件的缩写。

- Elasticsearch：搜索引擎，同时也是日志的存储。
- Logstash：日志采集器，它接收日志输入，对日志进行一些预处理，然后输出到Elasticsearch。
- Kibana：UI组件，通过Elasticsearch的API查找数据并展示给用户。

最后还有一个小问题是如何将日志发送到Logstash。一种方案是在日志输出的时候直接调用Logstash接口将日志发送过去。这样一来又（咦，为啥要用“又”）要修改代码……于是小明选用了另一种方案：日志仍然输出到文件，每个服务里再部署个Agent扫描日志文件然后输出给Logstash。

#### **网关 - 权限控制，服务治理-调用服务权限控制**

拆分成微服务后，出现大量的服务，大量的接口，使得整个调用关系乱糟糟的。经常在开发过程中，写着写着，忽然想不起某个数据应该调用哪个服务。或者写歪了，调用了不该调用的服务，本来一个只读的功能结果修改了数据……

为了应对这些情况，微服务的调用需要一个把关的东西，也就是网关。在调用者和被调用者中间加一层网关，每次调用时进行权限校验。另外，网关也可以作为一个提供服务接口文档的平台。

使用网关有一个问题就是要决定在多大粒度上使用：最粗粒度的方案是整个微服务一个网关，微服务外部通过网关访问微服务，微服务内部则直接调用；最细粒度则是所有调用，不管是微服务内部调用或者来自外部的调用，都必须通过网关。折中的方案是按照业务领域将微服务分成几个区，区内直接调用，区间通过网关调用。

由于整个网上超市的服务数量还不算特别多，小明采用的最粗粒度的方案：

![img](https://pic1.zhimg.com/50/v2-84a6eee84a5dc3f2e97f56b4148bbc66_720w.jpg?source=1940ef5c)![img](https://pic1.zhimg.com/80/v2-84a6eee84a5dc3f2e97f56b4148bbc66_720w.jpg?source=1940ef5c)

#### **服务注册于发现 - 动态扩容-自动发现部署的服务并注册到反向代理服务器Nginx**

前面的组件，都是旨在降低故障发生的可能性。然而故障总是会发生的，所以另一个需要研究的是如何降低故障产生的影响。

最粗暴的（也是最常用的）故障处理策略就是冗余。一般来说，一个服务都会部署多个实例，这样一来能够分担压力提高性能，二来即使一个实例挂了其他实例还能响应。

冗余的一个问题是使用几个冗余？这个问题在时间轴上并没有一个切确的答案。根据服务功能、时间段的不同，需要不同数量的实例。比如在平日里，可能4个实例已经够用；而在促销活动时，流量大增，可能需要40个实例。因此冗余数量并不是一个固定的值，而是根据需要实时调整的。

一般来说新增实例的操作为：

1. 部署新实例
2. 将新实例注册到负载均衡或DNS上

操作只有两步，但如果注册到负载均衡或DNS的操作为人工操作的话，那事情就不简单了。想想新增40个实例后，要手工输入40个IP的感觉……

解决这个问题的方案是服务自动注册与发现。首先，需要部署一个服务发现服务，它提供所有已注册服务的[地址信息](https://www.zhihu.com/search?q=地址信息&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A802678798})的服务。DNS也算是一种服务发现服务。然后各个应用服务在启动时自动将自己注册到服务发现服务上。并且应用服务启动后会实时（定期）从服务发现服务同步各个应用服务的地址列表到本地。服务发现服务也会定期检查应用服务的健康状态，去掉不健康的[实例地址](https://www.zhihu.com/search?q=实例地址&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A802678798})。这样新增实例时只需要部署新实例，实例下线时直接关停服务即可，服务发现会自动检查服务实例的增减。

![img](https://pic2.zhimg.com/50/v2-5b0fea85e31caa7b6ed88cb6fbdf5005_720w.jpg?source=1940ef5c)![img](https://pic2.zhimg.com/80/v2-5b0fea85e31caa7b6ed88cb6fbdf5005_720w.jpg?source=1940ef5c)

服务发现还会跟客户端负载均衡配合使用。由于应用服务已经同步服务地址列表在本地了，所以访问微服务时，可以自己决定负载策略。甚至可以在服务注册时加入一些元数据（服务版本等信息），客户端负载则根据这些元数据进行流量控制，实现A/B测试、蓝绿发布等功能。

服务发现有很多组件可以选择，比如说Zookeeper 、Eureka、Consul、Etcd等。不过小明觉得自己水平不错，想炫技，于是基于Redis自己写了一个……

#### **熔断、服务降级、限流**

##### **熔断-服务挂了之后通过一个服务直接返回错误，这个服务后面会定期检查服务是否开启，如果开启就会执行服务**

当一个服务因为各种原因停止响应时，调用方通常会等待一段时间，然后超时或者收到错误返回。如果调用链路比较长，可能会导致请求堆积，整条链路占用大量资源一直在等待下游响应。所以当多次访问一个服务失败时，应熔断，标记该服务已停止工作，直接返回错误。直至该服务恢复正常后再重新建立连接。

![img](https://pic1.zhimg.com/50/v2-1fbc686e2aeef234b9cfe096274e0206_720w.jpg?source=1940ef5c)![img](https://pic1.zhimg.com/80/v2-1fbc686e2aeef234b9cfe096274e0206_720w.jpg?source=1940ef5c)

> *图片来自《[微服务设计](https://link.zhihu.com/?target=https%3A//book.douban.com/subject/26772677/)》*

##### **服务降级-整体服务的一个服务挂掉之后就不用这个服务了，以保证主服务的运行**

当下游服务停止工作后，如果该服务并非核心业务，则上游服务应该降级，以保证核心业务不中断。比如网上超市下单界面有一个推荐商品凑单的功能，当推荐模块挂了后，下单功能不能一起挂掉，只需要暂时关闭推荐功能即可。

##### **限流-下游服务限制来自上游服务的服务请求防止自己挂掉**

一个服务挂掉后，上游服务或者用户一般会习惯性地重试访问。这导致一旦服务恢复正常，很可能因为瞬间网络流量过大又立刻挂掉，在棺材里重复着仰卧起坐。因此服务需要能够自我保护——限流。限流策略有很多，最简单的比如当单位时间内请求数过多时，丢弃多余的请求。另外，也可以考虑分区限流。仅拒绝来自产生大量请求的服务的请求。例如商品服务和订单服务都需要访问促销服务，商品服务由于代码问题发起了大量请求，促销服务则只限制来自商品服务的请求，来自订单服务的请求则正常响应。

![img](https://pica.zhimg.com/50/v2-9a4737be63222fb4928ac6a26b60c92b_720w.jpg?source=1940ef5c)![img](https://pica.zhimg.com/80/v2-9a4737be63222fb4928ac6a26b60c92b_720w.jpg?source=1940ef5c)

#### **测试**

微服务架构下，测试分为三个层次：

1. 端到端测试：覆盖整个系统，一般在用户界面机型测试。
2. 服务测试：针对服务接口进行测试。
3. [单元测试](https://www.zhihu.com/search?q=单元测试&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A802678798})：针对代码单元进行测试。

三种测试从上到下实施的容易程度递增，但是测试效果递减。端到端测试最费时费力，但是通过测试后我们对系统最有信心。单元测试最容易实施，效率也最高，但是测试后不能保证整个系统没有问题。

![img](https://pic3.zhimg.com/50/v2-7da95a84f6c0dfd889ceb96acdf98b88_720w.jpg?source=1940ef5c)![img](https://pic3.zhimg.com/80/v2-7da95a84f6c0dfd889ceb96acdf98b88_720w.jpg?source=1940ef5c)

由于端到端测试实施难度较大，一般只对核心功能做端到端测试。一旦端到端测试失败，则需要将其分解到单元测试：则分析失败原因，然后编写单元测试来重现这个问题，这样未来我们便可以更快地捕获同样的错误。

服务测试的难度在于服务会经常依赖一些其他服务。这个问题可以通过Mock Server解决：

![img](https://pic2.zhimg.com/50/v2-3f13157528d14462e26d08d1d6be0817_720w.jpg?source=1940ef5c)![img](https://pic2.zhimg.com/80/v2-3f13157528d14462e26d08d1d6be0817_720w.jpg?source=1940ef5c)

单元测试大家都很熟悉了。我们一般会编写大量的单元测试（包括回归测试）尽量覆盖所有代码。

#### **微服务框架**

指标接口、链路跟踪注入、日志引流、服务注册发现、路由规则等组件以及熔断、限流等功能都需要在应用服务上添加一些对接代码。如果让每个应用服务自己实现是非常耗时耗力的。基于DRY的原则，小明开发了一套微服务框架，将与各个组件对接的代码和另外一些公共代码抽离到框架中，所有的应用服务都统一使用这套框架进行开发。

使用微服务框架可以实现很多自定义的功能。甚至可以将程序调用堆栈信息注入到链路跟踪，实现代码级别的链路跟踪。或者输出线程池、连接池的状态信息，实时监控服务底层状态。

使用统一的微服务框架有一个比较严重的问题：框架更新成本很高。每次框架升级，都需要所有应用服务配合升级。当然，一般会使用兼容方案，留出一段并行时间等待所有应用服务升级。但是如果应用服务非常多时，升级时间可能会非常漫长。并且有一些很稳定几乎不更新的应用服务，其负责人可能会拒绝升级……因此，使用统一微服务框架需要完善的版本管理方法和开发管理规范。

#### **另一条路 - Service Mesh**

另一种抽象公共代码的方法是直接将这些代码抽象到一个反向代理组件。每个服务都额外部署这个代理组件，所有出站入站的流量都通过该组件进行处理和转发。这个组件被称为Sidecar。

> *Sidecar不会产生额外网络成本。Sidecar会和微服务节点部署在同一台主机上并且共用相同的虚拟网卡。所以sidecar和微服务节点的通信实际上都只是通过内存拷贝实现的。*

![img](https://pic1.zhimg.com/50/v2-567a3bd63e4894d1358c6141fca7ba72_720w.jpg?source=1940ef5c)![img](https://pic1.zhimg.com/80/v2-567a3bd63e4894d1358c6141fca7ba72_720w.jpg?source=1940ef5c)

> *图片来自：[Pattern: Service Mesh](https://link.zhihu.com/?target=http%3A//philcalcado.com/2017/08/03/pattern_service_mesh.html)*

Sidecar只负责网络通信。还需要有个组件来统一管理所有sidecar的配置。在Service Mesh中，负责网络通信的部分叫[数据平面](https://www.zhihu.com/search?q=数据平面&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A802678798})（data plane），负责配置管理的部分叫控制平面（control plane）。数据平面和控制平面构成了Service Mesh的基本架构。

![img](https://pic3.zhimg.com/50/v2-c79af0ff0b1b11ed4586701a3a2e314c_720w.jpg?source=1940ef5c)![img](https://pic3.zhimg.com/80/v2-c79af0ff0b1b11ed4586701a3a2e314c_720w.jpg?source=1940ef5c)

> *图片来自：[Pattern: Service Mesh](https://link.zhihu.com/?target=http%3A//philcalcado.com/2017/08/03/pattern_service_mesh.html)*

Sevice Mesh相比于微服务框架的优点在于它不侵入代码，升级和维护更方便。它经常被诟病的则是性能问题。即使回环网络不会产生实际的网络请求，但仍然有内存拷贝的额外成本。另外有一些集中式的流量处理也会影响性能。

#### **结束、也是开始**

微服务不是架构演变的终点。往细走还有Serverless、FaaS等方向。另一方面也有人在唱合久必分分久必合，重新发现[单体架构](https://www.zhihu.com/search?q=单体架构&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A802678798})……

不管怎样，微服务架构的改造暂时告一段落了。小明满足地摸了摸日益光滑的脑袋，打算这个周末休息一下约小红喝杯咖啡。



# 算法和数据结构相关

## 语言特性
1. 整数反转：A*10+B的溢出判断
2. 字符串转换整数：字符判断函数，溢出判断
3. 结构体指针的指针，二叉搜索树


## 暴力枚举找规律模拟
1. 两个正序数组的中位数（两个正序数组的第K大）：合并正序数组后找中位数和第K大
2. 最长回文子串：中心扩展法
3. Z字形变换：找变换得到的数的排列规律
4. 盛最多水的容器：双指针
5. 整数转罗马数字（罗马数字转整数）
6. 下一个排列：upper_bound, sort, vector
7. 外观数列：模拟
8. 数独（八皇后问题）：复杂度上限很高，但是样例可以回溯暴力通过
9. 缺失的第一个正整数：找规律
10. 顺时针螺旋矩阵：模拟
11. 爬楼梯问能否到达（爬楼梯问多少种爬法，爬楼梯问最少跳几次）：找右边边界
12. 二叉树的最大路径和
13. 给小朋友评分，按照评分分糖果，规则是中间分高的分多，每个人至少一个糖果
14. 数学除法模拟（分数转小数）
15. Nim游戏，先手在4的倍数条件下必输
16. 完全平方数，枚举加法情况找规律

## 基础算法
### 状态机
1. 只出现一次的数字，其他数字都出现两次或者三次：状态机

### 二分
1. 两个正序数组的中位数（两个正序数组的第K大）
2. 三数之和为0：枚举两个，查找第三个
3. 搜索旋转排序数组
4. 在排序数组中找一个元素的起始位置和终止位置：lowerbound 和upperbound
5. 求平方根
6. 寻找峰值，一个数组的峰值时一个数，他大于相邻的两个数

### 双指针
1. 两数之和，三数之和，四数之和：有序数组一个元素增大时另外一个减小
2. 最接近的是那个数之和
3. 数组中距离第i个数最远的大于第i个数的数：双指针
4. 求两个相交链表的交点


### 单调栈
1. 数组中距离第i个数最近的小于第i个数的数：单调栈
2. 二维数组最大全为1的举行
3. 柱状图最大矩形：单调栈


### 回溯DFS
1. 删除链表的第n个节点
2. 括号生成
3. N皇后问题：回溯剪枝
4. 二叉树的最大深度：DFS


### 全排列递归DFS
1. 包含重复数字的数组的不重复的全排列：剪枝
2. 全排列的第k个数列：剪枝

### 全部组合
1. 迭代：从0开始位运算
2. dfs：对于一个数可选和不选两个状态

### 滑动窗口
1. 最小覆盖子串：左右两个端往右边移动
2. 长度最小的子数组：双指针


### BFS
1. 二叉树的层序遍历：BFS
2. 二叉树的锯齿形层序遍历：双向队列判断进出开口
3. 水洼：BFS联通块


### 位运算
1. 奇数偶数：与
2. 只出现了一次的数字：两个相同相消，异或
3. 格雷编码
4. 给一个元素在[0,n]的n个数的数组，找出缺失的数： 异或

### 基数排序
1. 给一个无序数组，求其有序后两个数字的间隔最大，间隔定义为后一个数减去前一个数（要求线性空间和复杂度）

### 归并排序和快速排序

### 排序

排序的稳定性：排序时相同元素的相对位置不发生改变就是稳定的排序算法

稳定的排序算法有：冒泡排序，插入排序，归并排序，计数排序，基数排序，桶排序

不稳定的排序算法：选择排序，快速排序，堆排序，希尔排序

![](https://s7.51cto.com/images/blog/202107/02/683f8e7c222a81533a3dd448e0c49a5b.png?x-oss-process=image/watermark,size_16,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_90,type_ZmFuZ3poZW5naGVpdGk=)

[快排，堆排，归并排，选择排，插入排，冒泡排实现](https://www.nowcoder.com/practice/2baf799ea0594abd974d37139de27896?tpId=117&tqId=37851&companyId=139&rp=1&ru=%2Fcompany%2Fhome%2Fcode%2F139&qru=%2Fta%2Fjob-code-high%2Fquestion-ranking&tab=answerKey)



## 数据结构

### 线性表、树形结构和图形结构的区别

线性表：数据元素之间仅有线性关系，每个数据元素只有一个直接前驱和一个直接后继

树形结构：数据元素之间有明显的层次关系，并且每一层上的数据元素可能和下一层中多个元素（即其孩子结点）相关，但只能和上一层中一个元素（即其双亲结点）相关

图形结构：结点之间的关系可以是任意的，图中任意两个数据元素之间都可能相关


### 哈希表-解决哈希冲突方式

1. 开放定址法：
   1. 线性探查：从冲突位置后面找到一个空位置
   2. 二次探查：以一定步长左右探查（-1，1，-2，2）
   3. 随机数探查：生成随机步长探查
2. 再哈希法：使用多个哈希函数，一个冲突就用另外一个哈希函数生成哈希值
3. 链地址法：对哈希值开辟一个链表，如果冲突就添加到链表中
4. 建立公共溢出表：将哈希表分为基本表和溢出表，如果冲突，就将冲突数据放到溢出表。查找时候，如果基本表找到就返回，否则在溢出表顺序找。这种方式在数据冲突少的时候好用。

### 数组和矩阵

1. [数组中重复的数字-对于n长的元素大小在0到n-1之间的数组可以将第i个元素放到arr[i]的位置处理](https://www.nowcoder.com/practice/6fe361ede7e54db1b84adc81d09d8524?tpId=13&tqId=11203&tab=answerKey&from=cyc_github)

1. https://www.nowcoder.com/practice/e3769a5f49894d49b871c09cadd13a61?tpId=117&tqId=37804&companyId=139&rp=1&ru=%2Fcompany%2Fhome%2Fcode%2F139&qru=%2Fta%2Fjob-code-high%2Fquestion-ranking&tab=answerKey)

### 优先队列

1. [优先队列-合并K个有序表](https://www.nowcoder.com/practice/65cfde9e5b9b4cf2b6bafa5f3ef33fa6?tpId=190&tqId=35193&rp=1&ru=%2Factivity%2Foj&qru=%2Fta%2Fjob-code-high-rd%2Fquestion-ranking&tab=answerKey)

### 栈

1. [栈-链表反转，链表相加，链表从后往前每K个分一组](https://www.nowcoder.com/practice/c56f6c70fb3f4849bc56e33ff2a50b6b?tpId=190&tqId=35219&rp=1&ru=%2Fta%2Fjob-code-high-rd&qru=%2Fta%2Fjob-code-high-rd%2Fquestion-ranking&tab=answerKey)
2. [栈-括号匹配]( https://www.nowcoder.com/practice/37548e94a270412c8b9fb85643c8ccc2?tpId=117&tqId=37749&companyId=139&rp=1&ru=%2Fcompany%2Fhome%2Fcode%2F139&qru=%2Fta%2Fjob-code-high%2Fquestion-ranking&tab=answerKey )

### 队列
1. 一个队列实现栈，两个队列实现栈（没有工程意义，只是有些教学意义）
### 哈希链表
1. 实现LRU访存算法：哈希链表LinkedHashMap(哈希表+双向链表）
1. [链式哈希表-LRU缓存结构-LinkedHashmap](https://www.nowcoder.com/practice/e3769a5f49894d49b871c09cadd13a61?tpId=117&tqId=37804&companyId=139&rp=1&ru=%2Fcompany%2Fhome%2Fcode%2F139&qru=%2Fta%2Fjob-code-high%2Fquestion-ranking&tab=answerKey)


### 链表
1. 两数之和
2. 删除链表的倒数第n个节点：回溯
3. 两个有序链表的合并，利用旧的节点
4. 快慢指针：求有环单链表的环的入点, 求环的长度，求链表的中点
5. 链表插入排序
6. 链表归并排序（O(1)空间复杂度，快慢指针寻找中点）


###  栈
1. 检查括号
2. 最长有效括号：栈模拟找规律
3. 逆波兰表达式计算
4. 用两个栈实现队列
4. [栈-链表反转，链表相加，链表从后往前每K个分一组](https://www.nowcoder.com/practice/c56f6c70fb3f4849bc56e33ff2a50b6b?tpId=190&tqId=35219&rp=1&ru=%2Fta%2Fjob-code-high-rd&qru=%2Fta%2Fjob-code-high-rd%2Fquestion-ranking&tab=answerKey)
6. [栈-括号匹配]( https://www.nowcoder.com/practice/37548e94a270412c8b9fb85643c8ccc2?tpId=117&tqId=37749&companyId=139&rp=1&ru=%2Fcompany%2Fhome%2Fcode%2F139&qru=%2Fta%2Fjob-code-high%2Fquestion-ranking&tab=answerKey )


### 映射
1. 串联所有单词的子串：map判重

### unordered_map
1. 最长连续序列：unordered_map映射只是按key编号，key是无序的，复杂度查找复杂度O(1)

### 树
1. 二叉树的中序遍历
2. 构造二叉搜索树：先排序，构造的时候使用L,R来划定构造的节点区域，二叉排序树是中序遍历
3. 检查二叉搜索树是否合格：二叉搜索树的中序遍历是有序的
4. 检查两个二叉树是否相等：中序遍历+比较访问顺序; 设置两个指针同时移动
5. 检查两个二叉树是否对称：中序遍历+数组对称；设置两个指针同时对称移动
6. 从前序与中序遍历构造二叉树：结构体指针的指针来构造树
7. 平衡二叉树（有序数组构造平衡二叉树，严格平衡二叉树）
8. 二叉搜索树
9. 二叉树的最大路径和
10. 二叉树转先序|中序|后续遍历链表（添加一个空节点）：二叉搜索树迭代器
11. 二叉树翻转
11. [二叉树层序遍历-链式二叉树的层序遍历](https://www.nowcoder.com/practice/04a5560e43e24e9db4595865dc9c63a3?tpId=117&tqId=37723&companyId=139&rp=1&ru=%2Fcompany%2Fhome%2Fcode%2F139&qru=%2Fta%2Fjob-code-high%2Fquestion-ranking&tab=answerKey)
13. [二叉树-二叉树的最近公共祖先](https://www.nowcoder.com/practice/e0cc33a83afe4530bcec46eba3325116?tpId=190&tqId=35225&rp=1&ru=%2Factivity%2Foj&qru=%2Fta%2Fjob-code-high-rd%2Fquestion-ranking&tab=answerKey)
14. [二叉树DFS-二叉树路径和](https://leetcode-cn.com/problems/path-sum-ii/)

## 字符串算法

## KMP
1. 实现substr(): kmp 得到第一个匹配的位置
2. kmp的最短的匹配子串，子串个数，是否存在匹配子串
3. kmp求最长前缀回文串（rabin-carp字符串哈希算法，Manchester算法）

### 模式匹配

### Trie树
1. 构造Trie树，Trie树的插入，查找，前缀

### rabin-carp字符串哈希算法
1. 求最长前缀回文串

### Manchester算法
1. 求最长前缀回文串


## 动态规划
### 简单动态规划
1. 无重复字符最长子串（最大连续和）
2. 最长回文子串：动态规划
3. 最长有效括号：设置dp并找转移方程
4. 给定矩形网格并且规定只能往右或者往下走，问做到右下角有多少种走法（当有障碍有多少种走法）
5. 将一个单词转换成另外一个单词的最小转换次数：定义状态和找状态转移方程
6. 解码方法：对字母编码1，2...，问反向回字母串一共多少中解法
7. 给定1,2,3...n, 求二叉搜索树的个数：找规律
8. 字符串t匹配母串子序列的个数
9. 买卖股票的最佳时机（第一种，第i天有两个状态；第二种，第i天有五个状态）
10. 分割回文串（1，求分割所有方案；2，求分割最少次数）
11. 乘积最大子数组
12. 找一个子串使得任意两个元素再原数组中位置不相邻，最大化这个子串的和
13. 最长摆动序列
14. 最长上升子序列
14. [斐波拉契数列](https://www.nowcoder.com/practice/8c82a5b80378478f9484d87d1c5f12a4?tpId=117&tqId=37764&companyId=139&rp=1&ru=%2Fcompany%2Fhome%2Fcode%2F139&qru=%2Fta%2Fjob-code-high%2Fquestion-ranking&tab=answerKey)
16. [最长递增子序列]()

### 树形DP
1. 在一棵二叉树上选择一些顶点使得选得的所有数值和最大，相邻顶点不能被选择

### 背包
1. 01背包
2. 完全背包

## 树
### 线段树
1. 区间求和，最大最小，总和，最大公约数，最小公倍数
线段树构造了一个堆来管理整个数组，每个节点管理一段数组的元素，线段树的节点从1开始编号，1管理整个数组的性质（和，最值等）
1. 线段树求区间和
```
def getsum(l, r, s, t, q):
	# [l,r]是需要求的区间，q是当前节点编号，[s,t]是管理的元素
	if s>=l && t<=r:
		return D[q]
	mid = s+(t-s)/2
	tot = 0 
	if mid>=l:
		tot+=getsum(l,r,s,m,q*2)
	if mid<r :
		tot += getsum(l,r,mid+1,r,q*2+1)
	return tot 
```

### 树状数组
树状数组在数组上模拟了一个树，这棵树的性质是
1. 数组A存储从下表1开始，树C的节点从1开始标记
2. 树节点C的第i个节点管理的数组A中的元素是A[i-2^k+1]到A[i]

这样，我们在树状数组上的操作是
1. 单点更新，区间求和
	1. 求前缀和
	```
	ans = 0 
	while i>0:
		ans += C[i]
		i -= i&(-i)
	return ans 
	```
	2. 更新点
	```
	while i<=n
		C[i] += k
		i += i&(-i)
	```
2. 区间更新，单点查询
	对差分建立树状数组D
	```
	A[0]=0
	D[i] = A[i]-A[i-1]
	A[i] = D[1]+D[2]+...+D[i]
	```
	单点的数值是getsum(i)
3. 区间更新，区间求和
建立差分D和(i-1)D[i]的树状数组sum1, sum2
求前缀和是ans += sum1-sum2

## 图论
### 最短路

### DIJKSTRA算法
1. 单词接龙：构图算法使用虚拟节点构图复杂度为(nlogn\*单词长度)，一般算法复杂度是n^2

### 有向无环图的拓扑排序
1. 判断先修课程有没有环: 判断入度
2. 拓扑排序的顺序


## 数学
### 欧几里得算法和扩展欧几里得算法
1. 欧几里得算法求gcd(a,b)，两个数的最大公约数
2. 扩展欧几里得算法求最大公约数和ax+by=gcd的关于x和y的通解
3. 解同余方程组

### 素数筛选

### 极小化极大值
1. 猜数字大小：1到n里找到一个正确的数的开销是从i开始的最大的开销的最小值。dfs+记忆化

### 组合
1. 组合总和：暴力回溯剪枝
2. 交错字符串：动态规划

### 按位运算
1. 求0到n的所有数的比特数1的个数算法（动态规划+位运算，dp[n] = dp[n&(n-1)], 去除最低有效位
2. 判定n是否是3的幂
		1. (3^19%n==0)
		2.  (log(n)/log(3) + epsilon )<2 * epsilon
		3.  转换成以3为基的3进制数按位操作
		4.  不断除以3检查余数是不是0
3. 判断n是否是4的幂
    1. (log(n)/log(4)/2 + epsilon )<2 * epsilon
    2. 按位操作,：只有一位是1并且那一位是奇数位
    3. 取模性质：只有一位是1并且对3取模是1，如果是2的幂那么对3取模是2


### 矩阵变换
1. 矩阵旋转


## 杂题
### 数组
1. 是否存在一个连续k个数，存在两个数的差的绝对值小于一个常熟t
2. 最大全为1的正方形：枚举正方形+矩阵和的累加
3. 判断一个二维有序数组中存在一个数：O(m+n)的算法，假设target在右上角，每次丢掉一行或一列
4. 求两个数组的交集，交集元素出现的个数是两个数组中出现最少的那个部分
			1.两个unordered_map
			2.如果一个数组存在磁盘，很大不能全部读入内存，怎么做：用一个unordered_map记录出现次数，每次读入另外一个数组，如果他在第一个map出现，就减map出现次数，并且添加到交集，如果不出现或者是0，那就不添加。
			3. 两个变有序，双指针。
5. 找规律题目：累加数，判断一个字符串是否可以划分成一个斐波拉契数列。（首先发现这个数列一定是一个递增数列，其次，确定了前面两个数，那么这个数列也就确定了。由此枚举前面两个数，再枚举第三个数，如果这个数比前面两个小，那么接着枚举，如果相等，那么更新前面两个数，如果大于，那么这个数列不存在）
6. 水壶问题倒水（状态转移或者最大公约数问题）
7. 查找最小的k对数字（多指针+优先队列优化）
		给定两个升序数组，求前k对和最小的二元数组

## trick
1. 比特位计数，求比特数1的个数算法，log(n):
    n&(n-1)可以去除n的最后一个为1的位变成0，这样每次都循环这个式子，就可以计算n的所有位为1的个数
2. （496）求数组某一个元素下一个比他大的数：单调栈
3. 链表的公共节点
4. 旋转数组的二分查找
5. 快排
6. 栈如何实现队列

### 双指针 快慢指针

1. [快慢指针-判断链表是否有环和求环节点](https://www.nowcoder.com/practice/650474f313294468a4ded3ce0f7898b9?tpId=117&tqId=37714&companyId=139&rp=1&ru=%2Fcompany%2Fhome%2Fcode%2F139&qru=%2Fta%2Fjob-code-high%2Fquestion-ranking&tab=answerKey)
2. [求增量要先减A再加B，就可求B-A增量-使数组唯一的最小增量](https://leetcode-cn.com/problems/minimum-increment-to-make-array-unique/)

3. [双向双指针-接雨水问题](https://www.nowcoder.com/practice/31c1aed01b394f0b8b7734de0324e00f?tpId=188&&tqId=38549&rp=1&ru=/activity/oj&qru=/ta/job-code-high-week/question-ranking)
4. [双指针/栈-合并区间](https://leetcode-cn.com/company/mi-history/custom/SW50ZXJ2aWV3Q3VzdG9tU2Vzc2lvbk5vZGU6NTUzNjk4/merge-intervals/)

### 找规律

1. [完全平方数](https://leetcode-cn.com/problems/perfect-squares/)

2. 交换两个变量的值

   ```
   使用额外变量
   c = a;
   a = b ;
   b = c ;
   
   使用位运算
   a = a^b ;
   b = a^b ;
   a = a^b ;
   
   使用加减法
   a = a+b ;
   b = a-b ;
   a = a-b ;
   
   使用乘除法
   a = a*b ;
   b = a/b ;
   a = a/b ;
   
   上面的算法都只能处理整数，而且加减法和乘除法可能溢出，不能处理小数
   ```

## 面试&答疑

1. 说下[二叉树](https://www.nowcoder.com/jump/super-jump/word?word=二叉树)和B树的区别和各自优缺点?(没答好，B树效率高且适合数据多的情况，节点[二分查找](https://www.nowcoder.com/jump/super-jump/word?word=二分查找)，磁盘块读取，[二叉树](https://www.nowcoder.com/jump/super-jump/word?word=二叉树)适合数据量少的直接全部加载到内存去读)

2. HasnMap和ConcurrentHashMap的区别

3. [红黑树](https://www.nowcoder.com/jump/super-jump/word?word=红黑树)有了解吗，聊聊b树和b+树，b树和[二叉树](https://www.nowcoder.com/jump/super-jump/word?word=二叉树)比较下优缺点

4. 讲一下稳定的排序算法和不稳定的排序算法

5. 讲一下快速排序的思想

6. ArrayList和LinkedList区别

7. 冒泡时间复杂度

8. 说一说**[排序](https://www.nowcoder.com/jump/super-jump/word?word=排序)[算法](https://www.nowcoder.com/jump/super-jump/word?word=算法)**？选一种熟悉的说具体[算法](https://www.nowcoder.com/jump/super-jump/word?word=算法)？

   答：快排，堆排，归并。


# 其他

高级语言（C++，Java，Python）、框架（Connections框架，Spring框架）、软件工程、设计模式

数据库设计（MySQL，Redis，Mybatis，Hibernate）

中间件（RabbitMQ）

编译原理、机器语言

操作系统

计算机网络

计算机组成原理

脉冲电路与数字逻辑

大学物理、高等数学、线性代数、概率论

## 有什么想问的

有什么问的?(什么部门的, 主要业务)

1. 怎么管理项目成员
2. 当意见不一致时，如何沟通并说服开发成员，并举个例子
3. 怎么保证项目的进度
4. 技术选型，一个新技术和一个稳定的旧技术，你会怎么选择，选择的考虑有哪些
5. 说你印象最深的美团点评技术团队的三篇博客
6. 最近在学什么新技术
7. 你是怎么去接触一门新技术的
8. 会看哪些书
9. 怎么选择要看的书

你还有什么亮点吗——听到这个问题我就差不多意识到了这次面试凉了

问了问部门业务，框架（springcloud）等等。

看过哪些书？框架学习打算？

答：本以为要结束了就说了说不熟悉的SSM，没想到接着问了。

反问：问了问部门业务（做数据迁移），框架（springboot）等等。



部门内实习生会干些什么工作 

 有没有学习建议（自己总结吧，感觉你学习的深度还不错） 

 问面试结果（听提前批招聘群里的阿里招聘人员说可以直接问面试结果，然后面试官说还有再综合评估一下，晚点群里有人会通知你， 

 听其他人说面完就会直接告诉结果的，我感觉自己凉了，还是太菜了，而且还是二本学历，呜呜呜。



转正实习

[腾讯]()福利和工作环境是真的很不错，实习体验很好👍转正答辩是10分钟的PPT汇报+提问，主要就是说实习做了什么，收获了什么，以及对自己的规划之类的。答辩组一般5人，1（部门总监）+4（其他部门总监）。转正结果在9月初就出来了，基本组长都会提前通通气😸全程相对比较顺利。

阿里工作强度略大于[腾讯]()，不过阿里的平台基础设施和中间件感觉很不错，开发过程可专注项目搭建，开发流程清晰。阿里的业务属性要重一些，有好有坏吧，看个人选择啦。转正答辩全程1h左右，30分钟PPT汇报（小组业务+实习项目+中间件学习+感悟总结）30分钟问答，答辩组两P9（一个部门大老板，一个其他部门大老板）+hrg。相对来说阿里的答辩比较严格，前前后后准备了2周，部门模拟答辩都进行了好几次😵，不过期间收获还是很多滴，师兄们倾囊相助，超级nice。

信息真的很重要，可以添加一些秋招群大家一起共享信息，还有就是[牛客]()之类的信息平台、各司招聘微信公众号、学校的招聘公众号等等。就因为这些，字节秋招就没笔试，直接进面试👏 

选择很重要，但选择有时候选择是也盲目的，尤其在信息不对称的时候。差距不大的情况下还是想想自己的初衷和本心吧（不忘初心），永远相信自己选的就是最好的，是金子在哪里都可以发光！ 

心态也很重要，求职过程一定会遇到疲惫期，那就给自己一些放纵的时间，不要总是盯着[牛客]()[脉脉]()，负能量太多会很累的。





作者：HappY131c
链接：https://www.nowcoder.com/discuss/683433?type=post&order=recall&pos=&page=1&ncTraceId=&channel=-1&source_id=search_post_nctrack
来源：牛客网



1.自我介绍
2.八股文、基础（问的比较杂，但是很基础）
（1）java的特性（面向对象理解、三大特性）
（2）抽象类与接口、抽象类中可以有具体方法？
（3）为什么要有自动装箱、拆箱？为什么要有包装类？（我说是为了处理基本数据类型和引用数据类型，我知道是错的）
（4）基本数据类型有哪些，各占多大字节？（我惊了，问这个会不会太基础了点，一时懵逼）
（5）创建线程的方式（3种：Runnable、Thread、Callable）
（6）进程间通信的方式（4种：管道、消息队列、共享内存、套接字）
（7）java中死锁怎么产生的？
（8）jdk是1.8版本的，有什么新特性？（HashMap、ConcurrentHashMap从1.7~1.8）
（补充说labuda**什么，我没学过...）
（9）进程和线程
（10）Mysql索引（哈希、B+树：聚簇索引、非聚簇索引）
（11）Http协议、tcp协议（http通信过程、tcp的特点）
3.项目
（1）项目中遇到的问题、怎么解决的，通过什么方式？
（2）有没有遇到很难解决的问题和时候？
感觉更多的是从你的项目中了解到你个人的开发风格和性格等等，偏技术的比较少。
4.其他
（1）工作地有要求？（菜鸟不敢有，国内都可以，如果不是英语差，国外也行，不行，国外疫情太乱了）
（2）最近看神马书？（深入理解Java虚拟机、Redis深度历险、Mysql技术内幕...太多了记不起来，就说了三）
（3）有没有考研的想法？（没有没有，我觉得无论是考研还是工作其实我们都在一直往上走，加油就对了）
（4）个人规划？（孩子们，阿里的面试官粑粑建议我们要有个人规划哦！）
5.反问：您对我学习或者其他方面有什么建议吗？（感动！！贼有帮助！！！此生不愧面阿里）
总体觉得其实阿里面试感觉很轻快，虽然会给人一种很随便的感觉，但是真真切切的感觉到的是很轻松的感觉。
而且贼准时，说19:00真就19:00来电话。
都说一面简单基础，二面压力就上来了，我觉得我也得遭受这样的压力，毕竟我次次挂二面。

## 二面

8月10日 原本是视频面 后来因为特殊原因转成电话面
时长：30min
时间线拉的有点长
中间安排了一次笔试，隔了很久，然后才催了几次才安排了本次面试。
1.自我介绍
2.八股文、基础
java自动内存管理机制这块整个大概的都说了一下
3.实习项目
大概问了一下我的整个收获啊、经历、自己的一些感觉，自己的理论知识有什么帮助之类的。
4.个人经历
简历是旧的，问了我之前院会部长的荣誉和经历等。
5.如何看待八卦？
仅代表个人意见。
互联网的时代，会把一件事情的热度扩大到相对火热，但不太关心八卦的我，只想搞技术。

我觉得，阿里从某些方面上讲，还是会引发我们的一些技术和个人规划方向的思考吧。
真心建议简历不要造假，但凡卡住就很尴尬。

-- 世界都有黑白，哪管那么多。





自我介绍 

 你现在后端研发的主要技能是你自学的吗 

 synchronized方法的作用 

 synchronized和lock的区别（回答的不好） 

 countDownLatch和CyclicBarrier的介绍 

 ClassLoader双亲委派机制 

 为什么有了双亲委派这种机制？还要破坏这种机制，一般什么场景会那么做？（再熟悉一下） 

 ClassLoader里面loadclass()和findclass()区别（再熟悉一下） 

 java内存管理的垃圾回收器有哪些 

 GMS垃圾回收器的[算法]()介绍 

 spring的好处（总结一下） 

 spring的依赖注入 

 bean的生命周期 

 beanFactory和FactoryBean的区别 

 mysql分页查询的关键字 

 union all和union的区别 

 mysql的sql调优分几个步骤 

 Innodb插入和删除为什么比mysaim快 

 因为mysaim只支持表锁，innodb支持表锁和行锁 

 mysql主备同步 

 binlog的模式 

 一般来说binlog是逻辑日志，即记录的是sql语句。 

 binlog有三种模式一个是statement ，基于sql语句的日志 一个是row基于行的复制，不记录sql语句和上下文信息，只记录哪条数据被修改了 mixed两个都用，主要为statement，如果statement处理不了用row 

 消息队列作用 

 Kafka作为消息中间件具备**系统解耦**、冗余存储、**流量削峰**、缓冲、**异步通信**、扩展性、可恢复性等特点。 

 还学过其他消息队列吗？ 

 kafka顺序消息 

 kafka在发送一条消息的时候，可以指定 topic partition和key三个参数。partition和key是可选的。如果指定了partition，那就是所有消息都被发送到一个partition，就是有序的，或者你指定一个key，具有同一个key的消息会被发送到同一个partition，也是有序的。在消费端，kafka保证，1个partition只能被一个consumer消费。 

 [字节跳动]()实习的情况 

 ebay的[销售]()预测的方法项目 

 你在ebay的实习中一直在迭代这个[销售]()预测的方法吗 

 讲一下秒杀的设计 

 你这个项目是练手的还是给别人用的 

 最近在看哪些技术？平时会看哪些博客？ 

 之后想往哪个方向发展，未来1-3年的规划 

 论文接收了嘛？



作者：louis_code
链接：https://www.nowcoder.com/discuss/717557?type=post&order=recall&pos=&page=1&ncTraceId=&channel=-1&source_id=search_post_nctrack
来源：牛客网



\1. 自我介绍 

  问项目问了20分钟，后面就是一些常规问题 

1.  之前你现在考虑做研发，[算法]()你为什么不去搞了 
2.  java1.8跟7或者11有什么不一样的 
3.  用流式编程计算一个string的list里面有多少元素是以s结尾的 
4.  1.8里面默认的垃圾回收[算法]()是哪个 
5.  CMS和G1具体的区别 
6.  G1求解的目标函数的目标 
7.  G1的目标和CMS目标有什么区别 
8.  Concurrent HashMap的数据结构？底层是怎么实现的？ 
9.  Concurrent HashMap hashcode的原理（是不是数据结构内部实现的）和塞到[链表]()里面怎么做的 
10.  为什么hashmap里面用了[红黑树]()，[红黑树]()怎么保证并发 
11.  [redis]()部署方式有几种 
12.  讲一下主从、哨兵和集群的区别 
13.  [redis]()选主[算法]()是怎么做的 
14.  [redis]()怎么实现分布式锁 
15.  论文发在哪里 
16.  现在还在实习嘛？你现在还有其他的offer吗？为什么之前没有留下来？ 
17.  哪里人？多大了？ 
18.  阿里最近很火的问题？怎么看？ 
19.  其他offer的待遇大概是多少？ 
20.  本科和研究生成绩大概是多少？ 

 反问：认为基础知识怎么样？ 

   学习能力不错，建议多总结归纳，分布式实践比较少，建议多总结



作者：阿拉蕾与葫芦娃
链接：https://www.nowcoder.com/discuss/656345?type=post&order=recall&pos=&page=1&ncTraceId=&channel=-1&source_id=search_post_nctrack
来源：牛客网



你是做啥的，你未来做什么？不是[算法]()吧？ 

 你的项目用了SpringCloud,介绍一下怎么用的？Eeruka说一下怎么使用的，我用的[阿里巴巴]()的Nacos。说了Feign。一个服务器上线和下线怎么使用？ 

 说说MySQL的B+Tree索引。为啥用B+Tree？ 

 树高为啥是3？ 

 了解过MySQL的5.2以上版本的新特性吗？ 

 说说JVM 的内存模型？ 

 说说HashMap？HashMap怎么解决Hash冲突？ 

 HashMap怎么扩容的？什么时候扩容？ 

 三次握手和四次握手为什么四次和三次？ 

 说说死锁。 

 怎么预防死锁？ 

 说说你做的实验室项目的？挫折。 

 做道[算法题]()。两个有序数组和为一个有序数组。 

  一周内 HR会给你结果，什么时候来，现在已经有的实习生来了。



作者：stevess
链接：https://www.nowcoder.com/discuss/633796?type=post&order=recall&pos=&page=1&ncTraceId=&channel=-1&source_id=search_post_nctrack
来源：牛客网



上来先是自我介绍，然后没让我介绍项目，直接开问

 主要是围绕项目中的一些实现细节问了差不多20分钟

 项目外的问题：

1. netty高效在哪里 
2. 高可用的限流问题，给个场景，问如何解决（考察限流策略） 
3. 单线程[redis]()缓存高效的原因 
4. 讲下[redis]()线程模型底层实现细节 
5. 互斥锁和自旋锁 
6. 平时怎么学习java 
7. 在实验室里是什么角色，代码实现者还是设计者 
8. 你和别人的优势在哪里 

​      


##  二面（技术主管面1h20min）4.2 

 面完一面约的第二天晚上 但下午就打电话面试了

 还是没让介绍项目，直接开问

1. RPC和http的区别，为什么不用http实现远程调用 
2. http在哪层，应用层还有哪些协议 
3. [redis]()和mysql相比的优势 
4. 讲下数据库连接池 
5. [redis]()集群模型，如何传递消息，哨兵挂了如何处理 
6. [redis]()4.0建议几台机器做主从，从的数据是否一致    
7. netty的容错性 
8. 讲下Dubbo源码以及Dubbo调用失败的应对策略 
9. JUC包常用类 
10. 垃圾回收[算法]()在1.8，1.9的具体实现，默认哪些GC 
11. 详细讲下垃圾回收[算法]()，清除[算法]()的缺点 
12. 讲一下cms和G1 
13. JVM调优参数 
14. 发生内存溢出如何排查，什么原因 
15. 中间件了解哪些，zoo[keep]()er如何实现分布式锁 
16. Spring框架了解过没 
17. 对未来技术发展方向的规划 

##  三面（总监面30min）4.2 

  二面当天就约了晚上三面 

 上来先介绍了部分，然后让我简单做个自我介绍

1. 研究生做[算法]()为什么面开发 
2. 是不是保研，为什么跨考 
3. 操作系统的内存管理讲讲 
4. 讲下进程、线程、协程、纤程 
5. 场景题关于线程的通信的具体实现，口述 
6. 讲下CNN的整个实现过程，原理 
7. 讲下激活函数原理，用过哪些 
8. 池化层的作用，讲下感受野 
9. 听说过bert模型嘛，讲一下（NLP） 
10. 什么时候毕业，什么时候可以来实习 
11. 有什么想问的 

##  HR面（30min）4.6 

  节后第一天晚上9点过突击面试，正在健身房，赶紧找个角落接电话 

1. 是不是本硕连读 
2. 为什么选择考研 
3. 跨考原因 
4. 通过读研你学到了什么 
5. 最有成就感的事情 
6. 最让你有挫败感的事情 
7. 面试了几家拿了哪些offer 
8. 为什么选择[阿里巴巴]() 
9. 了解我们事业部嘛 
10. 说说自身优缺点 
11. 有什么想问的 

##  总结 

  整体的面试体验还是非常好的，听面试官说集团要求加快校招进度，所以面试流程很快 

 基本两天就面完三面，节后第一时间就面HR，面试官人都很好很和蔼，有很好的互动，

 在面试过程中你有不懂得问题，也会为你讲解，学到不少东西。

 目前已拿offer 





作者：G2的kkennys本人
链接：https://www.nowcoder.com/discuss/860668?type=all&order=recall&pos=&page=1&ncTraceId=&channel=-1&source_id=search_all_nctrack
来源：牛客网



1. **项目简单介绍一下**
   
2.  **Java
   ** jdk和jvm是什么？
    类的加载过程？
    常用的数据类型？
    装箱和拆箱？
    线程池优点？
    怎么创建线程池？ 
3.  **Redis
   ** 缓存穿透？怎么解决
    怎样降低布隆过滤器的hash冲突？
    缓存雪崩？怎么解决
    [redis]()数据结构都有什么？常用在哪举个例子？
    zset结构？
    [redis]()怎么实现分布式锁？（不了解） 
4.  **MySQL
   ** acid？
    隔离级别？
    怎么实现隔离性的？
    mvcc讲一下？
    怎么实现乐观锁和悲观锁？
   
5.  rpc了解吗？（不了解） 
6.  简单说一下单点登录？（不了解） 
7.  **计网
   ** http请求头有什么？
    cookies和sessions？ 
8.  **反问
   ** 在哪个方面需要提升自己？（数据库和java基础不错，一些简单的概念需要深入了解一下）
    贵组业务？（巴拉巴拉） 

 





作者：Steve_ZhuKW
链接：https://www.nowcoder.com/discuss/686564?type=all&order=recall&pos=&page=1&ncTraceId=&channel=-1&source_id=search_all_nctrack
来源：牛客网



\0. 介绍我研究生方向，选什么课？      

   ---->针对性，为以后当程序员做准备。课程：计算机基础四大课程， 分布式系统， 软件架构  

   \1. Java中hashmap底层实现原理？  

   ---->array + 拉[链表]()（长度大于8转[红黑树]()）  

   追问：如何put一个key-value呢？    

   --->位置上没别的key-value：直接放在array的那个位置上；有别的, 长度小于8: 插入到[链表]()； 长度大于8：插入进[红黑树]()。  

   \2. JVM了解吗？    

   --->  了解得不多，只知道这是java实现跨平台（跨操作系统）的原理。  

   \3. 数组和[链表]()有什么区别？    

   --->  数组有索引，[链表]()无索引；数组物理地址连续，[链表]()物理地址不一定连续；因为有索引，数组查询比[链表]()快；[链表]()插入删除节点比数组开销小；  

   \4. 说下MySQL索引？    

   --->  详细介绍聚簇，非聚簇；B+索引hash索引；主键，非主键；单值索引，联合索引；索引的适用场景和不适用场景。  

   \5. 四种隔离级别？  

   未提交读（Read Uncommited）：啥都不做  

   （一级封锁协议 ----> 解决丢失修改）  

   提交读（Read Commited）：二级封锁协议 ----> 解决脏读  

   可重复读（Repeatable Read）: 三级封锁协议 ----> 解决不可重复读  

   可串行化（Serializable）：两段锁协议强制事务串行执行 ----> 解决幻读问题  

   （其中提交读和可重复读也可以由MVCC实现）  

   \6. 五层网络协议？    

   ---->物理层，链路层，网络层，传输层， 应用层  

   \7. TCP包的结构（TCPs首部）？   

​    ---->源端口，目的端口，序号（保证有序，快重传），确认号，窗口（顺便讲了 发送窗口 = min（拥塞窗口，接收窗口）），校验和，（SYN, FIN）这些。  

   \8. 介绍一下TCP？    

   ---->可靠，有连接，不一定实时，三次握手，四次挥手，超时重传，快重传，以及与UDP的区别  

   \9. 了解设计模式吗？    

   ---->不了解但准备学  

   \10. 了解面向对象编程吗，了解定义属性五大原则吗？    

   --->  不了解  

   \11. 做过网络编程吗？    

   --->  不是这个方向  

   \12. 发过技术文章，或者开源项目贡献代码吗？    

   ---->技术文章github总结过代码场考题，开源项目没贡献过  

   \13. 学习方法？    

   ---->先保证知识广度，利用[google]()，github, stack overflow， 哪里不会学哪个，享受技术提升的过程。再保证基础的扎实程度，通过名校的公开课来系统学习计算机基础知识，让知识更加成体系。再往深度挖深，比如光学会某个[算法]()不够，要思考有哪些方向可以优化。  

   --------------根据我的意愿分到上海/杭州部门的面试了，业务是：淘系全球交易------------  

##      2021.3.23 二面（通过）   

   \0. 自我介绍  

   \1. 为什么选择上海，杭州base可以吗?  

   --->喜欢上海，杭州可以接受  

   \2. 愿意系统学习Java吗？  

   --->愿意  

   \3. 面试官详细地介绍了业务，并称我的一面答得挺好，不用问重复的问题了，直接约了leader面。  

​            2021.3.26 三面 大老板面 （通过）                     0. 自我介绍                        1. 研究生入学了没？                            --->  没                        2. 空档期一年学了哪些知识？怎么学的？                            --->  计算机基础四大课程，原本看视频，后面看书。                        3. 为何快毕业了才决定转码呢？                            --->  居家学习让我停下来思考我真正想要做什么                        4. 问个操作系统，信号量是干什么的？                          --->  进程间通信同步（位于共享内存和信号之后），线程间同步                        5. 信号量还有哪些其他应用场景？                          --->  不知道了，猜了一个系统性能监控                        6. 输入一个网址到返回界面的过程？                        发送http请求--->看本地缓存--->DNS解析出域名对应的IP地址--->TCP/IP五层协议--->可能会有代理（正向代理反向代理）--->TCP连接三次握手 / https认证，加密，解密                        --->找到端口号--->nignx定位到应用--->mvc框架下从views找到路由--->验证权限--->解析url参数--->看服务器中的缓存--->代码逻辑中获取数据并返回html模板                        --->服务端发送http响应--->浏览器渲染页面                        7. 这里面HTTP层做了什么？                          ---> 解析get和post请求, 比如代码里http库有些api可以解析get请求，取出传入的参数。(我忘记提HTTPS了)